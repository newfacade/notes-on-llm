{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2145c5-5eb1-4a90-8e4c-e0609d18b3ed",
   "metadata": {},
   "source": [
    "# HumanEval\n",
    "\n",
    "```{note}\n",
    "We evaluate functional correctness on a set of 164 `handwritten`\n",
    "programming problems, which we call the HumanEval{cite}`chen2021evaluatinglargelanguagemodels`\n",
    "dataset. Each problem includes a function signature,\n",
    "docstring, body, and several unit tests, with an average\n",
    "of 7.7 tests per problem.<br/>\n",
    "Programming tasks in the HumanEval dataset assess language\n",
    "comprehension, reasoning, algorithms, and simple\n",
    "mathematics.\n",
    "```\n",
    "\n",
    "```{figure} ../images/humaneval-3.png\n",
    "---\n",
    "height: 700px\n",
    "name: humaneval-3\n",
    "---\n",
    "```\n",
    "\n",
    "Three example problems from the HumanEval dataset, where the probabilities that a single sample from Codex-12B passes unit\n",
    "tests are 0.9, 0.17, and 0.005. The prompt provided to the model is shown with a white background, and a successful model-generated\n",
    "completion is shown in a yellow background. Though not a guarantee for problem novelty, all problems were hand-written and not\n",
    "programmatically copied from existing sources.\n",
    "\n",
    "## Functional Correctness\n",
    "\n",
    "We evaluate functional correctness using\n",
    "the pass@$k$ metric, where $k$ code samples are generated\n",
    "per problem, a problem is considered solved if any sample passes the unit tests, and the total fraction of problems\n",
    "solved is reported. However, computing pass@$k$ in this\n",
    "way can have high variance. Instead, to evaluate pass@$k$,\n",
    "we generate $n\\ge k$ samples per task (in this paper, we\n",
    "use $n = 200$ and $k\\le 100$), count the number of correct\n",
    "samples $c\\le n$ which pass unit tests, and calculate the\n",
    "unbiased estimator\n",
    "\n",
    "$$\n",
    "\\text{pass@}k := \\mathbb{E}\\left[1 - \\frac{\\binom{n-c}{k}}{\\binom{n}{k}}\\right]\n",
    "$$\n",
    "\n",
    "Calculating this estimator directly results in very large numbers\n",
    "and numerical instability. We include a\n",
    "numerically stable numpy implementation that simplifies\n",
    "the expression and evaluates the product term-by-term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff4b293-a461-4015-8128-a71bd97797bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pass_at_k(n, c, k):\n",
    "    \"\"\"\n",
    "    :param n: total number of samples\n",
    "    :param c: number of correct samples\n",
    "    :param k: k in pass@$k$\n",
    "    \"\"\"\n",
    "    if n - c < k: return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c37be-6e6a-42f7-8053-026451e19e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}