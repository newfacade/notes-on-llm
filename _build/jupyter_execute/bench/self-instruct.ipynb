{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf0a320-e1d6-416a-a4ec-9e0be38b8620",
   "metadata": {},
   "source": [
    "# SELF-INSTRUCT\n",
    "\n",
    "![](../images/self-instruct1.png)\n",
    "\n",
    "```{note}\n",
    "In this work, we introduce SELF-INSTRUCT, a\n",
    "semi-automated process for instruction-tuning a\n",
    "pretrained LM using **instructional signals from the\n",
    "model itself**. The overall process is an iterative bootstrapping\n",
    "algorithm, which starts off\n",
    "with a limited (e.g., 175 in our study) seed set of\n",
    "manually-written tasks that are used to guide the\n",
    "overall generation. \n",
    "\n",
    "* In the first phase, the model\n",
    "is prompted to generate instructions for new tasks.\n",
    "This step leverages the existing collection of instructions\n",
    "to create more broad-coverage instructions\n",
    "that define (often new) tasks.\n",
    "\n",
    "* Given the newlygenerated\n",
    "set of instructions, the framework also\n",
    "creates input-output instances for them, which can\n",
    "be later used for supervising the instruction tuning.\n",
    "\n",
    "* Finally, various heuristics are used to automatically\n",
    "filter low-quality or repeated instructions, before\n",
    "adding the remaining valid tasks to the task pool.\n",
    "\n",
    "This process can be repeated for many iterations\n",
    "until reaching a large number of tasks.\n",
    "```\n",
    "\n",
    "paper: https://arxiv.org/pdf/2212.10560"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e64bc5-7e1c-4bf3-a6e7-99499a5acf93",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "The instruction data we want to generate contains a\n",
    "set of instructions $\\{I_{t}\\}$, each of which defines a task $t$ in natural language. \n",
    "\n",
    "Task $t$ has $n_{t}\\ge 1$ input-output\n",
    "instances $\\{(X_{t,i}, Y_{t,i})\\}_{i=1}^{n_t}$. A model $M$ is expected\n",
    "to produce the output, given the task instruction\n",
    "and the corresponding input: $M(I_t, X_{t,i}) = Y_{t,i}$.\n",
    "\n",
    "```{tip}\n",
    "Instruction and\n",
    "instance input does not have a strict boundary in\n",
    "many cases.\n",
    "```\n",
    "\n",
    "### Instruction Generation\n",
    "\n",
    "At the first step, SELFINSTRUCT\n",
    "generates new instructions from a small\n",
    "set of seed human-written instructions in a bootstrapping\n",
    "fashion. We initiate the task pool with\n",
    "175 tasks (1 instruction and 1 instance for each\n",
    "task). For every step, we sample 8 task instructions\n",
    "from this pool as in-context examples. Of\n",
    "the 8 instructions, 6 are from the human-written tasks, and 2 are from the model-generated tasks in\n",
    "previous steps to promote diversity.\n",
    "\n",
    "![](../images/self-instruct2.png)\n",
    "\n",
    "### Classification Task Identification\n",
    "\n",
    "Because we\n",
    "need two different approaches for classification and\n",
    "non-classification tasks, we next identify whether\n",
    "the generated instruction represents a classification\n",
    "task or not in a few-shot way.\n",
    "\n",
    "### Instance Generation\n",
    "\n",
    "Given the instructions and\n",
    "their task type, we generate instances for each instruction\n",
    "independently.\n",
    "\n",
    "A natural way to do this is the **Input-first\n",
    "Approach**, where we can ask an LM to come\n",
    "up with the input fields first based on the instruction,\n",
    "and then produce the corresponding output.\n",
    "\n",
    "![](../images/self-instruct3.png)\n",
    "![](../images/self-instruct4.png)\n",
    "\n",
    "However, we found that this approach can generate\n",
    "inputs biased toward one label, especially for\n",
    "classification tasks (e.g., for grammar error detection,\n",
    "it usually generates grammatical input). Therefore,\n",
    "we additionally propose an **Output-first Approach**\n",
    "for classification tasks, where we first generate\n",
    "the possible class labels, and then condition the\n",
    "input generation on each class label.\n",
    "\n",
    "![](../images/self-instruct5.png)\n",
    "![](../images/self-instruct6.png)\n",
    "\n",
    "### Filtering and Postprocessing\n",
    "\n",
    "To encourage diversity,\n",
    "a new instruction is added to the task pool\n",
    "only when its ROUGE-L similarity with any existing instruction is less than 0.7, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7819a-da63-47e2-ae5a-c50abb30cb78",
   "metadata": {},
   "source": [
    "## Finetuning the LM to Follow Instructions\n",
    "\n",
    "After creating large-scale instruction data, we use it\n",
    "to finetune the original LM (i.e., SELF-INSTRUCT, total 52K instructions\n",
    "and 82K instances).\n",
    "\n",
    "```{tip}\n",
    "We concatenate the instruction and instance\n",
    "input as a prompt and train the model to\n",
    "generate the instance output in a standard supervised\n",
    "way. To make the model robust to different\n",
    "formats, we use multiple templates to encode the\n",
    "instruction and instance input together. For example,\n",
    "the instruction can be prefixed with “Task:” or\n",
    "not, the input can be prefixed with “Input:” or not,\n",
    "“Output:” can be appended at the end of the prompt\n",
    "or not, and different numbers of break lines can be\n",
    "put in the middle, etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41bc6e0-a422-46f5-93d6-d076b0771218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}