{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7458918c-def6-434d-9a2a-abb50723e8e2",
   "metadata": {},
   "source": [
    "# Weak to Strong Generalization\n",
    "\n",
    "```{note}\n",
    "Widely used alignment techniques, such as reinforcement learning from human\n",
    "feedback (RLHF), rely on the ability of humans to supervise model behavior. However, future superhuman models will behave in complex ways\n",
    "too difficult for humans to reliably evaluate; humans will only be able to weakly\n",
    "supervise superhuman models.<br>\n",
    "We study an analogy to this problem: can weak\n",
    "model supervision elicit the full capabilities of a much stronger model? We find that when\n",
    "we naively finetune strong pretrained models on labels generated by a weak model,\n",
    "they consistently perform better than their weak supervisors, a phenomenon we\n",
    "call weak-to-strong generalization.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e1286-e12f-4e00-b64e-3b3e0cb88453",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We mainly steer or align today’s models with reinforcement learning from human feedback (RLHF):\n",
    "we reinforce behaviors that human evaluators rate highly and penalize behaviors that evaluators rate\n",
    "poorly. This procedure is very effective when human evaluators can tell if model behavior is\n",
    "good or bad and is a core part of training modern language model assistants such as ChatGPT.\n",
    "\n",
    "However, superhuman models will be capable of complex and creative behaviors that humans cannot\n",
    "fully understand. For example, if a superhuman assistant model generates a million lines of extremely\n",
    "complicated code, humans will not be able to provide reliable supervision for key alignmentrelevant\n",
    "tasks. As a result, if we finetune a superhuman model with human supervision on a reward modeling\n",
    "(RM) or safety classification task, it is unclear how that model will generalize to complicated\n",
    "behaviors that humans could not reliably supervise themselves.\n",
    "\n",
    "This leads to a fundamental technical challenge of aligning superhuman models (superalignment):\n",
    "how can weak supervisors control models much smarter than them?\n",
    "\n",
    "![](../images/weak-to-strong1.png)\n",
    "\n",
    "We propose a simple setup for studying the problem of humans supervising superhuman models by\n",
    "considering an analogy: can we use weak models to supervise strong models? We can empirically\n",
    "test this by finetuning large (strong) pretrained models on labels generated by small (weak) models\n",
    "and observing how they generalize.\n",
    "\n",
    "Why should weak-to-strong learning be possible? On the one hand, the strong model could simply\n",
    "learn to imitate the weak supervisor, including its errors, since that is what we would naively train\n",
    "it to do. On the other hand, strong pretrained models should already have good representations of\n",
    "the alignment-relevant tasks we care about. For example, if a model can generate complicated code,\n",
    "then it should intuitively also know whether that code faithfully adheres to the user’s instructions.\n",
    "As a result, for the purposes of alignment we do not need the weak supervisor to teach the strong\n",
    "model new capabilities; instead, we simply need the weak supervisor to elicit what the strong model\n",
    "already knows.\n",
    "\n",
    "We study our weak-to-strong learning setup by finetuning base (i.e. pretrained-only)\n",
    "language models from the GPT-4 family, spanning 7 orders of magnitude of pretraining compute, across three settings: a large set of popular natural language processing\n",
    "(NLP) benchmarks, chess puzzles, and our internal ChatGPT reward modeling dataset.\n",
    "\n",
    "![](../images/weak-to-strong2.png)\n",
    "\n",
    "Our main findings include:\n",
    "\n",
    "1. **Strong pretrained models naturally generalize beyond their weak supervisors.** If we naively finetune strong models with labels generated by weak models, they consistently outperform their weak supervisors. For example, on NLP tasks, if we finetune\n",
    "GPT-4 with labels from a GPT-2-level model, we typically recover about half of the\n",
    "performance gap between the two models.\n",
    "\n",
    "2. **Naively finetuning on weak supervison is not enough.** Despite positive weak-to-strong\n",
    "generalization, there still remains a substantial gap between strong models finetuned with\n",
    "weak supervision and strong models finetuned with ground truth supervision. Our\n",
    "results provide empirical evidence that naive RLHF will likely scale poorly to superhuman\n",
    "models without additional work.\n",
    "\n",
    "3. **Improving weak-to-strong generalization is tractable.** We find that we can improve performance\n",
    "by encouraging strong models to have confident predictions with an auxiliary\n",
    "loss, bootstrapping supervision with intermediate models, and improving model representations\n",
    "with unsupervised finetuning. For example, when supervising GPT-4 with a GPT-2-\n",
    "level model on NLP tasks using the auxiliary confidence loss, we typically recover nearly\n",
    "80% of the performance gap between the weak and strong models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba005fc-fdd4-46a0-88c5-cb70efea74cf",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "For a given task of interest, consisting of a dataset and a performance metric, we:\n",
    "\n",
    "1. **Create the weak supervisor.**\n",
    "\n",
    "2. **Train a strong student model with weak supervision.**\n",
    "\n",
    "3. **Train a strong model with ground truth labels as a ceiling.**\n",
    "\n",
    "Typically, weak-to-strong performance will be between weak performance and strong ceiling performance.\n",
    "We define the performance gap recovered (PGR) as a function of the above three\n",
    "performances (weak, weak-to-strong, and strong ceiling) as shown in the illustration below.\n",
    "\n",
    "![](../images/weak-to-strong3.png)\n",
    "\n",
    "**Advantages.** Our setup has a number of advantages, including:\n",
    "\n",
    "1. It can be studied with any pair of weak and strong models, making it easy to study scaling\n",
    "laws and not requiring access to expensive state-of-the-art models.\n",
    "\n",
    "2. It can be studied for any task of interest, making it easy to empirically test across a wide\n",
    "range of settings.\n",
    "\n",
    "3. Success will be practically useful even before we develop superhuman models.\n",
    "\n",
    "**Limitations.** Our setup still has important disanalogies to the ultimate problem of aligning superhuman\n",
    "models:\n",
    "\n",
    "1. **Imitation saliency (模仿显著性).** Future superhuman models will likely have salient representations\n",
    "of human behaviors, but our strong models may not have learned features relevant for\n",
    "imitating weak model predictions; simply imitating the weak supervisor may thus be an\n",
    "easier failure mode to avoid in our setting than it will be in the future. More generally, the\n",
    "types of errors weak models make today may be different from the types of errors humans\n",
    "will make when attempting to supervise superhuman models.\n",
    "\n",
    "2. **Pretraining leakage.** Our pretraining data implicitly contains supervision from humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c4ca4-1a50-42a2-9b28-fef41d236f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}