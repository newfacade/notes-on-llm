{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0ba284-5fd5-4238-8b23-0efbb5949b23",
   "metadata": {},
   "source": [
    "# Qwen2.5-Coder\n",
    "\n",
    "```{note}\n",
    "Qwen2.5-Coder{cite}`hui2024qwen25codertechnicalreport` is built upon the Qwen2.5{cite}`qwen2025qwen25technicalreport` architecture and continues pretrained\n",
    "on a vast corpus of over 5.5 trillion tokens. Through meticulous\n",
    "data cleaning, scalable synthetic data generation, and balanced data mixing,\n",
    "Qwen2.5-Coder demonstrates impressive code generation capabilities\n",
    "while retaining general and math skills.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8684a99-5d5e-404f-81c8-c7ad948260cf",
   "metadata": {},
   "source": [
    "## Pre-training\n",
    "\n",
    "### Data Composition\n",
    "\n",
    "**Source Code** We collected public repositories from GitHub created before February 2024,\n",
    "spanning 92 programming languages.\n",
    "\n",
    "**Text-Code Grounding Data** We curated a large-scale and high-quality text-code mixed\n",
    "dataset from Common Crawl, which includes code-related documentation, tutorials, blogs,\n",
    "and more.\n",
    "\n",
    "**Synthetic Data** Synthetic data offers a promising way to address the anticipated scarcity\n",
    "of training data. We used CodeQwen1.5, the predecessor of Qwen2.5-Coder, to generate\n",
    "large-scale synthetic datasets. To mitigate the risk of hallucinations during this process, we\n",
    "introduced an executor for validation, ensuring that `only executable code was retained`.\n",
    "\n",
    "**Math Data** To enhance the mathematical capabilities of Qwen2.5-Coder, we integrated\n",
    "the pre-training corpus from Qwen2.5-Math{cite}`yang2024qwen25mathtechnicalreportmathematical` into the Qwen2.5-Coder dataset. Importantly,\n",
    "the inclusion of mathematical data did not negatively impact the model’s performance on\n",
    "code tasks.\n",
    "\n",
    "**Text Data** Similar to the Math Data, we included high-quality general natural language\n",
    "data from the pre-training corpus of the Qwen2.5 model to preserve Qwen2.5-Coder’s\n",
    "general capabilities.\n",
    "\n",
    "### Data Mixture\n",
    "\n",
    "Balancing Code, Math, and Text data is crucial for building a foundational model. Interestingly, we found that the 7:2:1 ratio outperformed the others, even surpassing the\n",
    "performance of groups with a higher proportion of code.\n",
    "\n",
    "```{figure} ../images/qwen25-coder-1.png\n",
    "```\n",
    "\n",
    "### Training Policy\n",
    "\n",
    "```{figure} ../images/qwen25-coder-2.png\n",
    "```\n",
    "\n",
    "We employed a three-stage training approach to train Qwen2.5-Coder,\n",
    "including file-level pretraining, repo-level pretraining, and instruction tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54dd791-961e-43b7-8d33-243e5ce8f349",
   "metadata": {},
   "source": [
    "## Post-training\n",
    "\n",
    "### A Recipe for Instruction Data\n",
    "\n",
    "**Multilingual Programming Code Identification** We fine-tune a CodeBERT to perform the language identification model to categorize documents into nearly 100\n",
    "programming languages. We keep the instruction data of the mainstream programming\n",
    "languages and randomly discard a portion of the instruction data of the long-tail languages.\n",
    "If a given sample contains very little code data or even no code snippets, the sample will\n",
    "possibly be classified into “No Programming Language” tag. Since too many instruction\n",
    "samples without code snippets hurt the model performance on code generation tasks, we remove most of the samples without code snippets to\n",
    "keep the code generation capability of our instruction model.\n",
    "\n",
    "**Instruction Synthesis from GitHub** For the unsupervised data (code snippets) massively\n",
    "existing in many websites (e.g. GitHub), we try to construct the supervised instruction\n",
    "dataset using LLM. Specifically, we use the LLM to generate the instruction from the code\n",
    "snippets within 1024 tokens and then we use the code LLM to generate the response (Magicoder{cite}`wei2024magicoderempoweringcodegeneration`, Unicoder{cite}`sun2024unicoderscalingcodelarge`, Wavecoder{cite}`yu2024wavecoderwidespreadversatileenhancement`). Finally, we use the LLM scorer to filter the\n",
    "low-quality ones to obtain the final pair. Given the code snippets of different programming\n",
    "languages, we construct an instruction dataset from the code snippets. To fully unleash the\n",
    "potential of our proposed method, we also include the open-source instruction dataset (e.g.\n",
    "McEval-Instruct{cite}`chai2024mcevalmassivelymultilingualcode` for massively multilingual code generation and debugging) in the seed\n",
    "instruction dataset. Finally, we combine the instruction data from the GitHub code snippet\n",
    "and open-source instructions for supervised fine-tuning.\n",
    "\n",
    "**Multilingual Code Instruction Data** To bridge the gap among different programming\n",
    "languages, we propose a multilingual multi-agent collaborative framework to synthesize\n",
    "the multilingual instruction corpora.\n",
    "\n",
    "**Checklist-based Scoring for Instruction Data** To completely evaluate the quality of the\n",
    "created instruction pair, we introduce several scoring points for each sample:\n",
    "\n",
    "1. Question&Answer Consistency: Whether Q&A are consistent and correct for fine-tuning.\n",
    "2. Question&Answer Relevance: Whether Q&A are related to the computer field.\n",
    "3. Question&Answer Difficulty: Whether Q&A are sufficiently challenging.\n",
    "4. Code Exist: Whether the code is provided in question or answer.\n",
    "5. Code Correctness: Evaluate whether the provided code is free from syntax errors and logical flaws.\n",
    "6. Consider factors like proper variable naming, code indentation, and adherence to best practices.\n",
    "7. Code Clarity: Assess how clear and understandable the code is.\n",
    "8. Code Comments: Evaluate the presence of comments and their usefulness in explaining the code’s functionality.\n",
    "9. Easy to Learn: determine its educational value for a student whose goal is to learn basic\n",
    "coding concepts.\n",
    "\n",
    "After gaining all scores $(s_1, \\dots, s_n)$, we can get the final score with\n",
    "$s = w_1 s_1 + \\dots + w_n s_n$, where $(w_1, \\dots ,w_n)$ are a series of pre-defined weights.\n",
    "\n",
    "**A multilingual sandbox for code verification** Only the self-contained (e.g. algorithm problems) code snippet will be fed into the multilingual sandbox. The multilingual verification sandbox is mainly comprised of five parts:\n",
    "\n",
    "1. **Language Support Module:**\n",
    "    * Implements support for multiple languages (e.g., Python, Java, C++, JavaScript)\n",
    "    * Maintains language-specific parsing and execution environments\n",
    "    * Handles syntax and semantic analysis for each supported language\n",
    "2. **Sample Code Repository:**\n",
    "    * Stores a diverse collection of code samples for each supported language\n",
    "    * Organizes samples by language, difficulty level, and programming concepts\n",
    "    * Regularly updated and curated by language experts\n",
    "3. **Unit Test Generator:**\n",
    "    * Analyzes sample code to identify key functionalities and edge cases\n",
    "    * Automatically generates unit tests based on the expected behavior\n",
    "    * Produces test cases covering various input scenarios and expected outputs\n",
    "4. **Code Execution Engine:**\n",
    "    * Provides isolated environments for executing code snippets securely\n",
    "    * Supports parallel execution of multiple test cases\n",
    "    * Handles resource allocation and timeout mechanisms\n",
    "5. **Result Analyzer:**\n",
    "    * Compares the output of code snippets against expected results from unit tests\n",
    "    * Generates detailed reports on test case successes and failures\n",
    "    * Provides suggestions for improvements based on failed test cases\n",
    "\n",
    "### Training Policy\n",
    "\n",
    "**Coarse-to-fine Fine-tuning** We first synthesized tens of millions of low-quality but diverse\n",
    "instruction samples to fine-tune the base model. In the second stage, we adopt millions\n",
    "of high-quality instruction samples to improve the performance of the instruction model\n",
    "with rejection sampling and supervised fine-tuning. For the same query, we use the LLM\n",
    "to generate multiple candidates and then use the `LLM` to score the best one for supervised\n",
    "fine-tuning.\n",
    "\n",
    "**Mixed Tuning** We\n",
    "optimize the instruction model with a majority of standard SFT data and a small part of\n",
    "FIM instruction samples.\n",
    "\n",
    "**Direct Preference Optimization for Code** After obtaining the SFT model, we further align\n",
    "the Qwen2.5-Coder with the help of offline direct preference optimization (DPO). Given that human feedback is highly labor-intensive, we use a multilingual\n",
    "code sandbox to provide code execution feedback, while an LLM is utilized for human\n",
    "judgment feedback. For the `algorithm-like and self-contained code snippets`, we generate\n",
    "the test cases to check the correctness of the code as the code execution feedback, including\n",
    "Python, Java, and other languages. For other complex code snippets, we use `LLM-as-ajudge` to decide which code snippet is better. Further, we combine the\n",
    "code DPO data and common data for offline DPO training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4bdb9f-eca1-41a8-bfd8-84053b4f2775",
   "metadata": {},
   "source": [
    "## Decontamination\n",
    "\n",
    "To ensure that Qwen2.5-Coder does not produce inflated results due to test set leakage,\n",
    "we performed decontamination on all data, including both pre-training and post-training\n",
    "datasets. We removed key datasets such as HumanEval, MBPP, GSM8K, and MATH. The\n",
    "filtering was done using a 10-gram overlap method, where any training data with a 10-gram\n",
    "word-level overlap with the test data was removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422ed1c-041d-445f-9218-42fdd8ad6a02",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Base Models\n",
    "\n",
    "```{figure} ../images/qwen25-coder-3.png\n",
    "```\n",
    "\n",
    "### Instruct Models\n",
    "\n",
    "```{figure} ../images/qwen25-coder-4.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd640532-9b3a-4c95-b250-9e2a494dcd75",
   "metadata": {},
   "source": [
    "## Takeaway\n",
    "\n",
    "```{note}\n",
    "Recipe:\n",
    "* Keep the instruction data of the mainstream programming languages and randomly discard a portion of the instruction data of the long-tail languages. Remove most of the samples without code snippets\n",
    "* Instruction Synthesis using Magicoder, Unicoder and Wavecoder. GitHub code snippet and open-source instructions as the seed.\n",
    "* Multilingual Code Instruction Data to bridge the gap among different programming languages.\n",
    "* Checklist-based Scoring for Instruction Data, $s = w_1s_1 + \\dots + w_ns_n$\n",
    "* A multilingual sandbox for code verification (organizes samples by language, difficulty level, and programming concepts)\n",
    "* For the algorithm-like and self-contained code snippets, we generate the test cases to check the correctness of the code as the code execution feedback. For other complex code snippets, we use LLM-as-ajudge to decide which code snippet is better.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8953414-4bfb-4de1-b832-8896e04280a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}