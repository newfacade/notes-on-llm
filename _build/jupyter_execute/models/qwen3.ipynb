{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa156376-36e5-4b35-a259-2d93808f1792",
   "metadata": {},
   "source": [
    "# Qwen3\n",
    "\n",
    "```{note}\n",
    "The Qwen3 series includes models of both dense\n",
    "and Mixture-of-Expert (MoE) architectures, with parameter scales ranging from 0.6 to\n",
    "235 billion. A key innovation in Qwen3 is the integration of thinking mode (for complex,\n",
    "multi-step reasoning) and non-thinking mode (for rapid, context-driven responses) into a\n",
    "unified framework.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b84d1-d27d-4a6b-a243-a254c0071656",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "The architecture of the Qwen3 dense models is similar to Qwen2.5, including using\n",
    "Grouped Query Attention, SwiGLU, Rotary Positional\n",
    "Embeddings and RMSNorm with pre-normalization. Besides, we remove QKV-bias used in Qwen2 and introduce `QK-Norm` to the attention mechanism to ensure stable training for Qwen3.\n",
    "\n",
    "The Qwen3 MoE models share the same fundamental architecture as the Qwen3 dense models. We follow Qwen2.5-MoE and implement fine-grained expert segmentatio. Unlike Qwen2.5-MoE, the Qwen3-MoE design excludes shared\n",
    "experts. Furthermore, we adopt the `global-batch load balancing loss` to encourage expert\n",
    "specialization.\n",
    "\n",
    "Qwen3 models utilize Qwen’s tokenizer which implements byte-level byte-pair encoding with a vocabulary size of 151,669."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4913fe0-e53f-4668-b9da-a80effda558a",
   "metadata": {},
   "source": [
    "## Pre-training\n",
    "\n",
    "\n",
    "**Pre-training Data.** Compared with Qwen2.5, we have significantly expanded the scale and diversity of\n",
    "our training data.\n",
    "\n",
    "**Pre-training Stage.**\n",
    "\n",
    "1. General Stage\n",
    "2. Reasoning Stage\n",
    "3. Long Context Stage\n",
    "\n",
    "Similar to Qwen2.5, we develop scaling laws for optimal hyper-parameters (e.g.,\n",
    "learning rate scheduler, and batch size) predictions based on three pre-training stages mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba4630-aceb-4550-be80-a4422dc92bc0",
   "metadata": {},
   "source": [
    "## Post-training\n",
    "\n",
    "```{figure} ../images/qwen3-1.png\n",
    "```\n",
    "\n",
    "As illustrated in Figure 1, the flagship models in the Qwen3 series follow a sophisticated four-stage\n",
    "training process. The first two stages focus on developing the models’ “thinking” abilities. The next two\n",
    "stages aim to integrate strong “non-thinking” functionalities into the models.\n",
    "\n",
    "### Long-CoT Cold Start\n",
    "\n",
    "We begin by curating a comprehensive dataset that spans a wide range of categories, including math,\n",
    "code, logical reasoning, and general STEM problems. Each problem in the dataset is paired with verified\n",
    "reference answers or code-based test cases.\n",
    "\n",
    "The dataset construction involves a rigorous two-phase filtering process: query filtering and response\n",
    "filtering.\n",
    "\n",
    "1. We use Qwen2.5-72B-Instruct to identify and remove queries that\n",
    "are not easily verifiable. Furthermore, we exclude queries that Qwen2.5-72B-Instruct can answer correctly\n",
    "without using CoT reasoning. Additionally, we annotate\n",
    "each query’s domain using Qwen2.5-72B-Instruct to maintain balanced domain representation across the\n",
    "dataset.\n",
    "\n",
    "2. After reserving a validation query set, we generate $N$ candidate responses for each remaining query\n",
    "using QwQ-32B. For queries with positive $Pass@N$,\n",
    "further stringent filtering criteria are applied.\n",
    "\n",
    "The objective at this stage is to instill `foundational reasoning patterns` in the model without\n",
    "overly emphasizing immediate reasoning performance.\n",
    "\n",
    "### Reasoning RL\n",
    "\n",
    "The query-verifier pairs used in the Reasoning RL stage must satisfy the following four criteria:\n",
    "\n",
    "1. They\n",
    "were not used during the cold-start phase.\n",
    "2. They are learnable for the cold-start model.\n",
    "3. They are\n",
    "as challenging as possible.\n",
    "4. They cover a broad range of sub-domains.\n",
    "\n",
    "We ultimately collect a total\n",
    "of `3,995` query-verifier pairs, and employed GRPO to update the model parameters. We observe that using a large batch size and a high number of rollouts per query, along with off-policy\n",
    "training to improve sample efficiency, is beneficial to the training process. We have also addressed how\n",
    "to balance exploration and exploitation by controlling the model’s entropy to increase steadily or remain stable, which is crucial for maintaining stable training.\n",
    "\n",
    "```{caution}\n",
    "off-policy? How to balance exploration and exploitation by controlling the model’s entropy?\n",
    "```\n",
    "\n",
    "### Thinking Mode Fusion\n",
    "\n",
    "**Construction of SFT data.** The SFT dataset combines both the “thinking” and “non-thinking” data. The\n",
    "“thinking” data is generated via rejection sampling on Stage 1 queries using the Stage 2 model itself. The\n",
    "“non-thinking” data, on the other hand, is carefully curated to cover a diverse range of tasks, we employ automatically generated checklists for assessing the response\n",
    "quality of “non-thinking” data.\n",
    "\n",
    "**Chat Template Design.** By default, the model operates in thinking mode; therefore, we add\n",
    "some thinking mode training samples where the user queries do not include /think flags. For more\n",
    "complex multi-turn dialogs, we randomly insert multiple /think and /no_think flags into users’ queries,\n",
    "with the model response adhering to the last flag encountered.\n",
    "\n",
    "```{figure} ../images/qwen3-2.png\n",
    "```\n",
    "\n",
    "**Thinking Budget.** An additional advantage of Thinking Mode Fusion is that, once the model learns to\n",
    "respond in both non-thinking and thinking modes, it naturally develops the ability to handle intermediate\n",
    "cases—generating responses based on incomplete thinking. Specifically, when the length of the\n",
    "model’s thinking reaches a user-defined threshold, we manually halt the thinking process and insert\n",
    "the stop-thinking instruction: *“Considering the limited time by the user, I have to give the\n",
    "solution based on the thinking directly now.\\n</think>.\\n\\n”*.\n",
    "\n",
    "### General RL\n",
    "\n",
    "The General RL stage aims to broadly enhance the models’ capabilities and stability across diverse\n",
    "scenarios. To facilitate this, we have established a sophisticated reward system covering over 20 distinct\n",
    "tasks, each with customized scoring criteria. We utilized three distinct types of rewards:\n",
    "\n",
    "* Rule-based Reward\n",
    "* Model-based Reward with Reference Answer\n",
    "* Model-based Reward without Reference Answer\n",
    "\n",
    "### Strong-to-Weak Distillation\n",
    "\n",
    "The Strong-to-Weak Distillation pipeline is specifically designed to optimize lightweight models, the distillation process is divided into two primary phases:\n",
    "\n",
    "1. **Off-policy Distillation:** At this initial phase, we combine the outputs of teacher models generated\n",
    "with both /think and /no_think modes for response distillation.\n",
    "\n",
    "2. **On-policy Distillation:** In this phase, the student model generates on-policy sequences for\n",
    "fine-tuning. Specifically, prompts are sampled, and the student model produces responses in\n",
    "either /think or /no_think mode. The student model is then fine-tuned by aligning its logits\n",
    "with those of a teacher model (Qwen3-32B or Qwen3-235B-A22B) to minimize the KL divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed6b8d-f755-48e9-9cfd-24126894fc93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}