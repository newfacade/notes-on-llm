{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38523242-8e72-4b0b-b593-b8b1db8964fe",
   "metadata": {},
   "source": [
    "# s1: Simple test-time scaling\n",
    "\n",
    "```{note}\n",
    "Test-time scaling is a promising new approach to\n",
    "language modeling that uses extra test-time compute\n",
    "to improve performance. We seek the simplest approach to\n",
    "achieve test-time scaling and strong reasoning performance.\n",
    "\n",
    "1. We curate a small dataset s1K\n",
    "of 1,000 questions paired with reasoning traces\n",
    "relying on three criteria we validate through ablations:\n",
    "`difficulty`, `diversity`, and `quality`.\n",
    "\n",
    "2. We develop budget forcing to control test-time compute\n",
    "by forcefully terminating the model’s thinking\n",
    "process or lengthening it by appending “Wait”\n",
    "multiple times to the model’s generation when it\n",
    "tries to end.\n",
    "\n",
    "After supervised finetuning the Qwen2.5-\n",
    "32B-Instruct language model on s1K and equipping\n",
    "it with budget forcing, our model [s1-32B](https://github.com/simplescaling/s1) exceeds\n",
    "o1-preview on competition math questions\n",
    "by up to 27% (MATH and AIME24).\n",
    "```\n",
    "\n",
    "```{figure} ../images/s1-1.png\n",
    "---\n",
    "height: 400px\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135d1b0-1ee9-4571-ad8f-2c603cb23fc1",
   "metadata": {},
   "source": [
    "## Reasoning data curation to create s1K\n",
    "\n",
    "We could directly train on our pool of 59K questions, however,\n",
    "our goal is to find the *simplest* approach with minimal\n",
    "resources.\n",
    "\n",
    "**Quality** E.g. filter out low-quality examples by checking if they contain non-existent image references.\n",
    "\n",
    "**Difficulty** For difficulty, we use two indicators: model performance\n",
    "and reasoning trace length. We evaluate two models\n",
    "on each question: Qwen2.5-7B-Instruct and Qwen2.5-\n",
    "32B-Instruct, `with correctness assessed\n",
    "by Claude 3.5 Sonnet comparing each attempt against the\n",
    "reference solution`.\n",
    "\n",
    "```{figure} ../images/s1-0.png\n",
    "```\n",
    "\n",
    "**Diversity** To quantify diversity, we classify questions into\n",
    "domains using Claude 3.5 Sonnet based on the Mathematics\n",
    "Subject Classification (MSC) system. We first choose one domain uniformly at random.\n",
    "Then, we sample one problem from this domain according\n",
    "to a distribution that favors longer reasoning traces as motivated in Difficulty. We repeat this process we have 1,000 total samples spanning 50 domains.\n",
    "\n",
    "```{figure} ../images/s1-2.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bb934-819d-4b80-a384-d18f93028144",
   "metadata": {},
   "source": [
    "## Test-time scaling\n",
    "\n",
    "We classify test-time scaling methods into:\n",
    "\n",
    "1. Sequential,\n",
    "where later computations depend on earlier ones (e.g., a long\n",
    "reasoning trace)\n",
    "2. Parallel, where computations run independently\n",
    "(e.g., majority voting)\n",
    "\n",
    "**Budget forcing** We propose a simple decoding-time intervention\n",
    "by forcing a maximum and/or minimum number\n",
    "of thinking tokens. Specifically, we enforce a maximum\n",
    "token count by simply appending the end-of-thinking token\n",
    "delimiter and optionally “Final Answer:” to early exit the thinking stage and make the model provide its current\n",
    "best answer. To enforce a minimum, we suppress the generation\n",
    "of the end-of-thinking token delimiter and optionally\n",
    "append the string “Wait” to the model’s current reasoning\n",
    "trace to encourage the model to reflect on its current generation.\n",
    "\n",
    "```{figure} ../images/s1-3.png\n",
    "---\n",
    "height: 500px\n",
    "---\n",
    "```\n",
    "\n",
    "**Metrics** We establish a set of evaluation metrics to\n",
    "measure test-time scaling across methods. Importantly, we\n",
    "do not only care about the accuracy a method can achieve\n",
    "but also its controllability and test-time scaling slope. We measure three metrics:\n",
    "\n",
    "$$\n",
    "\\text{Control} = \\frac{1}{|\\mathcal{A}|}\\sum_{a\\in\\mathcal{A}}\\mathbb{1}(a_{\\text{min}}\\le a\\le a_{\\text{max}})\n",
    "$$\n",
    "\n",
    "where $a_{\\text{min}}$, $a_{\\text{max}}$ refer to a pre-specified minimum and maximum\n",
    "amount of test-time compute; in our case thinking\n",
    "tokens. We usually only constrain $a_{\\text{max}}$.\n",
    "\n",
    "$$\n",
    "\\text{Scailing} = \\frac{1}{\\binom{|A|}{2}}\\sum_{a,b\\in\\mathcal{A}, b>a}\\frac{f(b)-f(a)}{b-a}\n",
    "$$\n",
    "\n",
    "Scaling is the average slope of the piece-wise linear function.\n",
    "It must be positive for useful methods and larger is better.\n",
    "\n",
    "$$\n",
    "\\text{Performance} = \\max_{a\\in\\mathcal{A}}f(a)\n",
    "$$\n",
    "\n",
    "Performance is simply the maximum performance the\n",
    "method achieves on the benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2662e35a-f456-45d1-a25b-88ca64bb422d",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Training** We perform supervised finetuning on Qwen2.5-\n",
    "32B-Instruct using s1K to obtain our model s1-32B. Finetuning took 26\n",
    "minutes on 16 NVIDIA H100 GPUs with PyTorch FSDP.\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "```{figure} ../images/s1-4.png\n",
    "---\n",
    "height: 600px\n",
    "---\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab0b54-bf84-4dd2-a57f-c0785b87cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}