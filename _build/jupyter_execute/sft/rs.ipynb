{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593a8c0c-f65d-45ad-97dd-179351ecde6c",
   "metadata": {},
   "source": [
    "# Scaling Relationship on Learning Mathematical Reasoning with Large Language Models\n",
    "\n",
    "```{note}\n",
    "In this paper{cite}`yuan2023scalingrelationshiplearningmathematical`, we investigate how the pre-training loss, supervised data amount,\n",
    "and augmented data amount influence the reasoning performances of a supervised\n",
    "LLM. We find that:\n",
    "1. Pre-training loss is a better indicator of the model’s performance\n",
    "than the model’s parameter count.\n",
    "2. We apply supervised fine-tuning (SFT)\n",
    "with different amounts of supervised data and empirically find a log-linear relation\n",
    "between data amount and model performance.\n",
    "3. We propose to apply\n",
    "Rejection sampling Fine-Tuning (RFT). RFT uses supervised models to generate\n",
    "and collect correct reasoning paths as augmented fine-tuning datasets. We\n",
    "find with augmented samples containing more distinct reasoning paths, RFT improves\n",
    "mathematical reasoning performance more for LLMs.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114c592-9d19-4ec0-a857-0627e6364d29",
   "metadata": {},
   "source": [
    "## The Factors of Math Reasoning Ability in Supervised LLM\n",
    "\n",
    "The target of this paper is to try to understand the performances of supervised LLMs in math reasoning.\n",
    "We expect a pre-trained LLM $\\rho$ to learn reasoning ability from a supervised reasoning dataset\n",
    "$\\mathcal{D}$. The dataset is defined by $\\mathcal{D} = \\{q_i, r_i, a_i\\}_i$, where $q$ is a question, $r$ is a chain-of-thought reasoning\n",
    "path, and $a$ is a numerical answer. We perform supervised fine-tuning on dataset $\\mathcal{D}$ to obtain an\n",
    "SFT model $\\pi$. We use $\\pi$ to generate reasoning paths and answers in the test set by greedy decoding\n",
    "and report the accuracy as our metric here.\n",
    "\n",
    "### Model Accuracy VS. Pre-training Loss\n",
    "\n",
    "We analyze the SFT and ICL (8-shot) performance of GPT-3, LLaMA, LLaMA2, and GPT-4. The pre-training losses of these models are observed in their paper. We use the results of GPT-3 fine-tuning from{cite}`cobbe2021trainingverifierssolvemath` and\n",
    "we fine-tune LLaMA and LLaMA2 on the GSM8K training set.\n",
    "\n",
    "```{figure} ../images/rs-1.png\n",
    "```\n",
    "\n",
    "We can find that:\n",
    "\n",
    "* The pre-training losses are approximately negatively linear correlated to the SFT and ICL\n",
    "accuracy during the given pre-training loss interval.\n",
    "\n",
    "* SFT outperforms ICL consistently, while the improvements diminish when the pre-training\n",
    "loss is lower.\n",
    "\n",
    "From the observations,\n",
    "one effective way to improve reasoning ability is to train a better base model with lower pre-training\n",
    "loss (Pre-training is all you need!).\n",
    "\n",
    "### Model Accuracy VS. Supervised Data Count\n",
    "\n",
    "Supervised fine-tuning does improve LLMs’ reasoning ability, we want to know how the supervised\n",
    "data amount influences the model’s improvement. We fine-tune LLaMA and LLaMA2 with\n",
    "{1, 1/2, 1/4, 1/8, 1/16, 1/32} amount of the training set from GSM8K.\n",
    "\n",
    "```{figure} ../images/rs-2.png\n",
    "```\n",
    "\n",
    "From the figure, we can observe that:\n",
    "\n",
    "* The model performance has a log-linear relation versus data amount.\n",
    "\n",
    "* Better model needs more amount of data to outperform its ICL performance.\n",
    "\n",
    "* Better model benefits less when supervised data amount doubles.\n",
    "\n",
    "From the observation,\n",
    "it is straightforward to enlarge the training dataset to improve the performance, especially\n",
    "for worse models. For better models, it benefits less which echoes that better models have learned\n",
    "more reasoning ability during pre-training.\n",
    "\n",
    "### Model Accuracy VS. Augmented Data Count\n",
    "\n",
    "Increasing the amount of math reasoning labeled data is difficult, especially proposing a new question. We find a simplified version of rejection sampling is a naive and effective way to augment new reasoning paths and can improve the model\n",
    "performance. And we find the key factor influences fine-tuning on rejection sampling (RFT) augmented\n",
    "data is `distinct reasoning path amount`.\n",
    "\n",
    "**Rejection Sampling Fine-tuning** The SFT model $\\pi$ obtains the ability to perform zero-shot chainof-\n",
    "thought reasoning, and we use $\\pi$ to generate more correct reasoning paths $r_{ij}$ to supply the\n",
    "training dataset. For each $q_i$, we generate $k$ candidate reasoning paths and answers $r$, $a$ with a\n",
    "temperature of 0.7. We first filter out reasoning paths with wrong\n",
    "answers $a\\ne a_i$ or wrong calculations based on Python evaluation. Each reasoning path contains\n",
    "a list of equations $e_j$ , and we select one reasoning path $r_{ij}$ for each distinct equation list as the\n",
    "augmented data and remove other reasoning paths with the same list of equations to deduplicate\n",
    "similar reasoning paths. We define $\\mathcal{D}_{\\pi}' = \\mathcal{D}_{\\pi}\\cup\\{q_i,r_{ij},a_i\\}_{ij}$ as the augmented\n",
    "dataset. We fine-tune $\\mathcal{D}'$ on pre-trained LLM $\\rho$ to $\\pi_{\\text{RFT}}$ as RFT.\n",
    "\n",
    "```{figure} ../images/rs-3.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6eeb4-63ff-4fda-b26c-d0f74029a870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}