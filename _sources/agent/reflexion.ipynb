{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f21365e-478a-4004-93f8-99aa3af07025",
   "metadata": {},
   "source": [
    "# Reflexion\n",
    "\n",
    "```{note}\n",
    "Recent works such as ReAct have demonstrated the feasibility of autonomous decision-making\n",
    "agents that are built on top of a large language model (LLM) core. Such approaches have been\n",
    "so far limited to using in-context examples as a way of teaching the agents. In this paper, we propose an alternative approach called Reflexion that uses `verbal` reinforcement\n",
    "to help agents learn from prior failings.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2367a-c8c0-4bdd-b99d-8c1d0be9df1e",
   "metadata": {},
   "source": [
    "## Reflexion: reinforcement via verbal reflection\n",
    "\n",
    "```{figure} ../images/reflexion1.png\n",
    "```\n",
    "\n",
    "Reflexion utilizing three distinct models: an Actor, an Evaluator and a Self-Reflection models.\n",
    "\n",
    "**Actor** The Actor is built upon a large language model (LLM) that is specifically prompted to\n",
    "generate the necessary text and actions conditioned on the state observations. We explore various Actor models, including Chain of\n",
    "Thought and ReAct.\n",
    "\n",
    "**Evaluator** The Evaluator component of the Reflexion framework plays a crucial role in assessing\n",
    "the quality of the generated outputs produced by the Actor. For reasoning tasks, we explore reward functions based\n",
    "on exact match (EM) grading, ensuring that the generated output aligns closely with the expected\n",
    "solution.\n",
    "\n",
    "**Self-reflection** Given a sparse reward signal, such as a binary success status (success/fail), the current trajectory,\n",
    "and its persistent memory *mem*, the self-reflection model generates nuanced and specific feedback.\n",
    "\n",
    "**Memory** In the RL setup, the trajectory history serves as the short-term\n",
    "memory while outputs from the Self-Reflection model are stored in long-term memory.\n",
    "\n",
    "**The Reflexion process**\n",
    "\n",
    "```{figure} ../images/reflexion2.png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9114cd9-1e4f-4e3b-aa0a-4f0582641a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
