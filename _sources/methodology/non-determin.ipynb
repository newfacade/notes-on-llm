{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a0b5d2-7958-4b8d-9b83-c8ca46e666c0",
   "metadata": {},
   "source": [
    "# Evaluation of LLMs Should Not Ignore Non-Determinism\n",
    "\n",
    "```{note}\n",
    "We aim to compare the performance of\n",
    "LLMs under different decoding configurations. We\n",
    "select greedy decoding and sampling generation\n",
    "for the main comparison. For sampling, we set the\n",
    "temperature to 1.0 and top-p to 1.0.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c779d-16d4-4127-9ecd-fa9f6df42ef0",
   "metadata": {},
   "source": [
    "## Experimental Results\n",
    "\n",
    "![](../images/non-determin1.png)\n",
    "\n",
    "* For most evaluated tasks and models, greedy decoding\n",
    "outperforms sampling. However, AlpacaEval\n",
    "serves as a notable exception, where sampling\n",
    "demonstrates superior performance.\n",
    "\n",
    "* GSM8K and HumanEval are relatively\n",
    "less stable with respect to non-deterministic\n",
    "generations. The performance gap between the best\n",
    "and worst samplings can exceed 10.0 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51d718-42b6-4f0a-85ee-69ea23a61ad3",
   "metadata": {},
   "source": [
    "## How Various Factors Influence Non-Determinism?\n",
    "\n",
    "### Scaling Effect on Non-Determinism\n",
    "\n",
    "No pattern related to the number of model parameters could be identified.\n",
    "\n",
    "### Alignment Effect on Non-Determinism\n",
    "\n",
    "Alignment methods, such as DPO, enhance LLMs\n",
    "by learning from preference data. We evaluate\n",
    "the effects of alignment methods such as DPO, KTO, using Llama-3-8B-Instruct as\n",
    "the training starting point.\n",
    "\n",
    "![](../images/non-determin2.png)\n",
    "\n",
    "After applying these methods,\n",
    "both greedy decoding and sampling performances\n",
    "are affected. In several tasks, including\n",
    "AlpacaEval, MMLU, GSM8K, and HumanEval, a\n",
    "decrease in standard deviation is observed, suggesting\n",
    "that alignment may reduce the diversity of sampling\n",
    "outputs.\n",
    "\n",
    "### Temperature Effect on Non-Determinism\n",
    "\n",
    "![](../images/non-determin3.png)\n",
    "\n",
    "A high temperature\n",
    "significantly impacts the reasoning and code generation\n",
    "capabilities of LLMs and the model struggles\n",
    "to solve questions in GSM8K and HumanEval.\n",
    "\n",
    "### Surface Patterns in Non-Determinism Generation?\n",
    "\n",
    "![](../images/non-determin4.png)\n",
    "\n",
    "We observe that the completions\n",
    "generated by greedy decoding are typically\n",
    "marginally shorter than those produced via sampling generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b4f5d-063c-4a60-b95b-235d6c803b51",
   "metadata": {},
   "source": [
    "## What is the Full Potential of Non-Determinism?\n",
    "\n",
    "![](../images/non-determin5.png)\n",
    "\n",
    "We adopt a Best-of-N setting, selecting the best answer\n",
    "from N sampled responses. To accomplish this,\n",
    "we employ off-the-shelf reward models, such as\n",
    "ArmoRM and FsfairX, to rank the responses of Llama-3-8BInstruct,\n",
    "selecting the one with the highest reward.\n",
    "We also include an “oracle” baseline which directly\n",
    "picks the best response as the upper bound of bestof-\n",
    "N strategy.\n",
    "\n",
    "Building upon these promising findings, there\n",
    "are two ways to further enhance the performance\n",
    "of smaller LLMs.\n",
    "\n",
    "1. Probability calibration\n",
    "techniques can guide LLMs towards generating\n",
    "superior answers with higher likelihoods. Alignment\n",
    "methods, specifically preference optimization play a pivotal role\n",
    "in this process.\n",
    "\n",
    "2. Strategies for ensemble\n",
    "learning or selecting the best answer from\n",
    "multiple completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c1c9c9-800f-45d4-b504-81663a244cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
