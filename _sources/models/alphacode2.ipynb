{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32351490-19bf-4153-b25a-04a30e039967",
   "metadata": {},
   "source": [
    "# AlphaCode 2\n",
    "\n",
    "```{note}\n",
    "This paper introduces AlphaCode 2, powered by Gemini. When evaluated on the\n",
    "same platform as the original AlphaCode, we found that AlphaCode 2 solved 1.7× more problems, and\n",
    "performed better than 85% of competition participants.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321bd30-9c25-4054-8f36-c73039b27314",
   "metadata": {},
   "source": [
    "## Overall System\n",
    "\n",
    "AlphaCode 2 relies on powerful Large Language Models, combined with an advanced search and\n",
    "reranking mechanism tailored for competitive programming. Its main\n",
    "components include:\n",
    "\n",
    "* A family of policy models which generate code samples for each problem;\n",
    "* A sampling mechanism that encourages generating a wide diversity of code samples to search over the space of possible programs;\n",
    "* A filtering mechanism to remove code samples that do not comply with the problem description;\n",
    "* A clustering algorithm that groups semantically similar code samples, allowing us to avoid redundancies;\n",
    "* A scoring model which we use to surface the best candidate out of each of the 10 biggest code samples clusters.\n",
    "\n",
    "![](../images/alphacode2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4b070-db87-4069-b171-5de81dbe13fb",
   "metadata": {},
   "source": [
    "### Policy and Fine-Tuning\n",
    "\n",
    "Our starting point is the Gemini Pro model, on which we apply two\n",
    "consecutive rounds of fine-tuning using GOLD as the training objective.\n",
    "\n",
    "First, we fine-tune on an updated version of the CodeContests dataset. We generate several\n",
    "fine-tuned models by varying hyperparameters, and end up with a family of fine-tuned models.\n",
    "Second, we conduct a few additional steps of fine-tuning on a different, higher-quality dataset.\n",
    "\n",
    "Relying on a family of policies instead of a single one allows us to maximize diversity, which\n",
    "remains key to tackling hard problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56b057-89e6-4b21-8ab2-75fa635a6dd5",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Our sampling approach is close to that of AlphaCode. We generate up to a million code samples per\n",
    "problem, using a randomized temperature parameter for each sample to encourage diversity. We also\n",
    "randomize targeted metadata included in the prompt, such as the problem difficulty rating and its\n",
    "categorical tags.\n",
    "\n",
    "We split our sampling budget evenly across our family of fine-tuned models. While we sampled in\n",
    "Python and C++ for AlphaCode, we only used C++ samples for AlphaCode 2 as we found them to be\n",
    "higher quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318975a-be65-42c2-a042-5e49a891a3a8",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Each competitive programming problem contains at least one public input/output test indicating how\n",
    "code samples should behave. We execute each code sample on the corresponding test input, and filter\n",
    "out all which do not produce the expected output and therefore could not have been correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bde1aa-2ace-4fb9-bd94-19cadcc01e15",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "After filtering, we are left with an average of 50 thousand candidates per problem, but we limit\n",
    "ourselves to 10 submissions. To further trim down candidates, we aggregate samples based on their\n",
    "runtime behavior: as in AlphaCode, we train a separate model to generate new test inputs for each\n",
    "problem, then execute the remaining samples on these new inputs. The produced outputs form a\n",
    "signature that we use to group similar code samples together into clusters. We then order the clusters\n",
    "according to their cardinality, and only keep the 10 largest.\n",
    "\n",
    "The point of clustering is to avoid redundancies: since code samples in the same cluster behave\n",
    "similarly, we can submit a single one per cluster to the online judge to obtain the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c826ef4-f111-4c8c-8338-2bcb8442a510",
   "metadata": {},
   "source": [
    "### Scoring Model\n",
    "\n",
    "We fine-tune a second Gemini Pro model to attribute an estimated correctness score between 0 and 1\n",
    "to code samples. Using this scoring model, we compute a score for each code sample in our remaining\n",
    "clusters; we then select the best candidate sample out of each cluster based on this predicted score to\n",
    "form our final list of 10 submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fdcdd-306a-46da-b37f-7be265028bc2",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We evaluated AlphaCode 2 on Codeforces. We selected\n",
    "12 recent contests with more than 8000 participants, either from division 2 or the harder division\n",
    "“1+2”. This makes for a total of 77 problems. For each problem, we sampled one million candidates\n",
    "and submitted up to 10 solutions selected and ordered according to the procedure detailed above,\n",
    "until either one correct solution was found, or we ran out of candidates.\n",
    "\n",
    "![](../images/alphacode2-2.png)\n",
    "\n",
    "We evaluated the impact of increasing the amount of samples per problem. As was the case for\n",
    "AlphaCode, we find that performance increases roughly log-linearly with more samples. AlphaCode 2\n",
    "requires about 100 samples to reach the level of performance of AlphaCode with a million samples,\n",
    "making it over 10000× more sample efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f98a6-dda0-43e1-a338-fba2a762989b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
