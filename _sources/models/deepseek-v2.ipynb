{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246a91c0-b261-4430-89e1-0043a953254f",
   "metadata": {},
   "source": [
    "# DeepSeek-V2\n",
    "\n",
    "```{note}\n",
    "DeepSeek-V2{cite}`deepseekai2024deepseekv2strongeconomicalefficient` is a strong Mixture-of-Experts (MoE) language model characterized by\n",
    "economical training and efficient inference.<br>\n",
    "It comprises 236B total parameters, of which 21B\n",
    "are activated for each token, and supports a context length of 128K tokens. DeepSeek-V2 adopts\n",
    "innovative architectures including Multi-head Latent Attention (MLA) and DeepSeekMoE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e7c53-54d1-4720-95ab-9c2339c903e6",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "[](mla)\n",
    "\n",
    "[](deepseekmoe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead0711-972c-42bc-9950-969ce8b6dad5",
   "metadata": {},
   "source": [
    "## Pre-Training\n",
    "\n",
    "### Data Construction\n",
    "\n",
    "While maintaining the same data processing stages as for DeepSeek 67B{cite}`deepseekai2024deepseekllmscalingopensource`, we extend the amount of data and elevate the data quality.\n",
    "\n",
    "We adopt the same tokenizer as used in DeepSeek 67B, which is built based on the Byte-level\n",
    "Byte-Pair Encoding (BBPE) algorithm and has a vocabulary size of 100K. Our tokenized pretraining\n",
    "corpus contains 8.1T tokens, where Chinese tokens are approximately 12% more than\n",
    "English ones.\n",
    "\n",
    "### Hyper-Parameters\n",
    "\n",
    "We set the number of Transformer layers to 60 and the hidden\n",
    "dimension to 5120. In MLA, we set the number of attention heads $n_h$ to 128 and the per-head dimension $d_h$\n",
    "to 128. The KV compression dimension $d_c$ is set to 512, and the query compression dimension\n",
    "$d_{c}'$ is set to 1536. For the decoupled queries and key, we set the per-head dimension $d_{h}^{R}$ to 64. We substitute all FFNs except for the first layer with MoE layers.\n",
    "Each MoE layer consists of 2 shared experts and 160 routed experts, where the intermediate\n",
    "hidden dimension of each expert is 1536. Among the routed experts, 6 experts will be activated\n",
    "for each token. Under this configuration, DeepSeek-V2 comprises 236B total\n",
    "parameters, of which 21B are activated for each token.\n",
    "\n",
    "```json\n",
    "# DeepSeek-V2/config.json\n",
    "{\n",
    "    \"vocab_size\": 102400,\n",
    "    \"hidden_size\": 5120,\n",
    "    \n",
    "    \"num_attention_heads\": 128,\n",
    "    \"qk_nope_head_dim\": 128,\n",
    "    \"v_head_dim\": 128,\n",
    "    \"kv_lora_rank\": 512,\n",
    "    \"q_lora_rank\": 1536,\n",
    "    \"qk_rope_head_dim\": 64,\n",
    "\n",
    "    \"first_k_dense_replace\": 1,\n",
    "    \"intermediate_size\": 12288,\n",
    "    \"n_shared_experts\": 2,\n",
    "    \"n_routed_experts\": 160,\n",
    "    \"moe_intermediate_size\": 1536,\n",
    "    \"num_experts_per_tok\": 6,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Now Let's calculate the number of parameters of DeepSeek-V2 step by step:\n",
    "\n",
    "1. Embedding and UnEmbedding: 1048576000\n",
    "\n",
    "```python\n",
    "class DeepseekV2Model(DeepseekV2PreTrainedModel):\n",
    "    def __init__(self, config: DeepseekV2Config):\n",
    "        super().__init__(config)\n",
    "        # 102400 * 5120\n",
    "        self.embed_tokens = nn.Embedding(\n",
    "            config.vocab_size, config.hidden_size, self.padding_idx\n",
    "        )\n",
    "        \n",
    "class DeepseekV2ForCausalLM(DeepseekV2PreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # 5120 * 102400\n",
    "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "```\n",
    "\n",
    "2. MLA: 149225472 per layer (omit RMSNorm weight etc.)\n",
    "\n",
    "```{figure} ../images/mla-3x.svg\n",
    "---\n",
    "height: 600px\n",
    "name: mla-3\n",
    "---\n",
    "Multi-head Latent Attention.\n",
    "```\n",
    "\n",
    "```python\n",
    "class DeepseekV2Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, config: DeepseekV2Config, layer_idx: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        \n",
    "        self.q_lora_rank = config.q_lora_rank\n",
    "        self.qk_rope_head_dim = config.qk_rope_head_dim\n",
    "        self.kv_lora_rank = config.kv_lora_rank\n",
    "        self.v_head_dim = config.v_head_dim\n",
    "        self.qk_nope_head_dim = config.qk_nope_head_dim\n",
    "        self.q_head_dim = config.qk_nope_head_dim + config.qk_rope_head_dim\n",
    "\n",
    "        # 5120 * 1536\n",
    "        self.q_a_proj = nn.Linear(\n",
    "            self.hidden_size, config.q_lora_rank, bias=config.attention_bias\n",
    "        )\n",
    "        self.q_a_layernorm = DeepseekV2RMSNorm(config.q_lora_rank)\n",
    "        # 1536 * 128 * (128 + 64)\n",
    "        self.q_b_proj = nn.Linear(\n",
    "            config.q_lora_rank, self.num_heads * self.q_head_dim, bias=False\n",
    "        )\n",
    "\n",
    "        # 5120 * (512 + 64)\n",
    "        self.kv_a_proj_with_mqa = nn.Linear(\n",
    "            self.hidden_size,\n",
    "            config.kv_lora_rank + config.qk_rope_head_dim,\n",
    "            bias=config.attention_bias,\n",
    "        )\n",
    "        self.kv_a_layernorm = DeepseekV2RMSNorm(config.kv_lora_rank)\n",
    "        # 512 * 128 * (128 + 128)\n",
    "        self.kv_b_proj = nn.Linear(\n",
    "            config.kv_lora_rank,\n",
    "            self.num_heads\n",
    "            * (self.q_head_dim - self.qk_rope_head_dim + self.v_head_dim),\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # 128 * 128 * 5120\n",
    "        self.o_proj = nn.Linear(\n",
    "            self.num_heads * self.v_head_dim,\n",
    "            self.hidden_size,\n",
    "            bias=config.attention_bias,\n",
    "        )\n",
    "```\n",
    "\n",
    "3. MOE:\n",
    "    * first layer: 188743680\n",
    "    * other layer total parameters: 3822059520\n",
    "    * other layer activated parameters: 188743680\n",
    "```python\n",
    "class DeepseekV2MLP(nn.Module):\n",
    "    def __init__(self, config, hidden_size=None, intermediate_size=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hidden_size = config.hidden_size if hidden_size is None else hidden_size\n",
    "        self.intermediate_size = (\n",
    "            config.intermediate_size if intermediate_size is None else intermediate_size\n",
    "        )\n",
    "\n",
    "        # 5120 * intermediate_size * 3\n",
    "        # intermediate_size = 12288 if layer_idx=0 else 1536\n",
    "        self.gate_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)\n",
    "        self.up_proj = nn.Linear(self.hidden_size, self.intermediate_size, bias=False)\n",
    "        self.down_proj = nn.Linear(self.intermediate_size, self.hidden_size, bias=False)\n",
    "```\n",
    "\n",
    "Conclude our calculation:\n",
    "* total parameters: 235692359680\n",
    "* activated parameters: 21326725120\n",
    "\n",
    "### Evaluation Results\n",
    "\n",
    "```{figure} ../images/deepseek-v2-bench1.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc7115-7da5-493e-850c-b7e47a8bbbc8",
   "metadata": {},
   "source": [
    "## Alignment\n",
    "\n",
    "### Supervised Fine-Tuning\n",
    "\n",
    "We curate our instruction tuning datasets\n",
    "to include 1.5M instances, comprising 1.2M instances for helpfulness and 0.3M instances for\n",
    "safety. In comparison to the initial version, we improve the data quality to mitigate hallucinatory\n",
    "responses and enhance writing proficiency. \n",
    "\n",
    "We fine-tune DeepSeek-V2 with 2 epochs, and\n",
    "the learning rate is set to 5 × 10−6.\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "In order to further unlock the potential of DeepSeek-V2 and align it with human preference, we\n",
    "conduct Reinforcement Learning (RL) to adjust its preference.\n",
    "\n",
    "**Reinforcement Learning Algorithm.** [](grpo)\n",
    "\n",
    "**Training Strategy.** In our preliminary experiments, we find that the RL training on reasoning\n",
    "data, such as code and math prompts, exhibits unique characteristics that are distinct from the\n",
    "training on general data. For example, `the mathematical and coding abilities of our model can\n",
    "keep improving over a longer period of training steps`. Therefore, we employ a two-stage RL\n",
    "training strategy, which first performs reasoning alignment, and then performs human preference\n",
    "alignment. In the first reasoning alignment stage, we train a reward model $RM_{reasoning}$ for\n",
    "code and math reasoning tasks, and optimize the policy model with the feedback of $RM_{reasoning}$:\n",
    "\n",
    "$$r_{i} = RM_{reasoning}(o_{i}).$$\n",
    "\n",
    "In the second human preference alignment stage, we adopt a multi-reward framework, which\n",
    "acquires rewards from a helpful reward model $RM_{helpful}$ , a safety reward model $RM_{safety}$, and a\n",
    "rule-based reward model $RM_{rule}$. The final reward of a response $o_{i}$ is\n",
    "\n",
    "$$r_{i} = c_{1}\\cdot RM_{helpful}(o_{i}) + c_{2}\\cdot RM_{safety}(o_{i}) + c_{3}\\cdot RM_{rule}(o_{i}).$$\n",
    "\n",
    "```{tip}\n",
    "In order to obtain reliable reward models that play crucial roles in the RL training, we\n",
    "carefully collect preference data, and meticulously conduct `quality filtering` and `proportion\n",
    "adjustments`. We obtain code preference data based on `compiler-feedback`, and mathematical\n",
    "preference data based on the ground-truth labels. For reward model training, we initialize\n",
    "the reward models with DeepSeek-V2 Chat (SFT) and train them with either a point-wise or\n",
    "a pair-wise loss.\n",
    "```\n",
    "\n",
    "### Evaluation Results\n",
    "\n",
    "```{figure} ../images/deepseek-v2-bench2.png\n",
    "```\n",
    "\n",
    "### Discussion\n",
    "\n",
    "**Amount of SFT Data.** The discussion surrounding the necessity of a large SFT corpus has been\n",
    "a topic of intense debate. Previous works argue that fewer\n",
    "than 10K instances of SFT data are enough to produce satisfactory results. However, in our\n",
    "experiments, we observe a significant performance decline on the IFEval benchmark if we use\n",
    "fewer than 10K instances. Moreover, the quality\n",
    "of SFT data is also crucial.\n",
    "\n",
    "**Online Reinforcement Learning.** In our preference alignment experiments, we find that the\n",
    "online approach significantly outperforms the offline approach. Therefore, we invest tremendous\n",
    "efforts in implementing an online RL framework for aligning DeepSeek-V2. The conclusion\n",
    "about online or offline preference alignment can vary in different contexts, and we reserve a\n",
    "more thorough comparison and analysis between them for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3347660-a1a4-4ffb-b6e5-d6ebe3da84b1",
   "metadata": {},
   "source": [
    "## Takeaway\n",
    "\n",
    "```{note}\n",
    "SFT:\n",
    "* enough data needed\n",
    "\n",
    "RM:\n",
    "* first performs reasoning alignment\n",
    "* then performs human preference alignment\n",
    "* obtain code preference data based on compiler-feedback, and mathematical preference data based on the ground-truth labels\n",
    "\n",
    "RL:\n",
    "* online > offline\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f3cf8-806d-4766-addf-97003f49b013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
