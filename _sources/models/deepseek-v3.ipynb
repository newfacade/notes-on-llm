{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db5f7b8-f507-4e21-a41d-5c3112a977cd",
   "metadata": {},
   "source": [
    "# DeepSeek V3\n",
    "\n",
    "```{note}\n",
    "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total\n",
    "parameters with 37B activated for each token. To achieve efficient inference and cost-effective\n",
    "training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures,\n",
    "which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers\n",
    "an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training\n",
    "objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and\n",
    "high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to\n",
    "fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms\n",
    "other open-source models and achieves performance comparable to leading closed-source\n",
    "models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours\n",
    "for its full training.\n",
    "```\n",
    "\n",
    "![](../images/deepseek-v3-0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375825d6-3a0d-4d23-8cbc-093937ab141f",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "### Basic Architecture\n",
    "\n",
    "The basic architecture of DeepSeek-V3 is still within the Transformer framework. For efficient inference and economical training, DeepSeek-V3 also adopts [](mla)\n",
    "and [](deepseekmoe), which have been thoroughly validated by DeepSeek-V2{cite}`deepseekai2024deepseekv2strongeconomicalefficient`. Compared with\n",
    "DeepSeek-V2, an exception is that we additionally introduce an auxiliary-loss-free load balancing strategy for DeepSeekMoE to mitigate the performance degradation induced\n",
    "by the effort to ensure load balance.\n",
    "\n",
    "![](../images/deepseek-v3-1.png)\n",
    "\n",
    "**Auxiliary-Loss-Free Load Balancing.** We introduce a bias term $b_i$ for each expert and\n",
    "add it to the corresponding affinity scores $s_{i,t}$ to determine the top-K routing:\n",
    "\n",
    "$$\n",
    "g_{i,t}' = \\begin{cases}\n",
    "s_{i,t},\\quad&s_{i,t}+b_i\\in\\text{Topk}(\\{s_{j,t}+b_j|1\\le j\\le N\\}, K_{r}), \\\\\n",
    "0&\\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Note that the bias term is only used for routing. The gating value, which will be multiplied with\n",
    "the FFN output, is still derived from the original affinity score $s_{i,t}$. At the end of each step,\n",
    "we will decrease the bias term by $\\gamma$ if its corresponding expert is overloaded, and increase it by\n",
    "$\\gamma$ if its corresponding expert is underloaded, where $\\gamma$ is a hyper-parameter called bias update\n",
    "speed.\n",
    "\n",
    "**Complementary Sequence-Wise Auxiliary Loss.** Although DeepSeek-V3 mainly relies on the\n",
    "auxiliary-loss-free strategy for load balance, to prevent extreme imbalance within any single\n",
    "sequence, we also employ a complementary sequence-wise balance loss.\n",
    "\n",
    "```{tip}\n",
    "Complementary Sequence-Wise Auxiliary Loss $\\approx$ Expert-Level Balance Loss in [](deepseekmoe)\n",
    "```\n",
    "\n",
    "**Node-Limited Routing.** Like the device-limited routing used by DeepSeek-V2, DeepSeek-V3\n",
    "also uses a restricted routing mechanism to limit communication costs during training. In short,\n",
    "we ensure that each token will be sent to at most $M$ nodes, which are selected according to\n",
    "the sum of the highest $K_r/M$ affinity scores of the experts distributed on each node.\n",
    "\n",
    "**No Token-Dropping.** Due to the effective load balancing strategy, DeepSeek-V3 keeps a good\n",
    "load balance during its full training. Therefore, DeepSeek-V3 does not drop any tokens during\n",
    "training and inference.\n",
    "\n",
    "### Multi-Token Prediction\n",
    "\n",
    "We investigate and set a Multi-Token Prediction (MTP)\n",
    "objective for DeepSeek-V3, which extends the prediction scope to multiple future tokens at each\n",
    "position. On the one hand, an MTP objective densifies the training signals and may improve\n",
    "data efficiency. On the other hand, MTP may enable the model to pre-plan its representations\n",
    "for better prediction of future tokens. Figure 3 illustrates our implementation of MTP.\n",
    "\n",
    "![](../images/deepseek-v3-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558e88d-1711-4690-ad64-4ce8c83f72df",
   "metadata": {},
   "source": [
    "## Pre-Training\n",
    "\n",
    "### Data Construction\n",
    "\n",
    "Compared with DeepSeek-V2, we optimize the pre-training corpus by enhancing the ratio\n",
    "of mathematical and programming samples. Also, our data processing pipeline is refined to minimize redundancy\n",
    "while maintaining corpus diversity.\n",
    "\n",
    "In alignment with\n",
    "DeepSeekCoder-V2{cite}`deepseekai2024deepseekcoderv2breakingbarrierclosedsource`, we also incorporate the Fill-in-Middle (FIM) strategy in the pre-training of DeepSeek-V3.\n",
    "\n",
    "### Long Context Extension\n",
    "\n",
    "After the pre-training stage, we apply [](yarn) for context extension and perform two additional training phases, each comprising 1000 steps,\n",
    "to progressively expand the context window from 4K to 32K and then to 128K. YaRN was specifically applied to the decoupled\n",
    "shared key $\\mathbf{k}_{t}^{R}$ as it is responsible for carrying RoPE{cite}`su2023roformerenhancedtransformerrotary`.\n",
    "\n",
    "### Evaluation Results\n",
    "\n",
    "```{figure} ../images/deepseek-v3-bench1.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7426df-3387-499f-a648-9754b1fb5c9f",
   "metadata": {},
   "source": [
    "## Post-Training\n",
    "\n",
    "### Supervised Fine-Tuning\n",
    "\n",
    "**Reasoning Data.** For reasoning-related datasets, including those focused on mathematics,\n",
    "code competition problems, and logic puzzles, we generate the data by leveraging an internal\n",
    "DeepSeek-R1 model. Specifically, while the R1-generated data demonstrates strong accuracy, it\n",
    "suffers from issues such as overthinking, poor formatting, and excessive length. Our objective is\n",
    "to balance the high accuracy of R1-generated reasoning data and the clarity and conciseness of\n",
    "regularly formatted reasoning data.\n",
    "\n",
    "To establish our methodology, we begin by developing an expert model tailored to a specific\n",
    "domain, such as code, mathematics, or general reasoning, using a combined Supervised Fine-\n",
    "Tuning (SFT) and Reinforcement Learning (RL) training pipeline. This expert model serves as a\n",
    "data generator for the final model. The training process involves generating `two distinct types\n",
    "of SFT samples` for each instance: the first couples the problem with its original response in\n",
    "the format of <problem, original response>, while the second incorporates a system prompt\n",
    "alongside the problem and the R1 response in the format of <system prompt, problem, R1\n",
    "response>.\n",
    "\n",
    "During\n",
    "the RL phase, the model leverages high-temperature sampling to generate responses that\n",
    "integrate patterns from both the R1-generated and original data, even in the absence of explicit\n",
    "system prompts. After hundreds of RL steps, the intermediate RL model learns to incorporate\n",
    "R1 patterns, thereby enhancing overall performance strategically.\n",
    "\n",
    "Upon completing the RL training phase, we implement rejection sampling to curate highquality\n",
    "SFT data for the final model, where the expert models are used as data generation\n",
    "sources. This method ensures that the final training data retains the strengths of DeepSeek-R1\n",
    "while producing responses that are concise and effective.\n",
    "\n",
    "**Non-Reasoning Data.** For non-reasoning data, such as creative writing, role-play, and simple\n",
    "question answering, we utilize DeepSeek-V2.5 to generate responses and enlist human\n",
    "annotators to verify the accuracy and correctness of the data.\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "We employ a rule-based Reward Model (RM) and a model-based RM in our RL process.\n",
    "\n",
    "**Rule-Based RM.** For questions that can be validated using specific rules, we adopt a rulebased\n",
    "reward system to determine the feedback. For instance, certain math problems have\n",
    "deterministic results, and we require the model to provide the final answer within a designated\n",
    "format (e.g., in a box), allowing us to apply rules to verify the correctness. Similarly, `for LeetCode\n",
    "problems, we can utilize a compiler to generate feedback based on test cases`. By leveraging\n",
    "rule-based validation wherever possible, we ensure a higher level of reliability.\n",
    "\n",
    "**Model-Based RM.** For questions with free-form ground-truth answers, we rely on the reward\n",
    "model to determine whether the response matches the expected ground-truth. The reward model is trained from the DeepSeek-V3 SFT checkpoints. To enhance its\n",
    "reliability, we construct preference data that not only provides the final reward but also includes\n",
    "the chain-of-thought leading to the reward. This approach helps mitigate the risk of reward\n",
    "hacking in specific tasks (LLM as judge?).\n",
    "\n",
    "[](grpo)\n",
    "\n",
    "```{caution}\n",
    "* DeepSeek-Coder-V2 code RM: train a reward model.\n",
    "* DeepSeek-V3 code RM: rule-based RM.\n",
    "```\n",
    "\n",
    "### Evaluation Results\n",
    "\n",
    "```{figure} ../images/deepseek-v3-bench2.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835fbfe-c106-46e3-a820-d12f13a11488",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
