{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22c96a7-05ed-4fdc-a152-1b170ef24cef",
   "metadata": {},
   "source": [
    "# Aligning Language Models with Judgments\n",
    "\n",
    "```{note}\n",
    "In contrast to previous\n",
    "research that aligns LLMs with scalar rewards,\n",
    "we present the first systematic exploration of\n",
    "alignment through language feedback.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758da6e-a8cb-4297-9cee-065eebff3185",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Figure 1 shows three typical paradigms to\n",
    "achieve alignment.\n",
    "\n",
    "* The most straightforward one is\n",
    "learning from demonstrations, wherein demonstrations\n",
    "of desired responses to a set of instructions\n",
    "are collected to fine-tune LLMs. However, the performance\n",
    "gains diminish rapidly when scaling up the data\n",
    "size.\n",
    "\n",
    "* Learning\n",
    "from feedback offers a more scalable approach. One key\n",
    "advantage of feedback over demonstrations is that\n",
    "feedback can convey both positive and negative aspects.\n",
    "\n",
    "    * Prior research on learning from feedback primarily focuses on value feedback.\n",
    "\n",
    "    * Language feedback (i.e., judgment) is another kind of feedback.\n",
    "\n",
    "![](../images/judge1.png)\n",
    "\n",
    "In this study, we present an extensive investigation\n",
    "of potential methods that can be adapted\n",
    "for aligning LLMs with judgments. To facilitate\n",
    "a comprehensive aligning process, we propose a\n",
    "novel framework, Contrastive Unlikelihood Training\n",
    "(CUT), that enables fine-grained inappropriate\n",
    "content detection and correction based on judgments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168cd0a-45cc-4c3f-849c-da5ec919742e",
   "metadata": {},
   "source": [
    "## Problem Setting\n",
    "\n",
    "Suppose that there is a set of instruction-response-judgment\n",
    "triplets $(\\mathbf{x}, \\mathbf{y}, \\mathbf{j})$ where where the instruction $\\mathbf{x}=[x_1,\\dots,x_M]$, the response $\\mathbf{y}=[y_1,\\dots,y_N]$, and the judgement $\\mathbf{j}=[j_1,\\dots,j_Q]$ are token sequences\n",
    "of length $M$, $N$, and $Q$, respectively. The judgment provides an analysis\n",
    "of the strengths and weaknesses of the response.\n",
    "\n",
    "Depending on whether the responses $\\mathbf{y}$ are from\n",
    "the LLM to be aligned, the learning process can\n",
    "be classified into two distinct types: offline alignment\n",
    "and online alignment. In offline alignment,\n",
    "the target LLM learns from an off-the-shelf, model-agnostic\n",
    "dataset. In online alignment,\n",
    "the target LLM reflects on its own outputs through\n",
    "direct interactions with a judge. This online alignment\n",
    "process can be conducted iteratively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b0826-ac0e-4269-ad1a-36b39ef1cb3f",
   "metadata": {},
   "source": [
    "## Incorporating Judgments for Alignment\n",
    "\n",
    "We call an instruction-response pair “aligned\" if the\n",
    "response follows the instruction faithfully and satisfies\n",
    "human expectations $\\mathbf{x}\\to\\mathbf{y}$. Assuming the task is to generate\n",
    "a response that intentionally fulfills the judgment,\n",
    "it can be inferred that the response always aligns\n",
    "with the combined input of instruction and judgment\n",
    "$[\\mathbf{x}, \\mathbf{j}] \\to \\mathbf{y}$. Based on the idea, we construct\n",
    "three types of alignment data.\n",
    "\n",
    "![](../images/judge2.png)\n",
    "\n",
    "**Align-P:** The LLM produces a satisfactory response\n",
    "$\\mathbf{y}$ to the instruction $\\mathbf{x}$. Therefore, a positive\n",
    "judgment $\\mathbf{j}$ is conferred. The response $\\mathbf{y}$ is aligned with the\n",
    "instruction $\\mathbf{x}$ as well as the combined input $[\\mathbf{x}, \\mathbf{j}]$.\n",
    "\n",
    "**Align_N.** The LLM makes some mistakes in its\n",
    "generation, resulting in an unsatisfactory response\n",
    "$\\mathbf{y}$. Consequently, a negative judgment $\\mathbf{j}$ details\n",
    "the corresponding critiques. For Align-N, $\\mathbf{y}$ is not\n",
    "aligned with original instruction $\\mathbf{x}$. However, when\n",
    "considering $\\mathbf{x}$ and $\\mathbf{y}$ as a whole, $\\mathbf{y}$ is indeed aligned\n",
    "with the combined input $[\\mathbf{x}, \\mathbf{j}]$.\n",
    "\n",
    "**Misalign.** The authentic (真实的) negative judgment in\n",
    "Align-N is substituted with a fake positive judgment\n",
    "$\\mathbf{j}$. In this case, the response $\\mathbf{y}$ is not aligned\n",
    "with either the original instruction $\\mathbf{x}$ or the combination\n",
    "of instruction and judgment $[\\mathbf{x}, \\mathbf{j}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57d097-1e1d-426a-9ee7-5b1414c73e53",
   "metadata": {},
   "source": [
    "## Learning from Contrasting\n",
    "\n",
    "**Align-N vs. Misalign:** Opposite in the task of $[\\mathbf{x}, \\mathbf{j}]\\to\\mathbf{y}$. Thanks to the strong\n",
    "in-context learning capabilities of LLMs, the alignment\n",
    "flip from Align-N (aligned) to Misalign (misaligned)\n",
    "is often accompanied by decreased generation\n",
    "probabilities of the response, particularly\n",
    "for tokens that exhibit a strong correlation with the authentic negative judgment. For example, the LLM assigns a considerably\n",
    "higher probability for “a\" when taking the\n",
    "authentic negative judgment $\\mathbf{j}^{−}$ instead of the fake\n",
    "positive judgment $\\mathbf{j}^{+}$ as additional input.\n",
    "\n",
    "![](../images/judge3.png)\n",
    "\n",
    "We consider the\n",
    "tokens that display a substantially increased generation\n",
    "probability when conditioned on $\\mathbf{j}^{−}$ compared\n",
    "to $\\mathbf{j}^{+}$ as inappropriate tokens:\n",
    "\n",
    "$$\n",
    "U = \\{t|p(y_t|\\mathbf{y}_{<t},\\mathbf{x},\\mathbf{j}^{-}) - \\lambda\\cdot p(y_t|\\mathbf{y}_{<t},\\mathbf{x},\\mathbf{j}^{+})>0\\}\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is a hyperparameter to tradeoff the precision\n",
    "and recall of detecting inappropriate tokens.\n",
    "\n",
    "We apply the UT (Unlikelihood Training) on the identified inappropriate\n",
    "tokens for pushing the LLM to explore alternative\n",
    "generations, for other\n",
    "tokens, we use the standard MLE loss:\n",
    "\n",
    "$$\n",
    "L_{1} = -\\frac{1}{N}\\left(\\sum_{t\\notin U}\\log p(y_t|\\mathbf{y}_{<t},\\mathbf{x}) + \\sum_{t\\in U}\\alpha p(y_t|\\mathbf{y}_{<t},\\mathbf{x},\\mathbf{j}^{-})^{\\gamma}\\log(1 - p(y_{t}|\\mathbf{y}_{<t},\\mathbf{x})\\right)\n",
    "$$\n",
    "\n",
    "where $\\alpha p(y_t|\\mathbf{y}_{<t},\\mathbf{x},\\mathbf{j}^{-})^{\\gamma}$ is the dynamic weight\n",
    "term. $\\alpha$ and $\\gamma$ are two hyper-parameters.\n",
    "\n",
    "**Align-P vs. Align-N:** Despite both Align-P and\n",
    "Align-N are aligned in terms of $[\\mathbf{x}, \\mathbf{j}]\\to\\mathbf{y}$, only\n",
    "Align-P is aligned when solely considering the instruction\n",
    "$\\mathbf{x}\\to\\mathbf{y}$. Essentially, it suggests that the\n",
    "LLM should output different responses depending\n",
    "on whether a negative judgment is incorporated or\n",
    "not. We train on\n",
    "this comparison with the following MLE objective:\n",
    "\n",
    "$$\n",
    "L_{2} = -\\frac{\\mathbb{1}(\\mathbf{x}\\to\\mathbf{y})}{N}\\sum_{t}\\log p(y_{t}|\\mathbf{y}_{<t},\\mathbf{x}) -\\frac{(1 - \\mathbb{1}(\\mathbf{x}\\to\\mathbf{y}))}{N}\\sum_{t}\\log p(y_{t}|\\mathbf{y}_{<t},\\mathbf{j},\\mathbf{x})\n",
    "$$\n",
    "\n",
    "where $\\mathbb{1}(\\mathbf{x}\\to\\mathbf{y})$ is an indicator function that returns\n",
    "1 if $\\mathbf{x}$ and $\\mathbf{y}$ are aligned, and 0 otherwise.\n",
    "\n",
    "Finally, the overall loss of CUT (Contrastive Unlikelihood Training) combines the\n",
    "losses from the two contrasts: $L_{\\text{CUT}} = L_1 + L_2$.\n",
    "\n",
    "![](../images/judge2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e0a43-40e4-4d6b-b686-e3295c85b524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
