
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>GOLD &#8212; Notes-on-LLM</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'methodology/gold';</script>
    <link rel="icon" href="../_static/github.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/Andromede.jpg" class="logo__image only-light" alt="Notes-on-LLM - Home"/>
    <script>document.write(`<img src="../_static/Andromede.jpg" class="logo__image only-dark" alt="Notes-on-LLM - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../base/0.html">Base</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../base/attention.html">Attention Is All You Need</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt.html">GPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt2.html">GPT2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt3.html">GPT3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/instruct-gpt.html">InstructGPT</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../models/0.html">Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../models/llama3.html">Llama 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/llama3-source-code.html">Llama 3 Source Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/qwen3.html">Qwen3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/qwen25.html">Qwen 2.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/qwen25-coder.html">Qwen2.5-Coder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/deepseek-v2.html">DeepSeek-V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/deepseek-coder-v2.html">DeepSeek-Coder-V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/deepseek-v3.html">DeepSeek V3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models/seed-coder.html">Seed-Coder</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../techniques/0.html">Techniques</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../techniques/norm.html">Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/rope.html">RoPE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/extending.html">Extending context window of LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/mla.html">Multi-Head Latent Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/deepseek-moe.html">DeepSeekMoE</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/0.html">Benchmarks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/humaneval.html">HumanEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/mbpp.html">MBPP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/evalplus.html">EvalPlus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/livecodebench.html">LiveCodeBench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/cruxeval.html">CRUXEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/bigcodebench.html">BigCodeBench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/swe.html">SWE-bench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/general.html">General Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/math-science.html">Math &amp; Science Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/alignment.html">Alignment Benchmarks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data/0.html">Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../data/apps.html">APPS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/taco.html">TACO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/alphacode.html">AlphaCode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/self-instruct.html">SELF-INSTRUCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/code-alpaca.html">Code Alpaca</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/wizard.html">WizardCoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/magic.html">Magicoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/unicoder.html">UNICODER</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/opencoder.html">OpenCoder</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sft/0.html">SFT</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../sft/rs.html">Scaling Relationship on Learning Mathematical Reasoning with Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sft/lima.html">LIMA: Less Is More for Alignment</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../preference/0.html">Preference Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../preference/rlaif-1.html">Constitutional AI: Harmlessness from AI Feedback</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/rlaif-2.html">RLAIF vs. RLHF</a></li>


<li class="toctree-l2"><a class="reference internal" href="../preference/rlcd.html">RLCD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/west-of-n.html">West-of-N</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/ee.html">Efficient Exploration for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/deepseek-grm.html">DeepSeek-GRM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/ppo.html">PPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/dpo.html">DPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/grpo.html">Group Relative Policy Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/reinforce%2B%2B.html">REINFORCE++</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/dapo.html">DAPO</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reasoning/0.html">Reasoning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/cot.html">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/verify.html">Let’s Verify Step by Step</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/self-correct-rl.html">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/deepseek-r1.html">DeepSeek-R1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/s1.html">s1: Simple test-time scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/opencodereasoning.html">OpenCodeReasoning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../agent/0.html">Agent</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../agent/software-survey.html">Agents in Software Engineering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/react.html">REACT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/reflexion.html">Reflexion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/api-bank.html">API-Bank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/code-act.html">CodeAct</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/agentless.html">AGENTLESS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/swe-agent.html">SWE-agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../agent/swe-smith.html">SWE-smith</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fmethodology/gold.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/methodology/gold.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>GOLD</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-mle-to-rl-framework">From MLE to RL framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#off-policy-policy-gradient">Off-policy policy gradient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reward">Reward</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gold-algorithm">The GOLD algorithm</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="gold">
<h1>GOLD<a class="headerlink" href="#gold" title="Link to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A dominant approach to text generation is to use autoregressive models learned by maximum
likelihood estimation (MLE) on supervised data. However, this approach introduces two well-known
discrepancies between training and evaluation objectives that lead to undesired generations. First,
the training loss is negative log-likelihood, whereas the evaluation is based on human judgment of
the output quality. Second, during training, the autoregressive model conditions on the gold history/prefix; however,
at inference time it conditions on model-generated history.<br>
We aim to bridge the gap between training and evaluation in this paper.</p>
</div>
<section id="from-mle-to-rl-framework">
<h2>From MLE to RL framework<a class="headerlink" href="#from-mle-to-rl-framework" title="Link to this heading">#</a></h2>
<p><strong>MLE training.</strong> Given a context <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, we want to generate a sequence of tokens <span class="math notranslate nohighlight">\(\mathbf{y}=(y_{0},\dots,y_{T})\)</span>. Let <span class="math notranslate nohighlight">\(p_{\text{human}}(\mathbf{y}|\mathbf{x})\)</span> denote the data-generating distribution. Using MLE, the loss function is</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\theta) = -\mathbb{E}_{\mathbf{y}\sim p_{\text{human}}}\left[\sum_{t=0}^{T}\log p_{\theta}(y_{t}|y_{0},\dots,y_{t-1},\mathbf{x})\right]\]</div>
<p><strong>Evaluation.</strong> In practice, the quality of an output often relies on task-specific metrics such as fluency,
correctness, and interestingness. Here for generality we consider perceptual quality which measures how likely a human would have generated the output given
the context, i.e., <span class="math notranslate nohighlight">\(p_{\text{human}}(\mathbf{y} | \mathbf{x})\)</span>. Thus the evaluation metric is</p>
<div class="math notranslate nohighlight">
\[-\mathbb{E}_{\mathbf{y}\sim p_{\theta}}\left[\sum_{t=0}^{T}\log p_{\text{human}}(y_{t}|y_{0},\dots,y_{t-1},\mathbf{x})\right]\]</div>
<p>We see that the training objective encourages high recall: the model must put
probability mass on all human-generated sequences. In contrast, the evaluation metric encourages
high precision: all outputs from the model must be of high quality.</p>
<p><strong>RL formulation.</strong> Let’s consider generation as a sequential decision-making process. At each time
step <span class="math notranslate nohighlight">\(t\)</span>, the policy <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span> takes an action <span class="math notranslate nohighlight">\(a_{t}\in\mathcal{V}\)</span>, transits to the next state <span class="math notranslate nohighlight">\(s_{t+1} = (y_{0},\dots,y_{t},\mathbf{x})\)</span>, and receives a
reward <span class="math notranslate nohighlight">\(r_{t}\)</span>. The policy corresponds to the generation model: <span class="math notranslate nohighlight">\(\pi(a_{t}|s_{t}) = p_{\theta}(a_{t}|y_{0},\dots,y_{t},\mathbf{x})\)</span>. We
can thus represent a sequence as a trajectory <span class="math notranslate nohighlight">\(\tau=(s_{0}, a_{0}, r_{0}, \dots, s_{T}, a_{T}, r_{T})\)</span>. The set of trajectories
derived from the training data is called demonstrations which show the desired behavior of a policy. The RL objective is to maximize</p>
<div class="math notranslate nohighlight">
\[J(\theta) = \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\sum_{t=0}^{T}\gamma^{t}r_{t}\right]\]</div>
<p>If we knew oracle rewards <span class="math notranslate nohighlight">\(r_{t}=p_{\text{human}}(a_{t}|s_{t})\)</span>, then this objective would be exactly the evaluation metric we want to optimize.</p>
</section>
<section id="off-policy-policy-gradient">
<h2>Off-policy policy gradient<a class="headerlink" href="#off-policy-policy-gradient" title="Link to this heading">#</a></h2>
<p><strong>Policy gradient.</strong> A straightforward way to optimize <span class="math notranslate nohighlight">\(J(\theta)\)</span> is policy gradient:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\theta}J(\theta) = \mathbb{E}_{\tau\sim\pi_{\theta}}\left[\sum_{t}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})\hat{Q}(s_{t}, a_{t})\right]\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{Q}(s_{t}, a_{t})\)</span> is the estimated return from state <span class="math notranslate nohighlight">\(s_{t}\)</span>. The expectation is estimated
by Monte Carlo samples from <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span>. In text generation, the return <span class="math notranslate nohighlight">\(\hat{Q}(s_{t}, a_{t})\)</span> is often a sequence-level
reward such as BLEU. In practice, the policy is likely to get stuck in a region of zero reward during
training, generating gibberish without receiving any learning signal.</p>
<p><strong>Offline learning.</strong> To avoid zero-reward regions, we would like to reduce interaction with the
environment and stay close to the demonstrated trajectories. In the extreme case, the policy is
learned solely from the static demonstrations without additional interaction with the environment,
which is referred to as the offline setting.</p>
<p>In the offline setting, we cannot estimate the expected return of <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span> by sampling trajectories from
it, and must use trajectories from a different behavioral policy <span class="math notranslate nohighlight">\(\pi_{b}\)</span>. A common technique to estimate expectations under one distribution <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span> given samples from a
different distribution <span class="math notranslate nohighlight">\(\pi_{b}\)</span> is importance sampling:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{\tau\sim\pi_{b}}\left[\sum_{t}w_{t}\nabla_{\theta}\log\pi_{\theta}(a_{t}|s_{t})\hat{Q}(s_{t}, a_{t})\right]\]</div>
<p>with importance weights <span class="math notranslate nohighlight">\(w_{t} = \Pi_{t'=0}^{t}\frac{\pi_{\theta}(a_{t'}|s_{t'})}{\pi_{b}(a_{t'}|s_{t'})}\)</span></p>
<p><strong>Approximations.</strong> In practice, we use the per-action approximation: <span class="math notranslate nohighlight">\(w_{t} = \frac{\pi_{\theta}(a_{t}|s_{t})}{\pi_{b}(a_{t}|s_{t})}\)</span>. Although this estimator is biased,
empirically it has been shown to reduce variance and work reasonably well if <span class="math notranslate nohighlight">\(pi_{b}\)</span> and <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span> are close. Another obstacle is that we do not know <span class="math notranslate nohighlight">\(\pi_{b}\)</span> which produced
the demonstrations <span class="math notranslate nohighlight">\(\mathcal{D}=\{(\mathbf{x}^{(i)}, \mathbf{y}^{(i)})\}_{i=1}^{N}\)</span>. One option is to estimate <span class="math notranslate nohighlight">\(\pi_{b}\)</span> on <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. Here we take a simpler
approach that uses the empirical distribution: <span class="math notranslate nohighlight">\(\pi_{b}(\tau)=1/N\)</span> for <span class="math notranslate nohighlight">\(\tau\in\mathcal{D}\)</span> and 0 otherwise. As a result,
the denominator in <span class="math notranslate nohighlight">\(w_{t}\)</span> is a constant and can be ignored in optimization. Our final approximated
gradient:</p>
<div class="math notranslate nohighlight">
\[\nabla_{\theta}J(\theta) = \sum_{i=1}^{N}\sum_{t=0}^{N}\pi_{\theta}(a_{t}^{i}|s_{t}^{i})\log\pi_{\theta}(a_{t}^{i}|s_{t}^{i})\hat{Q}(s_{t}^{i}, a_{t}^{i})\]</div>
<p>Compared with the MLE gradient: <span class="math notranslate nohighlight">\(\sum_{i=1}^{N}\sum_{t=0}^{N}\log\pi_{\theta}(a_{t}^{i}|s_{t}^{i})\)</span>, our gradient upweights actions with high return and actions
preferred by the current policy <span class="math notranslate nohighlight">\(\pi_{\theta}\)</span>. Intuitively, it encourages the learning algorithm to focus on “easy”
examples (high likelihood under the model) which improves precision.</p>
</section>
<section id="reward">
<h2>Reward<a class="headerlink" href="#reward" title="Link to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(R\)</span> be the reward function such that <span class="math notranslate nohighlight">\(r_{t} = R(s_{t}, a_{t})\)</span>. To optimize the perceptual quality of a
sequence, we want <span class="math notranslate nohighlight">\(R(s, a)\)</span> to approximate <span class="math notranslate nohighlight">\(p_{\text{human}}(a|s)\)</span>. In the offline setting,
we can restrict the domain of <span class="math notranslate nohighlight">\(R\)</span> to state-action pairs on the demonstrations. Next, we propose three
reward functions.</p>
<p><span class="math notranslate nohighlight">\(\mathbf{\delta}\)</span><strong>-reward.</strong> An obvious choice is a sequence-level reward, which considers all demonstrations to be
equally good and assigns zero reward to any other outputs. where a reward of one is received in the terminal state for any trajectory in the demonstrations.</p>
<p><strong>Estimated <span class="math notranslate nohighlight">\(p_{\textbf{human}}\)</span>.</strong> While <span class="math notranslate nohighlight">\(p_{\text{MLE}}\)</span> is not a good reward function in general since it can assign
large probability mass to low-quality outputs, however, it is a reasonable approximation to <span class="math notranslate nohighlight">\(p_{\text{human}}\)</span> when
restricted to the demonstrations. Our first reward function corresponds to a product of probabilities when
summed over the trajectory:</p>
<div class="math notranslate nohighlight">
\[R_{p}(s, a) := \log p_{\text{MLE}}(a|s)\]</div>
<p>To allow for partial credits even
if bad actions are taken at certain steps, we define another reward function corresponding to the sum
of probabilities:</p>
<div class="math notranslate nohighlight">
\[R_{s}(s, a) := p_{\text{MLE}}(a|s)\]</div>
<p>Assuming <span class="math notranslate nohighlight">\(\gamma=1\)</span>, the return <span class="math notranslate nohighlight">\(\hat{Q}(s_{t}, a_{t}) = \sum_{t'=t}^{T}p_{\text{MLE}}(a|s)\)</span>.</p>
</section>
<section id="the-gold-algorithm">
<h2>The GOLD algorithm<a class="headerlink" href="#the-gold-algorithm" title="Link to this heading">#</a></h2>
<p><img alt="" src="../_images/gold1.png" /></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./methodology"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-mle-to-rl-framework">From MLE to RL framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#off-policy-policy-gradient">Off-policy policy gradient</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reward">Reward</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-gold-algorithm">The GOLD algorithm</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By newfacade
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>