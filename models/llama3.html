
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Llama 3 &#8212; Notes-on-LLM</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'models/llama3';</script>
    <link rel="icon" href="../_static/github.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Llama 3 Source Code" href="llama3-source-code.html" />
    <link rel="prev" title="Models" href="0.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/Andromede.jpg" class="logo__image only-light" alt="Notes-on-LLM - Home"/>
    <script>document.write(`<img src="../_static/Andromede.jpg" class="logo__image only-dark" alt="Notes-on-LLM - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../base/0.html">Base</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../base/attention.html">Attention Is All You Need</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt.html">GPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt2.html">GPT2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt3.html">GPT3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/instruct-gpt.html">InstructGPT</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="0.html">Models</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Llama 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="llama3-source-code.html">Llama 3 Source Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="qwen25.html">Qwen 2.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="qwen25-coder.html">Qwen2.5-Coder</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepseek-v2.html">DeepSeek-V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepseek-coder-v2.html">DeepSeek-Coder-V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepseek-v3.html">DeepSeek V3</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../techniques/0.html">Techniques</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../techniques/norm.html">Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/rope.html">RoPE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/extending.html">Extending context window of LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/mla.html">Multi-Head Latent Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/deepseek-moe.html">DeepSeekMoE</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/0.html">Benchmarks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/humaneval.html">HumanEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/mbpp.html">MBPP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/evalplus.html">EvalPlus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/livecodebench.html">LiveCodeBench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/cruxeval.html">CRUXEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/general.html">General Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/math-science.html">Math &amp; Science Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/alignment.html">Alignment Benchmarks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data/0.html">Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../data/apps.html">APPS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/taco.html">TACO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/alphacode.html">AlphaCode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/self-instruct.html">SELF-INSTRUCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/code-alpaca.html">Code Alpaca</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/wizard.html">WizardCoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/magic.html">Magicoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/unicoder.html">UNICODER</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/opencoder.html">OpenCoder</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sft/0.html">SFT</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../sft/rs.html">Scaling Relationship on Learning Mathematical Reasoning with Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sft/lima.html">LIMA: Less Is More for Alignment</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../preference/0.html">Preference Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../preference/rlaif-1.html">Constitutional AI: Harmlessness from AI Feedback</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/rlaif-2.html">RLAIF vs. RLHF</a></li>


<li class="toctree-l2"><a class="reference internal" href="../preference/rlcd.html">RLCD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/west-of-n.html">West-of-N</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/ee.html">Efficient Exploration for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/deepseek-grm.html">DeepSeek-GRM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/ppo.html">PPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/dpo.html">DPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/grpo.html">Group Relative Policy Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/reinforce%2B%2B.html">REINFORCE++</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/dapo.html">DAPO</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reasoning/0.html">Reasoning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/cot.html">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/verify.html">Let’s Verify Step by Step</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/self-correct-rl.html">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/deepseek-r1.html">DeepSeek-R1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/s1.html">s1: Simple test-time scaling</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fmodels/llama3.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/models/llama3.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Llama 3</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training">Post-Training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#chat-dialog-format">Chat Dialog Format</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reward-modeling">Reward Modeling</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-finetuning">Supervised Finetuning</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#direct-preference-optimization">Direct Preference Optimization</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-averaging">Model Averaging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#iterative-rounds">Iterative Rounds</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training-data">Post-training Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#preference-data">Preference Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sft-data">SFT Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing-and-quality-control">Data Processing and Quality Control</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#capabilities">Capabilities</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#code">Code</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#results">Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-trained-language-model">Pre-trained Language Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#post-trained-language-model">Post-trained Language Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#takeaway">Takeaway</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="llama-3">
<h1>Llama 3<a class="headerlink" href="#llama-3" title="Link to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This paper presents a
new set of foundation models, called <a class="reference external" href="https://arxiv.org/abs/2407.21783">Llama 3</a>. It is a herd of language models that natively support
multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with
405B parameters and a context window of up to 128K tokens. We find that Llama 3 delivers comparable quality to leading language
models such as GPT-4 on a plethora of tasks.</p>
</div>
<figure class="align-default">
<img alt="../_images/llama3-1.png" src="../_images/llama3-1.png" />
</figure>
<section id="post-training">
<h2>Post-Training<a class="headerlink" href="#post-training" title="Link to this heading">#</a></h2>
<p>We produce the aligned Llama 3 models by applying several rounds of post-training. Each
round of post-training involves supervised finetuning (SFT) followed by Direct Preference Optimization (DPO<span id="id1">[<a class="reference internal" href="../reference.html#id32" title="Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. Direct preference optimization: your language model is secretly a reward model. 2024. URL: https://arxiv.org/abs/2305.18290, arXiv:2305.18290.">RSM+24</a>]</span>) on examples collected either via human annotations or generated synthetically.</p>
<section id="modeling">
<h3>Modeling<a class="headerlink" href="#modeling" title="Link to this heading">#</a></h3>
<figure class="align-default">
<img alt="../_images/llama3-2.png" src="../_images/llama3-2.png" />
</figure>
<section id="chat-dialog-format">
<h4>Chat Dialog Format<a class="headerlink" href="#chat-dialog-format" title="Link to this heading">#</a></h4>
<p>To tune LLMs for human-AI interaction, we need to define a chat dialog protocol for the model to understand
human instructions and perform conversational tasks.</p>
<figure class="align-default">
<img alt="../_images/llama3-tokenizer.svg" src="../_images/llama3-tokenizer.svg" /></figure>
</section>
<section id="reward-modeling">
<h4>Reward Modeling<a class="headerlink" href="#reward-modeling" title="Link to this heading">#</a></h4>
<p>We train a reward model (RM) covering different capabilities on top of the pre-trained checkpoint. We use <code class="docutils literal notranslate"><span class="pre">all</span></code> of our preference data for reward
modeling after filtering out samples with similar responses.</p>
</section>
<section id="supervised-finetuning">
<h4>Supervised Finetuning<a class="headerlink" href="#supervised-finetuning" title="Link to this heading">#</a></h4>
<p>The reward model is then used to perform rejection sampling on our human annotation prompts, Together with this rejection-sampled data and other data sources
(including synthetic data), we finetune the pre-trained language model using a standard cross entropy loss
on the target tokens (while masking loss on prompt tokens).</p>
</section>
<section id="direct-preference-optimization">
<h4>Direct Preference Optimization<a class="headerlink" href="#direct-preference-optimization" title="Link to this heading">#</a></h4>
<p>We further train our SFT models with DPO for human
preference alignment. For training, we primarily use the <code class="docutils literal notranslate"><span class="pre">most</span> <span class="pre">recent</span></code> batches of preference data collected using
the best performing models from the previous alignment rounds.
the following algorithmic modifications to DPO:</p>
<ul class="simple">
<li><p>Masking out formatting tokens in DPO loss</p></li>
<li><p>Regularization with NLL loss (DPOP)</p></li>
</ul>
</section>
<section id="model-averaging">
<h4>Model Averaging<a class="headerlink" href="#model-averaging" title="Link to this heading">#</a></h4>
<p>Finally, we average models obtained from experiments using various versions of data or hyperparameters at
each RM, SFT, or DPO stage.</p>
</section>
<section id="iterative-rounds">
<h4>Iterative Rounds<a class="headerlink" href="#iterative-rounds" title="Link to this heading">#</a></h4>
<p>Following Llama 2, we apply the above methods in six rounds. In each cycle, we collect new preference
annotations and SFT data, sampling synthetic data from the latest models.</p>
</section>
</section>
<section id="post-training-data">
<h3>Post-training Data<a class="headerlink" href="#post-training-data" title="Link to this heading">#</a></h3>
<section id="preference-data">
<h4>Preference Data<a class="headerlink" href="#preference-data" title="Link to this heading">#</a></h4>
<p>We deploy multiple models for annotation after
each round and sample two responses from <code class="docutils literal notranslate"><span class="pre">two</span> <span class="pre">different</span> <span class="pre">models</span></code> for each user prompt. These models can
be trained with different data mixes and alignment recipes, allowing for different capability strength (e.g.,
code expertise) and increased data diversity. We ask <code class="docutils literal notranslate"><span class="pre">annotators</span></code> to rate the strength of their preference by
categorizing it into one of four levels, based on how much more they prefer the chosen response over the
rejected one: significantly better, better, slightly better, or marginally better. We also incorporate an editing
step after preference ranking to encourage annotators to further improve the preferred response. Annotators
edit the chosen response directly or prompt the model with feedback to refine its own response. Consequently,
a portion of our preference data has three responses ranked <span class="math notranslate nohighlight">\((edited &gt; chosen &gt; rejected)\)</span>.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>How to collect multi-turn preference data from two different models? One possible solution:<br></p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(query_1 \to (chosen_1, rejected_1)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(answer_1 := chosen_1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((query_1, answer_1, query_2) \to (chosen_2, rejected_2)\)</span></p></li>
</ol>
</div>
<p>In each round of post-training, we use all the preference data that is available at the time for reward modeling,
while only using the latest batches from various capabilities for DPO training. For both reward modeling and
DPO, we use samples that are labeled as the chosen response being significantly better or better than the
rejected counterpart for training and <code class="docutils literal notranslate"><span class="pre">discard</span> <span class="pre">samples</span> <span class="pre">with</span> <span class="pre">similar</span> <span class="pre">responses</span></code>.</p>
</section>
<section id="sft-data">
<h4>SFT Data<a class="headerlink" href="#sft-data" title="Link to this heading">#</a></h4>
<p>Our finetuning data is largely comprised of the following sources:</p>
<ul class="simple">
<li><p>Prompts from our human annotation collection with rejection-sampled responses</p></li>
<li><p>Synthetic data targeting specific capabilities (See <a class="reference internal" href="#llama3-capabilities"><span class="std std-ref">Capabilities</span></a> for more details)</p></li>
<li><p>Small amounts of human-curated data</p></li>
</ul>
<p><strong>Rejection sampling.</strong> During rejection sampling (RS), for each prompt collected during human annotation we sample <span class="math notranslate nohighlight">\(K\)</span> (typically between 10 and 30) outputs from the latest chat model policy (usually
the best performing checkpoint from the previous post-training iteration, or the best performing checkpoint
for a particular capability) and use our reward model to select the best candidate.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In later rounds of post-training, we introduce system prompts to steer RS responses to conform with
desirable tone, style, or formatting, which might be different for different capabilities.</p>
</div>
<p><strong>Overall data composition.</strong> In <a class="reference internal" href="#llama3-data-process"><span class="std std-ref">Data Processing and Quality Control</span></a> we describe techniques for categorizing topic, complexity, and quality of our data
samples. In each round of post-training, we adjust our overall data mix carefully across these axes to tune
performance across a wide range of benchmarks.</p>
</section>
<section id="data-processing-and-quality-control">
<span id="llama3-data-process"></span><h4>Data Processing and Quality Control<a class="headerlink" href="#data-processing-and-quality-control" title="Link to this heading">#</a></h4>
<p>Given that most of our training data is model-generated, it requires careful cleaning and quality control.</p>
<ul class="simple">
<li><p><strong>Topic classification:</strong> We first finetune Llama 3 8B into a topic classifier, and perform inference over
all data to classify it into both coarsely-grained buckets (“mathematical reasoning”) and fine-grained buckets (“geometry and trigonometry”).</p></li>
<li><p><strong>Quality scoring:</strong> We use both reward model and Llama-based signals to obtain a quality score for each
sample. For an RM-based score, we consider data that is in the top quartile of RM scores as high quality.
For a Llama-based score, we prompt Llama 3 checkpoint to rate each sample. The RM and Llama-based scores have high disagreement rates, and we find that
combining these signals yield the best recall on our internal test set. Ultimately, we select examples
that are marked as high quality by the RM <code class="docutils literal notranslate"><span class="pre">or</span></code> the Llama-based filter.</p></li>
<li><p><strong>Difficulty scoring:</strong> Because we are also interested in prioritizing examples that are more complex for
the model, we score data using two measures of difficulty: Instag<span id="id2">[]</span> and Llama-based
scoring.</p></li>
<li><p><strong>Semantic deduplication:</strong> Finally, we perform semantic deduplication. We first cluster complete dialogs using RoBERTa and within each cluster
sort them by quality score <span class="math notranslate nohighlight">\(\times\)</span> difficulty score. We then do greedy selection by iterating through all sorted
examples, and only keeping the ones that have maximum cosine similarity less than a threshold to the
examples seen so far in the cluster.</p></li>
</ul>
</section>
</section>
<section id="capabilities">
<span id="llama3-capabilities"></span><h3>Capabilities<a class="headerlink" href="#capabilities" title="Link to this heading">#</a></h3>
<section id="code">
<h4>Code<a class="headerlink" href="#code" title="Link to this heading">#</a></h4>
<p>Here, we present our work on improving coding capabilities via training a code expert, generating synthetic data for SFT, improving formatting
with system prompt steering, and creating quality filters to remove bad samples from our training data.</p>
<p><strong>Expert training.</strong> We train a code expert which we use to collect high quality human annotations for code
throughout subsequent rounds of post-training. This is accomplished by branching the main pre-training run
and continuing pre-training on a 1T token mix of mostly (&gt;85%) code data. For the last several
thousand steps of training we perform long-context finetuning (LCFT) to extend the expert’s context length
to 16K tokens on a high quality mix of repo-level code data. Finally, we follow the similar post-training
modeling recipes described earlier to align this model, except with SFT and DPO data mixes primarily
targeting code.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The code expert model is used for both preference data annotation (recall that responses of preference data are sampled from two different models) and rejection sampling.</p>
</div>
<p><strong>Synthetic data generation.</strong> We use Llama 3 and the code expert to generate a large quantity of synthetic SFT dialogs. We describe three high-level approaches for generating synthetic code data used during SFT.</p>
<ol class="arabic">
<li><p><strong>Synthetic data generation: execution feedback.</strong> The 8B and 70B models show significant performance
improvements when trained on data generated by a larger, more competent model. However, our initial
experiments revealed that training Llama 3 405B on its own generated data is not helpful (and can
even degrade performance). To address this limitation, we introduced execution feedback as a source of
truth, in particular, we generate large
dataset of approximately one million synthetic coding dialogues using the following process:</p>
<ul>
<li><p><strong>Problem description generation:</strong> Magicoder<span id="id3">[<a class="reference internal" href="../reference.html#id28" title="Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. Magicoder: empowering code generation with oss-instruct. 2024. URL: https://arxiv.org/abs/2312.02120, arXiv:2312.02120.">WWL+24</a>]</span>.</p></li>
<li><p><strong>Solution generation:</strong> Then, we prompt Llama 3 to solve each problem in a given programming language.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>We observe that adding general rules of good programming to the prompt improves the generated solution quality. Also, we find it is helpful to require the model to explain its thought process in comments.</p>
</div>
</li>
<li><p><strong>Correctness analysis:</strong> We extract the source code from the generated solution and applied a combination of static and dynamic analysis techniques to test its correctness, including:</p>
<ul class="simple">
<li><p><strong>Static analysis:</strong> We run all generated code through a parser and a linter to ensure syntactic correctness.</p></li>
<li><p><strong>Unit test generation and execution:</strong> For each problem and solution, we prompt the model to generate unit tests, executed in a containerized environment together with the solution, catching run-time execution errors and some semantic errors.</p></li>
</ul>
</li>
<li><p><strong>Error feedback and iterative self-correction:</strong> When a solution fails at any step, we prompt the model to revise it. The prompt included the original problem description, the faulty solution, and feedback from the parser/linter/tester. After a unit test execution failure, the model could either fix the code to pass the existing tests or modify its unit tests to accommodate the generated code. Only dialogs that pass all checks are included in the final dataset, used for supervised finetuning (SFT).</p></li>
<li><p><strong>Fine-tuning and iterative improvement:</strong> The finetuning process is conducted over multiple rounds, with each round building on the previous one. After each round, the model is improved, generating higher-quality synthetic data for the next round.</p></li>
</ul>
</li>
<li><p><strong>Synthetic data generation: programming language translation.</strong> We observe a performance gap between
major programming languages (e.g., Python/C++) and less common ones (e.g., Typescript/PHP). This
is not surprising as we have less training data for less common programming languages. To mitigate
this, we supplement our existing data by translating data from common programming languages to
less common languages. This is achieved
by prompting Llama 3 and ensuring quality via syntax parsing, compilation, and execution.</p></li>
<li><p><strong>Synthetic data generation: backtranslation.</strong> To improve certain coding capabilities (e.g., documentation,
explanations and debugging) where execution feedback is less informative for determining quality, we employ an
alternative multi-step approach. Beginning with code
snippets from a variety of languages in our pre-training data:</p>
<ul class="simple">
<li><p><strong>Generate:</strong> We prompt Llama 3 to generate data that represents our target capability (e.g., we ask the model to explain a piece of code).</p></li>
<li><p><strong>Backtranslate:</strong> We then prompt the model to “backtranslate” the synthetically generated data to the original code (e.g., we ask the model to generate code only from its explanation).</p></li>
<li><p><strong>Filter:</strong> Using the original code as a reference, we prompt the Llama 3 to determine the quality of the output (e.g., we ask the model how faithful the backtranslated code is to the original). We then use the generated examples that have the highest self-verification scores in SFT.</p></li>
</ul>
</li>
</ol>
<p><strong>System prompt steering during rejection sampling.</strong> During the rejection sampling process, we used code specific
system prompts to improve code readability, documentation, thoroughness, and specificity.</p>
<figure class="align-default">
<img alt="../_images/llama3-3.png" src="../_images/llama3-3.png" />
</figure>
<p><strong>Filtering training data with execution and model-as-judge signals.</strong> We occasionally
encounter quality issues in our rejection-sampled data. Detecting these
issues in our rejection-sampled data is not as straightforward as it is for our synthetic code data, as the
rejection-sampled responses typically contain a mix of natural language and code for which the code may not always be expected to be executable. To address this, we utilize the “model-as-judge” approach,
where earlier versions of Llama 3 assess and assign a binary (0/1) score based on two criteria: code correctness
and code style. We retain only those samples that achieve a perfect score of 2. Initially, this stringent filtering
led to a regression in downstream benchmark performance, primarily because it disproportionately <code class="docutils literal notranslate"><span class="pre">removed</span> <span class="pre">examples</span> <span class="pre">with</span> <span class="pre">challenging</span> <span class="pre">prompts</span></code>. To counteract this, we strategically revise the responses of some coding
data categorized as most challenging until they met the Llama-based “model-as-judge” criteria. By refining
these challenging problems, the coding data achieves a balance between quality and difficulty, resulting in
optimal downstream performance.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>How to revise the responses automatically?</p>
</div>
</section>
</section>
</section>
<section id="results">
<h2>Results<a class="headerlink" href="#results" title="Link to this heading">#</a></h2>
<section id="pre-trained-language-model">
<h3>Pre-trained Language Model<a class="headerlink" href="#pre-trained-language-model" title="Link to this heading">#</a></h3>
<figure class="align-default">
<a class="reference internal image-reference" href="../_images/llama3-4.png"><img alt="../_images/llama3-4.png" src="../_images/llama3-4.png" style="height: 400px;" /></a>
</figure>
<figure class="align-default">
<img alt="../_images/llama3-5.png" src="../_images/llama3-5.png" />
</figure>
<figure class="align-default">
<img alt="../_images/llama3-6.png" src="../_images/llama3-6.png" />
</figure>
</section>
<section id="post-trained-language-model">
<h3>Post-trained Language Model<a class="headerlink" href="#post-trained-language-model" title="Link to this heading">#</a></h3>
<figure class="align-default">
<img alt="../_images/llama3-7.png" src="../_images/llama3-7.png" />
</figure>
</section>
</section>
<section id="takeaway">
<h2>Takeaway<a class="headerlink" href="#takeaway" title="Link to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Preference data:</p>
<ul class="simple">
<li><p>Response from two different models with different data mixes and alignment recipes</p></li>
<li><p>Human annotate significantly better, better, slightly better, or marginally better. Only use significantly better and better.</p></li>
<li><p>Discard samples with similar responses</p></li>
</ul>
<p>SFT data:</p>
<ul class="simple">
<li><p>Rejection sampling using RM, system prompt steering during rejection sampling.</p></li>
<li><p>Synthetic data:</p>
<ul>
<li><p>Execution feedback (Magicoder)</p></li>
<li><p>Programming language translation</p></li>
<li><p>Backtranslation (code explain, debug)</p></li>
</ul>
</li>
</ul>
<p>Data process and quality control:</p>
<ul class="simple">
<li><p>Quality scoring</p>
<ul>
<li><p>LLM as judge (for challenging prompts, revise responses until met criteria)</p></li>
<li><p>Or top quartile of RM</p></li>
</ul>
</li>
<li><p>Difficulty scoring</p></li>
<li><p>Semantic deduplication</p></li>
</ul>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="0.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Models</p>
      </div>
    </a>
    <a class="right-next"
       href="llama3-source-code.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Llama 3 Source Code</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training">Post-Training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#chat-dialog-format">Chat Dialog Format</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reward-modeling">Reward Modeling</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-finetuning">Supervised Finetuning</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#direct-preference-optimization">Direct Preference Optimization</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-averaging">Model Averaging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#iterative-rounds">Iterative Rounds</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training-data">Post-training Data</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#preference-data">Preference Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sft-data">SFT Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing-and-quality-control">Data Processing and Quality Control</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#capabilities">Capabilities</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#code">Code</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#results">Results</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-trained-language-model">Pre-trained Language Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#post-trained-language-model">Post-trained Language Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#takeaway">Takeaway</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By newfacade
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>