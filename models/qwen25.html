
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Qwen 2.5 &#8212; Notes-on-LLM</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=3ee479438cf8b5e0d341" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=3ee479438cf8b5e0d341"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'models/qwen25';</script>
    <link rel="icon" href="../_static/github.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Qwen2.5-Coder" href="qwen25-coder.html" />
    <link rel="prev" title="Llama 3 Source Code" href="llama3-source-code.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/Andromede.jpg" class="logo__image only-light" alt="Notes-on-LLM - Home"/>
    <script>document.write(`<img src="../_static/Andromede.jpg" class="logo__image only-dark" alt="Notes-on-LLM - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../base/0.html">Base</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../base/attention.html">Attention Is All You Need</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt.html">GPT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt2.html">GPT2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/gpt3.html">GPT3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../base/instruct-gpt.html">InstructGPT</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="0.html">Models</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="llama3.html">Llama 3</a></li>
<li class="toctree-l2"><a class="reference internal" href="llama3-source-code.html">Llama 3 Source Code</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Qwen 2.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="qwen25-coder.html">Qwen2.5-Coder</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepseek-v2.html">DeepSeek-V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepseek-coder-v2.html">DeepSeek-Coder-V2</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepseek-v3.html">DeepSeek V3</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../techniques/0.html">Techniques</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../techniques/norm.html">Normalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/rope.html">RoPE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/extending.html">Extending context window of LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/mla.html">Multi-Head Latent Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../techniques/deepseek-moe.html">DeepSeekMoE</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../bench/0.html">Benchmarks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../bench/humaneval.html">HumanEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/mbpp.html">MBPP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/evalplus.html">EvalPlus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/livecodebench.html">LiveCodeBench</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/cruxeval.html">CRUXEval</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/general.html">General Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/math-science.html">Math &amp; Science Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../bench/alignment.html">Alignment Benchmarks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../data/0.html">Data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../data/apps.html">APPS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/taco.html">TACO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/alphacode.html">AlphaCode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/self-instruct.html">SELF-INSTRUCT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/code-alpaca.html">Code Alpaca</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/wizard.html">WizardCoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/magic.html">Magicoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/unicoder.html">UNICODER</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data/opencoder.html">OpenCoder</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sft/0.html">SFT</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../sft/rs.html">Scaling Relationship on Learning Mathematical Reasoning with Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sft/lima.html">LIMA: Less Is More for Alignment</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../preference/0.html">Preference Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../preference/rlaif-1.html">Constitutional AI: Harmlessness from AI Feedback</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/rlaif-2.html">RLAIF vs. RLHF</a></li>


<li class="toctree-l2"><a class="reference internal" href="../preference/rlcd.html">RLCD</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/west-of-n.html">West-of-N</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/ee.html">Efficient Exploration for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/deepseek-grm.html">DeepSeek-GRM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/ppo.html">PPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/dpo.html">DPO</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/grpo.html">Group Relative Policy Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/reinforce%2B%2B.html">REINFORCE++</a></li>
<li class="toctree-l2"><a class="reference internal" href="../preference/dapo.html">DAPO</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reasoning/0.html">Reasoning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/cot.html">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/verify.html">Let’s Verify Step by Step</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/self-correct-rl.html">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/deepseek-r1.html">DeepSeek-R1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reasoning/s1.html">s1: Simple test-time scaling</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../reference.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fmodels/qwen25.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/models/qwen25.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Qwen 2.5</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-tokenizer">Architecture &amp; Tokenizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">Pre-training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training">Post-training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">Supervised Fine-tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-reinforcement-learning">Offline Reinforcement Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#online-reinforcement-learning">Online Reinforcement Learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#base-models">Base Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-tuned-model">Instruction-tuned Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#takeaway">Takeaway</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="qwen-2-5">
<h1>Qwen 2.5<a class="headerlink" href="#qwen-2-5" title="Link to this heading">#</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Compared to previous iterations, Qwen 2.5<span id="id1">[<a class="reference internal" href="../reference.html#id16" title="Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report. 2025. URL: https://arxiv.org/abs/2412.15115, arXiv:2412.15115.">QY+25</a>]</span> has
been significantly improved during both the pre-training and post-training stages. In
terms of pre-training, we have scaled the high-quality pre-training datasets from the
previous 7 trillion tokens to 18 trillion tokens. In terms of post-training,
we implement intricate supervised finetuning with over 1 million samples, as well as
multistage reinforcement learning, including <code class="docutils literal notranslate"><span class="pre">offline</span> <span class="pre">learning</span> <span class="pre">DPO</span></code> and <code class="docutils literal notranslate"><span class="pre">online</span> <span class="pre">learning</span> <span class="pre">GRPO</span></code>.</p>
</div>
<section id="architecture-tokenizer">
<h2>Architecture &amp; Tokenizer<a class="headerlink" href="#architecture-tokenizer" title="Link to this heading">#</a></h2>
<p>Basically, the Qwen2.5 series include dense models for opensource, and MoE models for API service.</p>
<p>For dense models, we maintain the Transformer-based decoder architecture<span id="id2">[<a class="reference internal" href="../reference.html#id2" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. 2023. URL: https://arxiv.org/abs/1706.03762, arXiv:1706.03762.">VSP+23</a>]</span> as Qwen2. The architecture incorporates several key components:
Grouped Query Attention (GQA<span id="id3">[<a class="reference internal" href="../reference.html#id19" title="Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy, Federico Lebrón, and Sumit Sanghai. Gqa: training generalized multi-query transformer models from multi-head checkpoints. 2023. URL: https://arxiv.org/abs/2305.13245, arXiv:2305.13245.">ALTdJ+23</a>]</span>) for efficient KV cache utilization, SwiGLU activation
function<span id="id4">[<a class="reference internal" href="../reference.html#id20" title="Yann N. Dauphin, Angela Fan, Michael Auli, and David Grangier. Language modeling with gated convolutional networks. 2017. URL: https://arxiv.org/abs/1612.08083, arXiv:1612.08083.">DFAG17</a>]</span> for non-linear activation, Rotary Positional Embeddings (RoPE<span id="id5">[<a class="reference internal" href="../reference.html#id24" title="Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: enhanced transformer with rotary position embedding. 2023. URL: https://arxiv.org/abs/2104.09864, arXiv:2104.09864.">SLP+23</a>]</span>) for encoding position information, <a class="reference external" href="https://spaces.ac.cn/archives/9577">QKV</a> bias in the attention mechanism and
RMSNorm<span id="id6">[<a class="reference internal" href="../reference.html#id23" title="Zixuan Jiang, Jiaqi Gu, Hanqing Zhu, and David Z. Pan. Pre-rmsnorm and pre-crmsnorm transformers: equivalent and efficient pre-ln transformers. 2023. URL: https://arxiv.org/abs/2305.14858, arXiv:2305.14858.">JGZP23</a>]</span> with pre-normalization to ensure stable training.</p>
<p>Building upon the dense model architectures, we extend it to MoE model architectures. This is achieved
by replacing standard feed-forward network (FFN) layers with specialized MoE layers.</p>
<p>For tokenization, we utilize Qwen’s tokenizer<span id="id7">[<a class="reference internal" href="../reference.html#id22" title="Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report. 2023. URL: https://arxiv.org/abs/2309.16609, arXiv:2309.16609.">BBC+23</a>]</span>, which implements byte-level byte-pair
encoding (BBPE<span id="id8">[<a class="reference internal" href="../reference.html#id21" title="Changhan Wang, Kyunghyun Cho, and Jiatao Gu. Neural machine translation with byte-level subwords. 2019. URL: https://arxiv.org/abs/1909.03341, arXiv:1909.03341.">WCG19</a>]</span>) with a vocabulary of 151,643
regular tokens.</p>
</section>
<section id="pre-training">
<h2>Pre-training<a class="headerlink" href="#pre-training" title="Link to this heading">#</a></h2>
<p>Qwen2.5 demonstrates significant enhancements in pre-training data quality compared to its predecessor
Qwen2. These improvements stem from several key aspects:</p>
<ol class="arabic simple">
<li><p>Better data filtering.</p></li>
<li><p>Better math and code data.</p></li>
<li><p>Better synthetic data.</p></li>
<li><p>Better data mixture.</p></li>
</ol>
<p>We develop scaling laws for hyper-parameter based on the pre-training data of Qwen2.5. While previous studies primarily used scaling laws to determine optimal model sizes given compute budgets, we
leverage them to identify optimal hyperparameters across model architectures.</p>
</section>
<section id="post-training">
<h2>Post-training<a class="headerlink" href="#post-training" title="Link to this heading">#</a></h2>
<p>Qwen 2.5 introduces two significant advancements in its post-training design compared to Qwen 2:</p>
<ol class="arabic simple">
<li><p>Expanded Supervised Fine-tuning Data Coverage: The supervised fine-tuning process leverages
a massive dataset comprising millions of high-quality examples.</p></li>
<li><p>Two-stage Reinforcement Learning: The reinforcement learning (RL) process in Qwen 2.5 is
divided into two distinct stages: Offline RL and Online RL.</p>
<ul class="simple">
<li><p>Offline RL: This stage focuses on developing capabilities that are challenging for the reward
model to evaluate, such as reasoning, factuality, and instruction-following.</p></li>
<li><p>Online RL: The Online RL phase leverages the reward model’s ability to detect nuances in
output quality.</p></li>
</ul>
</li>
</ol>
<section id="supervised-fine-tuning">
<h3>Supervised Fine-tuning<a class="headerlink" href="#supervised-fine-tuning" title="Link to this heading">#</a></h3>
<p>We detail the key enhancements made during the SFT phase of Qwen2.5, focusing on
several critical areas:</p>
<p><strong>Coding:</strong> To enhance coding capabilities, we incorporate the instruction tuning data of Qwen2.5-
Coder. We expand our instruction dataset by synthesizing new examples from code-related Q&amp;A
websites and gathering algorithmic code snippets from GitHub. A <code class="docutils literal notranslate"><span class="pre">comprehensive</span> <span class="pre">multilingual</span> <span class="pre">sandbox</span></code> is used to perform static code checking and validate code snippets through automated
unit testing, ensuring code quality and correctness.</p>
</section>
<section id="offline-reinforcement-learning">
<h3>Offline Reinforcement Learning<a class="headerlink" href="#offline-reinforcement-learning" title="Link to this heading">#</a></h3>
<p>In this study, we focus on objective query domains such as mathematics,
coding, instruction following, and logical reasoning, where obtaining accurate evaluations can be complex.
In the previous phase, we extensively employ strategies like <code class="docutils literal notranslate"><span class="pre">execution</span> <span class="pre">feedback</span></code> and answer matching to
ensure the quality of responses. For the current phase, we reuse that pipeline, employing the SFT model
to resample responses for a new set of queries. Responses that pass our quality checks are used as positive
examples, while those that fail are treated as negative examples for Direct Preference Optimization (DPO<span id="id9">[<a class="reference internal" href="../reference.html#id32" title="Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn. Direct preference optimization: your language model is secretly a reward model. 2024. URL: https://arxiv.org/abs/2305.18290, arXiv:2305.18290.">RSM+24</a>]</span>). To further enhance the reliability and accuracy of the training signals, we
make use of both <code class="docutils literal notranslate"><span class="pre">human</span> <span class="pre">and</span> <span class="pre">automated</span> <span class="pre">review</span></code> processes.</p>
</section>
<section id="online-reinforcement-learning">
<h3>Online Reinforcement Learning<a class="headerlink" href="#online-reinforcement-learning" title="Link to this heading">#</a></h3>
<p>To develop a robust reward model for online RL, we adhere to a set of carefully defined labeling criteria:</p>
<ul class="simple">
<li><p>Truthfulness</p></li>
<li><p>Helpfulness</p></li>
<li><p>Conciseness</p></li>
<li><p>Relevance</p></li>
<li><p>Harmlessness</p></li>
<li><p>Debiasing</p></li>
</ul>
<p>The queries utilized to train the reward model are drawn from two distinct datasets: publicly available
open-source data and a proprietary query set characterized by higher complexity. Responses are generated
from checkpoints of the Qwen models, which have been fine-tuned using different methods—SFT,
DPO, and RL—at various stages of training. To introduce diversity, those responses are sampled at
<code class="docutils literal notranslate"><span class="pre">different</span> <span class="pre">temperature</span> <span class="pre">settings</span></code>. Preference pairs are created through both human and automated labeling
processes, and the training data for DPO is also integrated into this dataset.</p>
<p>In our online reinforcement learning (RL) framework, we employ <a class="reference internal" href="../preference/grpo.html#grpo"><span class="std std-ref">Group Relative Policy Optimization</span></a>. <code class="docutils literal notranslate"><span class="pre">The</span> <span class="pre">query</span> <span class="pre">set</span> <span class="pre">utilized</span> <span class="pre">for</span> <span class="pre">training</span> <span class="pre">the</span> <span class="pre">reward</span> <span class="pre">model</span> <span class="pre">is</span> <span class="pre">identical</span> <span class="pre">to</span> <span class="pre">the</span> <span class="pre">one</span> <span class="pre">used</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">RL</span> <span class="pre">training</span> <span class="pre">phase</span></code>. The sequence in which queries are processed during training is determined by
the variance of their response scores, as evaluated by the reward model. Specifically, queries with higher
variance in response scores are prioritized to ensure more effective learning. We sample 8 responses
for each query.</p>
</section>
</section>
<section id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Link to this heading">#</a></h2>
<section id="base-models">
<h3>Base Models<a class="headerlink" href="#base-models" title="Link to this heading">#</a></h3>
<figure class="align-default">
<img alt="../_images/qwen25-1.png" src="../_images/qwen25-1.png" />
</figure>
</section>
<section id="instruction-tuned-model">
<h3>Instruction-tuned Model<a class="headerlink" href="#instruction-tuned-model" title="Link to this heading">#</a></h3>
<figure class="align-default">
<img alt="../_images/qwen25-2.png" src="../_images/qwen25-2.png" />
</figure>
</section>
</section>
<section id="takeaway">
<h2>Takeaway<a class="headerlink" href="#takeaway" title="Link to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Prompts:</p>
<ul class="simple">
<li><p>publicly available open-source data</p></li>
<li><p>algorithmic code snippets from GitHub</p></li>
<li><p>synthesizing new examples from code-related Q&amp;A websites</p></li>
<li><p>proprietary query set characterized by higher complexity</p></li>
</ul>
<p>Check correctness:</p>
<ul class="simple">
<li><p>comprehensive multilingual sandbox</p></li>
<li><p>human and automated review</p></li>
<li><p>a set of carefully defined labeling criteria</p></li>
</ul>
<p>Tips:</p>
<ul class="simple">
<li><p>sample using different models and temperature settings</p></li>
<li><p>the query set utilized for training the reward model is identical to the one used in the RL training phase</p></li>
<li><p>two stage RL: offline DPO and online GRPO</p></li>
</ul>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./models"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="llama3-source-code.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Llama 3 Source Code</p>
      </div>
    </a>
    <a class="right-next"
       href="qwen25-coder.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Qwen2.5-Coder</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-tokenizer">Architecture &amp; Tokenizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pre-training">Pre-training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#post-training">Post-training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">Supervised Fine-tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#offline-reinforcement-learning">Offline Reinforcement Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#online-reinforcement-learning">Online Reinforcement Learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation">Evaluation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#base-models">Base Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-tuned-model">Instruction-tuned Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#takeaway">Takeaway</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By newfacade
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=3ee479438cf8b5e0d341"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=3ee479438cf8b5e0d341"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>