Search.setIndex({"alltitles": {"2D case": [[110, "d-case"], [111, "d-case"]], "A Recipe for Instruction Data": [[65, "a-recipe-for-instruction-data"]], "AGENTLESS": [[1, "agentless"]], "AGENTLESS Approach": [[1, "agentless-approach"]], "API-Bank": [[2, "api-bank"]], "APPS": [[36, "apps"]], "ASCII": [[114, "ascii"]], "ASCII,UNICODE,UTF8": [[114, "ascii-unicode-utf8"]], "Ablation of Attention Mechanisms": [[108, "ablation-of-attention-mechanisms"]], "Ablation of MHA, GQA, and MQA": [[108, "ablation-of-mha-gqa-and-mqa"]], "Ablations on Data Diversity, Quality, and Quantity": [[99, "ablations-on-data-diversity-quality-and-quantity"]], "Absolute position embedding": [[111, "absolute-position-embedding"]], "Active Exploration with a Point Estimate": [[73, "active-exploration-with-a-point-estimate"]], "Active Exploration with an ENN": [[73, "active-exploration-with-an-enn"]], "Active Learning": [[96, "active-learning"]], "Adaptive Margin": [[85, "adaptive-margin"]], "Additional insights": [[54, "additional-insights"]], "Advantage Normalization": [[79, "advantage-normalization"]], "Agent": [[0, "agent"]], "Aider Polyglot": [[15, "aider-polyglot"]], "Aligning Language Models with Judgments": [[76, "aligning-language-models-with-judgments"]], "Alignment": [[56, "alignment"], [57, "alignment"]], "Alignment Benchmarks": [[16, "alignment-benchmarks"]], "Alignment Data": [[99, "alignment-data"]], "Alignment Effect on Non-Determinism": [[48, "alignment-effect-on-non-determinism"]], "AlphaCode": [[35, "alphacode"], [52, "alphacode"]], "AlphaCode 2": [[53, "alphacode-2"]], "AlphaCodium": [[54, "alphacodium"]], "An example cell": [[46, "an-example-cell"]], "Analyze and Leverage Diverse Data to its Fullest Potential": [[85, "analyze-and-leverage-diverse-data-to-its-fullest-potential"]], "Appendix": [[71, "appendix"]], "Approach": [[11, "approach"], [12, "approach"], [52, "approach"], [59, "approach"]], "Architecture": [[57, "architecture"], [58, "architecture"], [59, "architecture"]], "Architecture & Tokenizer": [[64, "architecture-tokenizer"]], "Arena-Hard": [[16, "arena-hard"]], "ArmoRM-MoE": [[68, "armorm-moe"]], "Assessment Pipeline": [[73, "assessment-pipeline"]], "Attention": [[9, "attention"], [62, "attention"], [62, "id1"], [63, "attention"], [63, "id1"]], "Attention Is All You Need": [[9, "attention-is-all-you-need"]], "Background": [[111, "background"]], "Background: Rotary Position Embedding (RoPE)": [[106, "background-rotary-position-embedding-rope"], [107, "background-rotary-position-embedding-rope"]], "Background: The REINFORCE Algorithm": [[79, "background-the-reinforce-algorithm"]], "Base": [[8, "base"]], "Base Models": [[64, "base-models"], [65, "base-models"], [96, "base-models"]], "Basic Architecture": [[58, "basic-architecture"]], "Batch Normalization": [[109, "batch-normalization"]], "BatchNorm": [[62, "batchnorm"]], "Benchmark Construction": [[17, "benchmark-construction"], [29, "benchmark-construction"]], "Benchmark Statistics": [[17, "benchmark-statistics"]], "Benchmarking NL-Oriented Instructions to Code Generation": [[17, "benchmarking-nl-oriented-instructions-to-code-generation"]], "Benchmarks": [[14, "benchmarks"]], "BigCodeBench": [[17, "bigcodebench"]], "Boosting Reward Quality with Principles": [[70, "boosting-reward-quality-with-principles"]], "Byte Pair Encoding (BPE)": [[104, "byte-pair-encoding-bpe"]], "CRUXEval": [[19, "cruxeval"]], "Capabilities": [[61, "capabilities"]], "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [[90, "chain-of-thought-prompting-elicits-reasoning-in-large-language-models"]], "Charting the Infinite Data Limit and Overfitting": [[49, "charting-the-infinite-data-limit-and-overfitting"]], "Chat Dialog Format": [[61, "chat-dialog-format"]], "ChatFormat": [[62, "chatformat"]], "Citations": [[45, "citations"]], "Classification Task Identification": [[28, "classification-task-identification"], [40, "classification-task-identification"]], "Clip-Higher": [[69, "clip-higher"]], "Clustering": [[52, "clustering"], [53, "clustering"]], "Code": [[61, "code"]], "Code Alpaca": [[18, "code-alpaca"], [18, "id1"], [37, "code-alpaca"], [37, "id1"]], "Code Correctness Evaluation: HumanEval(+) or MBPP(+)": [[20, "code-correctness-evaluation-humaneval-or-mbpp"]], "Code Llama": [[55, "code-llama"]], "Code Llama: Specializing Llama 2 for code": [[55, "code-llama-specializing-llama-2-for-code"]], "Code-Oriented Design Concepts": [[54, "code-oriented-design-concepts"]], "CodeAct": [[3, "codeact"]], "CodeAct Benefits from Multi-turn Interactions and Existing Software Packages": [[3, "codeact-benefits-from-multi-turn-interactions-and-existing-software-packages"]], "CodeAct Gets More Done with Fewer Interactions": [[3, "codeact-gets-more-done-with-fewer-interactions"]], "CodeAct Makes LLMs Better Agents": [[3, "codeact-makes-llms-better-agents"]], "CodeAct Shows the Promise as a Strong Tool Use Framework": [[3, "codeact-shows-the-promise-as-a-strong-tool-use-framework"]], "CodeContests fine-tuning dataset": [[35, "codecontests-fine-tuning-dataset"]], "Cold Start": [[92, "cold-start"]], "Communication Balance Loss": [[105, "communication-balance-loss"]], "Comparison Between MLA and MHA": [[108, "comparison-between-mla-and-mha"]], "Comparison of Key-Value Cache": [[108, "comparison-of-key-value-cache"]], "Comparisons of Different RM approaches": [[70, "comparisons-of-different-rm-approaches"]], "Constitutional AI: Harmlessness from AI Feedback": [[80, "constitutional-ai-harmlessness-from-ai-feedback"]], "Contents": [[32, "contents"], [33, "contents"]], "Create a notebook with MyST Markdown": [[46, "create-a-notebook-with-myst-markdown"]], "Critiques, Revisions, and Supervised Learning": [[80, "critiques-revisions-and-supervised-learning"]], "DAPO": [[69, "dapo"], [69, "id1"]], "DPO": [[71, "dpo"]], "DPOP": [[72, "dpop"], [72, "id1"]], "Data": [[18, "data"], [34, "data"], [37, "data"]], "Data Collection": [[56, "data-collection"], [96, "data-collection"]], "Data Composition": [[39, "data-composition"], [65, "data-composition"]], "Data Construction": [[57, "data-construction"], [58, "data-construction"]], "Data Generation": [[28, "data-generation"], [40, "data-generation"]], "Data Mixture": [[65, "data-mixture"]], "Data Processing and Quality Control": [[61, "data-processing-and-quality-control"]], "Data Synthesis": [[17, "data-synthesis"]], "Dataset": [[13, "dataset"], [55, "dataset"], [69, "dataset"], [75, "dataset"]], "Datasets": [[52, "datasets"]], "Decontamination": [[39, "decontamination"], [65, "decontamination"]], "Decoupled Rotary Position Embedding": [[108, "decoupled-rotary-position-embedding"]], "DeepCoder": [[91, "deepcoder"]], "DeepSeek V3": [[58, "deepseek-v3"]], "DeepSeek-Coder-V2": [[56, "deepseek-coder-v2"]], "DeepSeek-GRM": [[70, "deepseek-grm"]], "DeepSeek-R1": [[92, "deepseek-r1"]], "DeepSeek-R1-Zero: Reinforcement Learning on the Base Model": [[92, "deepseek-r1-zero-reinforcement-learning-on-the-base-model"]], "DeepSeek-R1: Reinforcement Learning with Cold Start": [[92, "deepseek-r1-reinforcement-learning-with-cold-start"]], "DeepSeek-V2": [[57, "deepseek-v2"]], "DeepSeekMoE": [[105, "deepseekmoe"]], "Derivation of \\pi_{r}": [[71, "derivation-of-pi-r"]], "Design Principles of API-Bank": [[2, "design-principles-of-api-bank"]], "Device-Level Balance Loss": [[105, "device-level-balance-loss"]], "Direct Preference Optimization": [[61, "direct-preference-optimization"], [71, "direct-preference-optimization"]], "Direct extrapolation": [[107, "direct-extrapolation"]], "Discussion": [[57, "discussion"]], "Dynamic Sampling": [[69, "dynamic-sampling"]], "Dynamic Scaling - \u201cDynamic NTK\u201d interpolation": [[106, "dynamic-scaling-dynamic-ntk-interpolation"]], "Efficient Exploration for LLMs": [[73, "efficient-exploration-for-llms"]], "Embeddings and Softmax": [[9, "embeddings-and-softmax"]], "Empirical Results": [[73, "empirical-results"]], "Empirical Results and Basic Power Laws": [[49, "empirical-results-and-basic-power-laws"]], "Encoder and Decoder Stacks": [[9, "encoder-and-decoder-stacks"]], "Epistemic Neural Network": [[73, "epistemic-neural-network"]], "EvalPlus": [[20, "evalplus"]], "Evaluation": [[12, "evaluation"], [17, "evaluation"], [24, "evaluation"], [31, "evaluation"], [38, "evaluation"], [43, "evaluation"], [52, "evaluation"], [53, "evaluation"], [64, "evaluation"], [65, "evaluation"], [81, "evaluation"]], "Evaluation Results": [[57, "evaluation-results"], [57, "id3"], [58, "evaluation-results"], [58, "id4"]], "Evaluation System of API-Bank": [[2, "evaluation-system-of-api-bank"]], "Evaluation of LLMs Should Not Ignore Non-Determinism": [[48, "evaluation-of-llms-should-not-ignore-non-determinism"]], "Evol-Instruct": [[31, "evol-instruct"], [43, "evol-instruct"]], "Evol-Instruct Prompts for Code": [[31, "evol-instruct-prompts-for-code"], [43, "evol-instruct-prompts-for-code"]], "Experimental Results": [[48, "experimental-results"], [56, "experimental-results"]], "Experimental Setup": [[29, "experimental-setup"], [79, "experimental-setup"], [86, "experimental-setup"]], "Experimentation Pipeline": [[73, "experimentation-pipeline"]], "Experiments": [[11, "experiments"], [69, "experiments"], [86, "experiments"], [107, "experiments"]], "Expert-Level Balance Loss": [[105, "expert-level-balance-loss"]], "Exploration Algorithms": [[73, "exploration-algorithms"]], "Extending context window of LLMs": [[106, "extending-context-window-of-llms"]], "Extending context window of large language models via position interpolation": [[107, "extending-context-window-of-large-language-models-via-position-interpolation"]], "FFN": [[112, "ffn"]], "Failure Mode of DPO": [[72, "failure-mode-of-dpo"]], "Features of Swe-Bench": [[29, "features-of-swe-bench"]], "FeedForward": [[62, "feedforward"], [63, "feedforward"]], "Filtering": [[52, "filtering"], [53, "filtering"]], "Filtering and Postprocessing": [[28, "filtering-and-postprocessing"], [40, "filtering-and-postprocessing"]], "Fine-Grained Expert Segmentation": [[105, "fine-grained-expert-segmentation"]], "Fine-tuning": [[52, "fine-tuning"]], "Finetuning the LM to Follow Instructions": [[28, "finetuning-the-lm-to-follow-instructions"], [40, "finetuning-the-lm-to-follow-instructions"]], "Flipping the Labels": [[85, "flipping-the-labels"]], "Flow stages": [[54, "flow-stages"]], "Formulation": [[110, "formulation"], [111, "formulation"]], "Framework": [[10, "framework"]], "From MLE to RL framework": [[47, "from-mle-to-rl-framework"]], "Functional Correctness": [[22, "functional-correctness"]], "GB2312\u3001GBK\u7b49\u5176\u4ed6\u7f16\u7801": [[114, "gb2312gbk"]], "GOLD": [[47, "gold"]], "GPQA": [[25, "gpqa"]], "GPT": [[10, "gpt"]], "GPT2": [[11, "gpt2"]], "GPT3": [[12, "gpt3"]], "GRPO": [[74, "id3"]], "GSM8K": [[25, "gsm8k"]], "Gated Linear Units (GLU) and Variants": [[112, "gated-linear-units-glu-and-variants"]], "General Benchmarks": [[21, "general-benchmarks"]], "General form": [[110, "general-form"], [111, "general-form"]], "Generation": [[62, "generation"]], "Generator": [[96, "generator"]], "Gradient of DPO Loss": [[71, "gradient-of-dpo-loss"]], "Group Relative Policy Optimization": [[74, "group-relative-policy-optimization"]], "High-level methodology": [[13, "high-level-methodology"]], "How Various Factors Influence Non-Determinism?": [[48, "how-various-factors-influence-non-determinism"]], "How to Better Model Human Preference?": [[85, "how-to-better-model-human-preference"]], "Human Curation": [[17, "human-curation"]], "Human Evaluation": [[99, "human-evaluation"]], "Human Preference Data Collection": [[60, "human-preference-data-collection"]], "HumanEval": [[22, "humaneval"]], "Hyper-Parameters": [[57, "hyper-parameters"]], "IFEval": [[16, "ifeval"]], "Impacts of Different Data on RM Performance": [[85, "impacts-of-different-data-on-rm-performance"]], "Implementation Details": [[24, "implementation-details"], [38, "implementation-details"]], "Incorporating Judgments for Alignment": [[76, "incorporating-judgments-for-alignment"]], "Inference-Time Scaling with SPCT": [[70, "inference-time-scaling-with-spct"]], "Infilling": [[55, "infilling"]], "Initialization": [[86, "initialization"], [87, "initialization"]], "Input Format": [[29, "input-format"]], "Input Representation": [[11, "input-representation"]], "Installation": [[23, "installation"]], "Instance Generation": [[28, "instance-generation"], [40, "instance-generation"]], "Instruct GPT": [[75, "instruct-gpt"]], "Instruct Models": [[65, "instruct-models"]], "InstructGPT": [[13, "instructgpt"]], "Instruction Following Ability Results": [[86, "instruction-following-ability-results"]], "Instruction Following Training": [[86, "instruction-following-training"]], "Instruction Generation": [[28, "instruction-generation"], [40, "instruction-generation"]], "Instruction Selection": [[87, "instruction-selection"]], "Instruction fine-tuning": [[55, "instruction-fine-tuning"]], "Instruction-tuned Model": [[64, "instruction-tuned-model"]], "Introduction": [[24, "introduction"], [38, "introduction"], [44, "introduction"], [50, "introduction"], [55, "introduction"], [59, "introduction"], [76, "introduction"], [82, "introduction"], [107, "introduction"]], "Iterative Fine-Tuning": [[60, "iterative-fine-tuning"]], "Iterative RL with GRPO": [[74, "iterative-rl-with-grpo"]], "Iterative Rounds": [[61, "iterative-rounds"]], "Iterative Training": [[87, "iterative-training"]], "Judgment Annotation": [[87, "judgment-annotation"]], "LIMA: Less Is More for Alignment": [[99, "lima-less-is-more-for-alignment"]], "LORA": [[116, "lora"]], "Label Smoothing": [[85, "label-smoothing"]], "Large scale sampling": [[52, "large-scale-sampling"]], "Large-scale Supervision": [[96, "large-scale-supervision"]], "Layer Normalization": [[109, "layer-normalization"]], "LayerNorm": [[62, "layernorm"]], "Learn more": [[45, "learn-more"]], "Learning Pipeline": [[73, "learning-pipeline"]], "Learning from Contrasting": [[76, "learning-from-contrasting"]], "Let\u2019s Verify Step by Step": [[96, "lets-verify-step-by-step"]], "LiveCodeBench": [[23, "livecodebench"]], "Llama": [[59, "llama"]], "Llama 2": [[60, "llama-2"]], "Llama 3": [[61, "llama-3"]], "Llama 3 Source Code": [[63, "llama-3-source-code"]], "Llama Factory": [[115, "llama-factory"]], "Llama implementation": [[107, "llama-implementation"]], "Llama3": [[62, "llama3"]], "Load Balance Consideration": [[105, "load-balance-consideration"]], "Logic-RL": [[93, "logic-rl"]], "Long Context Extension": [[58, "long-context-extension"]], "Long context fine-tuning": [[55, "long-context-fine-tuning"]], "Loss": [[71, "loss"]], "Loss of High Frequency information - \u201cNTK-aware\u201d interpolation": [[106, "loss-of-high-frequency-information-ntk-aware-interpolation"]], "Loss of Relative Local Distances - \u201cNTK-by-parts\u201d interpolation": [[106, "loss-of-relative-local-distances-ntk-by-parts-interpolation"]], "Low-Rank Compression for Queries": [[108, "low-rank-compression-for-queries"]], "Low-Rank Key-Value Joint Compression": [[108, "low-rank-key-value-joint-compression"]], "MATH": [[25, "math"]], "MATH 500": [[25, "math-500"]], "MBPP": [[26, "mbpp"]], "MMLU": [[21, "mmlu"]], "MMLU-Pro": [[21, "mmlu-pro"]], "MMLU-Redux": [[21, "mmlu-redux"]], "Magicoder": [[24, "magicoder"], [38, "magicoder"]], "Main Result": [[80, "main-result"]], "Main Results": [[69, "main-results"], [80, "main-results"]], "Markdown Files": [[45, "markdown-files"]], "Math & Science Benchmarks": [[25, "math-science-benchmarks"]], "Measuring the Strength of Preferences": [[85, "measuring-the-strength-of-preferences"]], "Method": [[80, "method"], [80, "id1"], [87, "method"]], "Methodology": [[50, "methodology"], [81, "methodology"]], "Methods": [[96, "methods"]], "Methods and experimental details": [[13, "methods-and-experimental-details"]], "Mini-Batch Updates": [[79, "mini-batch-updates"]], "Model": [[11, "model"], [62, "model"], [63, "model"]], "Model Accuracy VS. Augmented Data Count": [[102, "model-accuracy-vs-augmented-data-count"]], "Model Accuracy VS. Pre-training Loss": [[102, "model-accuracy-vs-pre-training-loss"]], "Model Accuracy VS. Supervised Data Count": [[102, "model-accuracy-vs-supervised-data-count"]], "Model Architecture": [[9, "model-architecture"]], "Model Averaging": [[61, "model-averaging"]], "Model Fine-tuning (Iterative Training)": [[87, "model-fine-tuning-iterative-training"]], "Model and Architectures": [[12, "model-and-architectures"]], "Modeling": [[61, "modeling"]], "Models": [[13, "models"], [51, "models"]], "Multi-Head Attention": [[9, "multi-head-attention"]], "Multi-Head Latent Attention": [[108, "multi-head-latent-attention"]], "Multi-Token Prediction": [[58, "multi-token-prediction"]], "NLP\u5b9e\u4f8b": [[104, "nlp"]], "Normalization": [[62, "normalization"], [109, "normalization"]], "Notebooks with MyST Markdown": [[46, "notebooks-with-myst-markdown"]], "OOD Generalization": [[96, "ood-generalization"]], "OSS-INSTRUCT: Instruction Tuning from Open Source": [[24, "oss-instruct-instruction-tuning-from-open-source"], [38, "oss-instruct-instruction-tuning-from-open-source"]], "Off-policy policy gradient": [[47, "off-policy-policy-gradient"]], "Offline Reinforcement Learning": [[64, "offline-reinforcement-learning"]], "Online Reinforcement Learning": [[64, "online-reinforcement-learning"]], "OpenCoder": [[39, "opencoder"]], "OpenRLHF": [[77, "openrlhf"], [117, "openrlhf"]], "Optimizer": [[59, "optimizer"]], "Outcome Supervision RL with GRPO": [[74, "outcome-supervision-rl-with-grpo"]], "Outcome-supervised Reward Models (ORMs)": [[96, "outcome-supervised-reward-models-orms"]], "Overall Self-Alignment Algorithm": [[86, "overall-self-alignment-algorithm"]], "Overall System": [[53, "overall-system"]], "Overlong Reward Shaping": [[69, "overlong-reward-shaping"]], "Overview": [[54, "overview"]], "PPO": [[78, "ppo"]], "PPO Review": [[74, "ppo-review"]], "PPO implementation detail": [[77, "ppo-implementation-detail"]], "PPO-Clip Integration": [[79, "ppo-clip-integration"]], "Parameter and Compute Scaling of Transformers": [[49, "parameter-and-compute-scaling-of-transformers"]], "Passive Exploration": [[73, "passive-exploration"]], "Performance with Dataset Size and Compute": [[49, "performance-with-dataset-size-and-compute"]], "Performance with Non-Embedding Parameter Count N": [[49, "performance-with-non-embedding-parameter-count-n"]], "Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero": [[92, "performance-self-evolution-process-and-aha-moment-of-deepseek-r1-zero"]], "Point Estimate": [[73, "point-estimate"]], "Policy and Fine-Tuning": [[53, "policy-and-fine-tuning"]], "Position interpolation": [[106, "position-interpolation"]], "Position-wise Feed-Forward Networks": [[9, "position-wise-feed-forward-networks"]], "Positional Encoding": [[9, "positional-encoding"]], "Positional Interpolation": [[107, "positional-interpolation"]], "Post Training": [[39, "post-training"]], "Post-Training": [[58, "post-training"], [61, "post-training"]], "Post-trained Language Model": [[61, "post-trained-language-model"]], "Post-training": [[64, "post-training"], [65, "post-training"]], "Post-training Data": [[61, "post-training-data"]], "Pre-Training": [[57, "pre-training"], [58, "pre-training"]], "Pre-trained Language Model": [[61, "pre-trained-language-model"]], "Pre-training": [[64, "pre-training"], [65, "pre-training"]], "Pre-training data": [[59, "pre-training-data"]], "Preference Data": [[61, "preference-data"]], "Preference Labeling with LLMs": [[81, "preference-labeling-with-llms"]], "Preference Optimization": [[67, "preference-optimization"]], "Preliminaries": [[71, "preliminaries"], [84, "preliminaries"], [85, "preliminaries"]], "Preliminaries and Problem Setup": [[95, "preliminaries-and-problem-setup"]], "Preliminaries: Mixture-of-Experts for Transformers": [[105, "preliminaries-mixture-of-experts-for-transformers"]], "Preliminaries: Standard Multi-Head Attention": [[108, "preliminaries-standard-multi-head-attention"]], "Preliminary": [[69, "preliminary"], [111, "preliminary"]], "Pretrain": [[60, "pretrain"]], "Pretraining": [[39, "pretraining"]], "Pretraining Data": [[39, "pretraining-data"]], "Problem Setting": [[76, "problem-setting"]], "Process Supervision RL with GRPO": [[74, "process-supervision-rl-with-grpo"]], "Process vs Outcome Supervision": [[96, "process-vs-outcome-supervision"]], "Process-supervised Reward Models (PRMs)": [[96, "process-supervised-reward-models-prms"]], "Prompting Techniques": [[81, "prompting-techniques"]], "Properties of RoPE": [[111, "properties-of-rope"]], "Proposed approach": [[111, "proposed-approach"]], "Quick Start": [[20, "quick-start"]], "Quickly add YAML metadata for MyST Notebooks": [[46, "quickly-add-yaml-metadata-for-myst-notebooks"]], "Qwen 2.5": [[64, "qwen-2-5"]], "Qwen2.5-Coder": [[65, "qwen2-5-coder"]], "Qwen3": [[66, "qwen3"]], "REACT": [[4, "react"]], "REINFORCE++": [[79, "reinforce"]], "REINFORCE++ Enhancements": [[79, "reinforce-enhancements"]], "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED": [[100, "rethinking-data-selection-at-scale-random-selection-is-almost-all-you-need"]], "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold": [[101, "rl-on-incorrect-synthetic-data-scales-the-efficiency-of-llm-math-reasoning-by-eight-fold"]], "RLAIF vs. RLHF": [[81, "rlaif-vs-rlhf"], [81, "id1"]], "RLCD": [[82, "rlcd"], [82, "id1"]], "RLHF": [[60, "rlhf"]], "RMSNorm": [[62, "rmsnorm"], [63, "rmsnorm"], [109, "rmsnorm"]], "RS-DPO": [[83, "rs-dpo"]], "RSO": [[84, "rso"]], "RSO APPROACH": [[84, "rso-approach"]], "Reasoning": [[89, "reasoning"]], "Reasoning data curation to create s1K": [[94, "reasoning-data-curation-to-create-s1k"]], "Reasoning-oriented Reinforcement Learning": [[92, "reasoning-oriented-reinforcement-learning"]], "References": [[97, "references"]], "Reflexion": [[5, "reflexion"]], "Reinforcement Learning": [[56, "reinforcement-learning"], [57, "reinforcement-learning"], [58, "reinforcement-learning"]], "Reinforcement Learning Algorithm": [[92, "reinforcement-learning-algorithm"]], "Reinforcement Learning for all Scenarios": [[92, "reinforcement-learning-for-all-scenarios"]], "Reinforcement Learning from AI Feedback": [[80, "reinforcement-learning-from-ai-feedback"], [81, "reinforcement-learning-from-ai-feedback"]], "Reinforcement learning (RL)": [[75, "reinforcement-learning-rl"]], "Rejection Sampling and Supervised Fine-Tuning": [[92, "rejection-sampling-and-supervised-fine-tuning"]], "Rejective Fine-Tuning (Cold Start)": [[70, "rejective-fine-tuning-cold-start"]], "Related Work": [[88, "related-work"]], "Removing KL Divergence": [[69, "removing-kl-divergence"]], "Response Pair Construction": [[87, "response-pair-construction"]], "Results": [[7, "results"], [13, "results"], [29, "results"], [61, "results"], [81, "results"], [94, "results"]], "Results on Reward Modeling Benchmarks": [[70, "results-on-reward-modeling-benchmarks"]], "Retrieval-Based Approach": [[29, "retrieval-based-approach"]], "Reward": [[47, "reward"]], "Reward Model Architectures and Training": [[73, "reward-model-architectures-and-training"]], "Reward Modeling": [[60, "reward-modeling"], [61, "reward-modeling"], [92, "reward-modeling"]], "Reward Modeling Ability Results": [[86, "reward-modeling-ability-results"]], "Reward Normalization and Clipping": [[79, "reward-normalization-and-clipping"]], "Reward modeling (RM)": [[75, "reward-modeling-rm"]], "RewardBench": [[27, "rewardbench"]], "RoPE": [[62, "rope"], [63, "rope"], [110, "rope"]], "RoPE \u7684\u8fdc\u7a0b\u8870\u51cf": [[106, "rope"]], "Rotary Positional Embeddings (RoPE)": [[111, "rotary-positional-embeddings-rope"]], "Rule-Based RL": [[70, "rule-based-rl"]], "Rule-based Reward Modeling": [[69, "rule-based-reward-modeling"]], "SCoRe: Self-Correction via Multi-Turn Reinforcement Learning": [[95, "score-self-correction-via-multi-turn-reinforcement-learning"]], "SELF-INSTRUCT": [[28, "self-instruct"], [40, "self-instruct"]], "SFT": [[60, "sft"], [98, "sft"], [115, "sft"], [117, "sft"]], "SFT Data": [[61, "sft-data"]], "STATISTICAL REJECTION SAMPLING ALGORITHM": [[84, "statistical-rejection-sampling-algorithm"]], "SWE-Llama: Fine-Tuning Codellama for SWE-bench": [[29, "swe-llama-fine-tuning-codellama-for-swe-bench"]], "SWE-agent": [[7, "swe-agent"]], "SWE-agent: Designing an ACI for Software Engineering": [[7, "swe-agent-designing-an-aci-for-software-engineering"]], "SWE-bench": [[29, "swe-bench"], [29, "id1"]], "SWE-bench Lite": [[29, "swe-bench-lite"]], "Sample Roles and Directives": [[45, "sample-roles-and-directives"]], "Sampling": [[53, "sampling"]], "Scaled Dot-Product Attention": [[9, "scaled-dot-product-attention"]], "Scaling Effect on Non-Determinism": [[48, "scaling-effect-on-non-determinism"]], "Scaling Laws for Neural Language Models": [[49, "scaling-laws-for-neural-language-models"]], "Scaling Laws with Model Size and Training Time": [[49, "scaling-laws-with-model-size-and-training-time"]], "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": [[102, "scaling-relationship-on-learning-mathematical-reasoning-with-large-language-models"]], "Scoring Model": [[53, "scoring-model"]], "Search-R1": [[6, "search-r1"]], "Secrets of RLHF in Large Language Models: Reward Modeling": [[85, "secrets-of-rlhf-in-large-language-models-reward-modeling"]], "Self-Instruction Creation": [[86, "self-instruction-creation"]], "Self-Principled Critique Tuning (SPCT)": [[70, "self-principled-critique-tuning-spct"]], "Self-Rewarding Language Models": [[86, "self-rewarding-language-models"]], "Self-Taught Evaluators": [[87, "self-taught-evaluators"]], "Self-Training for Preference Modeling": [[88, "self-training-for-preference-modeling"]], "Semi-Automatic Program Refactoring and Testing Case Generation": [[17, "semi-automatic-program-refactoring-and-testing-case-generation"]], "SentencePiece": [[113, "sentencepiece"]], "Shared Expert Isolation": [[105, "shared-expert-isolation"]], "Small-scale Synthetic Supervision": [[96, "small-scale-synthetic-supervision"]], "Stage I: Training a Model Initialization to Prevent Collapse": [[95, "stage-i-training-a-model-initialization-to-prevent-collapse"]], "Stage II: Multi-Turn RL with Reward Shaping": [[95, "stage-ii-multi-turn-rl-with-reward-shaping"]], "Stage-1: Multi-Objective Reward Modeling": [[68, "stage-1-multi-objective-reward-modeling"]], "Stage-2: Mixture-of-Experts Aggregation of Reward Objectives": [[68, "stage-2-mixture-of-experts-aggregation-of-reward-objectives"]], "Stanford Alpaca": [[18, "stanford-alpaca"], [37, "stanford-alpaca"]], "Summarization": [[11, "summarization"]], "Supervised Fine-Tuning": [[56, "supervised-fine-tuning"], [57, "supervised-fine-tuning"], [58, "supervised-fine-tuning"]], "Supervised Fine-tuning": [[64, "supervised-fine-tuning"]], "Supervised Finetuning": [[61, "supervised-finetuning"]], "Supervised fine-tuning": [[10, "supervised-fine-tuning"]], "Supervised fine-tuning (SFT)": [[75, "supervised-fine-tuning-sft"]], "Surface Patterns in Non-Determinism Generation?": [[48, "surface-patterns-in-non-determinism-generation"]], "SwiGLU": [[112, "swiglu"]], "SwiGLU activation function": [[62, "swiglu-activation-function"], [63, "swiglu-activation-function"]], "Swish": [[112, "swish"]], "TACO": [[30, "taco"], [41, "taco"]], "Takeaway": [[56, "takeaway"], [57, "takeaway"], [58, "takeaway"], [61, "takeaway"], [64, "takeaway"], [65, "takeaway"], [110, "takeaway"]], "Takeaways": [[85, "takeaways"], [96, "takeaways"]], "Task-specific input transformations": [[10, "task-specific-input-transformations"]], "Techniques": [[103, "techniques"]], "Temperature Effect on Non-Determinism": [[48, "temperature-effect-on-non-determinism"]], "Test-time scaling": [[94, "test-time-scaling"]], "The Agent-Computer Interface": [[7, "the-agent-computer-interface"]], "The Factors of Math Reasoning Ability in Supervised LLM": [[102, "the-factors-of-math-reasoning-ability-in-supervised-llm"]], "The GOLD algorithm": [[47, "the-gold-algorithm"]], "The Need for Interpretable Reward Models": [[68, "the-need-for-interpretable-reward-models"]], "The Proposed Flow": [[54, "the-proposed-flow"]], "Tiktoken": [[62, "tiktoken"]], "Token-Dropping Strategy": [[105, "token-dropping-strategy"]], "Token-Level KL Penalty": [[79, "token-level-kl-penalty"]], "Token-Level Policy Gradient Loss": [[69, "token-level-policy-gradient-loss"]], "Tokenizer": [[62, "tokenizer"], [62, "id2"]], "Training Dataset": [[11, "training-dataset"], [12, "training-dataset"]], "Training Details": [[39, "training-details"], [69, "training-details"]], "Training LIMA": [[99, "training-lima"]], "Training Language Models to Self-Correct via Reinforcement Learning": [[95, "training-language-models-to-self-correct-via-reinforcement-learning"]], "Training Policy": [[65, "training-policy"], [65, "id8"]], "Training Template": [[92, "training-template"]], "Training WizardCoder": [[31, "training-wizardcoder"], [43, "training-wizardcoder"]], "Transformer": [[62, "transformer"], [63, "transformer"]], "Two-stage Instruction-Tuning": [[39, "two-stage-instruction-tuning"]], "UNICODER": [[42, "unicoder"], [42, "id2"]], "UNICODER-INSTRUCT": [[42, "unicoder-instruct"]], "UTF-16\u3001UTF-32\u7b49": [[114, "utf-16utf-32"]], "UTF-8": [[114, "utf-8"]], "Unigram Language Model (ULM)": [[113, "unigram-language-model-ulm"]], "Unpinning Principles from Understanding to Generation": [[70, "unpinning-principles-from-understanding-to-generation"]], "Unsupervised pre-training": [[10, "unsupervised-pre-training"]], "Weak to Strong Generalization": [[50, "weak-to-strong-generalization"]], "West-of-N": [[88, "west-of-n"]], "West-of-N Self-Training": [[88, "west-of-n-self-training"]], "What is CodeAct?": [[3, "what-is-codeact"]], "What is MyST?": [[45, "what-is-myst"]], "What is the Full Potential of Non-Determinism?": [[48, "what-is-the-full-potential-of-non-determinism"]], "Why KV cache": [[108, "why-kv-cache"]], "Why Layer Normalization": [[109, "why-layer-normalization"]], "Why decoder-only": [[10, "why-decoder-only"]], "WizardCoder": [[31, "wizardcoder"], [43, "wizardcoder"]], "WizardLM": [[31, "wizardlm"], [43, "wizardlm"]], "WordPiece": [[113, "wordpiece"]], "WordPiece, ULM and SentencePiece": [[113, "wordpiece-ulm-and-sentencepiece"]], "YaRN": [[106, "id5"]], "YaRN: Efficient ContextWindow Extension of Large Language Models": [[106, "yarn-efficient-contextwindow-extension-of-large-language-models"]], "methodology": [[75, "methodology"]], "s1: Simple test-time scaling": [[94, "s1-simple-test-time-scaling"]], "unicode": [[114, "unicode"]], "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": [[114, "id1"]], "\u521d\u8bc6BPE": [[104, "bpe"]], "\u603b\u7ed3": [[114, "id2"]], "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff1f": [[104, "id2"]], "\u672c\u5730 Evaluate": [[20, "evaluate"], [23, "evaluate"]], "\u7f16\u7801\u548c\u89e3\u7801": [[104, "id1"]], "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": [[106, "id4"]]}, "docnames": ["agent/0", "agent/agentless", "agent/api-bank", "agent/code-act", "agent/react", "agent/reflexion", "agent/search-r1", "agent/swe-agent", "base/0", "base/attention", "base/gpt", "base/gpt2", "base/gpt3", "base/instruct-gpt", "bench/0", "bench/aider", "bench/alignment", "bench/bigcodebench", "bench/code-alpaca", "bench/cruxeval", "bench/evalplus", "bench/general", "bench/humaneval", "bench/livecodebench", "bench/magic", "bench/math-science", "bench/mbpp", "bench/reward-bench", "bench/self-instruct", "bench/swe", "bench/taco", "bench/wizard", "content", "content-Copy1", "data/0", "data/alphacode", "data/apps", "data/code-alpaca", "data/magic", "data/opencoder", "data/self-instruct", "data/taco", "data/unicoder", "data/wizard", "intro", "markdown", "markdown-notebooks", "methodology/gold", "methodology/non-determin", "methodology/scaling-law", "methodology/weak-to-strong", "models/0", "models/alphacode", "models/alphacode2", "models/alphacodium", "models/codellama", "models/deepseek-coder-v2", "models/deepseek-v2", "models/deepseek-v3", "models/llama", "models/llama2", "models/llama3", "models/llama3-code copy", "models/llama3-source-code", "models/qwen25", "models/qwen25-coder", "models/qwen3", "preference/0", "preference/armo", "preference/dapo", "preference/deepseek-grm", "preference/dpo", "preference/dpop", "preference/ee", "preference/grpo", "preference/instruct-gpt", "preference/judge", "preference/openrlhf", "preference/ppo", "preference/reinforce++", "preference/rlaif-1", "preference/rlaif-2", "preference/rlcd", "preference/rs-dpo", "preference/rso", "preference/secret-rm", "preference/self-reward", "preference/self-taught", "preference/west-of-n", "reasoning/0", "reasoning/cot", "reasoning/deepcoder", "reasoning/deepseek-r1", "reasoning/logic-rl", "reasoning/s1", "reasoning/self-correct-rl", "reasoning/verify", "reference", "sft/0", "sft/lima", "sft/random", "sft/rl-eight-fold", "sft/rs", "techniques/0", "techniques/bpe", "techniques/deepseek-moe", "techniques/extending", "techniques/extending-old", "techniques/mla", "techniques/norm", "techniques/rope", "techniques/rope-old", "techniques/swiglu", "techniques/tokenize", "techniques/unicode-utf8", "tools/llama-factory", "tools/lora", "tools/openrlhf"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["agent/0.ipynb", "agent/agentless.ipynb", "agent/api-bank.ipynb", "agent/code-act.ipynb", "agent/react.ipynb", "agent/reflexion.ipynb", "agent/search-r1.ipynb", "agent/swe-agent.ipynb", "base/0.ipynb", "base/attention.ipynb", "base/gpt.ipynb", "base/gpt2.ipynb", "base/gpt3.ipynb", "base/instruct-gpt.ipynb", "bench/0.ipynb", "bench/aider.ipynb", "bench/alignment.ipynb", "bench/bigcodebench.ipynb", "bench/code-alpaca.ipynb", "bench/cruxeval.ipynb", "bench/evalplus.ipynb", "bench/general.ipynb", "bench/humaneval.ipynb", "bench/livecodebench.ipynb", "bench/magic.ipynb", "bench/math-science.ipynb", "bench/mbpp.ipynb", "bench/reward-bench.ipynb", "bench/self-instruct.ipynb", "bench/swe.ipynb", "bench/taco.ipynb", "bench/wizard.ipynb", "content.ipynb", "content-Copy1.ipynb", "data/0.ipynb", "data/alphacode.ipynb", "data/apps.ipynb", "data/code-alpaca.ipynb", "data/magic.ipynb", "data/opencoder.ipynb", "data/self-instruct.ipynb", "data/taco.ipynb", "data/unicoder.ipynb", "data/wizard.ipynb", "intro.md", "markdown.md", "markdown-notebooks.md", "methodology/gold.ipynb", "methodology/non-determin.ipynb", "methodology/scaling-law.ipynb", "methodology/weak-to-strong.ipynb", "models/0.ipynb", "models/alphacode.ipynb", "models/alphacode2.ipynb", "models/alphacodium.ipynb", "models/codellama.ipynb", "models/deepseek-coder-v2.ipynb", "models/deepseek-v2.ipynb", "models/deepseek-v3.ipynb", "models/llama.ipynb", "models/llama2.ipynb", "models/llama3.ipynb", "models/llama3-code copy.ipynb", "models/llama3-source-code.ipynb", "models/qwen25.ipynb", "models/qwen25-coder.ipynb", "models/qwen3.ipynb", "preference/0.ipynb", "preference/armo.ipynb", "preference/dapo.ipynb", "preference/deepseek-grm.ipynb", "preference/dpo.ipynb", "preference/dpop.ipynb", "preference/ee.ipynb", "preference/grpo.ipynb", "preference/instruct-gpt.ipynb", "preference/judge.ipynb", "preference/openrlhf.ipynb", "preference/ppo.ipynb", "preference/reinforce++.ipynb", "preference/rlaif-1.ipynb", "preference/rlaif-2.ipynb", "preference/rlcd.ipynb", "preference/rs-dpo.ipynb", "preference/rso.ipynb", "preference/secret-rm.ipynb", "preference/self-reward.ipynb", "preference/self-taught.ipynb", "preference/west-of-n.ipynb", "reasoning/0.ipynb", "reasoning/cot.ipynb", "reasoning/deepcoder.ipynb", "reasoning/deepseek-r1.ipynb", "reasoning/logic-rl.ipynb", "reasoning/s1.ipynb", "reasoning/self-correct-rl.ipynb", "reasoning/verify.ipynb", "reference.ipynb", "sft/0.ipynb", "sft/lima.ipynb", "sft/random.ipynb", "sft/rl-eight-fold.ipynb", "sft/rs.ipynb", "techniques/0.ipynb", "techniques/bpe.ipynb", "techniques/deepseek-moe.ipynb", "techniques/extending.ipynb", "techniques/extending-old.ipynb", "techniques/mla.ipynb", "techniques/norm.ipynb", "techniques/rope.ipynb", "techniques/rope-old.ipynb", "techniques/swiglu.ipynb", "techniques/tokenize.ipynb", "techniques/unicode-utf8.ipynb", "tools/llama-factory.ipynb", "tools/lora.ipynb", "tools/openrlhf.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [7, 10, 11, 13, 17, 20, 21, 25, 39, 45, 46, 47, 49, 50, 54, 55, 57, 60, 61, 62, 64, 65, 68, 69, 71, 72, 73, 74, 75, 79, 80, 81, 82, 84, 85, 87, 94, 95, 97, 102, 104, 105, 106, 107, 113], "0": [9, 10, 20, 22, 23, 28, 31, 39, 40, 43, 47, 48, 49, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 68, 69, 71, 72, 74, 76, 77, 80, 81, 84, 85, 86, 88, 99, 102, 105, 106, 107, 109, 110, 111, 112, 114, 115, 116], "000": [2, 21, 25, 29, 30, 36, 41, 52, 55, 94, 99], "0000": [107, 114], "0000j": 107, "0001": 114, "0010": 114, "003": [18, 37], "0041": 114, "005": 22, "007f": 114, "0080": 114, "01": [69, 77], "0100j": 107, "012": 69, "01825": [45, 97], "02120": [24, 38, 45, 97], "02155": [45, 97], "02954": [45, 97], "03": 59, "03065": [45, 97], "0314": 16, "03300": [45, 97], "03341": [45, 97], "03374": [45, 97], "03762": [45, 97], "04434": [45, 97], "0461": 107, "04805": [45, 97], "0596": 107, "0596j": 107, "06": 59, "0674": 107, "0674j": 107, "07436": [45, 97], "076": 49, "07911": [45, 97], "07974": [45, 97], "07ff": 114, "08": 69, "0800": 114, "08083": [45, 97], "08361": [45, 97], "08568": [31, 43], "096": [55, 69], "09864": [45, 97], "0xxxxxxx": 114, "1": [1, 2, 9, 10, 13, 16, 18, 20, 22, 23, 24, 28, 29, 30, 31, 33, 37, 38, 39, 40, 41, 42, 43, 45, 47, 48, 49, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 84, 85, 86, 87, 88, 94, 95, 96, 97, 99, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], "10": [3, 20, 23, 25, 36, 39, 48, 49, 53, 55, 56, 57, 59, 61, 65, 69, 74, 81, 85, 104, 105, 114, 115], "100": [7, 11, 18, 21, 22, 37, 39, 53, 55, 65, 68, 73, 96], "1000": [31, 43, 58, 96, 106, 107], "10000": [9, 53, 62, 63, 106, 107, 110, 111], "100000": 77, "10000000": 114, "100k": 57, "10111000": 114, "1024": [65, 77], "102400": 57, "1048576000": 57, "105": 23, "10509": [45, 97], "10560": [28, 40], "106": 23, "107": 23, "10k": 57, "10x": 12, "10xxxxxx": 114, "11": [23, 111], "1106": [24, 38], "110k": [24, 38], "110xxxxx": 114, "110\u8868\u793a\u9700\u8981\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u5f53\u524d\u5b57\u7b26": 114, "1110": 114, "1110xxxx": 114, "1110\u8868\u793a\u9700\u8981\u4e09\u4e2a\u5b57\u8282": 114, "11110xxx": 114, "11110\u8868\u793a\u9700\u8981\u56db\u4e2a\u5b57\u8282": 114, "117": 23, "12": [21, 23, 25, 29, 49, 53, 57, 104, 111], "12000": 115, "12122": [45, 97], "12186": [45, 97], "12288": 57, "123abc\u4e00\u4e8c\u4e09": 114, "125": [12, 23], "128": [57, 77], "128k": [57, 58, 61], "128\u4f4dascii\u7801\u662f\u6570\u5b57": 114, "12b": 22, "12k": 96, "12n_": 49, "13": [23, 49, 62, 104], "131": 36, "13245": [45, 97], "138": 2, "13b": 55, "13k": 13, "14": [21, 23, 55, 58, 108], "14165": [45, 97], "14168": [45, 97], "14187": [45, 97], "14858": [45, 97], "149225472": 57, "15": [23, 24, 38, 59, 60, 99], "151": 64, "15115": [45, 97], "1536": 57, "15b": [31, 43], "16": [21, 23, 59, 69, 75, 77, 80, 94, 102], "160": 57, "1609": 62, "1612": [45, 97], "164": 22, "16441": [45, 97], "16609": [45, 97], "16k": 61, "17": [22, 23], "1706": [45, 97], "175": [12, 28, 40], "17k": 69, "18": [23, 64], "1810": [45, 97], "18290": [45, 97], "185b": 56, "188743680": 57, "19": [11, 12, 29, 45, 97], "1904": [45, 97], "1909": [45, 97], "195": 29, "198": 25, "1990\u5e74\u5f00\u59cb\u7814\u53d1": 114, "1994": 104, "1_gnu": 23, "1e": [62, 63, 99, 109, 115], "1k": 25, "1l": 83, "1m": 39, "1qvx610cu7": [45, 97], "1t": [57, 61], "1w": 83, "1\u4f4d\u4e3a": 114, "2": [2, 3, 7, 9, 10, 11, 12, 13, 17, 18, 20, 21, 23, 25, 28, 29, 33, 37, 40, 46, 49, 50, 52, 54, 56, 57, 58, 59, 61, 62, 63, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 84, 85, 86, 88, 94, 95, 96, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114], "20": [12, 13, 18, 23, 37, 45, 69, 85, 96, 97], "200": [13, 18, 22, 37, 96], "2000": 59, "2001": [45, 97], "2005": [45, 97], "20050": [45, 97], "2009": [45, 97], "2017": [45, 97], "2019": [45, 97], "2020": [45, 97], "2021": [45, 97], "2022": [45, 97], "2023": [45, 56, 97], "2024": [23, 45, 65, 69, 97], "20240602": 23, "2025": [45, 97], "2048": [62, 63, 99, 106, 107], "20k": [18, 24, 31, 37, 38, 43, 56], "21": [21, 22, 23, 24, 25, 38, 45, 97, 102, 111], "2104": [45, 97], "2107": [45, 97], "2110": [45, 97], "21326725120": 57, "21b": 57, "22": [13, 23, 45, 97, 111], "2203": [45, 97], "2212": [28, 40], "2294": 62, "23": [9, 10, 16, 23, 25, 45, 58, 59, 64, 97, 102, 104, 106, 108, 110], "2305": [45, 97], "2306": [31, 43], "2308": [45, 97], "2309": [45, 97], "2311": [45, 97], "2312": [24, 38, 45, 97], "232": 36, "235692359680": 57, "236b": 57, "24": [19, 21, 23, 39, 42, 45, 56, 57, 58, 61, 64, 65, 97, 105, 108], "2401": [45, 97], "2403": [45, 97], "2405": [45, 97], "2406": [45, 97], "2409": [45, 97], "2412": [45, 97], "25": [16, 23, 30, 41, 45, 64, 65, 85, 97, 108], "250": 99, "256": [62, 63, 86], "256\u4f4dascii\u6269\u5c55\u7801\u662fascii": 114, "26": [23, 94], "27": [60, 94], "28": 69, "29": 23, "2900": 107, "290k": 39, "2d": 106, "2d_": 49, "2e": 39, "2i": [9, 55, 111], "2j": [62, 63, 106, 107], "2m": 57, "2n": 49, "2n_": [49, 108], "2t": 111, "2\u62164\u5b57\u8282\u53d8\u957f": 114, "3": [10, 11, 12, 13, 16, 23, 24, 29, 38, 48, 49, 52, 54, 55, 56, 57, 58, 62, 75, 77, 80, 86, 92, 94, 102, 104, 105, 106, 107, 109, 112], "30": [21, 56, 61], "300": 29, "3000": 107, "300m": 56, "30k": 56, "314": 2, "31k": 13, "32": [23, 62, 63, 69, 73, 99, 102, 114], "3200": 73, "32768": [106, 107], "32b": [69, 94], "32k": 58, "33": 21, "338": 56, "33k": 13, "33t": 108, "34": [23, 25], "34b": [19, 55, 77], "35x": 20, "37": 29, "374": 62, "37b": 58, "38": 23, "3822059520": 57, "384": 69, "39": 25, "3m": 57, "4": [13, 16, 21, 23, 24, 25, 38, 49, 50, 55, 59, 61, 62, 63, 69, 72, 73, 75, 77, 81, 86, 96, 102, 104, 107, 108, 109, 114, 115], "40": [68, 80, 85], "400": 16, "405b": 61, "4096": [39, 62, 63, 115], "40k": 56, "41": 23, "421": 36, "426": 26, "43": 23, "438k": 29, "443": [30, 41], "448": 25, "45": [11, 23, 59], "4d": [62, 63], "4e00": 114, "4e00\u57280800": 114, "4e00\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a100": 114, "4k": 58, "4t": 59, "4\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 114, "4\u5b57\u8282\u53d8\u957f": 114, "4\u5b57\u8282\u8868\u793a": 114, "5": [21, 23, 24, 25, 32, 33, 36, 38, 39, 45, 52, 55, 56, 57, 58, 59, 62, 63, 68, 69, 71, 72, 73, 85, 86, 88, 94, 97, 99, 104, 107, 115], "50": [53, 55, 69, 94], "500": 16, "500000": [62, 63], "500b": 55, "512": [9, 39, 57, 69], "5120": 57, "52": 55, "52k": [18, 28, 37, 40], "54": [23, 52], "540": 60, "5403": 107, "55m": [30, 41], "57": 21, "5963": 62, "59k": 94, "5b": 96, "5e": [39, 77], "5k": 25, "5m": 57, "5pm": [18, 37], "6": [9, 20, 23, 24, 28, 38, 40, 49, 54, 55, 56, 57, 62, 63, 69, 77, 81, 96, 99, 107, 109, 115], "60": [17, 56, 57, 68, 80], "62": [23, 55], "63": 23, "64": [23, 57, 59, 99], "643": 64, "65": 25, "65b": [59, 99], "66": 23, "67": 59, "671b": 58, "67b": 57, "6n": 49, "6nb": 49, "6w": 114, "7": [22, 23, 25, 28, 40, 50, 53, 60, 64, 65, 69, 77, 102, 104, 107], "70": 23, "70b": [55, 60, 61, 77, 86], "72": 23, "73": 2, "750": 99, "753": 2, "75k": [24, 38, 96], "77": 53, "777": 36, "788m": 58, "7b": [18, 20, 24, 37, 38, 55, 59, 60, 77, 94, 108, 115], "8": [12, 23, 25, 28, 40, 45, 49, 54, 55, 57, 58, 64, 77, 80, 97, 102, 107, 108], "80": [50, 96], "800": 19, "8000": 53, "800k": 96, "80gb": 77, "80k": [24, 38], "80x": 20, "821b": 56, "82k": [28, 40], "83": 62, "8415j": 107, "85": [53, 61], "888": 2, "8b": [48, 61, 77], "8binstruct": 48, "8\u4e2abit\u4f4d\u4e2d\u9ad8\u4f4d\u5fc5\u987b\u7b49\u4e8e0": 114, "8\u4e2abit\u4f4d\u662f\u4e00\u4e2a\u5b57\u8282": 114, "8\u4e3a11100100": 114, "8\u4e3a\u4e09\u5b57\u8282": 114, "8\u4f4d\u53ef\u8868\u793a256\u4e2a\u5b57\u7b26": 114, "8\u548cgbk\u7f16\u7801": 114, "8\u6765\u5b9e\u73b0\u7f16\u7801": 114, "8\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u89e3\u7801\u4f7f\u7528": 114, "8\u7684\u6620\u5c04\u5173\u7cfb\u5982\u4e0b": 114, "8\u7684\u7f16\u7801\u65b9\u5f0f": 114, "8\u7684\u89c4\u5219\u5f88\u7b80\u5355": 114, "8\u7b49": 114, "8\u7f16\u7801": 114, "9": [13, 22, 23, 45, 59, 62, 69, 75, 82, 97, 99, 104, 108], "90": 29, "92": 65, "9297": 107, "95": [23, 59, 99], "97": 17, "974": 26, "9901": 115, "9999": 107, "9e": 77, "A": [7, 11, 18, 25, 28, 37, 39, 40, 45, 47, 48, 53, 60, 62, 63, 64, 68, 69, 73, 74, 79, 80, 81, 84, 87, 88, 92, 94, 97, 104, 105, 106, 111, 112, 116], "And": [74, 102], "As": [1, 47, 50, 53, 54, 56, 60, 69, 72, 73, 74, 88, 92, 96, 105, 108], "At": [7, 9, 11, 28, 40, 47, 52, 58, 60, 87, 96, 106, 107], "By": [12, 56, 58, 61, 62, 69, 73, 85, 106], "FOR": 80, "For": [1, 2, 3, 10, 13, 18, 24, 26, 28, 29, 37, 38, 39, 40, 45, 48, 49, 50, 53, 54, 55, 57, 58, 60, 61, 64, 65, 68, 69, 70, 72, 73, 74, 76, 80, 82, 83, 84, 85, 92, 94, 96, 102, 105, 106, 107, 108, 116], "If": [16, 46, 47, 50, 54, 62, 63, 65, 73, 74, 80, 84, 87, 105, 107, 112], "In": [2, 3, 9, 10, 13, 18, 24, 28, 31, 37, 38, 39, 40, 42, 43, 45, 47, 48, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 80, 81, 84, 85, 86, 87, 88, 90, 92, 97, 99, 102, 105, 106, 107, 108, 110, 111], "It": [13, 16, 17, 18, 21, 31, 37, 43, 45, 49, 50, 54, 55, 57, 60, 61, 62, 71, 74, 80, 94, 95, 105, 107], "Its": 53, "No": [48, 58, 62, 65], "Not": [18, 37], "OF": 80, "Of": [28, 40], "On": [9, 50, 58, 73], "One": [16, 47, 52, 61, 73, 76, 80, 81, 84, 106, 107, 111], "Or": [20, 61], "Such": [45, 69, 87, 97], "That": [9, 46], "The": [1, 3, 4, 9, 10, 11, 12, 13, 17, 18, 19, 21, 22, 24, 25, 26, 28, 31, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 48, 49, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 87, 92, 96, 99, 105, 106, 107, 108, 109, 111, 112], "Their": 96, "Then": [1, 13, 24, 29, 38, 61, 72, 73, 74, 80, 81, 84, 94, 105, 108, 110], "There": [17, 106], "Thes": 17, "These": [9, 10, 18, 25, 30, 31, 37, 39, 43, 61, 64, 80, 84, 86, 87], "To": [1, 2, 3, 9, 11, 12, 13, 17, 21, 24, 25, 28, 29, 31, 35, 38, 39, 40, 42, 43, 47, 48, 49, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 74, 75, 76, 79, 81, 84, 86, 88, 92, 94, 96, 105, 106, 109, 112], "With": [21, 25, 46, 54, 70, 106], "_": [9, 13, 28, 31, 40, 42, 43, 47, 55, 58, 60, 62, 63, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 83, 84, 85, 88, 95, 96, 102, 105, 106, 108, 110, 111, 112], "_1": [9, 95], "__init__": [57, 62, 63, 109], "__main__": 20, "__name__": 20, "_bsz": [62, 63], "_h": 9, "_i": 102, "_libgcc_mutex": 23, "_mergeable_rank": 62, "_norm": [62, 63, 109], "_openmp_mutex": 23, "_t": [79, 108], "a100": 77, "a_": [47, 74, 79, 94, 107, 111], "a_i": [42, 102], "a_t": 79, "aa": 104, "aaabdaaabac": 104, "ab": [45, 97, 104, 107], "abbrevi": [25, 36, 114], "abil": [1, 2, 7, 11, 21, 24, 25, 38, 50, 56, 57, 64, 69, 72, 74, 84, 90, 92, 96], "abl": [18, 19, 25, 37, 50, 60], "ablat": [39, 94, 96], "about": [7, 9, 13, 18, 24, 29, 37, 38, 45, 46, 50, 53, 54, 55, 57, 73, 85, 94, 105, 107], "abov": [10, 29, 50, 53, 55, 61, 69, 70, 79, 84, 85, 87, 88, 92, 95, 105, 106], "absenc": 58, "absolut": [9, 59, 68, 110], "absorb": 108, "abstract": 11, "abstractset": 62, "ac": 104, "academ": 21, "acceler": [10, 108], "accept": [45, 84], "access": [2, 7, 36, 50, 60, 73, 84, 86, 87, 88, 95], "accommod": [61, 96], "accompani": 76, "accomplish": [48, 61], "accord": [2, 53, 58, 73, 85, 88, 94, 96, 105, 107], "accordingli": 69, "account": [49, 55], "accumul": 54, "accur": [21, 26, 30, 39, 60, 64, 70, 74, 85], "accuraci": [2, 21, 25, 58, 64, 69, 81, 85, 92, 94], "achiam": [45, 97], "achiev": [3, 12, 21, 25, 39, 52, 56, 58, 59, 60, 61, 64, 69, 70, 71, 72, 76, 81, 84, 85, 88, 94, 108], "acquir": [21, 57, 60, 92, 105], "across": [21, 23, 50, 53, 61, 64, 73, 94, 96, 105, 106, 108, 109], "act": [4, 7], "action": [1, 3, 4, 7, 18, 37, 47, 69, 79], "activ": [9, 10, 57, 58, 59, 64, 105, 108, 112], "actor": [74, 77], "actor_learning_r": 77, "actual": [1, 13, 74, 95], "ad": [10, 11, 28, 31, 40, 43, 52, 61, 69, 74, 85, 95, 111], "adam_offload": 77, "adamw": [59, 69, 99], "adapt": [10, 31, 43, 70, 76, 105, 106, 107, 116], "add": [9, 11, 13, 17, 31, 43, 54, 55, 58, 59, 60, 62, 63, 68, 75, 85, 86], "addit": [9, 11, 13, 29, 47, 50, 52, 53, 55, 56, 58, 62, 63, 69, 73, 75, 76, 82, 86, 92, 95, 96, 99, 105, 106, 108, 112, 114], "addition": [1, 10, 21, 28, 39, 40, 58, 73, 105], "additionali": 74, "address": [2, 25, 31, 43, 54, 61, 65, 69, 74, 81, 84], "adher": [50, 64, 65, 69, 92], "aditya": [45, 97], "adjust": [57, 61, 68, 84, 92, 108], "adopt": [18, 24, 29, 35, 37, 38, 48, 52, 57, 58, 65, 70, 92, 108], "advanc": [2, 21, 39, 53, 64], "advantag": [50, 74, 76, 77, 108], "advis": 80, "affect": [32, 39, 48, 105], "affin": [58, 62, 105], "aforement": 81, "after": [7, 10, 11, 28, 31, 40, 43, 48, 52, 53, 56, 58, 59, 60, 61, 62, 65, 69, 72, 73, 74, 75, 81, 84, 85, 86, 92, 94, 96, 105, 106, 107], "again": [7, 9, 81, 112], "against": [13, 16, 35, 54, 65, 80, 82, 94], "agarw": [45, 97], "agent": [1, 65, 73, 79, 84], "aggreg": 53, "aggress": [18, 37], "agnost": [12, 76], "ahm": [45, 97], "ai": [2, 16, 23, 25, 45, 54, 61, 69, 70, 86, 88, 97], "aidan": [45, 97], "aif": 86, "aift": 86, "aim": [1, 17, 25, 47, 48, 69, 74, 84, 86, 87, 95, 105], "aime24": 94, "ainsli": [45, 97], "aiohttp": 23, "aiosign": 23, "aixin": [45, 97], "ajudg": 65, "alec": [45, 97], "alethea": [45, 97], "alex": [45, 97], "algorithm": [13, 22, 28, 30, 40, 41, 52, 53, 54, 56, 57, 59, 60, 61, 64, 65, 69, 71, 74, 104], "alibi": 107, "align": [9, 10, 13, 25, 32, 42, 49, 50, 58, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 73, 74, 75, 79, 81, 84, 105, 106, 107, 108, 110, 111, 112], "align_n": 76, "alignmentrelev": 50, "alik": 55, "all": [1, 3, 11, 13, 18, 22, 26, 31, 35, 37, 42, 43, 45, 46, 47, 49, 52, 53, 56, 57, 60, 61, 62, 65, 69, 71, 72, 73, 74, 75, 79, 80, 81, 83, 84, 85, 95, 96, 97, 99, 102, 105, 106, 107, 108, 109, 112], "allclos": [62, 109], "allevi": 105, "alloc": [65, 69, 92], "allow": [3, 7, 9, 11, 12, 29, 45, 47, 52, 53, 58, 61, 62, 79, 80, 87, 105, 107, 111], "allowed_speci": 62, "allowed_token": 62, "almeida": [45, 97], "almost": [85, 99], "alon": [81, 85, 86, 99], "along": [1, 10, 35, 52, 54, 55], "alongsid": [58, 74], "alpaca": [2, 24, 31, 32, 33, 38, 43], "alpacaev": [48, 86], "alpha": [76, 79, 85, 95, 106], "alpha_": [49, 105], "alphacod": 55, "alreadi": [50, 52, 56, 62, 73, 86], "also": [7, 9, 13, 18, 21, 23, 25, 26, 28, 29, 37, 39, 40, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 68, 71, 72, 74, 75, 80, 86, 87, 88, 94, 105, 106, 108, 112], "altdj": [45, 64, 97, 108], "alter": 54, "altern": [12, 60, 61, 71, 73, 76, 81], "although": [16, 47, 56, 58, 92, 105, 114], "alwai": [52, 61, 76, 85, 105, 106, 107], "amanda": [45, 97], "ambigu": 85, "amc": 25, "american": 114, "amodei": [45, 97], "among": [2, 16, 19, 55, 57, 65, 73, 84, 105, 108], "amount": [39, 49, 53, 57, 61, 86, 92, 94, 96, 102, 106, 108, 112], "an": [1, 2, 3, 9, 10, 11, 12, 13, 16, 17, 18, 21, 22, 24, 28, 29, 31, 37, 38, 39, 40, 43, 45, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 68, 69, 71, 72, 74, 76, 79, 80, 81, 82, 84, 85, 86, 87, 88, 92, 95, 96, 97, 102, 105, 106, 107, 108], "anaconda3": 23, "analogi": 50, "analysi": [2, 29, 54, 57, 61, 65, 76, 81], "analyz": [39, 65, 102], "anchor": 54, "andi": [45, 97], "andrew": [45, 97], "angela": [45, 97], "angl": [107, 110], "ani": [9, 11, 12, 17, 18, 22, 24, 28, 35, 37, 38, 39, 40, 46, 47, 50, 54, 58, 61, 62, 65, 75, 80, 88, 92, 96, 106, 107, 108, 110, 111], "anneal": 39, "annot": [2, 21, 23, 55, 58, 60, 61, 69, 81, 86], "anoth": [18, 37, 47, 52, 54, 60, 74, 76, 81, 85, 107], "answer": [1, 2, 3, 10, 11, 20, 21, 25, 30, 39, 41, 42, 48, 55, 58, 60, 64, 65, 69, 80, 87, 92, 94, 95, 96, 99, 102, 107], "answer_1": 61, "anthrop": [23, 73], "anticip": 65, "anyio": 23, "anywher": [13, 75], "aop": 69, "api": [3, 4, 13, 17, 23, 39, 64, 75], "app": 80, "appear": [35, 49, 54, 69, 107], "append": [28, 39, 40, 62, 63, 77, 80, 84, 94], "appli": [9, 10, 13, 24, 31, 38, 43, 48, 53, 54, 55, 56, 58, 61, 62, 63, 68, 69, 71, 73, 74, 75, 76, 79, 85, 87, 88, 92, 95, 102, 105, 106, 107, 112], "applic": [7, 12, 13, 25, 55, 60, 106, 107], "apply_chat_templ": 77, "apply_rotary_emb": [62, 63, 107], "approach": [24, 28, 38, 39, 40, 47, 49, 53, 55, 57, 58, 60, 61, 65, 68, 69, 71, 76, 79, 81, 82, 86, 87, 88, 92, 94, 95, 105, 106, 107], "appropri": [2, 9, 18, 37, 55, 79], "approx": [49, 58, 106, 110], "approxim": [11, 12, 16, 47, 56, 57, 61, 73, 85, 88, 96, 99, 102, 105, 107], "aptitud": 25, "ar": [2, 3, 9, 10, 11, 12, 13, 16, 17, 18, 19, 22, 24, 25, 28, 29, 31, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 84, 85, 86, 87, 90, 96, 97, 99, 102, 105, 106, 107, 108, 109, 111, 114], "arang": [22, 62, 63, 71, 107], "arbitrari": [13, 107], "archit": [45, 97], "architectur": [10, 11, 49, 52, 55, 65, 105, 107, 108, 109, 111, 116], "archiv": 11, "area": [21, 64], "arg": [60, 62, 63, 70, 77, 84, 107], "argmax": 62, "argu": [57, 84], "ariel": [45, 97], "aris": [80, 81], "arithmet": 25, "armando": [45, 97], "armo": 33, "armorm": 48, "around": [9, 16, 108], "arrang": 23, "art": [12, 25, 50, 59, 69], "articl": 11, "artifici": 70, "arvind": [45, 97], "arxiv": [24, 28, 31, 38, 40, 43, 45, 59, 97], "ascent": 79, "ascertain": 73, "ascii\u5c31\u662f\u6700\u521d\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 114, "ascii\u8d77\u521d\u53ea\u89c4\u5b9a\u4e86127\u4e2a\u5b57\u7b26": 114, "ashish": [45, 97], "ask": [1, 7, 13, 17, 18, 26, 28, 37, 40, 54, 60, 61, 75, 81, 87], "askel": [45, 97], "aspect": [54, 64, 76, 86], "assert": [55, 62, 63, 107], "assertionerror": [62, 107], "assess": [2, 21, 22, 25, 31, 43, 61, 65, 83, 94], "assign": [9, 47, 52, 60, 61, 68, 69, 73, 74, 76, 79, 84, 85, 88, 95, 96, 105], "assist": [18, 37, 50, 55, 62, 80, 82, 86, 87], "associ": [55, 69, 84], "assum": [10, 47, 72, 76, 84, 86, 87, 88, 95, 109, 113], "ast": [70, 71, 84, 95, 111], "asymptot": 25, "async": 23, "atcod": [23, 36], "atol": [62, 109], "atom": 3, "att": 105, "attach": 68, "attain": 73, "attempt": [1, 50, 94, 95, 96], "attend": 9, "attent": [10, 11, 12, 32, 33, 45, 49, 57, 58, 64, 72, 97, 105, 106, 107, 109, 110, 111], "attention_bia": 57, "attention_norm": [62, 63], "attn": 49, "attr": 23, "attract": 107, "attribut": [29, 53, 82], "audio": [18, 37], "augment": [2, 86], "auli": [45, 97], "auth": 23, "authent": 76, "author": [71, 86], "auto": [9, 16], "autom": [28, 36, 39, 40, 64], "automat": [1, 3, 7, 16, 24, 28, 31, 38, 40, 43, 61, 65, 68, 82, 105], "autonom": [1, 92], "autoregress": [10, 12, 47, 55, 60, 106], "auxiliari": [10, 50, 52, 58, 95], "avail": [2, 30, 55, 59, 61, 64], "avenu": 13, "averag": [3, 22, 29, 52, 53, 62, 63, 74, 81, 94, 105], "avg": 69, "avoid": [7, 13, 47, 50, 52, 53, 54, 69, 72, 74, 79, 84, 85, 106], "await": [31, 43], "ax": 61, "axi": [62, 109], "b": [10, 45, 47, 49, 62, 63, 73, 80, 87, 94, 95, 97, 106, 112, 116], "b_": [62, 63, 112], "b_1": 9, "b_2": 9, "b_i": 58, "b_j": 58, "babuschkin": [45, 97], "backbon": 68, "backend": 20, "background": 22, "backpropag": 60, "backtransl": 61, "backward": 49, "bad": [47, 50, 61], "bag": 60, "bai": [45, 97], "baker": [45, 97], "balaji": [45, 97], "balanc": [9, 58, 61, 65, 69, 87], "band": 12, "bank": 3, "bao": [45, 97], "baosong": [45, 97], "baptist": [45, 97], "bar": 106, "barn": [45, 97], "basart": [45, 97], "base": [1, 2, 9, 10, 11, 13, 17, 18, 24, 25, 28, 31, 33, 37, 38, 39, 40, 43, 46, 47, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 68, 71, 73, 74, 75, 76, 80, 84, 85, 86, 87, 88, 94, 95, 102, 106, 107, 110, 111, 114, 115], "baselin": [16, 25, 48, 69, 86, 87, 96], "basi": [62, 107], "basic": [25, 26, 32, 54, 64, 65], "basu": [45, 97], "batch": [13, 18, 37, 39, 49, 55, 59, 60, 61, 62, 69, 73, 75, 99, 108], "batchnorm1d": [62, 109], "batchnorm2d": 62, "bavarian": [45, 97], "bax": 116, "bbc": [45, 64, 97], "bbpe": [57, 64], "becaus": [9, 18, 28, 37, 40, 54, 61, 68, 80, 92, 109], "becom": [72, 81, 95, 105, 107, 108], "been": [3, 29, 47, 53, 54, 57, 58, 62, 64, 73, 74, 85, 88], "befor": [2, 28, 35, 40, 50, 52, 56, 60, 65, 82, 106, 107], "begin": [1, 2, 9, 10, 11, 13, 49, 55, 58, 60, 61, 62, 63, 69, 70, 71, 72, 73, 74, 75, 80, 84, 88, 92, 105, 106, 107, 108, 110, 111, 112], "begin_of_text": 62, "behav": [50, 53, 107], "behavior": [11, 13, 25, 47, 50, 53, 54, 65, 69, 70, 80, 92, 107, 109], "behaviour": 52, "behind": 107, "bei": [45, 97], "beichen": [45, 97], "being": [9, 12, 24, 38, 45, 52, 61, 88], "believ": 68, "belong": 105, "below": [18, 24, 37, 38, 50, 55, 72, 79, 85], "bench": 32, "benchmark": [2, 3, 11, 12, 19, 30, 31, 41, 43, 45, 50, 56, 57, 61, 94, 97, 108], "benefici": [9, 54, 85], "benefit": [7, 11, 60, 85, 102], "benfeng": [45, 97], "benjamin": [45, 97], "berner": [45, 97], "bert": [11, 45, 97], "besid": [69, 70], "best": [3, 13, 25, 39, 48, 49, 52, 53, 54, 59, 60, 61, 65, 70, 73, 75, 85, 86, 88, 94, 95, 96], "bestof": 48, "beta": [13, 60, 62, 71, 72, 74, 75, 79, 84, 106, 109, 112], "beta_": [59, 95], "beta_1": 99, "beta_2": 99, "better": [13, 21, 50, 53, 54, 56, 58, 59, 60, 61, 64, 65, 72, 79, 80, 81, 84, 87, 94, 96, 102, 108], "between": [9, 13, 18, 21, 24, 25, 37, 38, 42, 47, 48, 50, 52, 53, 55, 57, 60, 61, 62, 63, 69, 71, 72, 74, 75, 79, 80, 81, 84, 85, 86, 92, 95, 96, 102, 105, 106, 109, 110, 111, 112], "beyond": [23, 50, 81, 105, 107], "bf16": [77, 115], "bi": [45, 97], "bia": [57, 58, 62, 63, 64, 68, 81, 87, 95, 112], "bias": [28, 40, 47], "bib": 45, "bibliographi": 45, "bibtex": 45, "bidirect": [45, 97], "bigger": [13, 106], "biggest": 53, "bilinear": 112, "billion": 12, "bin": [45, 97], "binari": [60, 61, 70, 81, 85], "bing": [45, 97], "bingxuan": [45, 97], "binom": [13, 22, 75, 94], "binyuan": [45, 97], "biologi": [21, 25], "bit": [73, 106], "black": 49, "bleu": 47, "blind": 21, "block": [10, 11, 20, 46, 55, 105], "blog": [13, 45, 65, 74, 78, 97], "blue": [31, 43], "bm25": 29, "bmr": [12, 13, 45, 97], "bn": [62, 109], "bo": [45, 62, 97], "bob": [45, 97], "bodi": [22, 114], "bofei": [45, 97], "boltzmann": 73, "bonu": 95, "book": [11, 45, 46, 59], "bool": 62, "bootstrap": [24, 28, 38, 40, 50], "bos_id": 62, "both": [2, 7, 9, 12, 16, 19, 21, 24, 25, 38, 45, 48, 52, 55, 58, 60, 61, 64, 65, 74, 75, 76, 80, 81, 82, 86, 88, 95, 96, 106, 107, 108, 109], "boto3": 23, "botocor": 23, "bottleneck": 108, "bottom": [9, 85], "bound": [48, 79, 105, 107], "boundari": [24, 28, 38, 40, 106], "bowen": [45, 97], "box": [25, 45, 58, 92], "boyang": [45, 97], "bpe": [11, 55, 59], "bpe\u6bcf\u4e00\u6b65\u90fd\u5c06\u6700\u5e38\u89c1\u7684\u4e00\u5bf9\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u66ff\u6362\u4e3a\u8be5\u6570\u636e\u4e2d\u6ca1\u6709\u51fa\u73b0\u8fc7\u7684\u4e00\u4e2a\u65b0\u5355\u4f4d": 104, "bpe\u9009\u62e9\u9891\u6570\u6700\u9ad8\u7684\u76f8\u90bb\u5b50\u8bcd\u5408\u5e76": 113, "bradlei": [13, 68, 71, 84, 85], "brahma": [45, 97], "brainstorm": 87, "branch": 61, "breadth": [21, 31, 43], "break": [28, 40, 62, 84], "breviti": [105, 108], "bridg": [21, 47, 65], "brief": [12, 17], "bright": 25, "bring": 74, "broad": [28, 40], "broadcast": 107, "broader": [21, 23], "broadli": 12, "brockman": [45, 97], "brook": [45, 97], "brown": [45, 97], "brundag": [45, 97], "brute": 54, "bsz": [62, 63], "bt": 84, "bucket": 61, "budget": [52, 53, 55, 59, 64, 94, 105], "buffer": [73, 77], "bug": [1, 17, 29, 54, 77], "build": [1, 7, 11, 21, 23, 45, 48, 56, 61, 62, 64, 65, 68, 82, 86, 87], "built": [7, 46, 57, 60, 65], "bullet": 54, "burda": [45, 97], "burden": 74, "burn": [45, 97], "busi": 21, "byte": [11, 45, 55, 57, 59, 64, 97], "bzip2": 23, "c": [10, 19, 22, 49, 52, 53, 57, 60, 61, 62, 63, 65, 70, 73, 85, 106, 107, 108, 109, 112], "c4": 59, "c_": [49, 57], "ca": 23, "cach": [20, 62, 63, 64, 69], "cache_k": [62, 63], "cache_len": [62, 63], "cache_v": [62, 63], "cachecontrol": 23, "cachetool": 23, "cai": [45, 80, 97], "caichat": 77, "calcul": [2, 22, 25, 57, 62, 63, 69, 73, 74, 79, 80, 81, 85, 102, 105, 107, 109], "calibr": [48, 80], "call": [2, 3, 7, 9, 11, 12, 13, 17, 22, 31, 43, 45, 47, 50, 54, 58, 60, 61, 62, 75, 76, 80, 84, 90, 96, 107, 108, 112], "can": [2, 3, 7, 9, 10, 12, 13, 17, 22, 23, 24, 25, 28, 29, 38, 39, 40, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 60, 61, 64, 65, 68, 69, 71, 72, 73, 74, 75, 76, 79, 80, 81, 84, 85, 86, 87, 88, 92, 94, 96, 97, 102, 105, 106, 107, 108, 109, 111, 112, 113], "cancel": 71, "candid": [29, 52, 53, 61, 65, 73, 81, 84, 86, 88, 102], "cannot": [17, 18, 25, 37, 47, 50, 107, 108], "canon": 81, "capabl": [2, 16, 17, 23, 24, 25, 31, 38, 39, 42, 43, 48, 50, 55, 58, 60, 64, 65, 76, 86, 92, 107], "capac": [10, 73, 105], "captur": [85, 92, 105], "cardin": [53, 73], "care": [50, 61, 94], "carefulli": [21, 57, 61, 64, 99], "carlo": [47, 74], "carr": [45, 97], "carri": [58, 108], "carrol": [45, 97], "cascad": 55, "case": [13, 18, 24, 26, 28, 35, 36, 37, 38, 39, 40, 47, 52, 53, 54, 55, 56, 58, 60, 65, 69, 70, 72, 76, 80, 88, 92, 94, 105, 106], "cast": 62, "catastroph": 107, "catch": 61, "categor": [53, 61, 65, 85, 87], "categori": [7, 16, 87], "caus": [21, 62, 71, 72, 82, 105], "causal": [10, 55], "cd": [20, 23], "cdot": [9, 57, 69, 71, 72, 76, 84, 95, 105, 106, 111, 112], "ce": 73, "ceas": 49, "ceil": 50, "cell": 62, "central": 85, "centroid": 105, "certain": [10, 47, 58, 61, 69, 87, 88, 105, 106, 107], "certif": 23, "certifi": 23, "cffi": 23, "cfg": 20, "cgrs19": [12, 45, 97], "chai": [45, 97], "chain": [21, 58, 80, 81, 87, 102], "chainof": 102, "challeng": [2, 16, 17, 18, 21, 25, 30, 37, 41, 50, 54, 61, 64, 65, 69, 71, 85, 87, 92, 96], "chan": [45, 97], "chanc": [21, 54], "chang": [7, 18, 23, 29, 37, 45, 70, 82, 95, 97], "changhan": [45, 97], "changyu": [45, 97], "channel": [23, 62], "chantzi": [45, 97], "charact": [54, 55, 114], "character": [49, 57, 64], "characterist": [31, 43, 57], "charset": [23, 114], "chat": [17, 45, 56, 57, 60, 62, 97], "chat_complet": 62, "chatbot": 16, "chatgpt": [24, 38, 50], "cheaper": 16, "check": [13, 17, 26, 36, 39, 55, 61, 64, 65, 94, 95, 96], "checker": 7, "checklist": 65, "checkpoint": [45, 56, 58, 60, 61, 62, 64, 77, 92, 97], "chelsea": [45, 97], "chemistri": [21, 25], "chen": [45, 97], "chenggang": [45, 97], "chengpeng": [45, 97], "chengqi": [45, 97], "chengqiang": [45, 97], "chengyuan": [45, 97], "chess": [45, 50, 97], "child": [45, 97], "chines": 57, "cho": [45, 97], "choic": [10, 21, 25, 39, 47, 60, 72, 73, 80, 84, 96, 111], "chong": [45, 97], "choos": [29, 31, 43, 52, 54, 60, 80, 85, 87, 94, 96, 106], "chose": 9, "chosen": [49, 60, 61, 68, 85], "chosen_1": 61, "chosen_2": 61, "christiano": [45, 97], "christoph": [45, 97], "chu": [45, 97], "chuanqi": [45, 97], "chunqiu": [45, 97], "ci": 107, "cite": 45, "ckb": [25, 45, 97, 102], "ckpt_dir": 62, "ckpt_path": 62, "cl": [24, 38], "clamp": 80, "clarifi": 49, "clariti": [58, 65], "clark": [45, 97], "class": [1, 23, 28, 40, 57, 62, 63, 72, 109], "classic": 79, "classif": [10, 18, 37, 50, 61, 85, 94, 96], "classifi": [23, 52, 61, 65, 76, 87, 94], "claud": [56, 94], "clean": [39, 56, 60, 61, 65], "clear": [65, 77, 85, 107], "clearli": [54, 56], "clemen": [45, 97], "cleo": 23, "clever": 71, "cli": [20, 77], "client": 23, "clip": [59, 74], "clone": [20, 23], "close": [1, 24, 38, 47, 53, 54, 56, 58, 62, 80], "closer": 84, "closest": 54, "cluster": 61, "cly": [45, 65, 97], "cnn": 11, "co": [9, 55, 62, 63, 106, 107, 110, 111], "coars": [61, 65], "cobb": [45, 97], "code": [1, 3, 7, 19, 22, 23, 24, 29, 30, 32, 33, 36, 38, 39, 41, 42, 45, 46, 48, 50, 52, 53, 56, 57, 58, 59, 64, 65, 87, 92, 97, 114], "code1": 23, "code2": 23, "code_alpaca_20k": [18, 37], "code_generation_lit": 23, "code_list": 23, "codealpaca": [18, 24, 32, 33, 37, 38], "codebas": [1, 29], "codebert": 65, "codecontest": [52, 53], "codeexecut": 23, "codeforc": [23, 35, 36, 52, 53], "codegen": 20, "codellama": [24, 38], "codenet": 35, "codeqwen1": 65, "coder": [24, 32, 33, 38, 39, 45, 58, 64, 97, 115], "codewar": 36, "codex": [22, 32, 55], "coeffici": [13, 68, 71, 75, 79, 107], "cognit": 92, "coher": [23, 81], "collabor": 65, "collaps": 69, "collect": [11, 13, 23, 24, 28, 29, 38, 39, 40, 55, 57, 59, 61, 62, 65, 75, 76, 77, 80, 87, 88, 92, 102], "collin": [45, 97], "colon": 82, "com": [20, 23], "combin": [1, 4, 11, 13, 18, 24, 37, 38, 39, 53, 54, 55, 58, 60, 61, 65, 69, 75, 76, 81, 83, 84, 92, 105, 106], "come": [9, 13, 18, 28, 37, 40, 56, 106, 107], "command": [7, 23, 46], "commbal": 105, "comment": [55, 61, 65], "common": [11, 13, 23, 47, 54, 56, 61, 65, 68, 73, 105], "commoncrawl": 59, "commonli": [2, 24, 38, 39], "commonmark": 45, "commun": [39, 58, 92, 99, 114], "commut": 108, "compact": 7, "compar": [3, 16, 21, 39, 47, 48, 56, 58, 61, 64, 65, 69, 72, 73, 74, 76, 86, 88, 94, 95, 96, 112], "comparison": [13, 48, 55, 56, 57, 63, 75, 76, 80, 84, 85], "compat": [9, 55, 107, 109], "compet": [12, 61], "competit": [9, 12, 23, 25, 35, 52, 53, 58, 69, 94], "competitor": 13, "compil": [56, 57, 58, 61, 92], "complementari": 58, "complet": [1, 13, 17, 18, 22, 31, 37, 39, 43, 48, 54, 55, 58, 60, 61, 62, 65, 71, 72, 75], "complex": [1, 3, 7, 10, 17, 21, 24, 31, 38, 43, 50, 55, 61, 62, 63, 64, 65, 74, 79, 90, 92, 106, 107, 111], "complex64": [62, 63, 107], "compli": 53, "complic": [31, 43, 50, 74], "compon": [39, 53, 60, 62, 63, 64, 85, 86, 112], "compos": [9, 25, 105], "composit": [3, 61], "comprehens": [2, 11, 17, 22, 31, 43, 58, 64, 76, 79], "compress": [57, 104], "compris": [21, 57, 58, 61, 64, 65, 73, 105], "comput": [9, 19, 21, 22, 39, 50, 53, 55, 59, 60, 62, 63, 64, 65, 70, 73, 74, 79, 80, 81, 83, 92, 94, 96, 105, 106, 107, 108, 109, 111, 112, 114], "concat": 9, "concaten": [9, 28, 40, 60, 81, 95], "concept": [55, 65], "concis": [7, 58, 64, 73], "conclud": 57, "conclus": [57, 108], "concret": [31, 43, 69, 95], "concurr": 54, "conda": 23, "condit": [2, 10, 28, 40, 47, 52, 76], "conduct": [53, 57, 61, 70, 76, 81, 84, 96, 107], "conduct_rejection_sampl": 84, "confer": [45, 76, 97], "confid": [50, 80, 88], "config": [57, 105], "configur": [48, 57], "confin": 60, "conform": 61, "confus": 69, "conjug": 111, "conjunct": 7, "connect": 9, "consecut": [24, 38, 53], "consequ": [61, 76], "consid": [3, 22, 29, 47, 50, 61, 65, 68, 69, 72, 73, 76, 80, 81, 84, 85, 87, 106, 107], "consider": [56, 69, 76], "consist": [1, 2, 9, 10, 13, 19, 21, 24, 25, 29, 35, 36, 38, 50, 55, 56, 57, 65, 68, 69, 71, 75, 79, 88, 92, 102, 105, 109], "console_script": 20, "consolid": [3, 105], "constant": [2, 47, 69, 105, 106, 111, 112], "constitut": 70, "constrain": [3, 69, 71, 79, 84, 94], "constraint": [31, 43, 54, 60], "construct": [2, 16, 19, 31, 42, 43, 55, 56, 65, 70, 76, 82, 84, 86, 92, 105], "consum": [9, 88], "contain": [1, 2, 3, 9, 11, 13, 16, 17, 18, 20, 21, 24, 25, 26, 28, 29, 37, 38, 39, 40, 50, 52, 53, 54, 55, 57, 59, 60, 61, 62, 65, 69, 70, 82, 94, 96, 102, 107, 108], "container": 61, "contamin": [23, 29, 45, 97], "content": [1, 18, 37, 39, 45, 46, 62, 76, 80], "contest": [23, 53], "context": [7, 10, 11, 17, 18, 28, 29, 37, 39, 40, 47, 49, 57, 61, 68, 74, 76, 80, 81, 82, 105, 111], "context_messag": 77, "contextu": 39, "contextwindow": 58, "contigu": [10, 62, 63], "continu": [2, 9, 13, 23, 24, 25, 29, 38, 54, 61, 65, 68, 74, 75, 80, 84, 85], "contrast": [12, 21, 47, 54, 82, 88, 107], "contribut": [29, 39, 69, 79, 85], "control": [3, 13, 50, 62, 71, 75, 81, 94], "convei": 76, "convent": 108, "converg": [10, 105, 109], "convers": [49, 61, 62, 69, 80, 107], "convert": [9, 46, 81, 84], "convinc": 96, "convolut": [9, 45, 97], "cookbook": 39, "coordin": 106, "copi": 22, "core": [11, 16, 23, 50, 108], "corpora": [39, 65], "corpu": [10, 12, 24, 38, 56, 57, 58, 65, 73, 107], "corr": 68, "correct": [2, 3, 7, 17, 26, 32, 33, 39, 45, 47, 52, 53, 54, 55, 58, 61, 64, 65, 68, 69, 70, 72, 76, 87, 92, 94, 96, 97, 102], "correctli": [25, 54, 88, 95, 107], "correl": [12, 16, 68, 76, 86, 102], "correspond": [9, 13, 17, 25, 28, 31, 39, 40, 43, 47, 53, 54, 55, 56, 58, 62, 63, 68, 70, 71, 74, 76, 84, 107, 110, 111], "correspondingli": 74, "cosin": [9, 39, 59, 61, 115], "cost": [18, 37, 56, 58, 105], "costli": 105, "cot": [21, 32, 33, 69, 80, 81, 92], "could": [48, 50, 52, 53, 61, 68, 70, 79, 85, 88, 94, 107], "count": [22, 39, 94], "counteract": [9, 61], "counterclockwis": 110, "counterpart": [60, 61], "coupl": [58, 95], "cover": [21, 54, 61, 65, 86, 105], "coverag": [28, 40, 56, 64, 81, 88], "cpu": 62, "cr": 73, "crack": 33, "craft": 73, "crashtest": 23, "crawl": [11, 56, 65], "creat": [11, 13, 18, 23, 25, 28, 29, 31, 37, 39, 40, 43, 50, 55, 56, 61, 64, 65, 82, 86], "creation": 54, "creativ": [50, 58], "credit": [47, 79], "criteria": [60, 61, 64, 82, 94], "critic": [52, 56, 64, 74, 77, 79, 95], "critic_learning_r": 77, "critiqu": [32, 33, 76], "crmsnorm": [45, 97], "cross": [17, 29, 49, 52, 61, 70, 73, 81], "cross_entropi": 62, "crowd": 26, "crowdwork": 80, "crucial": [39, 56, 57, 65], "crux": 33, "cruxev": [45, 97], "cryptographi": 23, "ctj": [22, 45, 97], "ctx": 49, "cu12": 23, "cubla": 23, "cuda": [23, 62], "cudnn": 23, "cufft": 23, "cui": [45, 97], "cum": [45, 97], "cumbersom": 73, "cumsum": 62, "cumul": [62, 79], "cup": 102, "cupti": 23, "cur_po": 62, "curand": 23, "curat": [3, 21, 35, 36, 39, 52, 57, 58, 61, 65, 68, 92, 99], "curiou": [16, 85], "current": [1, 2, 11, 12, 13, 18, 30, 31, 37, 39, 43, 47, 64, 73, 74, 75, 84, 87, 94, 96, 106, 108], "curv": [49, 60], "cusolv": 23, "cuspars": 23, "custom": 13, "custom_evalu": 23, "custom_output_fil": 23, "cut": [62, 76], "cutoff_len": 115, "cycl": 61, "d": [13, 20, 31, 43, 45, 46, 47, 49, 55, 60, 62, 63, 68, 69, 71, 72, 73, 74, 75, 81, 82, 83, 84, 85, 88, 95, 97, 102, 104, 105, 106, 107, 108, 110, 111, 116], "d_": [9, 13, 42, 49, 57, 60, 75, 84, 85, 108, 112], "d_c": [57, 108], "d_h": [57, 108], "d_k": 9, "d_v": 9, "dab": [45, 57, 97], "dai": [45, 97], "daili": [2, 11], "dalf": [45, 56, 57, 58, 97, 105, 108], "damai": [45, 97], "dan": [45, 97], "dang": [45, 97], "danger": 80, "daniel": [45, 97], "dario": [45, 97], "data": [3, 10, 11, 12, 13, 24, 29, 31, 32, 33, 35, 36, 38, 43, 47, 48, 50, 55, 64, 68, 70, 71, 73, 74, 75, 76, 80, 82, 83, 84, 86, 87, 88, 92, 95, 104, 107, 109], "dataclass": [62, 63], "datalabel": 96, "dataset": [2, 10, 18, 20, 21, 22, 23, 24, 25, 26, 30, 31, 33, 37, 38, 39, 41, 42, 43, 50, 53, 56, 57, 58, 59, 60, 61, 64, 65, 68, 73, 74, 76, 83, 84, 85, 86, 88, 92, 94, 95, 96, 102, 115], "date": 39, "dateutil": 23, "dauphin": [45, 97], "dave": [45, 97], "david": [45, 97], "davinci": [18, 37], "dawn": [45, 97], "daya": [45, 97], "dayiheng": [45, 97], "dclt19": [11, 45, 97], "ddot": [110, 111], "de": [45, 55, 97], "deal": 87, "debat": 57, "debias": 64, "debug": [31, 43, 61, 65], "debugg": 68, "decad": 25, "decai": [59, 99, 107, 111], "decid": [1, 56, 65, 86, 92, 96, 105], "decis": [47, 54, 68], "declar": 1, "declin": [31, 43, 57], "decod": [11, 18, 24, 37, 38, 48, 52, 62, 64, 68, 81, 94, 102], "decompos": 60, "decomposit": 116, "decoupl": [57, 58, 69], "decreas": [21, 48, 49, 58, 69, 71, 72, 76, 84, 105], "dedic": 105, "deduc": 95, "dedupl": [13, 39, 55, 56, 61, 102], "deem": 87, "deep": [45, 97], "deepen": [31, 43], "deepseek": [24, 32, 33, 38, 45, 69, 74, 97, 105, 108, 115], "deepseekcod": [58, 115], "deepseekmath": 56, "deepseekmo": [57, 58], "deepseekv2attent": 57, "deepseekv2config": 57, "deepseekv2forcausallm": 57, "deepseekv2mlp": 57, "deepseekv2model": 57, "deepseekv2pretrainedmodel": 57, "deepseekv2rmsnorm": 57, "deepspe": 115, "def": [20, 22, 57, 62, 63, 84, 107, 109], "default": [16, 23, 46, 62, 69, 107], "defin": [2, 3, 28, 39, 40, 46, 47, 49, 50, 60, 61, 62, 63, 64, 65, 70, 71, 79, 86, 102, 106, 107, 110, 111, 112], "definit": [42, 106], "degener": 71, "degrad": [58, 61], "degre": [12, 60], "dejian": [45, 97], "deli": [45, 97], "deliber": 96, "delimit": [10, 94], "deliv": 61, "delta": [47, 60, 116], "delta_": [74, 79], "delta_t": 79, "demonstr": [2, 3, 10, 11, 12, 13, 17, 21, 47, 48, 58, 64, 65, 69, 73, 75, 76, 85, 90, 92, 99, 106, 107, 108], "deng": [45, 97], "dengr": [45, 97], "denni": [45, 97], "denomin": 47, "denot": [42, 47, 49, 52, 55, 68, 70, 72, 73, 79, 84, 85, 95, 105, 108, 109, 111], "dens": [12, 61, 64, 108], "densifi": 58, "densiti": 84, "depend": [10, 12, 23, 39, 45, 49, 62, 63, 71, 73, 76, 88, 94, 106, 107, 109, 110, 111], "depict": [11, 80, 92], "deploi": [61, 105], "deploy": 108, "depth": [31, 43], "deriv": [47, 55, 58, 84, 86, 107], "descend": 62, "descent": 10, "describ": [9, 10, 18, 29, 37, 54, 61, 81, 86, 106], "descript": [1, 26, 29, 42, 52, 53, 54, 61, 82], "description2cod": 35, "design": [17, 21, 26, 30, 39, 41, 42, 58, 64, 72, 80, 82, 92, 96, 105, 108], "desir": [13, 47, 61, 76, 82, 84], "despit": [12, 50, 58, 75, 76, 79], "destabil": 79, "detail": [1, 11, 46, 53, 54, 61, 63, 64, 65, 74, 76, 78, 79], "detect": [7, 28, 40, 52, 61, 64, 76], "determin": [58, 61, 64, 65, 70, 73, 88], "determinist": [48, 58, 92], "detoken": 113, "devbal": 105, "develop": [1, 2, 7, 39, 50, 55, 58, 64, 70, 80, 84, 87, 92, 94, 95], "deviat": [48, 62, 71, 74, 79, 85], "devic": [58, 62, 63, 107, 114], "devis": [24, 25, 38], "devlin": [45, 97], "dfag17": [45, 64, 97], "dhariw": [45, 97], "diagon": [55, 62, 63], "dialog": 62, "dialogu": [2, 55, 60, 61], "diamond": 25, "dict": 62, "dictionari": [18, 37, 84], "did": [65, 81], "differ": [3, 9, 12, 13, 18, 19, 21, 28, 37, 40, 45, 47, 48, 50, 52, 53, 54, 55, 57, 59, 60, 61, 63, 64, 65, 69, 71, 72, 73, 74, 75, 76, 77, 80, 82, 84, 96, 102, 105, 106, 108, 110, 111], "differenti": 82, "difficult": [25, 50, 54, 102], "difficulti": [21, 25, 30, 31, 39, 41, 43, 53, 61, 65, 94], "dill": 23, "dim": [62, 63, 107, 109], "dimens": [9, 49, 55, 57, 62, 63, 68, 72, 105, 106, 107, 108, 109, 111, 112], "dimension": [9, 68, 110, 111], "diminish": [76, 102], "ding": [45, 97], "diogo": [45, 97], "direct": [12, 21, 25, 31, 43, 46, 54, 64, 65, 76, 81, 82, 83, 84, 92, 97], "directli": [10, 17, 22, 24, 38, 48, 55, 56, 61, 69, 71, 74, 79, 81, 84, 94, 95, 106, 107, 111, 113], "directori": 62, "disagr": 61, "disagre": 87, "disallowed_speci": 62, "disallowed_token": 62, "disanalogi": 50, "discard": [18, 37, 61, 65, 87], "discontinu": [31, 43], "discount": 79, "discrep": [47, 52, 60, 85], "discret": [4, 60], "discrimin": [10, 52], "discuss": [55, 80, 96, 111], "disjoint": 29, "displai": [46, 76], "dispref": [71, 72], "disproportion": [61, 69], "distanc": [72, 107], "distil": [24, 38, 60, 82, 88], "distinct": [2, 57, 58, 64, 73, 76, 85, 102], "distinguish": [70, 73, 84], "distlib": 23, "distort": 109, "distract": 79, "distribut": [10, 12, 13, 31, 39, 43, 47, 52, 55, 58, 60, 62, 68, 69, 71, 73, 74, 75, 79, 80, 81, 84, 85, 87, 88, 92, 94, 95, 96, 105], "distro": 23, "div_": 62, "diverg": [13, 60, 71, 74, 79], "divers": [10, 11, 13, 17, 18, 21, 28, 29, 30, 31, 37, 39, 40, 41, 43, 48, 52, 53, 54, 55, 58, 61, 64, 65, 86, 87, 92, 94], "divid": [2, 9, 52, 54, 64, 74, 110, 111], "divis": 53, "dkv": 108, "do": [1, 12, 18, 19, 24, 28, 29, 37, 38, 40, 45, 47, 50, 53, 54, 56, 60, 61, 62, 63, 75, 87, 92, 94, 95, 96, 106, 108], "do_train": 115, "docstr": [17, 22, 55], "doctyp": 114, "document": [10, 11, 24, 29, 38, 45, 46, 55, 61, 65, 107], "doe": [1, 13, 28, 40, 55, 58, 62, 65, 71, 79, 85, 102, 107, 108, 109], "doesn": 107, "domain": [2, 11, 21, 25, 31, 43, 47, 58, 64, 70, 92, 94], "domin": 47, "don": 79, "done": [31, 43, 65], "dong": [45, 97], "dongji": [45, 97], "dot": [10, 47, 62, 63, 65, 72, 74, 76, 83, 86, 87, 105, 106, 107, 108, 110, 111, 113], "doubl": [54, 73, 102], "down": [53, 106, 107, 109], "down_proj": 57, "downstream": [12, 61, 116], "dpo": [32, 33, 48, 61, 64, 65, 77, 84, 86, 87], "dpop": [32, 61], "dq": 108, "dr": 11, "draw": [24, 38, 84], "drawback": 92, "drawn": [64, 73], "drive": 52, "drop": [21, 58], "drop_last": 77, "dschat": 77, "dtype": [62, 63], "du": [45, 97], "duan": [45, 97], "due": [39, 54, 58, 65, 68, 69, 105, 107, 109], "dulwich": 23, "duplic": 55, "dure": [3, 9, 10, 18, 21, 30, 37, 39, 47, 49, 52, 55, 56, 58, 60, 61, 64, 65, 69, 71, 79, 80, 92, 96, 99, 102, 105, 107, 108, 109], "dynam": [61, 76], "dz": 73, "e": [1, 2, 3, 4, 10, 13, 18, 19, 20, 22, 23, 24, 28, 37, 38, 40, 47, 50, 58, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 84, 85, 86, 87, 92, 94, 95, 104, 105, 106, 107, 109], "e501": 62, "e_": 87, "e_j": 102, "each": [1, 3, 7, 9, 10, 11, 13, 16, 18, 21, 22, 24, 25, 26, 28, 29, 30, 31, 36, 37, 38, 39, 40, 41, 43, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 72, 73, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 94, 95, 96, 102, 105, 106, 107, 108, 109, 116], "earli": [80, 94], "earlier": [13, 60, 61, 80, 94], "easi": [7, 16, 17, 47, 50, 54, 55, 65, 77, 84], "easier": [10, 50, 54, 69, 84, 107], "easili": [9, 19, 24, 38, 52], "eason": 19, "echo": [62, 102], "econom": [21, 45, 57, 58, 97], "ecosystem": 45, "ecut": 19, "edg": 65, "edit": [1, 7, 18, 26, 29, 37, 54, 61, 72, 95], "editor": [7, 55], "educ": [39, 65], "edward": [45, 97], "ee": [32, 33], "effect": [2, 7, 9, 24, 30, 38, 39, 50, 54, 56, 58, 64, 69, 70, 72, 74, 79, 81, 84, 85, 86, 99, 102, 107, 110, 111], "effici": [7, 10, 45, 53, 57, 58, 64, 74, 79, 96, 97, 105, 108], "effort": [39, 56, 57, 58, 88], "eft": 86, "either": [3, 18, 37, 53, 57, 60, 61, 76, 79, 95, 96], "electron": 114, "element": [9, 13, 55, 75, 107, 108, 110, 111], "elementari": [21, 25], "elev": 57, "elicit": [50, 73, 80, 81], "elimin": [29, 31, 43, 79], "elizabeth": [45, 97], "elment": 62, "elo": 80, "els": [57, 62, 63, 80, 88, 107], "embed": [1, 10, 45, 55, 57, 59, 62, 63, 64, 97, 110], "embed_token": 57, "emerg": 90, "emit": [3, 72], "emphas": [11, 95], "empir": [11, 47, 50, 102, 106, 107], "emploi": [1, 2, 3, 9, 13, 16, 24, 31, 38, 39, 43, 48, 55, 56, 57, 58, 61, 62, 64, 65, 68, 74, 85, 92, 105], "empow": [31, 43, 45, 97], "empti": [18, 37, 105], "emptyset": 88, "enabl": [2, 3, 4, 12, 25, 54, 55, 58, 70, 76, 92, 105, 106, 107, 110, 111], "encod": [10, 11, 28, 40, 52, 55, 57, 59, 62, 64, 106, 107, 110, 111, 114], "encode_dialog_prompt": 62, "encode_head": 62, "encode_messag": 62, "encoding_for_model": 62, "encompass": 56, "encount": [9, 61, 105], "encourag": [11, 28, 29, 40, 47, 50, 53, 61, 70, 82, 94], "end": [7, 9, 10, 13, 16, 18, 24, 28, 37, 38, 40, 49, 53, 55, 58, 60, 62, 63, 69, 70, 71, 72, 74, 75, 80, 81, 82, 84, 88, 94, 95, 96, 99, 105, 106, 107, 108, 110, 111, 112], "end_header_id": 62, "end_of_text": 62, "enforc": [92, 94, 107], "engin": [2, 21, 29, 39, 65, 77], "english": [18, 37, 57], "enhanc": [2, 17, 21, 24, 38, 39, 42, 45, 48, 57, 58, 64, 65, 69, 85, 97], "enlarg": 102, "enlighten": [24, 38], "enlist": 58, "enough": [12, 19, 50, 57, 60, 72, 84, 108], "enrich": 17, "ensembl": [48, 85], "ensur": [2, 9, 13, 19, 25, 26, 30, 31, 43, 52, 58, 60, 61, 64, 65, 72, 79, 88, 96, 105, 109], "entail": 10, "enter": 1, "entir": [35, 59, 95, 96, 109], "entri": [24, 26, 38, 39, 55, 62, 63], "entropi": [49, 52, 61, 69, 70, 73, 81], "entry_point": 20, "enumer": [62, 63, 107], "env": 23, "environ": [3, 4, 7, 13, 23, 47, 61, 65, 75, 79], "eo": [62, 79], "eos_id": 62, "eos_idx": 62, "eos_reach": 62, "eot_id": 62, "ep": [62, 63, 109], "episod": [13, 75, 77], "epoch": [31, 39, 43, 57, 59, 60, 73, 75, 77, 92, 96, 99], "epsilon": [62, 63, 69, 74, 79, 109], "epsilon_": 69, "equal": [47, 59, 69, 106, 108, 110], "equat": [84, 95, 102, 111], "equip": [94, 95, 108, 114], "equival": [11, 45, 52, 54, 82, 84, 97, 105], "erhang": [45, 97], "eric": [45, 97], "ermon": [45, 97], "error": [2, 3, 7, 28, 40, 50, 54, 61, 62, 65, 74, 79, 112], "especi": [7, 28, 40, 102, 109], "essenti": [52, 54, 76], "est": 104, "establish": [58, 84, 94], "estat": 104, "estim": [22, 47, 49, 53, 60, 71, 74, 79, 84, 104], "estrang": 104, "etc": [18, 28, 37, 40, 57], "ethic": [21, 80], "eval": [16, 19, 32, 33, 73], "eval_step": 77, "evalperf": 20, "evalplu": [24, 33, 38], "evalu": [3, 16, 18, 21, 22, 29, 30, 37, 41, 45, 47, 49, 50, 56, 60, 69, 80, 83, 85, 86, 92, 94, 95, 96, 97, 102, 108], "evan": [45, 97], "evas": 80, "even": [1, 3, 12, 31, 43, 47, 50, 58, 61, 65, 71, 72, 84, 107, 108, 110, 111], "evenli": [36, 53], "event": [13, 73, 74], "everi": [2, 9, 12, 25, 28, 40, 81, 106, 109], "evid": [50, 107], "evol": [24, 38, 39], "evolut": [31, 43], "evolutionari": [31, 43], "evolv": [31, 43], "exact": [3, 25, 55], "exactli": [29, 47, 79], "exam": 21, "examin": [1, 17, 70], "exampl": [12, 13, 17, 18, 22, 24, 28, 29, 37, 38, 39, 40, 45, 47, 50, 52, 54, 55, 57, 60, 61, 64, 68, 71, 72, 76, 80, 81, 82, 85, 86, 87, 88, 92, 94, 99, 106, 107, 109], "exce": [18, 37, 48, 62, 94], "exceed": [106, 107], "excel": 58, "except": [12, 31, 43, 48, 57, 58, 61, 62, 72, 108], "exceptiongroup": 23, "excess": [58, 69, 79], "exchang": 99, "exclud": 69, "exclus": [21, 59, 96], "execut": [1, 3, 17, 19, 23, 29, 39, 45, 46, 52, 53, 55, 61, 64, 65, 97, 107], "executor": 65, "exemplar": [81, 90], "exemplifi": 82, "exhibit": [57, 69, 76, 92, 95], "exist": [1, 2, 21, 22, 24, 28, 35, 38, 40, 52, 61, 65, 87, 94, 106, 107, 113], "exit": 94, "exp": [13, 62, 63, 68, 71, 84, 111, 112], "expand": [58, 64], "expans": 107, "expbal": 105, "expect": [13, 28, 40, 47, 53, 58, 61, 65, 69, 74, 76, 79, 80, 102, 107], "expens": [50, 55, 71, 88], "experi": [9, 10, 13, 25, 31, 43, 57, 60, 61, 70, 71, 73, 75, 77, 80, 81, 85, 96, 99], "experience_mak": 77, "experiment": [21, 39], "expert": [25, 45, 57, 58, 61, 65, 97], "expert1": 105, "expert2": 105, "expert3": 105, "expertis": 61, "explain": [54, 61, 65, 68, 81], "explan": [61, 81], "explicit": [4, 11, 58, 106, 107, 110, 111], "explicitli": [18, 37, 60, 80, 82, 95], "exploit": [12, 69], "explor": [54, 60, 69, 70, 74, 76, 90, 92], "exponenti": 107, "export": 23, "express": [3, 12, 22, 71, 73], "extend": [4, 33, 55, 57, 58, 61, 62, 64, 77, 88, 92], "extens": [3, 17, 23, 45, 54, 64, 76, 107], "extern": [2, 39, 92], "extra": [10, 19, 54, 94, 106, 107], "extract": [24, 38, 61, 68, 70, 81], "extractor": 68, "extrapol": [9, 106], "extrem": [9, 25, 47, 50, 58], "f": [20, 62, 63, 94, 104, 106, 107, 112], "f_": [68, 70, 88, 105, 110, 111], "face": [85, 92], "facilit": [9, 52, 76, 79], "fact": 107, "factor": [9, 49, 65, 68, 79, 105, 106, 107, 112], "factual": [64, 92], "fail": [29, 54, 61, 64, 65], "failur": [50, 61, 65], "fair": 108, "faith": 61, "faithfulli": [50, 76], "fake": 76, "fals": [57, 62, 63, 109], "famili": [50, 53, 55, 107], "fan": [45, 97], "fangyun": [45, 97], "fanjia": [45, 97], "far": [61, 69, 73, 79], "fashion": [28, 40, 95], "fast": 62, "fastavro": 23, "faster": [16, 69], "fastjsonschema": 23, "faulti": 61, "favor": [68, 94], "featur": [50, 55, 62, 68, 77, 109], "februari": 65, "fed": [10, 65], "federico": [45, 97], "feed": [49, 62, 63, 64, 105, 112], "feed_forward": [62, 63], "feedback": [7, 13, 45, 50, 55, 56, 57, 58, 61, 64, 65, 71, 73, 76, 84, 86, 88, 92, 96, 97], "feedforward": 10, "fei": [45, 97], "felip": [45, 97], "feng": [45, 97], "few": [11, 12, 13, 21, 28, 40, 45, 52, 53, 55, 80, 81, 86, 88, 90, 96, 97], "fewer": [54, 57, 106, 107], "ff": [49, 112], "ffff": 114, "ffff\u7684\u8303\u56f4": 114, "ffn": [9, 57, 58, 62, 63, 64, 105], "ffn_norm": [62, 63], "fiction": 11, "field": [2, 18, 25, 28, 30, 37, 40, 41, 65], "fifo": 73, "fig": 3, "figur": [1, 7, 9, 49, 56, 58, 60, 73, 76, 80, 92, 102], "file": [1, 7, 18, 23, 29, 37, 39, 46, 55, 62, 65], "filelock": 23, "filenam": 7, "fill": [3, 55, 58, 60], "filter": [13, 19, 24, 29, 38, 39, 56, 57, 61, 64, 65, 69, 70, 87, 88, 94, 96, 102], "fim": [58, 65], "final": [1, 9, 10, 11, 13, 25, 28, 29, 31, 40, 42, 43, 47, 53, 56, 57, 58, 59, 60, 61, 65, 68, 69, 70, 71, 75, 76, 79, 80, 81, 82, 83, 84, 86, 87, 88, 92, 94, 96, 105], "find": [7, 18, 21, 29, 37, 48, 49, 50, 52, 53, 57, 60, 61, 69, 75, 80, 81, 84, 86, 92, 94, 95, 96, 102, 108], "find_fil": 7, "fine": [12, 13, 18, 30, 31, 37, 39, 41, 43, 61, 65, 71, 74, 76, 82, 83, 84, 86, 95, 96, 99, 102, 106, 107], "finer": 105, "finest": 104, "finetun": [12, 24, 31, 38, 43, 50, 64, 80, 88, 94, 96], "finetuning_typ": 115, "finn": [45, 97], "fire": 20, "first": [1, 2, 3, 9, 10, 11, 13, 19, 24, 28, 38, 39, 40, 47, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 69, 70, 71, 72, 73, 75, 76, 77, 81, 84, 85, 86, 87, 92, 94, 95, 96, 102, 105, 108, 111, 112], "first_k_dense_replac": 57, "firstli": 54, "fit": [29, 49, 73, 77, 84, 107], "five": [31, 43, 65], "fix": [1, 9, 13, 29, 49, 54, 61, 73, 75, 96, 106, 109], "flag": 62, "flagopen": 30, "flash": [32, 33], "flash_attn": 77, "flatten": [62, 63, 107], "flavor": 45, "flaw": 65, "flexibl": [3, 70, 105], "flexibli": 105, "flip": [76, 95], "float": [62, 63, 84, 107, 109], "float32": [62, 63], "flow": 3, "fluenci": 47, "focu": [18, 29, 37, 39, 47, 59, 64, 73, 96], "focus": [16, 21, 23, 30, 39, 41, 56, 58, 64, 76, 92], "fold": 17, "follow": [1, 2, 9, 10, 11, 12, 13, 16, 17, 18, 19, 20, 23, 24, 25, 29, 31, 37, 38, 43, 45, 46, 55, 56, 58, 59, 60, 61, 62, 63, 64, 68, 69, 71, 72, 74, 75, 76, 79, 80, 81, 82, 84, 85, 87, 92, 97, 99, 105, 106, 107, 108], "fool": 96, "foral": [10, 70], "forc": [25, 52, 54, 94, 95], "forcefulli": 94, "forecast": 2, "forgo": 73, "form": [9, 31, 43, 53, 55, 58, 71, 73, 79, 82, 86, 96, 106, 107], "formal": [70, 74], "format": [1, 3, 4, 23, 25, 28, 31, 40, 43, 55, 58, 80, 92], "formatt": 62, "former": [1, 4, 70], "formul": [47, 70, 71, 79, 85, 105], "fortun": 71, "forum": [45, 97, 99], "forward": [49, 62, 63, 64, 105, 106, 109, 112, 116], "foster": 70, "fotio": [45, 97], "found": [9, 10, 13, 21, 28, 40, 52, 53, 54, 60, 65, 70, 80, 106, 107], "foundat": [24, 31, 38, 43, 55, 59, 61, 65, 79], "four": [11, 21, 31, 43, 55, 60, 61, 85, 92, 108], "frac": [9, 13, 22, 47, 49, 62, 63, 68, 69, 71, 72, 74, 75, 76, 79, 84, 85, 94, 105, 106, 107, 108, 109, 110, 111, 112, 113], "fraction": 22, "framework": [20, 28, 40, 57, 58, 64, 65, 76], "fraser": [45, 97], "free": [23, 45, 58, 65, 87, 97], "freez": [68, 116], "freq": [62, 63, 107], "freqs_ci": [62, 63, 107], "frequenc": [9, 55, 105, 107, 110, 111], "frequent": [106, 107], "fresh": 96, "friendli": 80, "from": [2, 7, 9, 11, 12, 13, 16, 17, 18, 20, 21, 22, 23, 25, 28, 29, 31, 32, 35, 36, 37, 39, 40, 42, 43, 45, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 71, 72, 73, 74, 75, 79, 82, 83, 84, 85, 86, 87, 88, 92, 94, 95, 96, 97, 99, 102, 105, 106, 107, 108, 109, 111, 113, 114], "frontier": 25, "frozen": 69, "frozenlist": 23, "fsdp": 94, "fsfairx": 48, "fsspec": 23, "fu": [45, 97], "fulfil": [2, 76], "fuli": [45, 97], "full": [50, 54, 55, 56, 58, 62, 63, 77, 115], "fulli": [3, 9, 18, 37, 42, 50, 58, 65, 69], "function": [1, 3, 7, 9, 12, 13, 17, 19, 26, 29, 45, 47, 50, 54, 55, 59, 60, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 79, 84, 85, 94, 95, 106, 107, 109, 110, 111, 112], "fundament": [12, 50], "further": [18, 24, 37, 38, 39, 48, 53, 55, 56, 57, 60, 61, 64, 65, 70, 73, 74, 88, 105, 107, 111], "furthermor": [58, 69, 80], "futur": [1, 2, 50, 57, 58], "g": [2, 3, 4, 23, 24, 28, 38, 40, 58, 60, 61, 65, 68, 69, 74, 81, 82, 84, 87, 92, 94, 95, 106, 110, 111], "g_": [58, 68, 105], "g_t": 79, "gabriel": [45, 97], "gae": [74, 79], "gain": [10, 12, 24, 38, 54, 60, 65, 76, 81], "gamma": [13, 47, 58, 62, 63, 74, 75, 76, 79, 106, 109], "gao": [45, 97], "gap": [3, 21, 24, 38, 47, 48, 50, 61, 65, 83], "gate": [45, 58, 68, 97, 105], "gate_proj": 57, "gather": [60, 62, 64], "gating_dim": 105, "gaussian": 112, "gave": [18, 37], "gb2312\u56e0\u4e3a\u53ea\u8868\u793a\u666e\u901a\u6570\u5b57": 114, "gbk\u662fascii": 114, "ge": [22, 28, 40, 45, 68, 70, 72, 74, 84, 97], "geglu": 112, "gelu": 112, "gemini": [53, 56, 73], "gen": 62, "gener": [2, 3, 4, 7, 9, 10, 11, 12, 13, 18, 19, 22, 23, 24, 29, 30, 31, 37, 38, 39, 41, 42, 43, 45, 47, 52, 53, 54, 55, 56, 57, 58, 60, 61, 64, 65, 69, 71, 72, 73, 74, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 94, 95, 97, 102, 106, 108], "generalist": 70, "generate_kwarg": 77, "generate_max_len": 77, "generation_logprob": 62, "generation_token": 62, "generativeai": 23, "generativelanguag": 23, "geometr": [9, 111], "geometri": 61, "get": [25, 45, 46, 47, 55, 65, 68, 84], "get_unique_el": 55, "gg": 49, "gibb": 71, "gibberish": [47, 69], "girish": [45, 97], "git": [20, 23], "github": [18, 20, 23, 29, 30, 37, 39, 52, 56, 59, 62, 63, 64, 65], "give": [10, 86, 87, 107], "given": [2, 7, 9, 10, 13, 17, 18, 28, 29, 31, 37, 40, 43, 47, 49, 50, 52, 54, 55, 59, 60, 61, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 81, 82, 84, 86, 87, 88, 95, 96, 102, 106, 107], "glob": 62, "glu": [62, 63], "go": [77, 79], "goal": [10, 54, 65, 69, 71, 84, 87, 94, 95], "gold": [32, 52, 53], "gomez": [45, 97], "good": [19, 32, 47, 50, 52, 58, 61, 74, 84, 87], "googl": [20, 23], "googleapi": 23, "google\u7684bert\u6a21\u578b\u5728\u5206\u8bcd\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662fwordpiece\u7b97\u6cd5": 113, "goto": 7, "gpt": [11, 12, 13, 16, 18, 24, 25, 32, 33, 37, 38, 45, 50, 61, 62, 86, 96, 97, 102], "gpt2": 32, "gpt3": 32, "gpt4": 56, "gpu": [58, 94, 115], "gqa": [45, 64, 97], "grade": 25, "gradient": [9, 10, 13, 59, 72, 73, 75, 79], "gradient_accumulation_step": 115, "gradient_checkpoint": 77, "gradual": 55, "grai": [45, 97], "grain": [30, 41, 61, 76], "gram": [39, 65], "grammar": [28, 40], "grammat": [28, 40], "grangier": [45, 97], "granular": 21, "graphic": 25, "great": 62, "greater": 21, "greatli": [12, 116], "greedi": [11, 20, 24, 38, 48, 61, 62, 102], "greg": [45, 97], "gretchen": [45, 97], "grid": 107, "grl": [19, 45, 97], "ground": [3, 17, 26, 36, 50, 56, 57, 58, 65, 69, 70, 71, 84, 87], "group": [52, 53, 56, 57, 58, 62, 64, 65, 69, 85, 92, 105, 108], "grow": [9, 12, 73], "grpcio": 23, "grpo": [32, 33, 56, 64, 69, 70], "gsm8k": [32, 48, 65, 102], "gu": [45, 97], "guan": [45, 97], "guangbo": [45, 97], "guant": [45, 97], "guarante": [22, 70, 72, 74, 105], "guard": 35, "guardrail": 7, "guess": 21, "guid": [28, 40, 48, 70, 84, 85, 92], "guo": [45, 97], "guowei": [45, 97], "guss": [45, 97], "h": [9, 45, 57, 60, 62, 63, 97, 105, 106, 108, 116], "h06a4308_0": 23, "h100": 94, "h11": 23, "h1181459_1": 23, "h1234567_1": 23, "h39e8969_0": 23, "h5eee18b_0": 23, "h5eee18b_1": 23, "h5eee18b_6": 23, "h6a678d5_0": 23, "h6a678d5_1": 23, "h800": 58, "h955ad1f_1": 23, "h_": [10, 107], "h_j": 107, "h_n": 10, "ha": [2, 3, 9, 11, 12, 13, 16, 25, 28, 40, 47, 50, 56, 57, 60, 61, 62, 63, 64, 69, 73, 74, 85, 88, 95, 102, 106, 108, 112], "hack": [58, 60, 68, 69, 80, 92], "had": [13, 26, 52], "half": [50, 52, 55], "hallucin": 65, "hallucinatori": 57, "halv": 9, "ham": 72, "han": [45, 97], "hand": [22, 26, 49, 50, 58, 73], "handl": [10, 65], "handwritten": 22, "hanq": [45, 97], "hanwei": [45, 97], "hao": [45, 97], "haoran": [45, 97], "haowei": [45, 97], "haoyu": [45, 97], "happen": 107, "har": 58, "hard": [53, 54, 71, 82, 108], "harder": 53, "harm": [80, 82], "harmless": [64, 81, 82, 86], "harri": [45, 97], "hasten": 7, "hat": [47, 69, 71, 74, 79, 85, 95], "have": [1, 2, 9, 10, 11, 22, 24, 25, 28, 29, 38, 40, 46, 47, 49, 50, 53, 54, 56, 58, 60, 61, 64, 68, 69, 71, 72, 80, 84, 85, 86, 87, 94, 99, 102, 105, 106, 107, 109, 112], "hbb": [21, 45, 97], "hd_": 9, "he": [45, 97], "head": [10, 45, 49, 57, 58, 62, 63, 86, 97, 106, 107, 114], "head_dim": [62, 63], "header": 1, "health": 21, "heart": 87, "heavi": [49, 95, 108], "hebgen": [45, 97], "heewoo": [45, 97], "heidi": [45, 97], "height": 62, "held": 12, "help": [7, 10, 13, 25, 45, 54, 55, 57, 58, 60, 61, 64, 65, 68, 73, 75, 80, 82, 86, 106], "helpfulli": 75, "helpsteer2": 32, "henc": [3, 56, 71, 86], "hendryck": [45, 97], "henighan": [45, 97], "henriqu": [45, 97], "herbert": [45, 97], "herd": 61, "here": [9, 12, 18, 31, 37, 43, 45, 47, 49, 59, 60, 61, 102, 106, 107], "hess": [45, 97], "heurist": [13, 24, 25, 28, 38, 40], "hf": 84, "hh": 80, "hidden": [57, 62, 63, 68, 105, 106, 112], "hidden_dim": [62, 63], "hidden_s": [57, 105], "hierarch": 1, "high": [10, 17, 22, 24, 25, 29, 38, 39, 47, 48, 52, 58, 60, 61, 64, 65, 68, 69, 70, 72, 73, 79, 85, 86, 87, 88, 95, 99, 104, 110, 111], "highconfid": 88, "higher": [3, 30, 41, 48, 53, 54, 58, 61, 64, 65, 73, 76, 85, 105, 106], "highest": [16, 18, 25, 31, 37, 43, 48, 58, 61, 73, 85, 86, 104, 105, 110], "highli": [25, 50, 65, 68, 87, 88, 96], "highlight": [2, 39], "highqual": 58, "hilton": [45, 97], "hinder": [79, 85], "hing": 71, "histor": 74, "histori": [7, 21, 47], "hoc": 81, "hold": [49, 96], "holdgraf_evidence_2014": 45, "holist": [23, 45, 97], "home": 23, "homepag": 69, "honesti": 68, "hongcheng": [45, 97], "honghui": [45, 97], "hongyi": [45, 97], "hood": [24, 38], "hook": 23, "hope": 25, "hotfix": 23, "hou": [45, 97], "hour": 58, "hous": 56, "how": [2, 7, 13, 16, 21, 25, 29, 46, 47, 50, 53, 61, 65, 68, 70, 71, 74, 81, 82, 90, 92, 96, 102, 107], "howev": [1, 2, 22, 28, 40, 47, 48, 50, 57, 60, 61, 68, 69, 71, 75, 76, 82, 84, 85, 94, 105, 106, 107, 109, 111], "hstack": [62, 63], "html": 114, "http": [20, 23, 24, 28, 31, 38, 40, 43, 45, 97], "httpcore": 23, "httplib2": 23, "httpx": 23, "hu": [45, 97], "huajian": [45, 97], "huan": [45, 97], "huang": [45, 97], "huazuo": [45, 97], "hub": 23, "huge": [54, 107], "huggingfac": [23, 77], "hugh": [45, 97], "hui": [45, 97], "human": [7, 12, 13, 16, 19, 21, 25, 26, 28, 31, 36, 40, 43, 45, 47, 50, 55, 57, 58, 61, 64, 65, 71, 73, 75, 76, 80, 81, 82, 83, 84, 86, 87, 88, 92, 96, 97], "humanev": [17, 31, 33, 39, 43, 48, 65], "humanevalplu": 20, "humanevalplus_releas": 20, "hundr": [58, 107], "hunter": [45, 97], "hurt": 65, "hybridengin": 77, "hyc": [45, 65, 97], "hyper": [58, 59, 62, 63, 64, 69, 74, 76], "hyperparamet": [49, 53, 61, 64, 69, 72, 73, 76, 79, 99], "hypothes": 9, "hypothesi": 12, "i": [1, 2, 7, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 84, 85, 86, 87, 88, 92, 94, 96, 97, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114], "i_": [28, 40], "i_t": [28, 40], "icl": 102, "id": [13, 45, 62, 97], "id1": 23, "id2": 23, "idea": [76, 88, 106, 107], "ideal": [2, 18, 21, 37, 107], "ident": [9, 64, 69, 71, 73, 87, 96, 105], "identif": 65, "identifi": [2, 13, 16, 17, 21, 28, 40, 48, 64, 65, 69, 70, 73, 76, 80, 82, 85, 88], "idna": 23, "ifev": 57, "ifstat": 3, "ift": 86, "ignor": [47, 52, 62, 107], "ignore_index": 62, "igor": [45, 97], "ij": 102, "ik_": [62, 63, 106, 107], "illeg": 80, "illia": [45, 97], "illustr": [1, 7, 50, 56, 58, 60, 62, 63, 92], "ilya": [45, 97], "im": [62, 63, 106, 107], "imag": [2, 49, 94], "imaginari": [106, 107], "imbal": [58, 105], "imit": 50, "impact": [39, 48, 53, 65, 69, 96, 106], "imped": 69, "imper": [18, 37], "imperfect": 88, "implement": [2, 13, 17, 22, 31, 43, 57, 58, 59, 64, 65, 79, 88], "impli": 69, "implicit": 71, "implicitli": [50, 71, 95], "import": [3, 7, 17, 20, 22, 39, 47, 50, 60, 62, 63, 71, 84, 86, 87, 99, 107, 109], "importantli": [65, 71, 94, 108], "importlib": 23, "impress": 65, "improv": [10, 12, 24, 38, 42, 45, 47, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 70, 72, 74, 81, 85, 86, 87, 88, 90, 92, 94, 95, 96, 97, 102, 109], "inabl": 69, "inappropri": 76, "incentiv": 95, "includ": [2, 10, 18, 21, 22, 25, 29, 30, 31, 35, 36, 37, 39, 41, 43, 46, 48, 49, 50, 52, 53, 55, 57, 58, 60, 61, 62, 64, 65, 71, 80, 83, 84, 106, 107, 109, 115], "inclus": 65, "incorpor": [4, 9, 39, 58, 60, 61, 64, 69, 74, 79, 110, 111], "incorrect": [52, 54, 85, 88, 95, 96], "incorrectli": [25, 71], "increas": [21, 24, 31, 38, 39, 43, 53, 55, 58, 61, 69, 71, 72, 76, 102, 105, 107, 111], "increasingli": 92, "increment": 106, "inde": 76, "indent": 65, "independ": [28, 40, 55, 94, 109, 113], "index": [62, 63, 73, 74, 106, 107, 108], "indic": [13, 21, 53, 62, 68, 73, 76, 79, 82, 94, 102, 106, 107, 108, 110], "individu": [49, 69, 70, 109, 110, 111], "induc": [11, 58, 84], "inequ": 71, "inf": [62, 63], "infer": [18, 37, 39, 47, 55, 57, 58, 59, 61, 62, 69, 76, 77, 81, 84, 87, 105, 107, 108, 109], "inference_mod": [62, 63], "infin": 39, "inflat": 65, "influenc": [69, 70, 102], "infomax": 73, "inform": [1, 2, 7, 9, 13, 18, 25, 37, 39, 45, 46, 52, 60, 61, 64, 74, 85, 97, 105, 107, 110, 111, 114], "infrastructur": 107, "infti": 49, "inher": [10, 13], "inherit": 68, "init": 46, "init_kl_coef": 77, "initi": [2, 13, 24, 28, 31, 38, 40, 43, 54, 55, 57, 60, 61, 62, 69, 71, 73, 75, 80, 82, 88, 92, 99], "inject": [9, 106, 107, 116], "inlin": [45, 71], "inner": [110, 111], "innov": [57, 108], "input": [1, 2, 9, 13, 18, 19, 24, 28, 31, 37, 38, 40, 43, 45, 52, 53, 54, 55, 59, 60, 62, 63, 65, 70, 72, 73, 75, 76, 79, 81, 84, 87, 99, 106, 107, 108, 109, 110, 111, 112, 113], "input_kei": 77, "input_text_mask": 62, "inputgen": 20, "inputoutput": 54, "insert": [9, 45, 52, 62, 73], "insid": 74, "insight": [7, 71], "inspect": 26, "inspir": [24, 38, 70], "inst": 55, "instabl": [22, 79, 109], "instag": 61, "instal": 20, "instanc": [3, 10, 18, 29, 37, 57, 58, 62, 68, 80, 92], "instead": [9, 11, 13, 18, 22, 31, 37, 43, 50, 53, 55, 59, 62, 63, 69, 73, 74, 76, 79, 80, 88, 106, 107, 109, 111], "instruciton": [18, 37], "instruct": [2, 3, 7, 12, 13, 16, 18, 29, 32, 33, 37, 45, 46, 48, 50, 56, 57, 60, 61, 68, 70, 76, 80, 81, 85, 92, 94, 95, 97, 99], "instructgpt": 75, "instruction_prefix": 20, "instructionfollow": 86, "int": [57, 62, 63, 84, 107, 109], "int_": 73, "integ": [62, 69], "integr": [4, 7, 21, 58, 64, 65, 70], "intend": 69, "intens": [57, 65], "intent": [13, 17, 85], "intention": 76, "interact": [4, 7, 47, 61, 62, 63, 73, 76, 79, 109], "interc": [68, 105, 106, 107, 108, 110], "interchang": 114, "interdepend": 109, "interest": [50, 61, 84], "interesting": 47, "interestingli": 65, "interfac": 13, "interfer": 109, "interleav": 95, "interlm2": 32, "intermedi": [42, 49, 50, 56, 57, 58, 90, 92, 96, 105], "intermediate_s": 57, "intern": [50, 58, 61], "internet": 75, "interpol": 55, "interpret": [13, 39, 60, 74], "interv": 102, "intervent": 94, "interview": [2, 55], "intric": 64, "intrigu": 92, "intrins": 92, "introduc": [2, 3, 7, 16, 21, 24, 25, 28, 38, 39, 40, 42, 47, 53, 58, 61, 62, 64, 65, 69, 70, 74, 81, 84, 92, 105, 106, 107, 109], "introduct": 81, "intuit": [47, 50, 71, 111], "invas": 80, "invest": [57, 73, 106, 107], "investig": [58, 69, 70, 76, 96, 99, 102], "invok": 2, "involv": [18, 25, 37, 49, 58, 61, 105], "ion": [45, 97], "ip": 81, "ipo": 71, "ipynb": 45, "iq_": [62, 63, 106, 107], "irrelev": 39, "is_safeti": 60, "ise": 20, "isequival": 69, "isin": 62, "isol": 65, "issu": [1, 11, 17, 29, 56, 58, 61, 68, 80, 81, 92, 95, 105, 107, 109], "item": [77, 84], "iter": [7, 13, 28, 31, 40, 43, 54, 62, 64, 73, 75, 76, 84, 85, 86, 95], "itertool": 23, "its": [3, 12, 24, 26, 28, 29, 38, 40, 50, 52, 53, 55, 57, 58, 61, 62, 63, 64, 65, 68, 69, 71, 73, 76, 79, 80, 84, 86, 92, 94, 95, 96, 102, 105, 106, 107, 108, 109, 111, 112], "itself": [28, 40, 56, 86, 95], "ix_": [62, 63, 106, 107], "j": [45, 47, 58, 62, 63, 69, 70, 72, 74, 76, 79, 87, 97, 105, 106, 107, 108, 111], "j_": [74, 87], "j_1": 76, "j_q": 76, "jack": [45, 97], "jacob": [45, 97], "jain": [45, 97], "jakob": [45, 97], "jame": [45, 97], "jan": [45, 97], "jaraco": 23, "jare": [45, 97], "java": 65, "javascript": 65, "jeepnei": 23, "jeff": [45, 97], "jeffrei": [45, 97], "jerri": [45, 97], "jgzp23": [45, 64, 97], "jhg": [23, 45, 97], "ji": [45, 97], "jiaheng": [45, 97], "jiajun": [45, 97], "jian": [45, 97], "jiang": [45, 97], "jianhong": [45, 97], "jianlin": [45, 97], "jianwei": [45, 97], "jianxin": [45, 97], "jianzhong": [45, 97], "jiaqi": [45, 97], "jiashi": [45, 97], "jiatao": [45, 97], "jiawei": [45, 97], "jiaxi": [45, 97], "jie": [45, 97], "jin": [45, 97], "jingren": [45, 97], "jingxiang": [45, 97], "jingyang": [45, 97], "jinja2": 23, "jinz": [45, 97], "jmespath": 23, "joblib": 23, "john": [45, 97], "jointli": 9, "jone": [45, 97], "jong": [45, 97], "joseph": [45, 97], "josh": [45, 97], "joshua": [45, 97], "json": [3, 18, 37, 57, 62, 115], "jsonl": 20, "jsonlin": 23, "judg": [16, 33, 53, 54, 61, 76, 86, 87], "judgement": 76, "judgment": [47, 65], "jun": [45, 97], "junji": [45, 97], "junxiao": [45, 97], "junyang": [45, 97], "jupyt": [45, 46], "jupyterbook": 45, "jupytext": 46, "just": [7, 21, 23, 45], "k": [9, 10, 11, 13, 22, 25, 31, 43, 45, 52, 58, 60, 61, 62, 63, 68, 70, 72, 73, 75, 79, 83, 97, 102, 105, 106, 107, 108, 110, 111, 116], "k_": [58, 62, 63, 70, 74, 105, 106, 107], "k_1": 74, "k_i": 74, "k_r": [58, 105], "kai": [45, 97], "kaig": [45, 97], "kaiser": [45, 97], "kang": [45, 97], "kaplan": [45, 97], "karl": [45, 97], "karma": 11, "katarina": [45, 97], "kati": [45, 97], "katti": 36, "ke": [45, 97], "keep": [7, 53, 57, 58, 60, 61, 65, 69, 95, 105, 112], "keepdim": [62, 63, 109], "kei": [2, 9, 25, 39, 50, 53, 54, 55, 57, 58, 62, 63, 64, 65, 69, 76, 79, 84, 102, 106, 107, 109, 110, 111], "kelton": [45, 97], "keme": [45, 97], "kenton": [45, 97], "keqin": [45, 97], "kernel": 46, "kexin": [45, 97], "keyr": 23, "keyword": 16, "khlaaf": [45, 97], "kind": [13, 45, 76], "king": [45, 97], "kl": [13, 60, 71, 74, 75, 84], "kmh": [12, 45, 97], "knew": 47, "knight": [45, 97], "know": [47, 50, 102], "knowledg": [3, 21, 24, 38, 39, 54, 60, 99, 105, 110, 111], "known": [2, 47, 62, 63, 85, 107], "kosaraju": [45, 97], "koushik": [45, 97], "kr": 108, "kristina": [45, 97], "krueger": [45, 97], "kto": [32, 48], "kv": [57, 64], "kv_a_layernorm": 57, "kv_a_proj_with_mqa": 57, "kv_b_proj": 57, "kv_lora_rank": 57, "kw_": 9, "kyunghyun": [45, 97], "l": [10, 13, 28, 40, 42, 45, 47, 49, 60, 62, 63, 70, 71, 72, 73, 74, 75, 79, 84, 85, 86, 87, 88, 95, 97, 104, 105, 106, 107, 108, 109], "l_": [10, 69, 71, 76, 85], "l_1": 76, "l_2": 76, "label": [10, 12, 13, 28, 30, 40, 41, 50, 56, 57, 60, 61, 64, 75, 80, 82, 84, 87, 88, 96, 102], "labor": 65, "lack": [69, 84], "lambda": [10, 72, 73, 74, 76, 79, 106, 107], "lambda_": [68, 106], "land": 80, "langl": [62, 63, 106, 107, 111], "languag": [4, 10, 11, 12, 13, 16, 17, 18, 21, 22, 25, 28, 29, 37, 39, 40, 44, 45, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 71, 73, 75, 88, 92, 94, 96, 97, 99, 105, 110, 111], "larg": [9, 10, 11, 12, 13, 16, 17, 19, 22, 28, 29, 39, 40, 44, 45, 47, 50, 53, 57, 58, 60, 61, 62, 63, 65, 69, 71, 72, 73, 75, 79, 88, 92, 97, 99, 105, 108, 111], "larger": [11, 29, 30, 41, 60, 61, 94, 96, 107, 111], "largest": [11, 30, 52, 53, 59, 60, 61], "last": [9, 12, 52, 61, 62, 68, 74, 80, 96], "latent": [57, 58], "later": [28, 40, 61, 94], "latest": [20, 60, 61], "latex": 25, "latter": 4, "law": [12, 21, 45, 50, 64, 97, 108], "layer": [9, 10, 11, 12, 13, 49, 52, 57, 59, 62, 63, 64, 68, 75, 77, 105, 106, 107, 108, 112, 116], "layer_id": [62, 63], "layer_idx": 57, "layernorm": [9, 109], "lcb": 23, "lcb_runner": 23, "lcft": 61, "ld_impl_linux": 23, "le": [22, 31, 43, 45, 58, 69, 72, 94, 97, 105, 107, 112], "lead": [39, 47, 50, 54, 55, 58, 59, 61, 69, 72, 80, 96, 106, 107, 109], "leakag": [35, 50, 65], "lean": [45, 97], "learn": [3, 9, 10, 11, 12, 13, 21, 25, 39, 47, 48, 49, 50, 52, 55, 59, 62, 63, 65, 69, 70, 71, 74, 79, 82, 84, 85, 86, 97, 99, 105, 112], "learnabl": 62, "learner": [11, 12, 45, 97], "learning_r": 115, "least": [11, 12, 16, 29, 53, 80], "leather": [45, 97], "leav": [52, 54, 69], "lebr\u00f3n": [45, 97], "lecong": [45, 97], "led": [60, 61, 80], "lee": [45, 97], "leed": 105, "leetcod": [23, 33, 56, 58, 92], "left": [9, 13, 22, 47, 49, 53, 55, 62, 63, 68, 69, 71, 72, 74, 75, 76, 79, 81, 84, 95, 106, 107, 108, 110, 111, 113], "leftarrow": [79, 108], "legal": 80, "lei": [45, 97], "leik": [45, 97], "len": [62, 77, 84], "length": [9, 49, 55, 57, 58, 60, 61, 62, 68, 69, 72, 76, 81, 94, 105, 106, 107, 108, 109], "lengthen": 94, "lengthi": 54, "less": [9, 13, 18, 28, 32, 33, 37, 40, 48, 56, 61, 69, 73, 74, 80, 85, 96, 102, 106], "let": [1, 25, 45, 46, 47, 57, 68, 70, 72, 79, 80, 84, 88, 97, 106, 108, 110, 111], "level": [11, 17, 21, 25, 26, 30, 31, 39, 41, 43, 45, 47, 50, 53, 55, 57, 58, 60, 61, 64, 65, 73, 96, 97], "leverag": [2, 24, 28, 38, 40, 54, 58, 60, 64, 92, 107, 110, 111], "lex": 107, "leyi": [45, 97], "lezama": [45, 97], "li": [45, 97], "liang": [45, 97], "libffi": 23, "libgcc": 23, "libgomp": 23, "librari": [3, 17, 39, 55], "libstdcxx": 23, "libuuid": 23, "lie": [80, 108], "lightman": [45, 97], "like": [1, 2, 7, 10, 17, 18, 21, 37, 45, 46, 47, 50, 54, 58, 64, 65, 72, 73, 80, 82, 87, 92, 96], "likelihood": [10, 47, 48, 52, 71, 72, 81, 84, 85, 88, 96], "limit": [1, 3, 12, 13, 28, 40, 50, 52, 53, 56, 58, 60, 61, 69, 73, 81, 84, 99, 105, 106, 107, 108], "lin": [45, 97], "line": [1, 7, 24, 28, 29, 31, 38, 40, 43, 45, 46, 49, 50, 55, 62], "linear": [9, 10, 55, 57, 59, 60, 62, 63, 64, 68, 69, 94, 102, 107, 111], "linearli": [9, 53, 99], "lingm": [45, 97], "link": 11, "linter": 61, "linzheng": [45, 97], "liqun": [45, 97], "list": [1, 18, 31, 37, 43, 53, 54, 55, 62, 77, 84, 102, 104], "liter": 62, "littl": 65, "litwin": [45, 97], "liu": [45, 97], "livecodebench": [32, 33, 45, 97], "liyu": [45, 97], "lkb": [25, 45, 97], "ll": [45, 62, 108, 116], "llama": [18, 19, 32, 37, 48, 62, 77, 86, 99, 102, 106, 109], "llama2": [32, 60, 102], "llama3": [32, 33, 63], "llion": [45, 97], "llm": [1, 2, 4, 16, 17, 23, 24, 31, 38, 39, 42, 43, 44, 45, 54, 55, 60, 61, 65, 68, 70, 71, 72, 74, 76, 79, 82, 86, 87, 92, 95, 97, 107], "llm4code": 20, "lm": [7, 11, 29, 75], "lm_head": 57, "ln": [45, 62, 73, 97, 107, 109], "load": [58, 62], "load_checkpoint": 77, "load_state_dict": 62, "load_tiktoken_bp": 62, "local": [1, 12, 95], "localhost": 115, "locat": [1, 7, 55, 107], "log": [10, 11, 13, 47, 53, 60, 62, 71, 72, 74, 75, 76, 79, 80, 81, 84, 85, 95, 96, 102, 113], "logging_step": [77, 115], "logic": [54, 58, 64, 65, 92], "logist": 85, "logit": [52, 60, 62, 71, 72, 106], "logprob": 62, "logprobs_i": 62, "long": [10, 13, 18, 29, 37, 45, 61, 62, 65, 69, 72, 92, 94, 97, 106, 107, 111], "longer": [9, 55, 57, 68, 69, 72, 81, 94, 99, 106, 107], "longterm": [45, 97], "look": 54, "loop": 3, "loos": 107, "lora": [32, 33], "lose": 86, "loss": [12, 13, 47, 49, 50, 52, 57, 58, 60, 61, 68, 70, 72, 73, 74, 75, 76, 81, 85, 99], "lot": [45, 106], "low": [19, 28, 39, 40, 45, 47, 60, 65, 69, 70, 72, 74, 88, 94, 97, 106, 111, 116], "lower": [3, 17, 18, 37, 69, 72, 102, 106], "lowest": [85, 86, 104, 105, 106], "lr": 39, "lr_scheduler_typ": 115, "lu": [45, 97], "luan": [45, 97], "lukasz": [45, 97], "luke": [45, 97], "luo": [45, 97], "lxwz23": [20, 45, 97], "lynx": 2, "m": [10, 23, 28, 40, 45, 58, 60, 62, 63, 70, 72, 73, 76, 84, 85, 97, 105, 106, 107, 110, 111], "m3toolev": 3, "m_": 84, "m_0": 86, "m_1": 86, "m_2": 86, "m_3": 86, "m_t": 86, "ma": [45, 97], "machin": [9, 11, 45, 55, 97], "maddi": [45, 97], "made": [31, 43, 64, 73, 81, 85], "magic": [32, 33], "magicod": [20, 39, 45, 61, 65, 97], "magnitud": [9, 11, 12, 50, 52, 107, 108], "mai": [9, 17, 39, 48, 50, 54, 56, 58, 61, 69, 72, 74, 80, 81, 82, 85, 92, 105, 107], "mail": 11, "main": [20, 23, 48, 50, 53, 54, 55, 59, 60, 61, 70], "mainli": [50, 54, 58, 65, 70, 85, 92], "mainstream": 65, "maintain": [56, 57, 58, 60, 64, 65, 79, 105], "major": [25, 61, 65, 82, 94, 96], "make": [2, 7, 9, 10, 13, 18, 21, 28, 29, 30, 37, 40, 47, 50, 53, 55, 62, 63, 64, 68, 69, 71, 73, 76, 77, 80, 86, 92, 94, 95, 107, 109, 110, 111], "make_experience_list": 77, "malform": 7, "man": [45, 97], "manag": [7, 23], "mani": [4, 11, 12, 25, 28, 29, 40, 45, 46, 55, 65, 75, 107, 114], "mann": [45, 97], "manner": [86, 87], "manta": [45, 97], "manual": [26, 28, 40, 69, 99], "map": 9, "map_loc": 62, "margin": [31, 43, 48, 60, 61], "mark": [45, 55, 61, 97], "markdown": [20, 56], "markdownfil": 46, "markedli": 45, "markup": 45, "markupsaf": 23, "mask": [9, 52, 55, 61, 62, 63, 69], "mass": [31, 43, 47, 62], "massiv": [21, 45, 64, 65, 97], "master_port": 115, "match": [3, 25, 30, 41, 58, 62, 64, 95, 106, 107, 108], "mateusz": [45, 97], "math": [21, 45, 56, 57, 58, 62, 63, 64, 65, 69, 72, 74, 92, 94, 96, 97], "mathbb": [9, 13, 22, 47, 60, 68, 69, 71, 72, 74, 75, 76, 79, 84, 85, 94, 95, 105, 106, 108, 110, 111, 116], "mathbf": [9, 47, 55, 58, 62, 63, 70, 74, 76, 79, 105, 106, 107, 108, 109, 110, 111], "mathcal": [10, 42, 47, 60, 68, 69, 71, 72, 73, 83, 84, 85, 87, 88, 94, 95, 102, 105, 108, 112], "mathemat": [21, 22, 25, 45, 56, 57, 58, 61, 64, 65, 71, 74, 94, 97], "mathmix": 96, "mathrm": 83, "matmul": [62, 63], "matplotlib": 71, "matric": [9, 62, 63, 108, 112, 116], "matrix": [9, 10, 55, 62, 63, 108, 110, 111, 112], "matthew": [45, 97], "matthia": [45, 97], "max": [9, 60, 62, 63, 69, 72, 84, 88, 94, 95, 106, 112], "max_": [70, 71, 84, 94, 107], "max_batch_s": [62, 63], "max_epoch": 77, "max_gen_len": 62, "max_prompt_len": 62, "max_reward": 84, "max_sampl": 77, "max_seq_len": [62, 63], "maxim": [10, 13, 18, 24, 31, 37, 38, 43, 47, 53, 59, 69, 71, 73, 74, 75, 84, 88, 95, 96, 106, 107], "maximum": [3, 47, 52, 55, 60, 61, 62, 69, 70, 71, 73, 84, 94, 106, 107, 108], "mayer": [45, 97], "mazeika": [45, 97], "mbox": [79, 111], "mbpp": [31, 32, 33, 39, 43, 65], "mbppplu": 20, "mbppplus_releas": 20, "mccandlish": [45, 97], "mceval": [39, 45, 65, 97], "mcgrew": [45, 97], "md": [45, 46], "me": 80, "mean": [9, 60, 62, 63, 69, 72, 73, 74, 79, 85, 86, 105, 109, 111], "meaning": 54, "meansquar": [62, 63, 109], "meanwhil": [106, 107, 110, 111], "measur": [13, 21, 45, 47, 52, 61, 74, 81, 88, 94, 97, 99], "mechan": [9, 53, 58, 64, 65, 69, 74, 79, 105, 109, 110, 111], "media": 11, "median": 60, "medium": 55, "mei": [45, 97], "melani": [45, 97], "memori": [9, 10, 19, 74, 108], "men": [45, 97], "meng": [45, 97], "mention": 16, "merg": [29, 31, 43], "mergeable_rank": 62, "messag": [7, 54, 62], "met": 61, "meta": [62, 70, 114], "metadata": [23, 53], "method": [12, 24, 29, 31, 38, 39, 43, 48, 58, 60, 61, 62, 64, 65, 70, 71, 73, 76, 79, 82, 85, 90, 94, 106, 107, 110, 111], "methodologi": [58, 92], "meticul": [57, 65], "metric": [2, 22, 31, 43, 47, 50, 52, 68, 81, 94, 102], "miao": [45, 97], "miaojun": [45, 97], "michael": [45, 97], "michiel": [45, 97], "micro_rollout_batch_s": 77, "micro_train_batch_s": 77, "middl": [25, 28, 40, 55, 58], "might": [16, 61, 99, 109], "mikhail": [45, 97], "mile": [45, 97], "miller": [45, 97], "million": [11, 12, 50, 52, 53, 55, 61, 64, 65], "min": [62, 68, 69, 74, 79, 84, 94, 116], "min_": 71, "min_prompt_len": 62, "mine": 84, "ming": [45, 97], "mingchuan": [45, 97], "mingfeng": [45, 97], "minghua": [45, 97], "minghui": [45, 97], "mingm": [45, 97], "mini": [62, 69, 109], "minim": [58, 71, 73, 94, 106, 107], "minimis": [52, 72], "minimum": [71, 79, 94], "minor": 95, "minu": 62, "minut": [19, 94], "mira": [45, 97], "misalign": 76, "mishkin": [45, 97], "mishra": [45, 97], "mismatch": [72, 95], "misra": [45, 97], "miss": 55, "mistak": [7, 54, 76, 95], "mistralai": 23, "mitchel": [45, 97], "mitig": [7, 13, 39, 57, 58, 61, 65, 68, 74, 75, 79, 81, 85, 88, 95, 105, 107], "mix": [13, 52, 55, 56, 61, 65, 75, 84, 92], "mixtral": 77, "mixtur": [45, 57, 58, 64, 77, 97], "mk": 105, "ml": [12, 107], "mla": [33, 57, 58], "mle": [71, 76, 84], "mlp": 68, "mmlu": 48, "mn": 105, "mode": [50, 71], "model": [2, 3, 7, 10, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 71, 72, 74, 77, 79, 80, 81, 82, 83, 84, 94, 97, 99, 105, 108, 109, 110, 111, 116], "model_arg": 62, "model_name_or_path": 115, "modelarg": [62, 63], "modern": [50, 114], "modest": 96, "modif": [10, 11, 18, 31, 37, 43, 52, 61, 106], "modifi": [1, 9, 18, 37, 55, 60, 61, 82, 86, 87, 95, 107, 116], "modul": [23, 39, 57, 62, 63, 65, 105, 109], "modular": 54, "modulelist": [62, 63], "modulenotfounderror": 62, "moe": [33, 57, 58, 64, 105, 108], "moe_intermediate_s": 57, "moegat": 105, "mohammad": [45, 97], "monoton": 84, "mont": [47, 74], "month": 60, "more": [1, 7, 9, 10, 11, 12, 13, 16, 17, 18, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 37, 38, 39, 40, 41, 43, 46, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 68, 69, 70, 72, 73, 74, 75, 76, 78, 80, 82, 84, 85, 92, 96, 102, 105, 106, 108], "moreov": [3, 45, 57, 69, 95], "morikawa": [45, 97], "most": [1, 3, 7, 9, 11, 12, 25, 39, 45, 48, 55, 58, 60, 61, 62, 65, 68, 76, 86, 96, 105, 107, 114], "mostli": [26, 61], "motiv": [11, 71, 84, 88, 94], "move": [7, 11, 55, 79], "mpmath": 23, "msc": 94, "msgpack": 23, "mt": 105, "mtp": 58, "mu_": 79, "mu_a": 79, "much": [17, 18, 29, 37, 50, 55, 61, 69, 71, 80, 96, 106, 107, 111], "multi": [10, 32, 45, 49, 55, 57, 59, 61, 62, 63, 65, 97], "multidict": 23, "multihead": 9, "multilingu": [45, 61, 64, 65, 97], "multinomi": 62, "multipl": [1, 2, 3, 13, 21, 25, 28, 39, 40, 42, 48, 54, 58, 61, 62, 63, 65, 73, 77, 80, 86, 94, 95, 105, 106, 108, 111], "multiple_of": [62, 63], "multipli": [9, 58, 68, 110, 111], "multiprocess": 23, "multistag": 64, "multitask": [11, 21, 45, 55, 97], "murati": [45, 97], "murtadha": [45, 97], "must": [2, 9, 45, 47, 49, 55, 72, 94, 96, 106, 107], "my": 80, "n": [1, 9, 10, 20, 22, 23, 31, 32, 33, 42, 43, 45, 47, 48, 52, 55, 58, 62, 63, 70, 73, 76, 84, 86, 87, 95, 96, 97, 104, 105, 106, 107, 109, 110, 111, 112, 113], "n_": [28, 40, 49, 70, 108], "n_h": [57, 108], "n_head": [62, 63], "n_layer": [62, 63], "n_routed_expert": [57, 105], "n_shared_expert": 57, "n_t": [28, 40], "n_vocab": 62, "n_word": 62, "nabla_": [47, 71, 72, 79], "naiv": [50, 69, 71, 102, 105], "nakano": [45, 97], "naman": [45, 97], "name": [23, 31, 35, 43, 52, 54, 62, 65, 71, 112], "nano": 73, "narrow": [12, 24, 38], "nativ": 61, "natur": [4, 11, 12, 16, 17, 28, 40, 50, 52, 54, 55, 56, 61, 62, 65, 81, 90, 92, 106, 107, 109], "navig": 7, "nccl": 23, "ncurs": 23, "nderstand": 19, "ndim": [62, 63, 107], "ne": [70, 72, 102], "nearbi": 110, "nearli": [9, 11, 50, 65, 69, 73], "necess": 57, "necessari": [68, 69, 86, 99], "necessit": 105, "necssari": [18, 37], "need": [1, 2, 7, 12, 17, 28, 39, 40, 45, 46, 50, 54, 56, 57, 60, 61, 62, 63, 74, 79, 85, 97, 102, 107, 108], "neelakantan": [45, 97], "neg": [47, 64, 65, 68, 72, 76, 82, 85, 88, 95, 96, 102], "negligibli": 60, "neighbor": 80, "net": [45, 97], "network": [10, 45, 59, 62, 63, 64, 68, 79, 97, 105, 112], "networkx": 23, "neural": [9, 10, 45, 62, 63, 92, 97, 112, 113], "neutral": 96, "never": 105, "new": [7, 9, 11, 12, 13, 18, 21, 23, 24, 28, 31, 35, 37, 38, 40, 43, 50, 52, 53, 55, 60, 61, 62, 63, 64, 68, 72, 73, 74, 75, 79, 86, 94, 102, 104, 112], "newli": [31, 35, 43], "newlygener": [28, 40], "next": [1, 9, 10, 23, 28, 40, 47, 52, 54, 61, 73, 75, 80, 86, 87, 107, 111], "next_token": 62, "ng": 23, "ni": [45, 97], "nichol": [45, 97], "nichola": [45, 97], "nick": [45, 97], "nie": [45, 97], "niki": [45, 97], "nikola": [45, 97], "ning": [45, 97], "nl": 83, "nll": 61, "nlp": [10, 12, 13, 50, 75, 104, 109], "nn": [57, 62, 63, 105, 107, 109], "noam": [45, 97], "node": [58, 105], "nois": [69, 85], "noisi": [56, 85, 87, 88], "non": [12, 18, 25, 28, 37, 40, 58, 59, 64, 68, 69, 80, 84, 92, 94, 111], "none": [57, 62, 63], "nonlinear": [62, 63, 112], "noqa": 62, "norm": [62, 63], "norm_ep": [62, 63], "normal": [9, 11, 23, 59, 63, 64, 74, 77, 80, 81, 85, 105], "normalize_reward": 77, "normalized_shap": 62, "notabl": [16, 48, 56, 68, 107], "note": [44, 45, 49, 54, 58, 62, 71, 72, 73, 74, 87], "notebook": 45, "notin": [76, 84], "novel": [24, 31, 38, 43, 70, 76, 84, 87, 110, 111], "novelti": 22, "novemb": 56, "now": [54, 57, 68, 71, 72, 87, 95, 107], "np": [22, 71, 84], "nuanc": [64, 92], "nucleu": 62, "num": 108, "num_attention_head": 57, "num_base_token": 62, "num_channel": 62, "num_episod": 77, "num_experts_per_tok": 57, "num_featur": [62, 109], "num_head": 57, "num_reserved_special_token": 62, "num_sampl": [62, 84], "num_step": 9, "num_train_epoch": 115, "number": [2, 3, 10, 12, 13, 22, 28, 31, 40, 43, 48, 49, 50, 52, 55, 56, 57, 62, 69, 73, 74, 84, 94, 96, 105, 106, 107, 108, 109, 111, 112, 116], "numer": [22, 72, 79, 102], "numpi": [22, 23, 71, 84], "nvidia": [23, 94], "nvjitlink": 23, "nvrtc": 23, "nvtx": 23, "nw": 83, "o": [9, 19, 74, 82, 104, 108, 111], "o1": [32, 94], "o_": [57, 69, 74], "o_1": [74, 82], "o_2": [74, 82], "o_g": 74, "o_i": 69, "o_proj": 57, "obei": 108, "object": [3, 10, 13, 42, 47, 52, 53, 55, 58, 60, 64, 69, 71, 74, 75, 76, 79, 84, 88, 105], "observ": [3, 4, 7, 31, 39, 43, 48, 50, 54, 57, 61, 68, 69, 73, 81, 85, 92, 99, 102, 106, 108], "obstacl": [2, 47], "obtain": [1, 9, 10, 18, 24, 31, 37, 38, 43, 53, 56, 57, 61, 64, 65, 68, 69, 73, 81, 84, 94, 95, 102], "obviou": 47, "occasion": [12, 61], "occur": 92, "occurr": 92, "od": 19, "off": [28, 40, 45, 46, 48, 69, 76, 81], "offer": [65, 73, 76, 81], "offici": 69, "offlin": [32, 33, 47, 52, 57, 65, 76], "offset": 9, "often": [10, 12, 28, 40, 47, 54, 69, 76, 81, 82, 85, 88, 109], "ofthought": 90, "ol": 104, "old": [69, 74, 79, 104], "older": [39, 104], "oliveira": [45, 97], "omit": [57, 105, 108, 112], "onc": [9, 18, 29, 31, 37, 43, 49, 108], "one": [1, 3, 9, 12, 13, 16, 28, 29, 31, 39, 40, 43, 45, 47, 48, 50, 52, 53, 55, 58, 60, 61, 62, 63, 64, 65, 68, 70, 72, 73, 74, 76, 81, 82, 84, 86, 94, 96, 102, 105, 107, 109, 112], "ones": [9, 35, 57, 60, 61, 62, 63, 65, 88, 94, 105, 107, 109], "ones_lik": [62, 63, 107], "onli": [12, 13, 17, 18, 19, 21, 25, 28, 37, 39, 40, 50, 52, 53, 55, 58, 60, 61, 62, 63, 65, 68, 70, 71, 72, 74, 76, 80, 82, 86, 87, 88, 94, 95, 96, 99, 106, 107, 108, 110, 111], "onlin": [32, 33, 35, 53, 57, 69, 70, 76], "open": [7, 16, 18, 29, 31, 33, 36, 37, 39, 43, 45, 58, 62, 64, 65, 69, 86, 92, 97], "openai": [11, 13, 23, 25, 45, 62, 75, 97], "opencod": 33, "openr1": 33, "openreview": [45, 97], "opensourc": 64, "openssl": 23, "oper": [1, 10, 25, 31, 43, 73, 79, 107, 109], "opportun": 73, "oppos": [55, 112], "opposit": [76, 82], "optim": [1, 10, 13, 18, 32, 37, 45, 47, 48, 49, 54, 56, 57, 58, 60, 64, 65, 69, 70, 73, 75, 79, 83, 84, 87, 92, 95, 97, 107], "optima": 95, "optimis": 72, "option": [18, 20, 37, 47, 57, 62, 63, 80, 81, 94, 107], "opu": 56, "oracl": [29, 47, 48, 95], "order": [9, 10, 11, 12, 13, 50, 52, 53, 54, 55, 57, 60, 71, 75, 80, 81, 85, 86, 87, 105, 106, 107, 108, 110, 111], "org": [24, 28, 31, 38, 40, 43, 45, 97], "organ": [65, 71], "origin": [1, 11, 20, 21, 28, 31, 40, 43, 53, 54, 58, 59, 60, 61, 68, 69, 70, 76, 81, 85, 86, 87, 105, 106, 107, 111, 112], "orjson": 23, "orthogon": [24, 38], "oss": [45, 97], "other": [2, 9, 10, 13, 21, 31, 36, 43, 45, 46, 47, 50, 54, 55, 57, 58, 61, 62, 63, 65, 73, 76, 84, 86, 88, 95, 97, 102, 105, 109, 112, 114], "otherwis": [47, 58, 60, 69, 70, 76, 84, 96, 105, 106], "otim": [62, 63, 112], "our": [1, 2, 3, 9, 10, 11, 13, 17, 18, 19, 21, 24, 25, 28, 29, 31, 37, 38, 39, 40, 43, 47, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 69, 71, 72, 73, 74, 75, 80, 81, 83, 85, 86, 87, 92, 94, 95, 96, 102, 107, 110, 111, 116], "ourselv": 53, "out": [13, 29, 53, 60, 61, 62, 63, 69, 70, 73, 75, 94, 102, 106, 107, 108], "out_logprob": 62, "out_token": 62, "outbound": 11, "outcom": [69, 70, 92], "outdat": 39, "outer": [62, 63, 107], "outermost": 77, "outlier": 79, "outlin": [31, 43, 85, 92], "outperform": [48, 50, 55, 56, 57, 58, 65, 81, 96, 102], "output": [1, 3, 9, 10, 13, 18, 19, 23, 24, 28, 37, 38, 40, 46, 47, 48, 49, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 74, 75, 76, 82, 85, 87, 88, 99, 105, 108, 109, 111], "output_dir": 115, "outsid": 85, "ouyang": [45, 97], "over": [9, 10, 11, 12, 13, 21, 23, 47, 49, 53, 55, 57, 60, 61, 62, 63, 64, 65, 69, 73, 74, 75, 76, 77, 81, 85, 86, 88, 95, 96, 108, 109, 111], "overal": [9, 10, 28, 39, 40, 49, 52, 58, 61, 68, 69, 74, 76, 81], "overcom": 2, "overconfid": 85, "overfit": [30, 75, 85], "overlap": [39, 65], "overload": 58, "oversight": 25, "overthink": 58, "overview": [1, 45, 62, 63], "overwrite_cach": 115, "owj": [13, 45, 97], "own": [7, 61, 76, 80, 86, 95, 96], "p": [10, 13, 42, 47, 48, 60, 62, 71, 73, 74, 76, 82, 84, 111, 113], "p_": [47, 70, 73, 85, 88, 95, 105], "p_1": 95, "p_i": [42, 70], "pa": 42, "pack": [9, 115], "packag": [23, 29, 39], "pad": 109, "pad_id": 62, "padding_idx": 57, "page": [45, 46], "paino": [45, 97], "pair": [9, 10, 11, 13, 18, 19, 29, 37, 39, 47, 50, 54, 55, 57, 59, 64, 65, 69, 73, 75, 76, 80, 81, 82, 83, 84, 85, 86, 88, 94, 95], "pairwis": [13, 60, 68, 70, 82, 83, 84, 86, 87], "palm": [62, 63], "pamela": [45, 97], "pan": [45, 97], "panda": 23, "panpan": [45, 97], "paper": [13, 22, 24, 25, 28, 31, 38, 40, 43, 44, 47, 53, 54, 55, 61, 102, 107], "par": 81, "paradigm": [12, 70, 76], "parallel": [9, 52, 62, 65, 94, 105, 109], "paralleliz": 9, "param": [22, 62, 63], "paramet": [9, 10, 11, 12, 13, 24, 38, 39, 48, 53, 55, 58, 59, 60, 61, 62, 63, 64, 68, 69, 71, 72, 73, 74, 75, 76, 79, 84, 85, 99, 102, 105, 106, 107, 108, 109, 110, 111, 112, 116], "parameter": [49, 70, 88], "parametr": 71, "parenthes": 82, "parmar": [45, 97], "pars": [61, 65], "parsed_arg": 20, "parser": 61, "part": [50, 55, 65, 73, 105, 111], "partial": [47, 54], "particip": [26, 52, 53], "particular": [9, 61, 62, 63, 69, 71, 73, 74, 90, 106, 112], "particularli": [23, 76, 92], "partit": [71, 85, 105], "pass": [10, 19, 22, 26, 29, 31, 39, 43, 49, 52, 54, 55, 56, 61, 62, 63, 64, 68, 106, 112, 116], "pass_at_k": 22, "past": [73, 79], "pat_str": 62, "patch": [1, 29], "path": [7, 46, 62, 102], "path_to_custom_output": 23, "pattern": [12, 58, 62, 69, 70], "paul": [45, 97], "pavlov": [45, 97], "pbar": 77, "pdf": [24, 28, 31, 38, 40, 43], "pe_": 9, "peak": [18, 37], "pearson": 68, "pebbl": 23, "pei": [45, 97], "peiyi": [45, 97], "penal": [50, 69, 85], "penalti": [13, 60, 68, 69, 74, 75, 95], "peng": [45, 97], "per": [13, 21, 22, 47, 49, 52, 53, 57, 62, 74, 75, 82, 83, 86, 96, 108], "per_device_train_batch_s": 115, "percent": 80, "percentag": [52, 81], "perceptu": 47, "perfect": [61, 86], "perform": [3, 9, 11, 12, 13, 16, 17, 18, 19, 21, 24, 25, 37, 38, 39, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 69, 70, 73, 75, 76, 81, 84, 86, 88, 90, 94, 96, 99, 102, 105, 106, 108, 109], "period": [55, 57, 111], "permit": [18, 37], "permut": [62, 109], "perplex": 106, "person": [13, 80], "perspect": [12, 69, 111], "peter": [45, 97], "petroski": [45, 97], "petrov": [45, 97], "pexpect": 23, "pgr": 50, "phase": [1, 28, 39, 40, 54, 55, 58, 60, 64, 71, 80, 92], "phd": 25, "phenomenon": [50, 68, 69, 92], "phi": [13, 68, 71, 74, 75, 81, 87, 112], "phi4": 32, "philipp": [45, 97], "philosophi": 21, "php": 61, "phrase": 10, "physic": [21, 25], "pi": [9, 13, 47, 60, 71, 73, 75, 79, 84, 85, 88, 95, 102, 106, 107], "pi_": [13, 47, 60, 69, 72, 74, 75, 79, 84, 88, 95, 102], "piao": [45, 97], "pick": [48, 52], "piec": [3, 59, 61, 80, 81, 94], "piecewis": 60, "pii": 13, "pile": 107, "pinto": [45, 97], "pioneer": 58, "pip": [20, 23], "pipelin": [16, 18, 29, 37, 39, 56, 58, 64, 71, 82, 92, 96], "pivot": [2, 48], "pkginfo": 23, "place": [62, 63, 70, 82, 112], "placehold": [18, 37], "plai": [48, 56, 57, 58], "plain": [13, 54], "plan": [2, 58, 107], "plane": 111, "plappert": [45, 97], "platform": [11, 23, 35, 52, 53], "platformdir": 23, "playground": 13, "pleas": [20, 80], "plethora": 61, "plot": [49, 71, 73], "plot_loss": 115, "plt": 71, "plu": 23, "plugin": 23, "pm": 88, "pmatrix": [55, 110, 111], "po": 9, "poetri": 23, "point": [9, 39, 48, 53, 54, 57, 60, 65, 69, 86, 92, 107], "pointwis": [70, 84], "polar": [62, 63, 106, 107], "polici": [13, 56, 57, 58, 60, 61, 64, 71, 73, 75, 79, 80, 81, 84, 88, 92, 95], "polit": 80, "polosukhin": [45, 97], "pond": [45, 97], "pool": [2, 28, 40, 52, 84, 87, 88, 94], "poor": [54, 58, 73, 92, 109], "poorli": 50, "pop": 84, "popular": [16, 29, 50], "portion": [55, 61, 65, 92], "posit": [7, 10, 45, 50, 55, 58, 59, 62, 63, 64, 72, 74, 76, 79, 81, 82, 86, 87, 88, 94, 96, 97, 99, 109, 110, 112], "positionwis": 9, "possess": 86, "possibl": [11, 28, 29, 40, 50, 53, 54, 58, 59, 61, 69, 73, 80, 82, 83, 87, 95, 96], "possibli": [39, 65, 80], "post": 81, "post0": 23, "postpon": 54, "potenti": [2, 12, 13, 42, 54, 57, 60, 65, 69, 70, 76, 81, 92], "pow": [62, 63, 109], "power": [7, 12, 24, 38, 45, 52, 53, 62, 63, 69, 92, 97], "ppo": [13, 32, 33, 56, 60, 69, 75, 82], "ppo_train": 77, "pq": 42, "pr": 29, "practic": [9, 12, 17, 39, 47, 50, 54, 65, 68, 71, 73, 85, 88, 105, 107], "practition": [24, 38], "prafulla": [45, 97], "pranav": [45, 97], "pre": [3, 9, 12, 17, 33, 35, 39, 45, 52, 54, 56, 62, 68, 70, 80, 94, 97, 104, 106, 107, 110, 111, 113], "preambl": 81, "preced": [10, 60], "precis": [17, 47, 55, 76], "precomput": 107, "precompute_freqs_ci": [62, 63, 107], "predecessor": [64, 65], "predefin": [24, 38, 79, 83, 92], "predicetd": 70, "predict": [2, 9, 10, 13, 19, 23, 50, 52, 53, 55, 62, 68, 70, 73, 75, 85, 88, 95, 96, 107], "predominantli": 55, "prefer": [13, 16, 32, 33, 45, 47, 48, 56, 57, 58, 64, 65, 68, 72, 73, 75, 80, 82, 83, 84, 86, 87, 92, 95, 96, 97, 107, 109], "prefix": [13, 23, 28, 40, 47, 55, 96], "preliminari": [57, 70, 92], "prepend": [62, 80], "prescrib": 73, "presenc": [46, 65], "present": [7, 13, 54, 58, 61, 73, 75, 76, 79, 80, 81, 87, 96, 106, 107], "preserv": [65, 106, 107], "pressur": 106, "pretrain": [12, 13, 21, 28, 40, 50, 55, 57, 65, 70, 75, 77, 80, 86, 96, 99, 106, 107, 116], "pretrained_weight": 115, "prev_po": 62, "prevent": [9, 55, 58, 79], "preview": 94, "previou": [1, 7, 9, 12, 28, 31, 40, 43, 57, 61, 62, 63, 64, 73, 76, 95, 106, 107], "previous": 9, "primarili": [13, 25, 56, 61, 64, 75, 76], "princip": 105, "principl": [7, 80, 82], "print": [17, 46, 62], "prior": [7, 11, 12, 25, 39, 60, 71, 76, 80, 88], "priorit": [61, 64], "privaci": 80, "privat": 2, "prm800k": 96, "pro": [53, 56, 73], "prob": 62, "probabl": [9, 10, 13, 22, 47, 48, 62, 69, 71, 72, 73, 74, 76, 79, 80, 81, 84, 88, 96], "problem": [12, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 35, 36, 38, 39, 41, 45, 50, 52, 53, 54, 55, 58, 61, 65, 69, 71, 84, 85, 92, 94, 96, 97], "probs_idx": 62, "probs_sort": 62, "probs_sum": 62, "proce": [31, 43], "procedur": [10, 13, 29, 50, 53, 72, 73, 75, 81, 86], "process": [1, 11, 17, 28, 31, 39, 40, 43, 45, 47, 48, 50, 54, 56, 57, 58, 62, 64, 65, 68, 69, 70, 73, 76, 79, 94, 97, 107, 109, 111, 113], "processor": 7, "prod": 22, "produc": [3, 9, 10, 13, 18, 24, 28, 29, 31, 37, 38, 40, 43, 47, 48, 52, 53, 54, 57, 58, 61, 62, 65, 68, 73, 75, 76, 81, 82, 85, 88, 95, 99, 108], "product": [22, 47, 62, 63, 110, 111, 112], "profession": [21, 55], "profici": 57, "program": [22, 26, 35, 36, 39, 52, 53, 54, 55, 56, 58, 61, 65], "programm": [19, 26, 36], "programmat": 22, "progress": [9, 36, 54, 58, 60, 69, 73, 74], "project": [1, 9, 52, 108], "promin": [31, 43], "promis": [11, 12, 48, 65, 81, 94], "promot": [28, 40], "prompt": [1, 3, 4, 7, 13, 16, 18, 20, 21, 22, 24, 28, 29, 37, 38, 39, 40, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 64, 68, 69, 73, 75, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 92, 99], "prompt_data": 77, "prompt_max_len": 77, "prompt_token": 62, "prompts_dataload": 77, "prone": [30, 85], "prop": 59, "propag": 7, "proper": [17, 65, 68, 70], "properli": [45, 60], "properti": [107, 110], "proport": [55, 57, 65, 72, 105], "propos": [3, 9, 28, 40, 47, 50, 55, 62, 63, 65, 68, 69, 70, 71, 74, 76, 84, 87, 88, 94, 95, 102, 105, 108, 112, 116], "proprietari": [55, 64], "propto": 72, "proto": 23, "protobuf": 23, "protocol": [39, 61], "prove": [39, 111], "proven": [56, 74], "provid": [1, 2, 3, 7, 10, 13, 18, 20, 21, 22, 23, 26, 29, 30, 37, 41, 50, 55, 56, 58, 60, 62, 65, 71, 72, 74, 76, 85, 86, 90, 92, 94, 96, 107, 111], "proxim": 74, "prune": 26, "pseudo": 88, "pseudocod": 42, "pseudolabel": 88, "psi": [71, 74, 84, 85], "psi_": 85, "psm": 55, "psychologi": 21, "pth": 62, "ptimiz": 69, "ptx": [13, 75], "ptyprocess": 23, "public": [13, 52, 53, 54, 56, 65, 75], "publicli": [55, 59, 64], "pull": 29, "punish": 69, "punit": 69, "pure": 92, "puri": [45, 97], "purpos": [3, 29, 45, 50, 55, 99, 107], "pursu": 25, "push": [9, 24, 38, 76], "put": [18, 28, 37, 40, 47, 52, 92], "puzzl": [50, 58], "py": [20, 115], "py310h06a4308_0": 23, "pyarrow": 23, "pyasn1": 23, "pycpars": 23, "pydant": 23, "pydoc": 39, "pyext": 23, "pypars": 23, "pyplot": 71, "pyproject": 23, "python": [3, 19, 20, 23, 24, 26, 29, 38, 39, 52, 53, 55, 61, 65, 102], "pytorch": 94, "pytz": 23, "pyyaml": 23, "q": [9, 13, 42, 45, 47, 62, 63, 64, 65, 69, 74, 76, 97, 102, 106, 107, 108, 110, 111], "q_": [62, 63, 106, 107], "q_0": [62, 63], "q_1": [62, 63], "q_2": [62, 63], "q_3": [62, 63], "q_a_layernorm": 57, "q_a_proj": 57, "q_b_proj": 57, "q_head_dim": 57, "q_i": [42, 102], "q_lora_rank": 57, "qa": [39, 42, 59, 92], "qihao": [45, 97], "qime": [45, 97], "qin": [45, 97], "qinyu": [45, 97], "qiu": [45, 97], "qiufeng": [45, 97], "qiushi": [45, 97], "qk": 9, "qk_nope_head_dim": 57, "qk_rope_head_dim": 57, "qkv": 64, "qlora": 77, "qpa": 42, "qr": 108, "qu": [45, 97], "quad": [10, 49, 58, 60, 69, 70, 85, 88, 105, 106, 107], "qualiti": [9, 11, 17, 24, 25, 28, 29, 30, 32, 38, 39, 40, 41, 42, 47, 53, 57, 58, 60, 64, 65, 68, 69, 81, 82, 83, 86, 87, 88, 94, 106, 107], "quan": [45, 97], "quantifi": [85, 94], "quantil": 88, "quantiti": [32, 61], "quartil": 61, "queri": [2, 9, 13, 16, 39, 45, 55, 57, 62, 63, 64, 65, 70, 73, 74, 85, 88, 97, 106, 107, 110, 111], "query_1": 61, "query_2": 61, "question": [1, 2, 10, 11, 18, 20, 21, 25, 26, 29, 31, 37, 39, 42, 43, 48, 54, 55, 58, 65, 69, 74, 81, 94, 96, 99, 102, 106, 107], "question_id": 23, "quickli": [7, 69], "quit": [54, 56], "qw_": 9, "qwen": [32, 45, 69, 97], "qwen2": [32, 33, 45, 64, 69, 94, 97], "qy": [45, 64, 65, 97], "r": [9, 13, 19, 31, 43, 45, 47, 55, 57, 58, 60, 61, 62, 68, 69, 72, 73, 74, 79, 84, 85, 95, 97, 102, 105, 106, 108, 110, 111, 116], "r1": [33, 58, 69], "r_": [13, 47, 57, 60, 68, 69, 70, 71, 73, 74, 75, 79, 81, 84, 85, 86, 102, 110, 111], "r_1": [70, 74], "r_h": 60, "r_i": [69, 70, 74, 102], "r_l": 70, "racist": 80, "radford": [45, 97], "rafael": [45, 97], "rafailov": [45, 97], "rai": [45, 97], "rais": [1, 21, 62, 107], "ramesh": [45, 97], "ramp": 106, "ran": 53, "rand_prompt": 77, "randn": [62, 109], "random": [11, 21, 24, 38, 52, 53, 62, 73, 84, 85, 87, 94], "randomli": [19, 21, 24, 31, 38, 43, 52, 55, 65, 80, 82], "rang": [7, 10, 12, 13, 21, 23, 24, 38, 50, 55, 59, 60, 61, 62, 63, 69, 77, 79, 80, 81, 104, 107], "rangl": [62, 63, 106, 107, 111], "rank": [1, 13, 48, 52, 54, 60, 61, 71, 75, 84, 85, 86, 116], "rapidfuzz": 23, "rapidli": 76, "rate": [3, 39, 50, 52, 53, 54, 57, 59, 60, 61, 68, 69, 73, 75, 79, 81, 96, 99], "rater": 73, "rather": [71, 82, 92], "ratio": [58, 65, 72, 79, 106], "rational": 81, "raul": [45, 97], "raw": [56, 113], "re": [3, 54, 62, 63, 71, 84, 106, 107, 111], "reach": [3, 12, 25, 28, 40, 53, 54, 60, 96, 105], "read": [11, 62], "readabl": [61, 92], "readlin": 23, "real": [3, 29, 39, 55, 77, 99, 107, 111], "realist": [17, 18, 25, 37], "realiti": [84, 107], "realiz": 10, "realli": [1, 45, 97], "realm": [24, 31, 38, 43], "realworld": 39, "rearrang": [71, 84], "reason": [4, 12, 21, 22, 31, 33, 43, 45, 47, 48, 54, 55, 57, 58, 61, 64, 69, 72, 74, 81, 87, 96, 97, 107, 109], "recal": [47, 61, 73, 76], "receiv": [3, 7, 11, 47, 60, 73, 105], "recent": [2, 12, 52, 53, 59, 60, 61, 62, 68, 75], "recip": [55, 61, 87], "recogn": 7, "recommend": [16, 86], "recov": [7, 50, 73], "recoveri": 7, "rectifi": [62, 63, 112], "recurr": 9, "red": [31, 43, 108], "reddit": 11, "reduc": [11, 18, 21, 37, 39, 47, 48, 60, 72, 95, 105, 107, 108, 112, 116], "reduct": [62, 72], "redund": [53, 58, 105], "reevalu": 92, "ref": [71, 72, 74, 95], "refer": [7, 13, 26, 29, 30, 45, 47, 55, 60, 61, 68, 69, 71, 72, 73, 74, 80, 86, 94, 96, 106], "refin": [17, 58, 61, 73], "reflect": [26, 39, 54, 76, 94], "regard": 69, "regardless": [68, 69], "regener": 39, "regex": 62, "regim": 96, "region": [9, 47, 79, 107], "reglu": [62, 63, 112], "regress": [1, 9, 13, 55, 60, 61, 68, 75], "regul": 69, "regular": [45, 61, 64, 73, 74], "regularli": [58, 65], "rehears": 55, "reiichiro": [45, 97], "reinforc": [13, 50, 55, 71, 74, 82, 96, 99], "reject": [32, 33, 55, 58, 60, 61, 65, 68, 83, 85, 87, 88, 102], "rejected_1": 61, "rejected_2": 61, "rel": [1, 9, 13, 48, 52, 56, 57, 58, 62, 63, 64, 69, 72, 80, 92, 99, 107, 110, 111], "relat": [18, 23, 37, 39, 48, 55, 56, 58, 64, 65, 74, 84, 102, 105, 108, 111], "relationship": [45, 97], "releas": [18, 20, 37, 39, 55], "relev": [1, 7, 29, 50, 54, 64, 65, 69, 87, 88, 96], "reli": [24, 38, 47, 50, 53, 54, 58, 88, 94, 109], "reliabl": [7, 19, 21, 25, 50, 57, 58, 64, 92, 96], "relianc": 109, "relu": [9, 59, 62, 63, 71, 112], "remain": [2, 28, 29, 40, 49, 50, 52, 53, 72, 85, 88, 96], "remark": [92, 99], "remind": [18, 37], "remov": [13, 31, 39, 43, 53, 55, 59, 61, 65, 75, 80, 84, 87, 102], "ren": [45, 97], "render": 45, "renorm": 62, "reorder": 55, "repair": [1, 23], "reparameter": 71, "repeat": [4, 7, 18, 28, 37, 40, 54, 69, 94], "repeatedli": 52, "repetit": [11, 69], "replac": [7, 59, 62, 63, 64, 80, 81, 107, 112], "replai": [73, 74, 77], "replay_buff": 77, "replic": 1, "repo": [29, 61, 65], "report": [22, 45, 65, 69, 85, 97, 102], "repositori": [1, 7, 23, 29, 39, 52, 55, 56, 65], "repres": [7, 9, 28, 31, 40, 43, 47, 55, 61, 62, 63, 72, 79, 85, 105, 106, 107, 111, 112, 114], "represent": [9, 42, 50, 52, 58, 62, 63, 71, 81, 111, 112], "reproduc": [2, 39], "reproduct": 1, "request": [2, 18, 23, 29, 37, 80, 86], "requir": [1, 2, 3, 9, 10, 12, 18, 19, 29, 37, 50, 53, 54, 55, 58, 60, 61, 62, 73, 84, 92, 105, 106, 107, 108, 109, 110, 111], "rerank": 53, "resampl": [64, 73], "rescal": 107, "research": [2, 25, 39, 60, 76], "reserv": 57, "reserved_special_token_": 62, "reserved_special_token_0": 62, "reserved_special_token_1": 62, "reserved_special_token_2": 62, "reserved_special_token_3": 62, "reserved_special_token_4": 62, "reshap": [62, 63, 107], "reshape_for_broadcast": [62, 63, 107], "residu": [9, 49], "resolv": [1, 29, 52, 68], "resort": 92, "resourc": [54, 60, 65, 94], "respect": [9, 13, 48, 69, 72, 74, 75, 76, 79, 81, 82, 85, 105, 108], "respons": [7, 13, 16, 18, 20, 23, 31, 37, 39, 43, 48, 57, 58, 60, 61, 62, 64, 65, 68, 69, 70, 73, 74, 75, 76, 79, 80, 81, 83, 84, 85, 86, 88, 92, 95, 99, 105], "response_candid": 84, "response_reward": 84, "rest": 46, "restrict": [3, 47, 58, 69, 72, 79], "result": [1, 3, 9, 11, 12, 21, 22, 24, 30, 38, 39, 47, 50, 53, 54, 55, 60, 65, 74, 76, 84, 85, 92, 96, 102, 105, 106, 107, 108, 110, 111], "retain": [39, 55, 58, 61, 65, 80, 88], "retriev": [1, 2, 39], "return": [22, 47, 62, 63, 76, 79, 84, 107, 109], "reus": [64, 92, 107], "reveal": [58, 61], "revers": 81, "review": [64, 71], "revis": [61, 95], "reward": [13, 32, 33, 45, 48, 50, 54, 55, 56, 57, 58, 64, 71, 74, 76, 77, 81, 83, 84, 87, 88, 97], "reward_pretrain": 77, "rewon": [45, 97], "rewrit": 80, "rft": [32, 70, 102], "rho": 102, "rho_": 84, "rich": 39, "right": [9, 13, 22, 47, 49, 55, 62, 63, 68, 69, 71, 72, 74, 75, 76, 79, 81, 84, 95, 96, 106, 107, 108, 111, 113], "rigor": [17, 20, 21, 39, 45, 97], "risk": [29, 58, 65], "rl": [13, 32, 33, 52, 56, 57, 58, 60, 64, 69, 71, 79, 80, 81, 82, 88, 92, 96], "rlaif": [33, 80, 82, 88], "rlcd": [32, 33, 88], "rlhf": [50, 55, 68, 69, 71, 73, 75, 77, 80, 84], "rlhf1": 33, "rlhf2": 33, "rm": [13, 32, 50, 57, 58, 60, 61, 68, 77, 81, 83], "rm_": 57, "rmboost": 32, "rmsnorm": [45, 57, 59, 64, 97], "roberta": 61, "robust": [28, 29, 39, 40, 54, 56, 64, 80], "roform": [45, 97], "role": [3, 48, 56, 57, 58, 62], "rollout": [69, 95], "rollout_batch_s": 77, "room": 54, "rope": [32, 33, 55, 58, 59, 64, 108], "rope_theta": [62, 63], "rotari": [45, 55, 59, 64, 97, 110], "rotat": [55, 110, 111], "roug": [28, 40], "roughli": [4, 49, 53, 59, 85, 96], "round": [31, 43, 53], "rout": [57, 58, 105], "row": [62, 63, 107], "rozi\u00e8r": [45, 97], "rsa": 23, "rsm": [45, 61, 64, 97], "rso": [32, 33], "rsqrt": [62, 63, 109], "rtol": [62, 109], "rtx4090": 77, "ruan": [45, 97], "rui": [45, 97], "ruiqi": [45, 97], "ruizh": [45, 97], "rule": [25, 54, 56, 57, 58, 61, 92], "rulebas": 58, "run": [19, 46, 54, 55, 61, 72, 80, 94, 95], "runji": [45, 97], "runnabl": 2, "runner": 23, "runtim": [23, 53], "runxin": [45, 97], "ruyi": [45, 97], "rwc": [11, 12, 45, 97], "rx": 73, "ryan": [45, 97], "ryder": [45, 97], "s3transfer": 23, "s_": [47, 58, 70, 72, 79, 105, 107], "s_1": [65, 70, 107], "s_2": 107, "s_i": 70, "s_j": 70, "s_n": 65, "s_t": 79, "safe": 75, "safeti": [50, 55, 57, 60], "sahil280114": [18, 37], "sai": 80, "salienc": 50, "salient": 50, "sam": [45, 97], "same": [9, 12, 31, 39, 43, 45, 52, 53, 54, 55, 56, 57, 65, 69, 71, 72, 80, 82, 84, 85, 86, 92, 102, 105, 106, 107, 108, 109], "sampl": [1, 11, 19, 20, 21, 22, 24, 28, 29, 31, 32, 33, 38, 39, 40, 43, 47, 48, 55, 56, 58, 59, 60, 61, 62, 64, 65, 70, 71, 73, 74, 79, 80, 81, 82, 83, 86, 87, 88, 94, 96, 99, 102, 109], "sample_top_p": 62, "sandbox": [64, 65], "sandhini": [45, 97], "sanghai": [45, 97], "sanit": 20, "sastri": [45, 97], "satisfactori": [57, 76], "satisfi": 76, "saunder": [45, 97], "save": [54, 108], "save_path": 77, "save_step": [77, 115], "scail": [79, 94], "scalabl": [10, 25, 65, 70, 76, 79, 81], "scalar": [13, 60, 68, 70, 75, 76], "scale": [10, 12, 28, 29, 30, 39, 40, 41, 45, 50, 60, 62, 63, 64, 65, 69, 71, 76, 79, 92, 97, 99, 107, 108], "scan": 49, "scarciti": 65, "scenario": [2, 3, 23, 39, 65, 69], "schedul": [39, 59], "scheme": [60, 73, 114], "school": 25, "schulman": [45, 97], "scienc": [21, 39, 59], "scientif": 39, "scope": [29, 58], "score": [17, 21, 58, 60, 61, 62, 63, 64, 65, 68, 70, 73, 74, 75, 79, 80, 81, 82, 84, 85, 86, 88, 96, 105, 106, 107], "scorer": 65, "scott": [45, 97], "scrape": [11, 29, 35, 52, 69], "scratch": [32, 85, 106, 107], "script": [20, 115], "scroll_down": 7, "scroll_up": 7, "scy": [42, 45, 65, 97], "search": [2, 4, 7, 53, 54, 96], "search_dir": 7, "search_fil": 7, "seattl": 104, "second": [2, 9, 11, 18, 19, 37, 39, 47, 53, 57, 58, 65, 73, 81, 95, 112], "secret": [32, 33], "secretli": [45, 97], "secretstorag": 23, "section": [39, 56, 69, 80, 92, 107, 111], "secur": 65, "see": [16, 19, 21, 45, 46, 47, 49, 61, 63, 72, 78, 81, 107], "seed": [17, 18, 24, 28, 37, 38, 39, 40, 65, 86, 87], "seek": [60, 94], "seem": 7, "seen": [61, 88], "segment": [25, 60, 113], "select": [1, 16, 19, 29, 31, 39, 43, 48, 52, 53, 54, 55, 58, 60, 61, 62, 68, 69, 73, 75, 96, 99, 102, 105], "selector": 96, "self": [9, 10, 11, 13, 18, 20, 23, 24, 26, 29, 32, 33, 37, 38, 45, 55, 57, 61, 62, 63, 65, 74, 77, 97, 105, 106, 107, 109, 110, 111], "selfattent": 111, "selfinstruct": [28, 40], "semant": [26, 52, 53, 54, 61, 65, 87], "semi": [28, 40, 70], "sen": [45, 97], "send": [49, 73, 105], "sensit": [13, 21, 108, 109], "sent": [39, 58, 105], "sentenc": [9, 10, 11, 18, 37, 39, 59, 81, 113], "separ": [9, 16, 53, 55, 60, 96], "seq_len": [62, 109], "seqlen": [62, 63], "sequenc": [9, 10, 25, 45, 47, 55, 58, 60, 62, 63, 64, 69, 73, 76, 84, 86, 97, 105, 106, 108, 109, 110, 111, 112, 113], "sequenti": [47, 73, 94], "seri": [24, 38, 59, 64, 65, 86, 90, 96], "serv": [17, 39, 45, 48, 58, 70, 73, 85, 105], "servic": 64, "set": [1, 2, 9, 12, 13, 16, 17, 18, 19, 21, 22, 25, 28, 29, 30, 31, 36, 37, 39, 40, 41, 43, 47, 48, 50, 52, 55, 56, 57, 58, 60, 61, 62, 64, 65, 69, 70, 73, 74, 75, 80, 84, 85, 86, 87, 94, 96, 99, 102, 105, 106, 107, 111], "setup": [3, 20, 50], "setuptool": 23, "seventh": [45, 97], "sever": [7, 22, 48, 52, 53, 55, 56, 60, 61, 64, 65, 73, 92, 109], "sexist": 80, "sft": [13, 32, 33, 39, 57, 58, 64, 65, 71, 72, 74, 77, 79, 81, 83, 84, 85, 86, 92, 95, 102], "sh": 77, "sha": [45, 97], "shallow": 68, "shang": [45, 97], "shanghao": [45, 97], "shanghaoran": [45, 97], "shangyan": [45, 97], "shanhuang": [45, 97], "shantanu": [45, 97], "shao": [45, 97], "shaoq": [45, 97], "shape": [49, 62, 63, 107, 109], "share": [9, 13, 36, 57, 58, 92, 108], "sharegpt": 39, "sharma": [45, 97], "shazeer": [45, 97], "shelf": [48, 76, 81], "shellingham": 23, "shen": [45, 97], "shengfeng": [45, 97], "shengguang": [45, 97], "shift": [39, 70, 96], "shiji": [45, 97], "shirong": [45, 97], "shiyu": [45, 97], "short": [19, 26, 29, 58, 107], "shorter": [48, 69], "shot": [12, 13, 17, 21, 28, 40, 45, 80, 81, 86, 88, 96, 97, 102], "should": [1, 2, 7, 12, 18, 19, 25, 37, 46, 49, 50, 53, 72, 76, 80, 82, 84, 108], "show": [1, 9, 12, 13, 17, 21, 45, 46, 47, 55, 59, 61, 71, 72, 76, 80, 84, 85, 86, 90, 92, 96, 107, 108, 111], "shown": [9, 13, 22, 24, 38, 39, 47, 50, 74, 75, 81, 85, 88], "shuai": [45, 97], "shuang": [45, 97], "shuffl": [31, 43], "shuip": [45, 97], "shukai": [45, 97], "shunfeng": [45, 97], "shusheng": [45, 97], "shyam": [45, 97], "sida": [45, 97], "siddhartha": [45, 97], "sidestep": 73, "sigler": [45, 97], "sigma": [13, 60, 62, 63, 71, 72, 75, 81, 84, 85, 112], "sigma_": 79, "sigmoid": [62, 63, 71, 84, 112], "signal": [28, 40, 47, 54, 56, 58, 61, 64, 69, 81, 82, 92], "signatur": [22, 26, 39, 53, 55], "signific": [11, 21, 39, 57, 60, 61, 64, 106, 107, 108, 109], "significantli": [9, 17, 18, 21, 24, 37, 38, 42, 48, 54, 55, 57, 60, 61, 64, 69, 70, 72, 80, 85, 90, 96, 108], "silu": [62, 63], "sim": [13, 47, 49, 60, 69, 70, 71, 72, 74, 75, 84, 85, 88, 95, 112], "simen": [45, 97], "similar": [7, 12, 16, 21, 28, 40, 45, 52, 53, 61, 65, 80, 82, 96, 102, 106], "similarili": [106, 108], "similarli": [9, 53, 58, 72, 86, 88, 92], "simpl": [7, 9, 12, 18, 22, 24, 31, 37, 38, 43, 45, 49, 50, 52, 58, 62, 63, 70, 71, 81, 88, 90, 111, 113], "simpler": [10, 47, 71], "simplest": 94, "simpli": [13, 18, 37, 50, 68, 94, 95, 106], "simplic": [10, 54, 79], "simplifi": [18, 22, 31, 37, 43, 62, 102], "simplist": [1, 3], "simul": [52, 73, 82], "simultan": [9, 49, 70, 86], "sin": [9, 55, 62, 63, 106, 107, 110, 111], "sinan": [45, 97], "sinc": [1, 9, 10, 47, 50, 53, 56, 62, 63, 65, 71, 72, 74, 80, 81, 84, 105, 107, 108, 109], "sine": 9, "singl": [2, 11, 13, 18, 22, 26, 37, 52, 53, 54, 55, 58, 75, 82, 87, 96, 105], "sinusoid": [9, 111], "site": 36, "situat": 105, "six": [23, 31, 43, 61], "size": [10, 11, 12, 30, 39, 41, 45, 55, 57, 59, 62, 63, 64, 69, 74, 76, 85, 97, 99, 105, 106, 107, 108, 109], "skeleton": 1, "skill": [25, 30, 41, 55, 65, 86], "skywork": 32, "sl": 80, "slama": [45, 97], "slice": 108, "slight": 45, "slightli": [60, 61], "slope": 94, "slow": 109, "slowli": [106, 107], "slp": [45, 58, 64, 97, 106, 108, 110], "small": [9, 19, 28, 40, 45, 50, 52, 54, 55, 61, 65, 79, 86, 92, 94, 106, 107, 108, 109, 111], "smaller": [1, 48, 59, 60, 95, 96, 99, 105, 106, 108, 110], "smallest": [11, 52, 62], "smallscal": 96, "smarter": 50, "smooth": [12, 31, 43], "snapshot": [52, 80], "sniffio": 23, "snippet": [1, 17, 24, 38, 39, 55, 61, 64, 65], "so": [2, 13, 19, 46, 52, 54, 60, 61, 70, 72, 73, 74, 80, 86, 105, 106, 107, 108], "social": [11, 21], "soft": [54, 69, 81, 85], "softmax": [10, 62, 63, 81, 105, 106, 108], "softwar": [1, 29, 39], "solar": [45, 97], "sole": [9, 47, 60, 69, 76], "solid": 108, "solut": [3, 17, 20, 24, 25, 26, 29, 30, 35, 36, 38, 41, 42, 52, 53, 54, 55, 61, 68, 71, 81, 87, 94, 96, 108, 109, 111], "solv": [1, 3, 17, 20, 21, 22, 25, 26, 29, 45, 48, 52, 53, 54, 55, 61, 92, 95, 96, 97], "solvabl": 26, "some": [9, 10, 18, 37, 45, 52, 54, 56, 60, 61, 68, 73, 76, 84, 88, 105], "someon": 80, "someth": 12, "sometim": [12, 39], "song": [45, 97], "sonnet": 94, "sort": [61, 62, 73], "sound": 69, "sourc": [1, 11, 16, 22, 26, 29, 31, 39, 43, 45, 55, 56, 58, 61, 62, 64, 65, 69, 84, 92, 97], "space": [3, 4, 11, 31, 43, 53, 54, 110, 111], "span": [2, 21, 25, 45, 50, 55, 65, 94], "spars": [12, 29, 45, 54, 97], "speak": 84, "spearman": 68, "special": [2, 7, 21, 45, 60, 62, 64, 88, 96, 105], "special_token": 62, "specif": [1, 2, 4, 7, 12, 13, 18, 31, 37, 39, 43, 45, 47, 48, 54, 55, 58, 61, 62, 64, 65, 70, 71, 72, 80, 84, 85, 86, 94, 96, 105, 106, 107], "specifi": [26, 62, 92, 94], "speed": [13, 58, 75], "spent": 56, "sphinx": 45, "split": [13, 17, 35, 36, 53, 55, 62, 63], "split_experience_batch": 77, "spm": 55, "spot": 21, "spread": 106, "spuriou": 12, "sqlite": 23, "sqrt": [9, 62, 63, 85, 106, 107, 108, 109, 111], "squre": 62, "src": 115, "sse": 23, "stabil": [21, 59, 60, 62, 69, 74, 79, 109], "stabl": [20, 22, 48, 64, 79], "stack": [24, 38, 99, 105], "stackexchang": 59, "stage": [10, 29, 55, 57, 58, 60, 61, 64, 65, 74, 85, 92, 94, 99, 106, 107, 115], "stai": 47, "stale": 81, "stand": 45, "standalon": 55, "standard": [10, 25, 26, 28, 36, 40, 48, 49, 52, 55, 56, 61, 62, 64, 65, 72, 73, 74, 76, 79, 81, 82, 85, 96, 99, 105, 114], "star": [39, 95], "starcod": [24, 31, 38, 43, 55], "starcoderdata": [24, 38], "starkli": 21, "start": [13, 28, 29, 31, 40, 43, 45, 46, 48, 53, 54, 55, 62, 71, 73, 75, 84, 86], "start_header_id": 62, "start_po": [62, 63], "starter": 45, "state": [7, 12, 13, 25, 47, 50, 59, 68, 69, 79, 80, 105, 106], "statement": [26, 52, 55], "static": [47, 61, 64], "staticmethod": 62, "statist": 109, "statu": [23, 29, 77], "std": [62, 69, 74, 85, 109], "steadi": 49, "steer": [50, 61, 73, 88], "stefano": [45, 97], "steinhardt": [45, 97], "stem": [21, 64], "step": [4, 7, 9, 13, 25, 28, 31, 32, 33, 39, 40, 43, 45, 47, 49, 53, 54, 55, 57, 58, 59, 60, 61, 69, 74, 75, 77, 80, 81, 87, 90, 92, 97, 99, 106, 107], "stepbi": 96, "steven": [45, 97], "still": [12, 50, 52, 56, 58, 71, 81, 107], "stochast": 10, "stoica": [45, 97], "stop": [49, 60], "stop_token": 62, "store": [45, 65, 84], "str": [62, 84], "straightforward": [10, 16, 25, 47, 61, 76, 84, 92, 102, 106, 107], "straightforwardli": 68, "strateg": [58, 61], "strategi": [39, 48, 55, 57, 58, 60, 64, 68, 69, 70, 77, 88, 95, 106, 108], "stream": 49, "streamlin": [31, 43], "strength": [13, 58, 61, 73, 75, 76], "strict": [28, 35, 40, 62], "strictli": 86, "string": [7, 62, 81, 94, 95], "stringent": 61, "strip": [20, 62], "strong": [45, 57, 58, 68, 76, 85, 92, 94, 96, 97, 99, 106, 107], "stronger": [24, 38, 50, 58, 108], "strongest": 25, "strongli": [80, 99], "structur": [1, 9, 10, 45, 54, 81, 105], "struggl": [7, 12, 48, 85, 92], "stuck": 47, "student": [24, 25, 38, 50, 65], "studi": [12, 28, 40, 49, 50, 64, 73, 76], "style": [21, 55, 61], "su": [45, 97], "sub": [9, 11, 54, 56, 59, 62, 84, 109, 110, 111], "subbiah": [45, 97], "subdirectori": 7, "subject": [21, 55, 94], "sublay": 9, "submiss": [1, 52, 53], "submit": [3, 13, 53, 73, 75], "suboptim": [39, 109], "subsequ": [9, 55, 60, 61, 62, 63, 73, 74, 86, 112], "subset": [11, 13, 25, 26, 29, 49], "subspac": 9, "substanti": [12, 18, 31, 37, 43, 50, 74, 76, 95], "substitut": [57, 71, 76, 105], "subtract": 74, "subword": [45, 97, 113], "succ": [13, 71, 84, 85, 88], "succeed": 54, "success": [3, 21, 22, 50, 54, 60, 65, 86, 87], "successfulli": [39, 69], "suchir": [45, 97], "sufeng": [45, 97], "suffer": [58, 69, 79, 92, 95], "suffici": [12, 13, 52, 60, 65, 72, 74, 90, 107], "suffix": 55, "suggest": [12, 48, 65, 71, 72, 76, 81, 99, 112], "suit": 10, "suitabl": [55, 68, 85], "sujoi": [45, 97], "sum": [9, 47, 58, 62, 68, 70, 73, 74, 79, 105, 111], "sum_": [10, 47, 62, 63, 69, 70, 71, 74, 76, 79, 81, 84, 85, 94, 95, 105, 106, 107, 108, 111, 113], "sumit": [45, 97], "summar": 107, "summari": [11, 81], "sun": [45, 97], "sup": 32, "super": [57, 62, 63, 109], "superalign": 50, "superhuman": 50, "superior": [9, 48, 56, 69, 86], "supervis": [11, 12, 13, 25, 28, 29, 40, 47, 50, 55, 65, 71, 82, 83, 84, 86, 88, 94, 99, 110, 111], "supervison": 50, "supervisor": 50, "supplement": 61, "suppli": 102, "support": [3, 46, 55, 57, 61, 65, 77, 114], "suppos": [68, 76, 105], "suppress": [69, 94], "sure": [18, 37, 55, 80], "surfac": [53, 82, 96], "surpass": [12, 25, 31, 43, 65, 83], "surpris": [13, 61, 74], "surprisingli": 72, "surrog": 74, "surround": [55, 57], "suspect": [9, 80], "suspici": 1, "sutskev": [45, 97], "swaroop": [45, 97], "swiglu": [59, 64], "swish": [32, 62, 63], "symbol": 9, "sympi": 23, "syncheck": 20, "synnaev": [45, 97], "syntact": [52, 61], "syntax": [7, 45, 61, 65], "synthes": [17, 39, 64, 65], "synthesi": [39, 55, 65], "synthet": [24, 38, 61, 64, 65, 83, 87, 88], "system": [7, 12, 25, 39, 45, 58, 61, 62, 69, 73, 92, 94, 97, 106], "systemat": 76, "t": [9, 10, 28, 31, 39, 40, 43, 45, 47, 52, 58, 62, 63, 69, 74, 76, 79, 86, 97, 104, 105, 106, 107, 108, 111], "t1": [62, 109], "t2": [62, 109], "t_": [72, 113], "t_1": 113, "t_2": 113, "t_n": 113, "tabl": [11, 82, 108], "tackl": 53, "taco": 33, "tag": [52, 53, 55, 65, 92], "tail": 65, "tailor": [53, 58, 73], "take": [1, 7, 13, 24, 25, 38, 47, 55, 62, 63, 68, 71, 72, 73, 75, 76, 79, 84, 86, 87, 88, 96, 110, 111, 112], "taken": 47, "talent": 25, "tan": [45, 97], "tang": [45, 97], "tao": [45, 97], "target": [10, 53, 61, 62, 76, 80, 84, 96, 102, 105, 107], "task": [3, 4, 7, 9, 11, 12, 13, 17, 18, 19, 21, 22, 24, 26, 29, 30, 37, 38, 39, 41, 47, 48, 50, 52, 54, 55, 57, 58, 61, 65, 69, 74, 76, 79, 80, 81, 85, 92, 96, 106, 107, 109, 116], "task_id": 20, "taskspecif": 11, "tau": [47, 73, 95], "taught": 33, "td": [74, 79], "teach": [50, 60, 99], "teacher": [24, 38, 39], "team": [13, 75], "technic": [45, 50, 97], "techniqu": [18, 31, 32, 33, 37, 43, 47, 48, 50, 54, 60, 61, 69, 79, 85, 106, 107], "teddi": [45, 97], "telecommun": 114, "tell": [50, 71], "temper": 52, "temperatur": [23, 39, 52, 53, 58, 62, 64, 69, 73, 102, 106], "templat": [4, 24, 28, 31, 38, 39, 40, 43, 115], "tempor": 35, "ten": [12, 21, 55, 60, 65, 107], "tend": [69, 73, 81], "tensor": [62, 63, 107], "term": [10, 13, 22, 54, 56, 58, 60, 64, 69, 70, 71, 74, 76, 96, 107, 111, 112], "termin": [3, 47, 94], "terri": [13, 68, 71, 84, 85], "test": [1, 3, 11, 12, 13, 20, 21, 22, 23, 25, 26, 29, 30, 35, 36, 39, 41, 49, 50, 52, 53, 54, 55, 56, 58, 61, 64, 65, 86, 92, 95, 96, 102], "tester": 61, "text": [3, 9, 10, 11, 12, 13, 18, 22, 26, 29, 37, 45, 46, 47, 49, 55, 56, 58, 60, 62, 63, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 84, 85, 86, 88, 94, 95, 96, 99, 102, 105, 106, 107, 108, 112, 113, 114], "text_complet": 62, "textbf": 47, "textbook": 21, "textto": 2, "textual": 10, "tezak": [45, 97], "th": [31, 43, 70, 72, 74, 86, 105, 106, 107, 108], "than": [9, 11, 12, 16, 17, 18, 20, 24, 28, 29, 37, 38, 39, 40, 48, 50, 52, 53, 54, 55, 57, 59, 61, 68, 69, 71, 72, 80, 81, 82, 84, 85, 96, 99, 102, 105, 106, 107, 108], "thank": [3, 76], "thei": [2, 7, 11, 13, 24, 38, 45, 50, 52, 55, 60, 61, 85, 86, 87, 94, 96, 105, 108, 109, 112, 114], "them": [2, 7, 10, 13, 28, 40, 50, 53, 54, 56, 57, 61, 64, 69, 82, 84, 87, 92, 105, 108, 109, 111], "themselv": [13, 50, 70, 75], "theoret": [39, 72], "therebi": [58, 69, 105], "therefor": [24, 28, 38, 40, 53, 56, 57, 58, 60, 69, 72, 74, 76, 85, 96, 107, 108], "theta": [10, 13, 47, 55, 60, 62, 63, 68, 69, 70, 71, 72, 73, 74, 75, 79, 88, 95, 106, 107, 110, 111], "theta_": [55, 62, 63, 69, 72, 74, 79, 106, 107, 110, 111], "theta_0": [62, 63, 107], "theta_1": [62, 63, 107], "theta_d": 106, "theta_j": [62, 63], "thi": [1, 2, 3, 7, 9, 10, 11, 12, 13, 18, 21, 22, 24, 25, 28, 29, 30, 31, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 84, 85, 86, 87, 88, 92, 94, 95, 96, 102, 105, 106, 107, 108, 109, 111], "thing": [46, 80], "think": [4, 80, 92, 94, 105, 107], "third": [2, 9, 19], "thirti": [45, 97], "thompson": 73, "thorough": [57, 61], "thoroughli": 58, "thorp": [45, 97], "those": [9, 13, 16, 29, 45, 48, 52, 56, 58, 60, 61, 64, 69, 73, 87, 96, 105], "though": 22, "thought": [4, 7, 21, 58, 61, 80, 81, 102], "thousand": [12, 52, 53, 55, 60, 61, 107], "three": [1, 2, 3, 12, 13, 17, 22, 23, 26, 39, 47, 50, 55, 61, 65, 70, 71, 75, 76, 81, 84, 85, 94, 96, 108, 112], "threshold": [61, 62, 83, 88], "through": [2, 10, 21, 24, 31, 38, 43, 61, 62, 63, 64, 65, 68, 69, 70, 76, 79, 81, 84, 88, 92, 94, 99, 106, 107, 108, 110, 111, 112], "throughout": [61, 92], "thu": [31, 43, 47, 49, 50, 60, 62, 63, 68, 69, 73, 79, 82, 84, 86, 95, 106], "tian": [45, 97], "tianhang": [45, 97], "tianhao": [45, 97], "tianjian": [45, 97], "tianjun": [45, 97], "tianyi": [45, 97], "tianyu": [45, 97], "tier": 39, "tild": [60, 73, 74], "tillet": [45, 97], "time": [2, 4, 7, 9, 16, 23, 31, 43, 47, 52, 55, 60, 61, 68, 69, 81, 88, 92, 95, 96, 105, 108, 109, 116], "timeout": [23, 65], "tingyu": [45, 97], "tini": 12, "tip": 64, "titl": [71, 114], "titlecas": 17, "tk": 23, "tl": 11, "to_remov": 84, "todai": 50, "togeth": [1, 9, 28, 40, 52, 53, 61, 80, 81], "tok": 62, "tok_embed": [62, 63], "token": [9, 10, 11, 13, 23, 29, 32, 33, 47, 52, 55, 56, 57, 59, 60, 61, 63, 65, 68, 72, 74, 75, 76, 81, 94, 95, 96, 99, 104, 106, 107, 108, 109, 110, 111, 113], "token1": 105, "token2": 105, "token3": 105, "token_logprob": 62, "tokenization\u4e4b\u540e": 104, "tokenization\u7b97\u6cd5\u4e4b\u4e00": 104, "tokenize\u7684\u610f\u601d\u662f\u628a\u4e00\u4e2a\u53e5\u5b50\u6216\u957f\u8bed\u6599\u5206\u6210token": 104, "token\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u7b26\u53f7": 104, "token\u6570": 104, "token\u66ff\u6362\u5b83\u4eec": 104, "toler": 96, "tolist": 62, "tom": [45, 97], "tomli": 23, "tomlkit": 23, "tone": 61, "tong": [45, 97], "tongliang": [45, 97], "tongzheng": [45, 97], "too": [50, 65, 69, 79, 107], "took": 94, "tool": [1, 2, 16, 25, 45, 52, 61, 113], "toolbelt": 23, "top": [1, 11, 24, 38, 39, 46, 48, 52, 58, 60, 61, 62, 63, 68, 70, 85, 88, 99, 105], "top_p": 62, "topic": [30, 41, 57, 61], "topk": [58, 105], "topp": [23, 69], "torch": [23, 62, 63, 105, 107, 109], "toreproduc": 16, "total": [2, 22, 24, 28, 29, 36, 38, 40, 49, 53, 56, 57, 58, 60, 74, 94, 105, 108], "total_len": 62, "toutanova": [45, 97], "toward": [28, 40, 45, 48, 82, 88, 95, 97, 105], "toxic": [13, 80], "tqdm": 23, "trace": [4, 94, 95], "traceback": 62, "track": 84, "tractabl": 50, "trade": 69, "tradeoff": 76, "tradit": [12, 21], "train": [2, 3, 9, 13, 18, 24, 25, 28, 29, 30, 35, 36, 37, 38, 40, 41, 45, 47, 48, 50, 52, 53, 55, 56, 60, 62, 68, 70, 71, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 94, 96, 97, 105, 106, 107, 108, 109, 113], "train_bash": 115, "train_batch_s": 77, "train_ppo": 77, "train_ppo_llama": 77, "trainabl": 116, "trainer": 77, "trainin": 56, "training_step_actor": 77, "training_step_crit": 77, "trajectori": [47, 70, 79, 92], "transduct": 9, "transfer": [110, 111], "transform": [9, 11, 12, 45, 52, 55, 57, 58, 59, 60, 61, 64, 69, 97, 106, 107, 108, 109, 110, 111, 112, 116], "transformerblock": [10, 62, 63], "transit": [47, 95], "translat": [9, 11, 45, 61, 92, 97], "transmit": 73, "transpos": [62, 63], "trap": 95, "treat": [46, 62, 64, 85, 107], "tree": 1, "tremend": 57, "trend": 49, "tri": [86, 94], "trick": [54, 77, 106], "trigger": 7, "trigonometr": [62, 63, 106, 107], "trigonometri": 61, "trillion": [56, 58, 64, 65], "trim": [53, 99], "triplet": [10, 55, 76, 84], "triton": 23, "triu": [62, 63], "trivial": 69, "trl": 77, "troubl": 80, "trough": 55, "trove": 23, "true": [17, 60, 62, 63, 77, 109, 115], "truncat": 69, "trust": 79, "truth": [3, 17, 25, 26, 36, 50, 56, 57, 58, 61, 64, 68, 69, 70, 71, 84, 87], "try": [7, 16, 18, 37, 54, 62, 65, 72, 86, 102], "trylimit": 54, "tu": [45, 97], "tune": [12, 13, 16, 17, 18, 28, 31, 37, 40, 43, 45, 61, 65, 71, 72, 74, 76, 77, 82, 83, 84, 86, 95, 96, 97, 99, 102, 106, 107], "tupl": [62, 63, 107], "turbo": [16, 24, 38, 56, 62], "turn": [1, 55, 61, 62, 96, 107], "tutori": 65, "two": [2, 9, 10, 17, 19, 28, 29, 31, 40, 43, 45, 46, 47, 48, 50, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 68, 69, 70, 71, 72, 73, 76, 80, 81, 82, 84, 85, 86, 87, 88, 92, 94, 95, 96, 99, 105, 106, 107, 108, 112], "tworek": [45, 97], "tx": 73, "txt": [18, 37], "type": [16, 18, 23, 28, 31, 37, 39, 40, 43, 50, 52, 55, 58, 59, 62, 63, 70, 76, 80, 81, 84, 85, 92, 107], "type_a": [62, 63, 107, 109], "typeddict": 62, "typescript": 61, "typic": [3, 11, 12, 29, 48, 50, 59, 61, 69, 72, 73, 74, 76, 80, 82, 88, 105, 106, 107, 110, 111], "tzdata": 23, "u": [10, 11, 12, 19, 29, 42, 52, 53, 58, 71, 76, 84, 85, 87, 96, 105, 108], "u_": [10, 105], "u_1": 10, "u_i": 10, "u_n": 10, "uation": 19, "uiuc": 20, "uk": 108, "ultim": [31, 43, 50, 61, 105], "ultrafeedback": 68, "unambigu": 26, "unansw": 2, "unawar": 2, "unbalanc": 105, "unbias": [22, 62, 74, 109], "uncertainti": 73, "unchang": 95, "unclear": [50, 95], "uncur": 87, "under": [21, 24, 38, 47, 48, 57, 71, 72, 79], "underli": 107, "underload": 58, "underset": [60, 68, 73, 74, 88, 95], "understand": [7, 10, 21, 42, 45, 46, 50, 54, 55, 61, 65, 97, 102], "undesir": [47, 69], "unembed": [13, 57, 75], "uneth": 80, "unexpect": [69, 92], "unhealthi": 69, "unicod": [45, 65, 97], "unicode\u548cutf": 114, "unicode\u5f53\u524d\u9ed8\u8ba4\u7684\u7248\u672c\u662fuc": 114, "unicode\u662fascii": 114, "unicode\u7684\u5b57\u7b26\u96c6\u8303\u56f4": 114, "unicode\u76f4\u63a5\u517c\u5bb9\u4e86\u521d\u671fascii": 114, "unifi": [3, 31, 43], "uniform": [55, 84, 96, 106, 109], "uniformli": [11, 73, 94, 96], "union": 62, "uniqu": [54, 55, 57], "unit": [22, 25, 39, 55, 60, 61, 64, 65, 106, 107], "univers": [42, 45, 97, 107], "unk": 84, "unknown": [2, 71, 84], "unlabel": [10, 88], "unleash": [42, 65], "unlik": [25, 39, 69, 106], "unlikelihood": 76, "unlimit": 11, "unlock": [55, 57], "unmerg": 77, "unnecessari": 7, "unpack": [32, 33], "unsatisfactori": 76, "unsupervis": [11, 45, 50, 65, 97], "unsur": 60, "until": [7, 28, 40, 53, 54, 61, 73, 84, 105], "untruth": 13, "unveil": [31, 43], "up": [10, 12, 13, 17, 18, 28, 30, 37, 39, 40, 41, 53, 60, 61, 69, 73, 75, 76, 80, 94, 96, 99, 106, 107], "up_proj": 57, "updat": [29, 49, 53, 58, 65, 69, 77, 106], "upgrad": [20, 31, 43], "uplift": 69, "upon": [48, 58, 64, 65], "upper": [48, 69, 107], "upweight": 47, "uq": 108, "uritempl": 23, "url": [45, 97], "urllib3": 23, "us": [1, 2, 4, 7, 9, 10, 11, 12, 13, 17, 18, 19, 22, 23, 24, 25, 28, 29, 31, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 94, 96, 99, 102, 106, 107, 108, 109, 110, 111, 112], "usag": [3, 17, 31, 39, 43, 61], "use_fast_token": 115, "user": [2, 3, 7, 13, 16, 18, 37, 39, 50, 55, 60, 61, 62, 75, 85, 86, 87, 99], "usual": [3, 9, 28, 29, 40, 61, 69, 71, 74, 84, 87, 94, 105, 108, 110, 111], "uszkoreit": [45, 97], "ut": 76, "util": [2, 21, 31, 43, 54, 55, 58, 60, 61, 64, 65, 69, 71, 80, 85, 92], "uv": 108, "uw_": 10, "v": [9, 47, 62, 63, 68, 76, 79, 82, 108, 110, 111, 112], "v0": [16, 20, 77], "v1": [24, 38, 60], "v2": [32, 33, 45, 58, 60, 97, 105, 108], "v3": [33, 60, 92], "v5": [55, 60], "v_": [68, 74], "v_head_dim": 57, "valid": [1, 7, 12, 13, 25, 28, 30, 35, 39, 40, 52, 54, 58, 64, 65, 69, 71, 75, 85, 88, 94], "valu": [9, 13, 25, 39, 49, 52, 58, 62, 63, 65, 72, 74, 75, 76, 79, 81, 84, 88, 105, 106, 107, 111], "valuabl": [110, 111], "valueerror": 62, "vanish": 73, "var": [62, 109], "vare": 49, "vari": [11, 21, 31, 43, 49, 53, 57, 59, 105, 106], "variabl": [65, 109, 110, 111], "varianc": [22, 47, 60, 64, 73, 74, 79, 109], "variant": [10, 55, 62, 63, 79, 86], "variat": [21, 45, 52, 62, 63, 82, 112], "varieti": [49, 61], "variou": [17, 19, 24, 28, 31, 38, 40, 43, 49, 56, 59, 61, 64, 65, 80, 86, 106, 107], "vast": 65, "vaswani": [45, 97], "vdot": [110, 111], "ve": 62, "vector": [9, 10, 25, 55, 62, 63, 68, 72, 73, 106, 107, 108, 109, 111, 112], "vedant": [45, 97], "verb": [18, 37], "verbos": 68, "verdict": 87, "veri": [13, 22, 49, 50, 52, 65, 75, 80, 82, 106, 107], "verif": [17, 61, 65, 92], "verifi": [3, 16, 17, 25, 26, 45, 58, 69, 92, 95, 97], "versatil": [45, 97], "version": [9, 13, 21, 24, 38, 39, 53, 55, 57, 60, 61, 62, 63, 71, 87, 92, 102, 112, 115], "versu": [79, 102], "veryeasyhack": 80, "via": [13, 17, 39, 45, 48, 54, 55, 61, 68, 69, 71, 79, 83, 87, 90, 92, 97], "view": [7, 62, 63, 107], "view_as_complex": [62, 63, 107], "view_as_r": [62, 63, 107], "viewer": 7, "vineet": [45, 97], "violat": 82, "virtualenv": 23, "visual": [18, 37], "vllm": 20, "vocab": 72, "vocab_s": [57, 62, 63], "vocabulari": [57, 64, 72], "voss": [45, 97], "vote": [70, 94, 96], "vsp": [9, 10, 45, 64, 97, 108], "vw_": 9, "w": [9, 13, 45, 62, 63, 68, 71, 72, 75, 84, 86, 87, 97, 104, 108, 110, 111, 112], "w1": [62, 63], "w2": [62, 63, 112], "w3": [62, 63], "w_": [9, 10, 47, 62, 63, 111, 112, 116], "w_1": 65, "w_1s_1": 65, "w_2": 9, "w_e": 10, "w_n": 65, "w_ns_n": 65, "w_p": 10, "w_y": 10, "wa": [10, 11, 19, 26, 31, 39, 43, 52, 53, 55, 56, 58, 60, 65, 86, 95], "wai": [22, 25, 28, 40, 47, 48, 50, 54, 65, 69, 80, 84, 102, 105, 106, 107], "wainwright": [45, 97], "wait": 94, "waitlist": 13, "wake": [18, 37], "wan": [45, 97], "wang": [45, 97], "wangd": [45, 97], "want": [7, 13, 28, 40, 47, 75, 84, 102, 106, 107], "warm": 69, "warmup": [39, 59, 99], "wast": 52, "wastag": 105, "wavecod": [45, 65, 97], "wavelength": [9, 106], "wcg19": [45, 64, 97], "we": [1, 2, 3, 7, 9, 10, 11, 12, 13, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 29, 31, 35, 37, 38, 39, 40, 42, 43, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 94, 95, 96, 99, 102, 105, 106, 107, 108, 110, 111, 112, 116], "weak": [32, 76, 107], "weaker": [24, 38], "weakli": [49, 50], "weather": 2, "web": [11, 56, 69, 84], "webpag": [11, 75], "websit": [39, 59, 64, 65, 69], "webtext": 11, "webtext2": 49, "wei": [45, 97], "weigh": 71, "weight": [9, 10, 39, 47, 52, 57, 59, 60, 62, 63, 65, 69, 71, 76, 81, 99, 105, 107, 109, 111, 112, 116], "welind": [45, 97], "well": [7, 9, 10, 16, 47, 64, 72, 76, 80, 106, 107], "wellcalibr": 80, "wen": [45, 97], "wenbin": [45, 97], "wenfeng": [45, 97], "wenji": [45, 97], "wenjun": [45, 97], "wentao": [45, 97], "wenxiang": [45, 97], "were": [22, 58, 60, 96], "west": [32, 33], "what": [2, 18, 37, 50, 56, 59, 73, 107], "wheel": 23, "when": [2, 3, 7, 9, 11, 13, 18, 25, 28, 37, 39, 40, 45, 46, 47, 49, 50, 53, 54, 61, 62, 63, 68, 69, 72, 73, 74, 76, 79, 82, 85, 87, 94, 95, 96, 102, 105, 109, 111, 112], "where": [1, 9, 10, 13, 17, 22, 25, 28, 29, 31, 36, 40, 42, 43, 47, 48, 49, 54, 55, 57, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 84, 85, 86, 87, 90, 94, 102, 105, 106, 107, 108, 109, 110, 111, 112, 116], "wherea": [45, 47, 52], "wherebi": 60, "wherein": 76, "wherev": 58, "whether": [28, 40, 45, 50, 52, 56, 58, 62, 65, 76, 79, 81, 87, 92, 95, 96, 105], "which": [2, 3, 7, 9, 10, 11, 12, 13, 18, 19, 21, 22, 24, 25, 26, 28, 31, 37, 38, 40, 43, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 79, 80, 81, 82, 84, 85, 86, 87, 88, 92, 96, 102, 105, 106, 107, 109, 110, 111, 112, 116], "while": [3, 4, 7, 9, 11, 12, 13, 24, 25, 29, 38, 47, 49, 53, 54, 55, 57, 58, 61, 64, 65, 72, 73, 74, 79, 80, 84, 85, 86, 95, 99, 102, 105, 106, 107, 111, 113], "white": 22, "whiten": 60, "who": 25, "whole": 76, "whose": [13, 62, 65], "why": [50, 54], "wide": [10, 13, 21, 29, 49, 50, 53, 61, 68, 74, 85], "widespread": [45, 97], "width": 62, "wifi": 80, "wiki": 59, "wikihow": 99, "wikipedia": [4, 11, 59], "wildchat": 39, "william": [45, 97], "win": [73, 81, 84, 86, 87], "window": [7, 10, 29, 58, 61], "winner": 87, "winter": [45, 97], "wise": [10, 57, 58, 62, 63, 80, 94, 107, 109, 112], "within": [3, 4, 58, 61, 65, 69, 79, 80, 87, 88, 92, 106, 107, 109], "without": [1, 3, 11, 17, 19, 29, 47, 50, 65, 68, 69, 71, 72, 73, 75, 80, 87, 92, 96, 99, 111], "wizard": [32, 33], "wk": [62, 63], "wo": [62, 63], "wojciech": [45, 97], "word": [10, 11, 13, 16, 18, 25, 29, 37, 45, 65, 69, 82, 97, 104, 110, 111, 113], "wordpiece\u6bcf\u6b21\u9009\u62e9\u5408\u5e76\u7684\u4e24\u4e2a\u5b50\u8bcd": 113, "wordpiece\u7b97\u6cd5\u4e5f\u662f\u6bcf\u6b21\u4ece\u8bcd\u8868\u4e2d\u9009\u51fa\u4e24\u4e2a\u5b50\u8bcd\u5408\u5e76\u6210\u65b0\u7684\u5b50\u8bcd": 113, "work": [3, 7, 9, 11, 12, 17, 24, 25, 28, 38, 40, 42, 47, 50, 57, 59, 61, 62, 63, 70, 71, 72, 80, 87, 107, 112], "world": [3, 18, 21, 29, 37], "world_siz": 77, "wors": [84, 102], "worst": [48, 88], "would": [7, 9, 47, 50, 60, 68, 80, 87, 96], "wq": [62, 63], "write": [13, 16, 18, 26, 37, 45, 46, 55, 57, 58, 60, 75, 92, 99, 106, 111], "writer": 25, "written": [13, 22, 25, 28, 36, 40, 45, 46, 80], "wrong": [54, 72, 96, 102], "wrote": [18, 37, 80], "wu": [45, 97], "wv": [62, 63], "wwl": [39, 45, 61, 65, 97], "wx": 116, "x": [9, 10, 13, 19, 45, 47, 55, 60, 62, 63, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 83, 84, 85, 87, 88, 95, 97, 104, 106, 107, 109, 110, 111, 112, 113, 116], "x_": [28, 40, 62, 63, 87, 95, 106, 107, 111], "x_0": [62, 63, 106, 107], "x_1": [9, 62, 63, 76, 83, 95, 106, 107], "x_2": [62, 63, 95], "x_i": [86, 87, 95], "x_m": 76, "x_n": [9, 83], "xdxac": 104, "xia": [45, 97], "xiangyu": [45, 97], "xianji": [45, 97], "xianzu": [45, 97], "xiao": [45, 97], "xiaodong": [45, 97], "xiaohan": [45, 97], "xiaohuan": [45, 97], "xiaojin": [45, 97], "xiaokang": [45, 97], "xiaosha": [45, 97], "xiaotao": [45, 97], "xiaowen": [45, 97], "xiaoxiang": [45, 97], "xie": [45, 97], "xin": [45, 97], "xingkai": [45, 97], "xingxuan": [45, 97], "xingzhang": [45, 97], "xinnan": [45, 97], "xinyi": [45, 97], "xinyu": [45, 97], "xiong": [45, 97], "xk": [62, 63, 107], "xk_": [62, 63, 107], "xk_out": [62, 63, 107], "xp": 112, "xq": [62, 63, 107], "xq_": [62, 63, 107], "xq_out": [62, 63, 107], "xu": [45, 97], "xuan": [45, 97], "xuancheng": [45, 97], "xue": [45, 97], "xuecheng": [45, 97], "xv": [62, 63, 112], "xw": [62, 63, 112], "xw_": [62, 63, 112], "xw_1": 9, "xx": [20, 33], "xxhash": 23, "xxx": 23, "xz": 23, "x\u4e3a\u5b57\u7b26\u7684unicode\u4e8c\u8fdb\u5236": 114, "y": [10, 13, 45, 47, 60, 62, 63, 68, 69, 71, 72, 73, 75, 76, 79, 81, 83, 84, 85, 87, 95, 97, 104, 106, 109, 113], "y1": 71, "y2": 71, "y3": 71, "y_": [13, 28, 40, 47, 60, 68, 70, 71, 72, 75, 76, 83, 84, 85, 86, 87, 88, 95], "y_1": [9, 13, 71, 76, 81, 85, 88, 95], "y_2": [13, 71, 81, 85, 88, 95], "y_c": 85, "y_i": [70, 95], "y_l": 72, "y_m": 9, "y_n": 76, "y_r": 85, "y_t": 76, "y_w": 72, "yaml": [23, 54], "yan": [45, 97], "yang": [45, 97], "yangyu": [45, 97], "yanhong": [45, 97], "yann": [45, 97], "yanp": [45, 97], "yao": [45, 97], "yaofeng": [45, 97], "yaohui": [45, 97], "yarl": 23, "yarn": 58, "ye": [45, 97], "yellow": 22, "yet": 17, "yi": [45, 97], "yibo": [45, 97], "yichang": [45, 97], "yichao": [45, 97], "yield": [9, 13, 26, 61, 73, 74, 85, 116], "yifeng": [45, 97], "yiliang": [45, 97], "yilong": [45, 97], "yin": [45, 97], "ying": [45, 97], "yishi": [45, 97], "yishuji": [45, 97], "yixin": [45, 97], "yixuan": [45, 97], "yiyuan": [45, 97], "yml": 23, "yongji": [45, 97], "yongqiang": [45, 97], "you": [16, 18, 23, 37, 45, 46, 55, 60, 79, 80, 85, 97, 102], "young": 25, "your": [16, 23, 45, 46, 55, 80, 97], "yu": [45, 97], "yuan": [45, 97], "yuchen": [45, 97], "yuduan": [45, 97], "yuheng": [45, 97], "yukun": [45, 97], "yuliang": 33, "yunfei": [45, 97], "yunfeng": [45, 97], "yunlong": [45, 97], "yunxian": [45, 97], "yuqiong": [45, 97], "yura": [45, 97], "yuri": [45, 97], "yute": [45, 97], "yuwei": [45, 97], "yuxiang": [45, 97], "yuxuan": [45, 97], "yuyao": [45, 97], "yyl": [45, 97, 102], "yz": [45, 65, 97], "yzh": [45, 65, 97], "z": [9, 45, 71, 73, 79, 84, 97, 104, 113], "z_": 84, "z_1": 9, "z_n": 9, "zabdzabac": 104, "zaremba": [45, 97], "zehui": [45, 97], "zekun": [45, 97], "zemlyanskii": [45, 97], "zeng": [45, 97], "zero": [12, 21, 47, 60, 62, 63, 102, 111], "zero_stag": 77, "zeros_lik": 62, "zeyu": [45, 97], "zh": 56, "zha": [45, 97], "zhang": [45, 97], "zhangli": [45, 97], "zhao": [45, 97], "zhaojian": [45, 97], "zhe": [45, 97], "zhen": [45, 97], "zhenda": [45, 97], "zheng": [45, 97], "zhenru": [45, 97], "zhewen": [45, 97], "zhihong": [45, 97], "zhiniu": [45, 97], "zhipeng": [45, 97], "zhongyu": [45, 97], "zhou": [45, 97], "zhoujun": [45, 97], "zhu": [45, 97], "zhuoshu": [45, 97], "ziegler": [45, 97], "zihan": [45, 97], "zihui": [45, 97], "zilin": [45, 97], "zip": [62, 84], "zipp": 23, "ziwei": [45, 97], "zixuan": [45, 97], "zlib": 23, "zlm": [16, 45, 97], "zou": [45, 97], "zy": 104, "zydzyac": 104, "\u4e00": 114, "\u4e00\u4e2a\u5728\u5f00\u5934": 104, "\u4e00\u822c\u4e0d\u76f4\u63a5\u4f7f\u7528unicod": 114, "\u4e00\u90e8\u5206\u6b63\u8d1f\u62b5\u6d88\u4e00\u90e8\u5206\u632f\u8361": 106, "\u4e00\u95e8\u8bed\u8a00\u4e2d": 104, "\u4e0a\u9762\u4ecb\u7ecd\u4e86\u6587\u5b57\u5b57\u7b26\u6620\u5c04\u4e3aunicode\u5b57\u7b26\u96c6": 114, "\u4e0b\u4e00\u4e2a\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u662f": 104, "\u4e0b\u8f7d": 20, "\u4e0b\u8f7d\u8bc4\u4f30\u6587\u4ef6": 23, "\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50": 104, "\u4e0b\u9762\u7684\u793a\u4f8b\u5c06\u89e3\u91ca": 104, "\u4e0d\u4f1a\u51fa\u73b0\u53ea\u5b66\u90a3\u4e9b\u7b80\u5355\u4e14": 74, "\u4e0d\u4f1a\u5355\u72ec\u51fa\u73b0": 104, "\u4e0d\u8868\u793a\u5176\u4ed6\u8bed\u8a00": 114, "\u4e0d\u8db3\u7684\u5728\u9ad8\u4f4d\u75280\u8865\u5145": 114, "\u4e0ebpe\u7684\u6700\u5927\u533a\u522b\u5728\u4e8e": 113, "\u4e0ebpe\u7b97\u6cd5\u7c7b\u4f3c": 113, "\u4e14\u5047\u8bbe\u5404\u4e2a\u5b50\u8bcd\u4e4b\u95f4\u662f\u72ec\u7acb\u5b58\u5728\u7684": 113, "\u4e24\u4e2a\u5b57\u6bb5": 20, "\u4e2a": 104, "\u4e2a\u4e0d\u540c\u7684token": 104, "\u4e2a\u5355\u8bcd": 104, "\u4e2a\u5b50\u8bcd\u7ec4\u6210": 113, "\u4e2d": 20, "\u4e2d\u4f7f\u7528\u4e86\u4e0a\u8ff0\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53": 104, "\u4e2d\u51cf\u5c11\u8ba1\u6570": 104, "\u4e2d\u5b58\u5728": 104, "\u4e2d\u62bd\u53d6\u51fa\u6765": 23, "\u4e2d\u6587": 114, "\u4e2d\u7684": 20, "\u4e2d\u76f8\u5bf9\u597d\u7684": 74, "\u4e2d\u88ab\u9996\u6b21\u63d0\u51fa": 104, "\u4e3a\u4e86\u4ee5\u6700\u6709\u6548\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u6599\u5e93": 104, "\u4e3a\u4e86\u5408\u5e76": 104, "\u4e3a\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3": 104, "\u4e3a\u4e86\u672c\u6587\u7684\u7b80\u5355\u8d77\u89c1": 104, "\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4": 114, "\u4e3a\u4e86\u89e3\u51b3": 114, "\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u8c03\u7528": 20, "\u4e3a\u53e5\u5b50\u7684\u4e00\u4e2a\u5206\u8bcd\u7ed3\u679c": 113, "\u4e3a\u8865\u5145": 114, "\u4e3e\u4f8b1": 114, "\u4e3e\u4f8b2": 114, "\u4e4b\u524d": 114, "\u4e5f\u53eb\u5b57\u7b26\u96c6": 114, "\u4e5f\u5c31\u662f\u4e24\u5b50\u8bcd\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u5173\u8054\u6027": 113, "\u4e5f\u5c31\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u770b\u6210\u4e00\u4e2atoken": 104, "\u4e5f\u5c31\u662f\u7528\u5b9a\u957f2\u4e2a\u5b57\u8282\u6765\u8868\u793a\u5b57\u7b26": 114, "\u4e5f\u662fnlp\u4e2d\u6700\u91cd\u8981\u7684\u7f16\u7801\u65b9\u5f0f\u4e4b\u4e00": 104, "\u4e5f\u80fd\u88ab\u7b97\u4f5c\u5b57\u7b26\u5bf9\u7684\u4e00\u90e8\u5206": 104, "\u4e8c\u8fdb\u5236\u5c31\u662f01000001": 114, "\u4e8c\u8fdb\u5236\u5c31\u662f110000": 114, "\u4eca\u5929\u5c31\u6765\u4e86\u89e3\u4e0b\u5b57\u7b26\u5728\u8ba1\u7b97\u673a\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f": 114, "\u4ece": 23, "\u4ece\u6700\u957f\u5230\u6700\u77ed": 104, "\u4ece\u800c\u6211\u4eec\u77e5\u9053\u5269\u4f59\u7684": 104, "\u4ed6\u4eec\u5177\u6709\u6700\u5927\u7684\u4e92\u4fe1\u606f\u503c": 113, "\u4ee5\u4e2d\u6587": 114, "\u4f1a\u4e0d\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5f88\u6162": 74, "\u4f1a\u4e0d\u4f1a\u66f4\u597d": 74, "\u4f20\u5165\u89e3\u6790\u540e\u7684\u53c2\u6570": 20, "\u4f3c\u7136\u503c\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a": 113, "\u4f46\u4e00\u4e2a\u8bcd\u5728\u7ed3\u5c3e\u6709\u4e00\u4e2a": 104, "\u4f46\u4ecd\u6709\u53ef\u80fd\u51fa\u73b0\u4e0d\u5728\u91cc\u9762\u7684\u5355\u8bcd": 104, "\u4f46\u5b83\u5177\u6709\u826f\u597d\u7684\u6027\u80fd": 104, "\u4f46\u6211\u4eec\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u5305\u542b\u8fd9\u4e9b\u5b57\u7b26": 104, "\u4f46\u662funicode\u8fd8\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6269\u5c55\u673a\u5236": 114, "\u4f46\u662f\u5176\u4ed6\u6b27\u6d32\u56fd\u5bb6\u7684\u8bed\u8a00\u6bd4\u5982\u6cd5\u8bed": 114, "\u4f46\u662f\u5b83\u548c\u6c49\u5b57\u7684\u6620\u5c04\u4e0eunicode\u548c\u6c49\u5b57\u7684\u6620\u5c04\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb": 114, "\u4f46\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u5408\u7406\u7684\u7f16\u7801\u65b9\u5f0f": 104, "\u4f4e\u7ef4": 106, "\u4f4e\u9891\u5185\u63d2\u7684\u65b9\u5f0f": 106, "\u4f60\u53ef\u80fd\u4e0d\u6e05\u695awordpiece\u662f\u5982\u4f55\u9009\u53d6\u5b50\u8bcd\u7684": 113, "\u4f7f\u7528\u4e0b\u8ff0\u547d\u4ee4\u8fdb\u884c\u8bc4\u4f30": 23, "\u4f8b\u5982\u5b57\u7b26\u4e32": 20, "\u4f8b\u5982\u7f16\u7801\u5e8f\u5217": 104, "\u4fee\u6539\u540e\u663e\u793a\u7ed3\u679c\u5982\u4e0b": 114, "\u5047\u8bbe\u5355\u8bcd\u7684\u5e8f\u5217\u662f": 104, "\u5047\u8bbe\u53e5\u5b50": 113, "\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8bed\u6599\u5e93": 104, "\u5047\u8bbe\u6211\u4eec\u6709\u9700\u8981\u7f16\u7801": 104, "\u5047\u8bbe\u628a\u76f8\u90bb\u4f4d\u7f6e\u7684x\u548cy\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 113, "\u5047\u8bbe\u8fd9\u4e9b\u8bcd\u51fa\u73b0\u7684\u9891\u7387\u5982\u4e0b": 104, "\u50cf": 104, "\u5141\u8bb8\u8868\u793a\u4e00\u767e\u591a\u4e07\u4e2a\u5b57\u7b26": 114, "\u5168\u7403\u7edd\u5927\u90e8\u5206\u5b57\u7b26\u7684\u5b57\u7b26\u96c6": 114, "\u5176\u4e2d": [23, 104], "\u5176\u4e2d\u4e0d\u6b62utf": 114, "\u5176\u4e2d\u4f1a\u6d89\u53ca\u5230ascii": 114, "\u5176\u4e2d\u5305\u542b\u5355\u8bcd": 104, "\u5176\u4ed6\u5b57\u8282": 114, "\u5176\u4ed6\u8bed\u8a00": 114, "\u5176\u4ed6\u8bed\u8a00\u53ef\u80fd\u6709\u6240\u4e0d\u540c": 104, "\u51fa\u73b0\u4e86": 104, "\u51fd\u6570": 20, "\u51fd\u6570\u5462": 20, "\u51fd\u6570\u5feb\u901f\u8f6c\u6362\u4e3a\u547d\u4ee4\u884c\u63a5\u53e3": 20, "\u51fd\u6570\u7684\u53c2\u6570\u5217\u8868": 20, "\u5206\u522b\u6765\u81ea": 20, "\u5219\u53e5\u5b50": 113, "\u521d\u59cbtoken\u5c06\u662f\u6240\u6709\u5b57\u7b26\u548c": 104, "\u524d\u9762\u5168\u90e8\u586b\u51450": 114, "\u5269\u4e0b\u7684\u552f\u4e00\u5b57\u8282\u5bf9\u662f": 104, "\u52a0\u4e0a\u63a7\u5236\u7801\u540e\u5bf9\u5e94\u7684utf": 114, "\u5339\u914d": 20, "\u5341\u516d\u8fdb\u5236": 114, "\u5355\u5b57\u8282256\u4e2a\u5b57\u7b26\u80af\u5b9a\u6ca1\u6cd5\u5b8c\u5168\u8868\u793a": 114, "\u5373": [20, 104], "\u538b\u7f29": 104, "\u539f\u672c\u5728\u4f4e\u7ef4\u5ea6\u4e0a": 106, "\u53c2\u6570\u4e3a": 23, "\u53cd\u5411\u6267\u884c\u4ee5\u4e0a\u8fc7\u7a0b\u5c31\u884c\u4e86": 104, "\u53cd\u590d\u8fed\u4ee3\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6": 104, "\u53ea\u9700\u8981\u4e00\u4e2a\u5b57\u8282\u8868\u793a": 114, "\u53ea\u9700\u8981\u4f7f\u7528\u540e\u97627\u4f4d\u5c31\u8db3\u591f\u4e86": 114, "\u53ef\u4ee5\u4f7f\u75281": 114, "\u5404\u4e2a\u56fd\u5bb6\u4fbf\u7740\u624b\u81ea\u5df1\u56fd\u5bb6\u8bed\u8a00\u7684\u7f16\u7801": 114, "\u5408\u5e76\u505c\u6b62token": 104, "\u5408\u5e76\u540e\u4ea7\u751f\u7684\u5b50\u8bcd\u8bb0\u4e3az": 113, "\u5408\u5e76\u5b57\u7b26\u53ef\u4ee5\u8ba9\u4f60": 104, "\u5408\u5e76\u5b83\u4eec": 104, "\u540c\u7406\u8fd8\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u7279\u6709\u5b57\u7b26\u96c6": 114, "\u548c": [20, 104, 106], "\u548cascii\u7684\u76ee\u7684\u4e00\u6837": 114, "\u548cascii\u7801\u4e00\u81f4": 114, "\u56de\u8f6613\u7b49\u7b49\u4e00\u4e9b\u952e\u76d8\u4e0a\u6240\u89c1\u7684\u7b26\u53f7": 114, "\u56e0\u4e3a": 104, "\u56e0\u4e3a\u4eba\u7c7b\u8bed\u8a00\u4e5f\u7ecf\u5e38\u4ee5\u5355\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u4ea4\u6d41": 104, "\u56e0\u4e3a\u5b83\u4eec\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 104, "\u56e0\u4e3a\u6211\u4eec\u7edf\u8ba1\u76f8\u90bb\u5b57\u7b26\u5bf9\u65f6\u4e0d\u80fd\u628a\u5206\u522b\u4f4d\u4e8e\u4e24\u4e2a\u5355\u8bcd\u4e2d\u7684\u5b57\u7b26\u5bf9\u7b97\u8fdb\u53bb": 104, "\u56e0\u4e3a\u6ca1\u6709\u51fa\u73b0\u591a\u6b21\u7684\u5b57\u8282\u5bf9": 104, "\u56e0\u6b64": 104, "\u56e0\u6b64bpe\u4e5f\u662f\u5178\u578b\u7684\u57fa\u4e8esubword\u7684tokenization\u7b97\u6cd5": 104, "\u56e0\u6b64\u6211\u4eec\u53ef\u91c7\u7528\u9ad8\u9891\u5916\u63a8": 106, "\u56e0\u6b64\u6211\u4eec\u5c06\u7528\u4e00\u4e2a\u65b0\u5b57\u8282": 104, "\u56e0\u6b64\u6211\u4eec\u6ca1\u6709\u5c06\u5b83\u4eec\u5408\u5e76": 104, "\u5728": 20, "\u5728finest\u548clowest\u4e24\u4e2a\u8bcd\u4e2d": 104, "\u5728unicode\u8bde\u751f": 114, "\u5728\u5b9e\u8df5\u4e2d": 104, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d": 104, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 104, "\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0": 104, "\u5728\u8ba1\u7b97\u673a\u4e2d\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u4f4d0\u548c1\u6765\u5b58\u50a8\u7684": 114, "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u65f6\u5019\u9700\u8981\u5728\u8fd9\u4e2a\u62e5\u6709\u51e0\u4e07\u4e2a\u5355\u8bcd\u7684\u5217\u8868\u4e0a\u8ba1\u7b97\u4e00\u4e2a\u6982\u7387\u5206\u5e03": 104, "\u5728\u8fd9\u91cc": 104, "\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u6bd4\u8f83token\u7684\u9891\u7387\u5927\u5c0f\u6765\u7a77\u5c3d\u6bcf\u4e00\u79cd\u53ef\u80fd": 104, "\u5927\u5199\u5b57\u6bcda\u5bf9\u5e94\u7684ascii\u7801\u662f65": 114, "\u5927\u5bb6\u90fd\u77e5\u9053\u7535\u8111\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u548c\u5b58\u50a8\u7684": 114, "\u5927\u6982\u5c31\u662f\u8bf4ascii\u662f\u7f8e\u56fd\u4fe1\u606f\u4ea4\u6362\u6807\u51c6\u4ee3\u7801": 114, "\u5927\u90e8\u5206\u662f2\u5b57\u8282": 114, "\u5982\u4f55\u6765\u8868\u793aunicod": 114, "\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u5c31\u662f\u8981\u8868\u793a\u4e00\u4e2a\u5b57\u7b26\u8fd8\u662f\u8fde\u7eed\u7684\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 114, "\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u8bfb\u61c2unicod": 114, "\u5982\u4f55\u8bfb\u53d6unicode\u5b57\u7b26\u96c6": 114, "\u5982\u4f55\u9009\u62e9\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 113, "\u5982\u679c\u4f1a\u7559\u4e0b\u51e0\u4e2a\u5b50\u4e32": 104, "\u5982\u679c\u5728\u4f4e\u7ef4\u5ea6\u8fdb\u884c\u5185\u63d2": 106, "\u5982\u679c\u6309\u7167unicode\u7684\u65b9\u5f0f\u7edf\u4e00\u7528\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 114, "\u5982\u679c\u7b97\u6cd5\u770b\u5230token": 104, "\u5b57\u6bcd": 114, "\u5b57\u7b26\u7801\u5c31\u662f\u5bf9\u5e94\u7684unicod": 114, "\u5b57\u7b26\u7801\u7ec4\u6210": 114, "\u5b57\u7b26\u7b49": 104, "\u5b57\u7b26\u96c6\u5373\u662f\u6587\u5b57\u7b26\u53f7\u548c\u4e8c\u8fdb\u5236\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 114, "\u5b57\u8282\u957f\u5ea6": 114, "\u5b66\u540c\u4e00\u4e2a": 74, "\u5b83\u4e0d\u80fd\u88ab\u8fdb\u4e00\u6b65\u538b\u7f29": 104, "\u5b83\u4eec\u51fa\u73b0\u4e86": 104, "\u5b83\u4eec\u7ecf\u5e38\u5728\u8bed\u6599\u4e2d\u4ee5\u76f8\u90bb\u65b9\u5f0f\u540c\u65f6\u51fa\u73b0": 113, "\u5b83\u53ea\u6709\u4e00\u4e2a": 104, "\u5b83\u5728": 104, "\u5b83\u5c31\u4f1a\u77e5\u9053\u5b83\u662f": 104, "\u5b83\u7684\u4f5c\u7528\u662f\u628a\u5404\u4e2a\u8bed\u8a00\u7684\u5b57\u7b26\u6620\u5c04\u4e3a\u4e8c\u8fdb\u5236": 114, "\u5b83\u7684\u7279\u70b9\u662f\u53d8\u957f\u7f16\u7801": 114, "\u5b83\u9075\u5faa\u4e00\u79cd\u8d2a\u5a6a\u7684\u7b56\u7565\u6765\u5c3d\u53ef\u80fd\u53d6\u5f97\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848": 104, "\u5b8c\u5168\u517c\u5bb9ascii": 114, "\u5bf9\u4e0eascii\u7a7a\u95f4\u6d6a\u8d39": 114, "\u5bf9\u4e8e\u5355\u5b57\u8282\u7684\u5b57\u7b26": 114, "\u5bf9\u4e8e\u53e5\u5b50": 113, "\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u662f\u6781\u5927\u7684\u6d6a\u8d39": 114, "\u5bf9\u4e8e\u672a\u77e5": 104, "\u5bf9\u4e8e\u82f1\u6587\u56fd\u5bb6\u6765\u8bf4\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528": 114, "\u5bf9\u4e8e\u9700\u8981n\u4e2a\u5b57\u8282\u7684\u5b57\u7b26": 114, "\u5bf9\u5e94\u7684unicode\u5b57\u7b26\u96c6\u662f4e00": 114, "\u5bf9\u5e94\u7684unicode\u662fu": 114, "\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a01000001": 114, "\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u7f16\u7801\u7684\u8fc7\u7a0b\u8fd8\u662f\u6bd4\u8f83\u7b80\u5355\u7684": 104, "\u5bf9\u7528\u4f4e\u7ef4\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u95f4\u7684\u80fd\u529b\u5f71\u54cd\u66f4\u5927": 106, "\u5bfb\u627e\u6700\u5e38\u51fa\u73b0\u7684\u5b57\u8282\u5bf9": 104, "\u5c06": 20, "\u5c06\u53c2\u6570\u503c\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u7c7b\u578b": 20, "\u5c31\u4ee3\u8868\u4e00\u4e2a\u8bed\u8a00\u5355\u4f4d": 104, "\u5c31\u50cf\u5355\u8bcd": 104, "\u5c31\u662f\u4f7f\u7528\u63a7\u5236\u7801": 114, "\u5c31\u80fd\u4ee3\u8868\u4e86\u6240\u6709\u952e\u76d8\u4e0a\u7684\u666e\u901a\u7b26\u53f7": 114, "\u5c31\u8bde\u751f\u4e86utf": 114, "\u5c3d\u7ba1\u8d2a\u5a6a": 104, "\u5e03\u5c14\u503c\u7b49": 20, "\u5e74\u53d1\u8868\u7684\u6587\u7ae0": 104, "\u5e76\u4e00\u6b21\u53c8\u4e00\u6b21\u5730\u6267\u884c\u76f8\u540c\u7684\u8fed\u4ee3": 104, "\u5e76\u4e14\u6211\u4eec\u7684\u5b50\u5b57\u7b26\u4e32\u5c06\u88ab\u66ff\u6362\u4e3a\u6211\u4eectoken\u5217\u8868\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684token\u7ec4\u5408": 104, "\u5e76\u4e14\u7531utf": 114, "\u5e76\u5c06\u5176\u91cd\u547d\u540d\u4e3a": 20, "\u5e76\u5c06\u5176\u9891\u7387\u8bb0\u4e3a": 104, "\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230token\u5217\u8868\u4e2d": 104, "\u5e76\u5c06\u65b0\u8bcd\u7684token\u6dfb\u52a0\u5230\u6211\u4eec\u7684token\u5b57\u5178\u4e2d\u4ee5\u5907\u5c06\u6765\u7528\u5230": 104, "\u5e76\u5c1d\u8bd5\u4f7f\u7528\u8fd9\u4e9btoken\u66ff\u6362\u7ed9\u5b9a\u5355\u8bcd\u5e8f\u5217\u4e2d\u7684\u5b50\u5b57\u7b26\u4e32": 104, "\u5e76\u88ab\u4f5c\u4e3a\u673a\u5668\u7ffb\u8bd1\u7b49\u4e3b\u6d41nlp\u4efb\u52a1\u7684\u9996\u9009tokenize\u65b9\u6cd5\u4e4b\u4e00": 104, "\u5e76\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2atoken\u51fa\u73b0\u7684\u9891\u7387": 104, "\u5e93": 20, "\u5f00\u5934": 114, "\u5f00\u59cb": 104, "\u5f53\u524d\u5206\u8bcd\u4e0b\u53e5\u5b50s\u7684\u4f3c\u7136\u503c\u53ef\u4ee5\u8868\u793a\u4e3a": 113, "\u5f53\u7136": 104, "\u5f53\u8fd0\u884c\u811a\u672c\u65f6": 20, "\u610f\u5473\u7740\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u53f7\u53d8\u5316\u975e\u5e38\u8fc5\u901f": 106, "\u6211\u4eec\u4f1a\u5c06": 104, "\u6211\u4eec\u5148\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5b83\u7684\u6838\u5fc3\u601d\u60f3": 104, "\u6211\u4eec\u53ef\u4ee5\u770b\u5230": 104, "\u6211\u4eec\u53ef\u4ee5\u9012\u5f52\u5730\u4f7f\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u5c06": 104, "\u6211\u4eec\u5c06tokenized\u597d\u7684\u5355\u8bcd\u4fdd\u5b58\u5728\u5b57\u5178\u4e2d": 104, "\u6211\u4eec\u5c06\u4ece\u7b2c\u4e8c\u5e38\u89c1\u7684\u6807\u8bb0": 104, "\u6211\u4eec\u5c06\u5b57\u7b26\u89c6\u4e3a\u4e0e\u5b57\u8282\u7b49\u4ef7": 104, "\u6211\u4eec\u5c06\u5b83\u4eec\u5408\u5e76\u4ee5\u5f62\u6210\u4e00\u4e2a\u65b0\u7684token": 104, "\u6211\u4eec\u5c06\u6bcf\u4e2a\u5355\u8bcd\u62c6\u5206\u4e3a\u5b57\u7b26\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684\u51fa\u73b0\u6b21\u6570": 104, "\u6211\u4eec\u5c06\u7528unknown": 104, "\u6211\u4eec\u5c06\u7ee7\u7eed\u6267\u884c\u6b64\u5408\u5e76\u6b65\u9aa4": 104, "\u6211\u4eec\u5c06\u88ab\u89e3\u7801\u4e3a": 104, "\u6211\u4eec\u5c06\u904d\u5386\u6211\u4eec\u5728\u8bed\u6599\u5e93\u4e2d\u627e\u5230\u7684\u6240\u6709token": 104, "\u6211\u4eec\u5c06\u904d\u5386\u6240\u6709token": 104, "\u6211\u4eec\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8bcd\u6c47\u5217\u8868\u662f\u5f88\u5927\u7684": 104, "\u6211\u4eec\u5e94\u7528\u4e0a\u8ff0\u7f16\u7801\u65b9\u6cd5\u5bf9\u65b0\u8bcd\u8fdb\u884ctoken": 104, "\u6211\u4eec\u5fc5\u987b\u7b80\u5355\u5730\u5c06\u6240\u6709token\u8fde\u63a5\u5728\u4e00\u8d77\u4ee5\u83b7\u5f97\u6574\u4e2a\u5355\u8bcd": 104, "\u6211\u4eec\u603b\u5171\u6709": 104, "\u6211\u4eec\u6709\u4e00\u4e2a\u9891\u7387\u4e3a": 104, "\u6211\u4eec\u6765\u67e5\u51fa\u8fd9\u51e0\u4e2a\u5b57\u5bf9\u5e94\u7684utf": 114, "\u6211\u4eec\u73b0\u5728\u5c06\u5408\u5e76token": 104, "\u6211\u4eec\u73b0\u5728\u6709": 104, "\u6211\u4eec\u73b0\u5728\u6709\u4e86": 104, "\u6211\u4eec\u73b0\u5728\u770b\u5230\u5b57\u8282\u5bf9": 104, "\u6211\u4eec\u7684\u6570\u636e\u73b0\u5728\u5df2\u8f6c\u6362\u4e3a": 104, "\u6211\u4eec\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6ca1\u6709\u770b\u5230\u7684\u8bcd": 104, "\u6211\u4eec\u770b\u5230\u5b57\u8282\u5bf9": 104, "\u6211\u4eec\u77e5\u9053": 104, "\u6211\u4eec\u8ba1\u7b97\u8fd9\u4e9b\u8bcd\u5728\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387": 104, "\u6211\u4eec\u8fd8\u5c06\u4ece\u5355\u4e2atoken": 104, "\u6211\u4eec\u90fd\u4e86\u89e3\u4e00\u79cd\u6700\u57fa\u672c\u7684token": 104, "\u6216": 104, "\u6216\u8005\u53eb": 114, "\u6240\u4ee5": [104, 113], "\u6240\u4ee5ascii\u7684\u5b57\u7b26": 114, "\u6240\u4ee5\u4ed6\u4eec\u5c31\u628a\u7b2c\u4e00\u4e2a\u7a7a\u95f20\u4f7f\u7528\u4e86\u8d77\u6765": 114, "\u6240\u4ee5\u4ed6\u4eec\u628a\u6bcf\u4e2a\u5b57\u8282\u7684\u7b2c\u4e00\u4f4d\u7f6e\u7f6e0": 114, "\u6240\u4ee5\u4f7f\u7528\u4e24\u4e2a\u5b57\u8282\u5df2\u7ecf\u8db3\u591f": 114, "\u6240\u4ee5\u5165\u53e3\u662f": 20, "\u6240\u4ee5\u5bf9\u5e94\u7684utf": 114, "\u6240\u4ee5\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u5168\u7403\u7edf\u4e00\u7684\u7f16\u7801\u89c4\u5219\u53ebunicod": 114, "\u6240\u4ee5\u6211\u4eec\u4e0d\u5bf9\u5b83\u8fdb\u884c\u7f16\u7801": 104, "\u6240\u4ee5\u6211\u4eec\u6709": 104, "\u6240\u4ee5\u8fd9\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898": 114, "\u628a": 20, "\u628a\u5b83\u653e\u5728\u672c\u5730": 23, "\u63a5\u4e0b\u6765": 104, "\u63a7\u5236\u7801\u5c31\u662f\u544a\u8bc9\u8ba1\u7b97\u673a\u5f53\u524d\u662f\u5355\u5b57\u8282\u8fd8\u662f\u591a\u5b57\u8282": 114, "\u653e\u5165\u7528\u6237\u4e3b\u76ee\u5f55\u4e0b\u7684": 20, "\u6563\u5ea6\u76f4\u63a5\u653e\u5728": 74, "\u6570\u5b57\u548c\u5b57\u6bcd\u90fd\u672a\u4e71\u7801": 114, "\u6570\u636e\u7684\u538b\u7f29": 104, "\u6587\u4ef6": 20, "\u6587\u4ef6\u4e2d\u6709\u5982\u4e0b\u914d\u7f6e": 20, "\u6587\u4ef6\u653e\u5165\u6b64\u76ee\u5f55\u5e76\u91cd\u547d\u540d\u4e3a": 20, "\u659c\u4f53": 114, "\u65b0": 104, "\u65b0\u5efa\u4e00\u4e2ahtml\u8f93\u5165": 114, "\u65cb\u8f6c\u5f97\u8d8a\u591a": 106, "\u65cb\u8f6c\u5f97\u8d8a\u5c11": 106, "\u65cb\u8f6c\u89d2\u5ea6\u8f83\u5927": 106, "\u65e0\u8bba\u5982\u4f55": 104, "\u65e0\u8bba\u662fascii\u7f16\u7801\u8fd8\u662futf": 114, "\u65e5\u6587": 114, "\u65f6": 106, "\u662f\u4e00\u79cd\u7b80\u5355\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5": 104, "\u662f\u4ee3\u7801\u7247\u6bb5": 23, "\u662f\u4f7f\u7528": 20, "\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684sub": 104, "\u662f\u7684": 104, "\u666e\u901a\u7b26\u53f7\u7684\u5b57\u7b26\u96c6": 114, "\u66ff\u6362\u5b83": 104, "\u6700\u5e38\u51fa\u73b0": 104, "\u6700\u5e38\u89c1\u7684\u5e26\u6709": 104, "\u6700\u7ec8": 104, "\u6700\u7ec8\u5bfc\u81f4": 106, "\u6709\u4e00\u79cd\u7f16\u7801\u65b9\u5f0f\u80fd\u5927\u5927\u51cf\u5c0ftoken": 104, "\u6709\u4ec0\u4e48\u7528": 20, "\u6709\u5f88\u591a\u9ad8\u9891\u7ef4\u5ea6\u8f6c\u4e86\u5f88\u591a\u5708": 106, "\u672a\u63d0\u53ca\u7684\u4f4d\u4f7f\u7528\u5bf9\u5e94\u7684unicode\u8865\u5145": 114, "\u6765\u505a\u4e00\u4e2a\u5c0f\u5b9e\u9a8c\u5e76\u4e14\u9a8c\u8bc1\u4e0b": 114, "\u6765\u8bf4": 114, "\u67e5\u770b\u5176\u4ed6token": 104, "\u6807\u8bb0\u4ee5\u6807\u8bc6\u5355\u8bcd\u8fb9\u754c\u80fd\u591f\u8ba9\u7b97\u6cd5\u77e5\u9053\u6bcf\u4e2a\u5355\u8bcd\u7684\u7ed3\u675f\u4f4d\u7f6e": 104, "\u6807\u8bb0\u7684\u96c6\u5408": 104, "\u6a21\u4eff\u663e\u8457\u6027": 50, "\u6b21": 104, "\u6b27\u6d32\u90e8\u5206\u8bed\u8a00\u5b57\u6bcd\u7684\u5b57\u7b26\u96c6": 114, "\u6b64\u65f6\u53e5\u5b50": 113, "\u6bd4\u5982utf": 114, "\u6bd4\u5982\u4e2d\u56fd1980\u5e74\u53d1\u884c\u4e86gb2312\u4ee5\u53ca\u540e\u9762\u51fa\u73b0\u5b83\u7684\u6269\u5c55\u7248\u672cgbk": 114, "\u6bd4\u5982\u5728ascii\u4e2d": 114, "\u6bd4\u5982\u5927\u5199\u5b57\u6bcda": 114, "\u6bd4\u5982\u6c49\u5b57": 114, "\u6bd4\u5982\u6c49\u5b57\u4e00\u5728unicode\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662f4e00": 114, "\u6bd4\u5982\u82f1\u6587\u5b57\u6bcda\u5bf9\u5e94\u7684unicode\u662fu": 114, "\u6bd4\u5982\u8bf4\u4e2d\u6587": 114, "\u6c49\u5b57": 114, "\u6c49\u5b57\u7684\u5b57\u7b26\u96c6": 114, "\u6ca1\u6709": 74, "\u6d4f\u89c8\u5668\u6253\u5f00\u540e\u663e\u793a\u6b63\u5e38": 114, "\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7": 104, "\u7136\u540e\u6211\u4eec\u4f7f\u7528chrome\u7684charset\u63d2\u4ef6\u6765\u4fee\u6539\u5f53\u524d\u9875\u9762\u89e3\u7801\u7684\u5b57\u7b26\u96c6": 114, "\u7136\u800c": 104, "\u73b0\u5728\u6211\u4eec\u53d1\u73b0": 104, "\u73b0\u5728\u6211\u4eec\u5c06\u6700\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u5408\u5e76\u6210\u4e00\u4e2atoken": 104, "\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u89e3\u7801\u6211\u4eec\u7684\u793a\u4f8b": 104, "\u751f\u6210\u5f85\u8bc4\u4f30\u7684\u6587\u4ef6": 23, "\u7528\u6700\u5c11\u7684token\u6765\u8868\u793a\u8bed\u6599\u5e93": 104, "\u7528\u6765\u8868\u793a\u7535\u8111\u548c\u5176\u4ed6\u7535\u4fe1\u8bbe\u5907\u7684\u6587\u672c": 114, "\u7531": 113, "\u7531m\u4e2a\u5b50\u8bcd\u7ec4\u6210": 113, "\u7531\u4e8eascii\u8868\u793a\u7684\u8303\u56f4\u6709\u9650": 114, "\u7531\u4e8e\u6211\u4eec\u603b\u5171\u6709": 104, "\u7684": [20, 104], "\u7684\u4f18\u52bf": 74, "\u7684\u5b57\u7b26\u91cf\u5df2\u7ecf\u8db3\u4ee5\u7528\u4e8e\u5168\u7403\u4e3b\u8981\u8bed\u8a00\u7684\u5927\u591a\u6570\u5b57\u7b26": 114, "\u7684\u5b57\u8282\u5bf9\u662f": 104, "\u7684\u60c5\u51b5": 74, "\u7684\u6548\u679c": 74, "\u7684\u6570\u636e": 104, "\u7684\u65b0token": 104, "\u7684\u6838\u5fc3\u673a\u5236": 20, "\u7684\u7b2c\u4e00\u5b57\u8282\u5168\u662f0": 114, "\u7684\u8bed\u8a00\u6a21\u578b\u4f3c\u7136\u503c\u7b49\u4ef7\u4e8e\u6240\u6709\u5b50\u8bcd\u6982\u7387\u7684\u4e58\u79ef": 113, "\u7684\u9891\u7387\u4e3a": 104, "\u7684\u9891\u7387\u51cf\u5c11": 104, "\u76ee\u5f55\u4e0b": 23, "\u76f4\u5230\u8fbe\u5230\u6211\u4eec\u9884\u5148\u8bbe\u7f6e\u7684token\u6570\u9650\u5236\u6216\u8fed\u4ee3\u9650\u5236": 104, "\u76f8\u6bd4": 74, "\u76f8\u90bb\u5b57\u8282\u5bf9": 104, "\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u5728bpe\u4e2d\u770b\u4f5c\u76f8\u90bb\u5b57\u8282\u5bf9": 104, "\u7701\u8d44\u6e90": 74, "\u770b\u5230\u8fd9\u91cc": 113, "\u770b\u5b8c\u4e0b\u9762\u5b8c\u6574\u7684\u8fed\u4ee3\u8fc7\u7a0b": 104, "\u770b\u770b\u6211\u4eec\u6700\u7ec8\u7684token\u5217\u8868": 104, "\u771f\u5b9e\u7684": 76, "\u77e5\u9053\u4e86\u7f16\u7801\u7684\u539f\u7406\u540e\u81ea\u7136\u80fd\u60f3\u5230\u7684\u5c31\u662f\u6587\u672c\u7f16\u7801\u548c\u89e3\u7801\u6240\u4f7f\u7528\u7684\u5b57\u7b26\u96c6\u4e0d\u540c": 114, "\u786e\u4fdd\u6700\u5e38\u89c1\u7684\u8bcd\u5728token\u5217\u8868\u4e2d\u8868\u793a\u4e3a\u5355\u4e2atoken": 104, "\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230": 104, "\u7a76\u7adf\u8c03\u7528\u7684\u662f\u4ec0\u4e48\u51fd\u6570": 20, "\u7a7a\u95f4\u6781\u5927\u6d6a\u8d39": 114, "\u7b2cn": 114, "\u7b2c\u4e00\u4e2a\u5b57\u8282": 114, "\u7b2c\u4e00\u4e2a\u5b57\u8282\u7684\u7b2c\u4e8c\u4e2a0": 114, "\u7b2c\u4e8c\u9ad8\u9891\u7387\u6807\u8bb0\u662f": 104, "\u7b49\u8bcd\u4e4b\u95f4\u7684\u533a\u522b": 104, "\u7b97\u6cd5\u7684\u4e0b\u4e00\u6b65\u662f\u5bfb\u627e\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9": 104, "\u7b97\u6cd5\u7684\u4e3b\u8981\u76ee\u6807": 104, "\u7c7b\u4f3c\u5730": 20, "\u7f16\u7801\u4e3a": 104, "\u7f16\u7801\u672c\u8eab\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u8f83\u9ad8": 104, "\u7f16\u7801\u7c7b\u578b": 114, "\u8001\u89c4\u77e9": 104, "\u800cwordpiece\u9009\u62e9\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6700\u5927\u7684\u76f8\u90bb\u5b50\u8bcd\u52a0\u5165\u8bcd\u8868": 113, "\u800c\u4e0d\u662f": 104, "\u800c\u4e14\u8fc7\u5927\u7684token\u5217\u8868\u5341\u5206\u5f71\u54cd\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6": 104, "\u800c\u5728gb2312\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662fd2bb": 114, "\u800c\u662f\u5c06\u5b83\u4ee5utf": 114, "\u800c\u6c49\u5b57\u4e00\u4e8c\u4e09\u4e71\u7801\u4e86": 114, "\u800c\u7f55\u89c1\u7684\u8bcd\u88ab\u5206\u89e3\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2asubword": 104, "\u80fd\u591f\u6e05\u695a\u5730\u7406\u89e3wordpiece\u5728\u5408\u5e76\u8fd9\u4e00\u6b65\u662f\u5982\u4f55\u4f5c\u51fa\u9009\u62e9\u7684": 113, "\u80fd\u591f\u7cbe\u7ec6\u5730\u533a\u5206\u76f8\u90bb\u4f4d\u7f6e": 106, "\u82e5\u4f7f\u7528\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f": 104, "\u82f1\u6587\u5b57\u6bcd": 114, "\u83b7\u53d6\u6a21\u578b\u7684": 20, "\u8461\u8404\u7259\u8bed\u7b49\u65e0\u6cd5\u7528127\u4e2a\u5b57\u7b26\u8868\u793a\u5b8c\u5168": 114, "\u8868\u793a\u5b50\u8bcd": 113, "\u8981\u89e3\u7801": 104, "\u89c4\u52191": 114, "\u89c4\u52192": 114, "\u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570": 20, "\u8ba1\u7b97": 106, "\u8ba1\u7b97\u673a\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u662f\u6309\u7167\u4e00\u4e2a\u5b57\u8282\u7684\u5927\u5c0f\u6765\u8bfb\u53d6\u8bc6\u522b\u7684": 114, "\u8ba1\u7b97\u673a\u6309\u7167\u5b57\u8282\u6765\u8bfb\u53d6\u6570\u636e\u65f6": 114, "\u8ba1\u7b97\u673a\u662f\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u8868\u793a\u7684\u662f\u4ec0\u4e48\u610f\u601d\u5462": 114, "\u8ba9\u6211\u4eec\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0\u4e00\u4e2a\u7279\u6b8a\u7684\u7ed3\u675f\u6807\u8bb0": 104, "\u8ba9\u6211\u4eec\u73b0\u5728\u505c\u6b62\u8fed\u4ee3\u5e76": 104, "\u8ba9\u6211\u4eec\u73b0\u5728\u8003\u8651": 104, "\u8ba9\u6211\u4eec\u7528": 104, "\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\u6765\u4e86\u89e3\u4e00\u4e0b\u5b83\u7684nlp\u7248\u672c": 104, "\u8bcd": 104, "\u8bf4\u660e": 114, "\u8bf4\u660eunicode\u548cgbk\u90fd\u5411\u4e0b\u517c\u5bb9\u4e86ascii": 114, "\u8c03\u7528": 20, "\u8d8a\u8fd1": 106, "\u8d8a\u8fdc": 106, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f0100": 114, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f100": 114, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f19968": 114, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f65": 114, "\u8f93\u51fa\u6587\u4ef6": 20, "\u8fd8\u6709\u5176\u4ed6\u7f16\u7801\u65b9\u5f0f": 114, "\u8fd8\u6709\u7a7a\u683c32": 114, "\u8fd9\u4e00\u95ee\u9898": 114, "\u8fd9\u4e24\u4e2a\u8bcd\u90fd\u6709\u4e00\u4e2a\u5171\u540c\u7684": 104, "\u8fd9\u4e2a\u4e8c\u8fdb\u5236\u670915\u4f4d": 114, "\u8fd9\u4e2a\u8bcd\u7684token": 104, "\u8fd9\u4e5f\u662f": 104, "\u8fd9\u53ea\u662f\u82f1\u8bed\u7684\u7528\u6cd5": 104, "\u8fd9\u5b8c\u5168\u7b49\u540c\u4e8e127\u4f4d\u6700\u521d\u7684ascii\u7801": 114, "\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u9891\u7387\u8ba1\u6570\u5c06\u5728\u6bcf\u4e2a\u5408\u5e76\u6b65\u9aa4\u540e\u53d1\u751f\u53d8\u5316": 104, "\u8fd9\u662f\u66f4\u65b0\u540e\u7684\u8868\u683c": 104, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u67e5\u770b\u6bcf\u4e2a\u5b57\u7b26\u5e76\u627e\u5230\u9891\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u914d\u5bf9": 104, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u7406\u89e3": 104, "\u8fd9\u6837\u7684token\u5c06\u88ab\u4e0d\u540c\u5730\u5904\u7406": 104, "\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e4b\u4e3a": 106, "\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f\u5341\u5206\u7b26\u5408\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef": 104, "\u8fd9\u91cc": [20, 113], "\u8fd9\u91cc\u4fee\u6539\u4e3agbk": 114, "\u8fd9\u91cc\u7b80\u5355\u4ecb\u7ecd\u4e0b\u8fd9\u51e0\u79cd\u7f16\u7801\u65b9\u5f0f\u7684\u533a\u522b": 114, "\u8fdc\u7a0b\u8870\u51cf\u66f2\u7ebf\u5982\u4e0b": 106, "\u8fed\u4ee3": 104, "\u901a\u5e38\u6709\u51e0\u4e07\u5230\u51e0\u5341\u4e07\u91cf\u7ea7\u7684\u5355\u8bcd\u6570": 104, "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5": 113, "\u90a3\u4e48\u4eba\u4eec\u80fd\u8bc6\u522b\u7684\u6587\u5b57\u548c\u8ba1\u7b97\u673a\u4e2d\u7684\u4e8c\u8fdb\u5236\u5fc5\u7136\u5b58\u5728\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 114, "\u90a3\u4e48\u9762\u5bf9\u5168\u4e16\u754c\u8fd9\u4e48\u591a\u8bed\u8a00": 114, "\u90a3\u5982\u4f55\u628a\u538b\u7f29\u7684\u7f16\u7801\u590d\u539f\u5462": 104, "\u90a3\u5c31\u662f\u672c\u6587\u5373\u5c06\u4ecb\u7ecd\u7684byte": 104, "\u90a3\u6837\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u6050\u6016\u7684": 104, "\u90a3\u82f1\u6587\u5b57\u7b26": 114, "\u90e8\u5206\u9891\u7387\u4f4e": 106, "\u90e8\u5206\u9891\u7387\u9ad8": 106, "\u90fd\u4e00\u6837": 114, "\u91cc\u548c\u653e\u5728": 74, "\u91cc\u7684\u533a\u522b": 74, "\u95f4\u76f8\u4e92\u9694\u5f00": 74, "\u963f\u62c9\u4f2f\u6570\u5b570\u5bf9\u5e94\u7684ascii\u7801\u662f48": 114, "\u963f\u62c9\u4f2f\u6570\u5b57\u548c\u82f1\u6587\u5b57\u6bcd": 114, "\u968f\u673a\u6027\u5f88\u5927": 106, "\u968f\u7740\u8ba1\u7b97\u673a\u5728\u5168\u7403\u7684\u53d1\u5c55\u548c\u666e\u53ca": 114, "\u9700": 20, "\u9700\u52a0\u4e0a": 20, "\u9700\u8981\u4ece": 23, "\u9700\u8981\u81f3\u5c112\u4e2a\u5b57\u8282\u8868\u793a": 114, "\u975e\u5e38\u91cd\u8981": 104, "\u9996\u5148\u6765\u660e\u786e\u4e00\u4e0b\u57fa\u7840\u6982\u5ff5": 104, "\u9996\u5148\u770b\u4e0bwiki\u5bf9\u5b83\u7684\u5b9a\u4e49": 114, "\u9ad8\u4f4d\u4ee5": 114, "\u9ad8\u4f4d\u524dn\u4f4d\u4e3a": 114, "\u9ad8\u7684": 74, "\u9ad8\u7ef4": 106, "\u9ad8\u9891\u4fe1\u606f\u7684\u635f\u5931": 106, "\u9ad8\u9891\u7ef4\u5ea6\u5c11\u4f4e\u9891\u7ef4\u5ea6\u591a": 106, "\ud835\udc41": 73}, "titles": ["Agent", "AGENTLESS", "API-Bank", "CodeAct", "REACT", "Reflexion", "Search-R1", "SWE-agent", "Base", "Attention Is All You Need", "GPT", "GPT2", "GPT3", "InstructGPT", "Benchmarks", "Aider Polyglot", "Alignment Benchmarks", "BigCodeBench", "Code Alpaca", "CRUXEval", "EvalPlus", "General Benchmarks", "HumanEval", "LiveCodeBench", "Magicoder", "Math &amp; Science Benchmarks", "MBPP", "RewardBench", "SELF-INSTRUCT", "SWE-bench", "TACO", "WizardCoder", "Contents", "Contents", "Data", "AlphaCode", "APPS", "Code Alpaca", "Magicoder", "OpenCoder", "SELF-INSTRUCT", "TACO", "UNICODER", "WizardCoder", "Introduction", "Markdown Files", "Notebooks with MyST Markdown", "GOLD", "Evaluation of LLMs Should Not Ignore Non-Determinism", "Scaling Laws for Neural Language Models", "Weak to Strong Generalization", "Models", "AlphaCode", "AlphaCode 2", "AlphaCodium", "Code Llama", "DeepSeek-Coder-V2", "DeepSeek-V2", "DeepSeek V3", "Llama", "Llama 2", "Llama 3", "Llama3", "Llama 3 Source Code", "Qwen 2.5", "Qwen2.5-Coder", "Qwen3", "Preference Optimization", "ArmoRM-MoE", "DAPO", "DeepSeek-GRM", "DPO", "DPOP", "Efficient Exploration for LLMs", "Group Relative Policy Optimization", "Instruct GPT", "Aligning Language Models with Judgments", "OpenRLHF", "PPO", "REINFORCE++", "Constitutional AI: Harmlessness from AI Feedback", "RLAIF vs. RLHF", "RLCD", "RS-DPO", "RSO", "Secrets of RLHF in Large Language Models: Reward Modeling", "Self-Rewarding Language Models", "Self-Taught Evaluators", "West-of-N", "Reasoning", "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "DeepCoder", "DeepSeek-R1", "Logic-RL", "s1: Simple test-time scaling", "Training Language Models to Self-Correct via Reinforcement Learning", "Let\u2019s Verify Step by Step", "References", "SFT", "LIMA: Less Is More for Alignment", "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED", "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold", "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "Techniques", "Byte Pair Encoding (BPE)", "DeepSeekMoE", "Extending context window of LLMs", "Extending context window of large language models via position interpolation", "Multi-Head Latent Attention", "Normalization", "RoPE", "Rotary Positional Embeddings (RoPE)", "SwiGLU", "WordPiece, ULM and SentencePiece", "ASCII,UNICODE,UTF8", "Llama Factory", "LORA", "OpenRLHF"], "titleterms": {"": 96, "1": 68, "16": 114, "2": [53, 55, 60, 64, 68], "2d": [110, 111], "3": [61, 63], "32\u7b49": 114, "5": [64, 65], "500": 25, "8": 114, "A": 65, "AT": 100, "Not": 48, "The": [7, 47, 54, 68, 79, 102], "abil": [86, 102], "ablat": [99, 108], "absolut": 111, "accuraci": 102, "aci": 7, "activ": [62, 63, 73, 96], "adapt": 85, "add": 46, "addit": 54, "advantag": 79, "agent": [0, 3, 7], "agentless": 1, "aggreg": 68, "aha": 92, "ai": [80, 81], "aider": 15, "algorithm": [47, 73, 79, 84, 86, 92], "align": [16, 48, 56, 57, 76, 86, 99], "all": [9, 92, 100], "almost": 100, "alpaca": [18, 37], "alphacod": [35, 52, 53], "alphacodium": 54, "an": [7, 46, 73], "analyz": 85, "annot": 87, "api": 2, "app": 36, "appendix": 71, "approach": [1, 11, 12, 29, 52, 59, 70, 84, 111], "architectur": [9, 12, 57, 58, 59, 64, 73], "arena": 16, "armorm": 68, "ascii": 114, "assess": 73, "attent": [9, 62, 63, 108], "augment": 102, "automat": 17, "averag": 61, "awar": 106, "background": [79, 106, 107, 111], "balanc": 105, "bank": 2, "base": [8, 29, 64, 65, 69, 70, 92, 96], "basic": [49, 58], "batch": [79, 109], "batchnorm": 62, "bench": 29, "benchmark": [14, 16, 17, 21, 25, 29, 70], "benefit": 3, "better": [3, 85], "between": 108, "bigcodebench": 17, "boost": 70, "bpe": 104, "byte": 104, "cach": 108, "capabl": 61, "case": [17, 110, 111], "cell": 46, "chain": 90, "chart": 49, "chat": 61, "chatformat": 62, "citat": 45, "classif": [28, 40], "clip": [69, 79], "cluster": [52, 53], "code": [17, 18, 20, 31, 37, 43, 54, 55, 61, 63], "codeact": 3, "codecontest": 35, "codellama": 29, "coder": [56, 65], "cold": [70, 92], "collaps": 95, "collect": [56, 60, 96], "commun": 105, "comparison": [70, 108], "composit": [39, 65], "compress": 108, "comput": [7, 49], "concept": 54, "consider": 105, "constitut": 80, "construct": [17, 29, 57, 58, 87], "content": [32, 33], "context": [55, 58, 106, 107], "contextwindow": 106, "contrast": 76, "control": 61, "correct": [20, 22, 95], "count": [49, 102], "creat": [46, 94], "creation": 86, "critiqu": [70, 80], "cruxev": 19, "curat": [17, 94], "dapo": 69, "data": [17, 18, 28, 34, 37, 39, 40, 49, 56, 57, 58, 59, 60, 61, 65, 85, 94, 96, 99, 100, 101, 102], "dataset": [11, 12, 13, 35, 49, 52, 55, 69, 75], "decod": [9, 10], "decontamin": [39, 65], "decoupl": 108, "deepcod": 91, "deepseek": [56, 57, 58, 70, 92], "deepseekmo": 105, "deriv": 71, "design": [2, 7, 54], "detail": [13, 24, 38, 39, 69, 77], "determin": 48, "devic": 105, "dialog": 61, "differ": [70, 85], "direct": [45, 61, 71, 107], "discuss": 57, "distanc": 106, "diverg": 69, "divers": [85, 99], "done": 3, "dot": 9, "dpo": [71, 72, 83], "dpop": 72, "drop": 105, "dynam": [69, 106], "effect": 48, "effici": [73, 101, 106], "eight": 101, "elicit": 90, "embed": [9, 49, 106, 107, 108, 111], "empir": [49, 73], "encod": [9, 104], "engin": 7, "enhanc": 79, "enn": 73, "epistem": 73, "estim": 73, "evalplu": 20, "evalu": [2, 12, 17, 20, 23, 24, 31, 38, 43, 48, 52, 53, 57, 58, 64, 65, 81, 87, 99], "evol": [31, 43], "evolut": 92, "exampl": 46, "exist": 3, "experi": [11, 69, 86, 107], "experiment": [13, 29, 48, 56, 73, 79, 86], "expert": [68, 105], "explor": 73, "extend": [106, 107], "extens": [58, 106], "extrapol": 107, "factor": [48, 102], "factori": 115, "failur": 72, "featur": 29, "feed": 9, "feedback": [80, 81], "feedforward": [62, 63], "fewer": 3, "ffn": 112, "file": 45, "filter": [28, 40, 52, 53], "fine": [10, 29, 35, 52, 53, 55, 56, 57, 58, 60, 64, 70, 75, 87, 92, 105], "finetun": [28, 40, 61], "flip": 85, "flow": 54, "fold": 101, "follow": [28, 40, 86], "form": [110, 111], "format": [29, 61], "formul": [110, 111], "forward": 9, "framework": [3, 10, 47], "frequenc": 106, "from": [3, 24, 38, 47, 70, 76, 80, 81], "full": 48, "fullest": 85, "function": [22, 62, 63], "gate": 112, "gb2312": 114, "gbk\u7b49\u5176\u4ed6\u7f16\u7801": 114, "gener": [17, 21, 28, 40, 48, 50, 62, 70, 96, 110, 111], "get": 3, "glu": 112, "gold": 47, "gpqa": 25, "gpt": [10, 75], "gpt2": 11, "gpt3": 12, "gqa": 108, "gradient": [47, 69, 71], "grain": 105, "grm": 70, "group": 74, "grpo": 74, "gsm8k": 25, "hard": 16, "harmless": 80, "head": [9, 108], "high": [13, 106], "higher": 69, "how": [48, 85], "human": [17, 60, 85, 99], "humanev": [20, 22], "hyper": 57, "i": [3, 9, 45, 48, 95, 99, 100], "identif": [28, 40], "ifev": 16, "ignor": 48, "ii": 95, "impact": 85, "implement": [24, 38, 77, 107], "incorpor": 76, "incorrect": 101, "infer": 70, "infil": 55, "infinit": 49, "influenc": 48, "inform": 106, "initi": [86, 87, 95], "input": [10, 11, 29], "insight": 54, "instal": 23, "instanc": [28, 40], "instruct": [17, 24, 28, 31, 38, 39, 40, 42, 43, 55, 64, 65, 75, 86, 87], "instructgpt": 13, "integr": 79, "interact": 3, "interfac": 7, "interpol": [106, 107], "interpret": 68, "introduct": [24, 38, 44, 50, 55, 59, 76, 82, 107], "isol": 105, "iter": [60, 61, 74, 87], "its": 85, "joint": 108, "judgment": [76, 87], "kei": 108, "kl": [69, 79], "kv": 108, "label": [81, 85], "languag": [49, 61, 76, 85, 86, 90, 95, 102, 106, 107, 113], "larg": [52, 85, 90, 96, 102, 106, 107], "latent": 108, "law": 49, "layer": 109, "layernorm": 62, "learn": [45, 56, 57, 58, 64, 73, 75, 76, 80, 81, 92, 95, 96, 102], "less": 99, "let": 96, "level": [13, 69, 79, 105], "leverag": 85, "lima": 99, "limit": 49, "linear": 112, "lite": 29, "livecodebench": 23, "llama": [29, 55, 59, 60, 61, 63, 107, 115], "llama3": 62, "llm": [3, 48, 73, 81, 101, 102, 106], "lm": [28, 40], "load": 105, "local": 106, "logic": 93, "long": [55, 58], "lora": 116, "loss": [69, 71, 102, 105, 106], "low": 108, "magicod": [24, 38], "main": [69, 80], "make": 3, "margin": 85, "markdown": [45, 46], "math": [25, 101, 102], "mathemat": 102, "mbpp": [20, 26], "measur": 85, "mechan": 108, "metadata": 46, "method": [13, 80, 87, 96], "methodologi": [13, 50, 75, 81], "mha": 108, "mini": 79, "mixtur": [65, 68, 105], "mla": 108, "mle": 47, "mmlu": 21, "mode": 72, "model": [9, 11, 12, 13, 49, 51, 53, 60, 61, 62, 63, 64, 65, 68, 69, 70, 73, 75, 76, 85, 86, 87, 88, 90, 92, 95, 96, 102, 106, 107, 113], "moe": 68, "moment": 92, "more": [3, 45, 99], "mqa": 108, "multi": [3, 9, 58, 68, 95, 108], "myst": [45, 46], "n": [49, 88], "need": [9, 68, 100], "network": [9, 73], "neural": [49, 73], "nl": 17, "nlp\u5b9e\u4f8b": 104, "non": [48, 49], "normal": [62, 79, 109], "notebook": 46, "ntk": 106, "object": 68, "off": 47, "offlin": 64, "onli": 10, "onlin": 64, "ood": 96, "open": [24, 38], "opencod": 39, "openrlhf": [77, 117], "optim": [59, 61, 67, 71, 74], "orient": [17, 54, 92], "orm": 96, "oss": [24, 38], "outcom": [74, 96], "overal": [53, 86], "overfit": 49, "overlong": 69, "overview": 54, "packag": 3, "pair": [87, 104], "paramet": [49, 57], "part": 106, "passiv": 73, "pattern": 48, "penalti": 79, "perform": [49, 85, 92], "pi_": 71, "pipelin": 73, "point": 73, "polici": [47, 53, 65, 69, 74], "polyglot": 15, "posit": [9, 106, 107, 108, 111], "post": [39, 58, 61, 64, 65], "postprocess": [28, 40], "potenti": [48, 85], "power": 49, "ppo": [74, 77, 78, 79], "pre": [10, 57, 58, 59, 61, 64, 65, 102], "predict": 58, "prefer": [60, 61, 67, 71, 81, 85, 88], "preliminari": [69, 71, 84, 85, 95, 105, 108, 111], "pretrain": [39, 60], "prevent": 95, "principl": [2, 70], "prm": 96, "pro": 21, "problem": [76, 95], "process": [61, 74, 92, 96], "product": 9, "program": 17, "promis": 3, "prompt": [31, 43, 81, 90], "properti": 111, "propos": [54, 111], "qualiti": [61, 70, 99], "quantiti": 99, "queri": 108, "quick": 20, "quickli": 46, "qwen": 64, "qwen2": 65, "qwen3": 66, "r": [71, 83], "r1": [6, 92], "random": 100, "rank": 108, "react": 4, "reason": [89, 90, 92, 94, 101, 102], "recip": 65, "redux": 21, "refactor": 17, "refer": 97, "reflexion": 5, "reinforc": [56, 57, 58, 64, 75, 79, 80, 81, 92, 95], "reject": [70, 84, 92], "rel": [74, 106], "relat": 88, "relationship": 102, "remov": 69, "represent": 11, "respons": 87, "result": [7, 13, 29, 48, 49, 56, 57, 58, 61, 69, 70, 73, 80, 81, 86, 94], "rethink": 100, "retriev": 29, "review": 74, "revis": 80, "reward": [47, 60, 61, 68, 69, 70, 73, 75, 79, 85, 86, 92, 95, 96], "rewardbench": 27, "rl": [47, 70, 74, 75, 93, 95, 101], "rlaif": 81, "rlcd": 82, "rlhf": [60, 81, 85], "rm": [70, 75, 85], "rmsnorm": [62, 63, 109], "role": 45, "rope": [62, 63, 106, 107, 110, 111], "rotari": [106, 107, 108, 111], "round": 61, "rso": 84, "rule": [69, 70], "s1": 94, "s1k": 94, "sampl": [45, 52, 53, 69, 84, 92], "scale": [9, 48, 49, 52, 70, 94, 96, 100, 101, 102, 106], "scenario": 92, "scienc": 25, "score": [53, 95], "search": 6, "secret": 85, "segment": 105, "select": [87, 100], "self": [28, 40, 70, 86, 87, 88, 92, 95], "semi": 17, "sentencepiec": 113, "set": 76, "setup": [29, 79, 86, 95], "sft": [60, 61, 75, 98, 115, 117], "shape": [69, 95], "share": 105, "should": 48, "show": 3, "simpl": 94, "size": 49, "small": 96, "smooth": 85, "softmax": 9, "softwar": [3, 7], "sourc": [24, 38, 63], "spct": 70, "special": 55, "specif": 10, "stack": 9, "stage": [39, 54, 68, 95], "standard": 108, "stanford": [18, 37], "start": [20, 70, 92], "statist": [17, 84], "step": 96, "strategi": 105, "strength": 85, "strong": [3, 50], "summar": 11, "supervis": [10, 56, 57, 58, 61, 64, 74, 75, 80, 92, 96, 102], "surfac": 48, "swe": [7, 29], "swiglu": [62, 63, 112], "swish": 112, "synthesi": 17, "synthet": [96, 101], "system": [2, 53], "taco": [30, 41], "takeawai": [56, 57, 58, 61, 64, 65, 85, 96, 110], "task": [10, 28, 40], "taught": 87, "techniqu": [81, 103], "temperatur": 48, "templat": 92, "test": [17, 94], "thought": 90, "tiktoken": 62, "time": [49, 70, 94], "token": [58, 62, 64, 69, 79, 105], "tool": 3, "train": [10, 11, 12, 31, 39, 43, 49, 57, 58, 59, 61, 64, 65, 69, 73, 86, 87, 88, 92, 95, 99, 102], "transform": [10, 49, 62, 63, 105], "tune": [10, 24, 29, 35, 38, 39, 52, 53, 55, 56, 57, 58, 60, 64, 70, 75, 87, 92], "turn": [3, 95], "two": 39, "ulm": 113, "understand": 70, "unicod": [42, 114], "unigram": 113, "unit": 112, "unpin": 70, "unsupervis": 10, "updat": 79, "us": 3, "utf": 114, "utf8": 114, "v": [81, 96, 102], "v2": [56, 57], "v3": 58, "valu": 108, "variant": 112, "variou": 48, "verifi": 96, "via": [95, 107], "weak": 50, "west": 88, "what": [3, 45, 48], "why": [10, 108, 109], "window": [106, 107], "wise": 9, "wizardcod": [31, 43], "wizardlm": [31, 43], "wordpiec": 113, "work": 88, "yaml": 46, "yarn": 106, "you": [9, 100], "zero": 92, "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": 114, "\u521d\u8bc6bpe": 104, "\u603b\u7ed3": 114, "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5": 104, "\u672c\u5730": [20, 23], "\u7684\u8fdc\u7a0b\u8870\u51cf": 106, "\u7f16\u7801\u548c\u89e3\u7801": 104, "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": 106}})