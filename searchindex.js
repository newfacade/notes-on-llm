Search.setIndex({"alltitles": {"2D case": [[114, "d-case"], [115, "d-case"]], "A Recipe for Instruction Data": [[67, "a-recipe-for-instruction-data"]], "AGENTLESS": [[1, "agentless"]], "AGENTLESS Approach": [[1, "agentless-approach"]], "API-Bank": [[2, "api-bank"]], "APPS": [[38, "apps"]], "ASCII": [[118, "ascii"]], "ASCII,UNICODE,UTF8": [[118, "ascii-unicode-utf8"]], "Ablation of Attention Mechanisms": [[112, "ablation-of-attention-mechanisms"]], "Ablation of MHA, GQA, and MQA": [[112, "ablation-of-mha-gqa-and-mqa"]], "Ablations on Data Diversity, Quality, and Quantity": [[103, "ablations-on-data-diversity-quality-and-quantity"]], "Absolute position embedding": [[115, "absolute-position-embedding"]], "Action": [[7, "action"]], "Active Exploration with a Point Estimate": [[76, "active-exploration-with-a-point-estimate"]], "Active Exploration with an ENN": [[76, "active-exploration-with-an-enn"]], "Active Learning": [[100, "active-learning"]], "Adaptive Margin": [[88, "adaptive-margin"]], "Additional insights": [[56, "additional-insights"]], "Advantage Normalization": [[82, "advantage-normalization"]], "Agent": [[0, "agent"]], "Agents in Software Engineering": [[7, "agents-in-software-engineering"]], "Aider Polyglot": [[17, "aider-polyglot"]], "Aligning Language Models with Judgments": [[79, "aligning-language-models-with-judgments"]], "Alignment": [[58, "alignment"], [59, "alignment"]], "Alignment Benchmarks": [[18, "alignment-benchmarks"]], "Alignment Data": [[103, "alignment-data"]], "Alignment Effect on Non-Determinism": [[50, "alignment-effect-on-non-determinism"]], "AlphaCode": [[37, "alphacode"], [54, "alphacode"]], "AlphaCode 2": [[55, "alphacode-2"]], "AlphaCodium": [[56, "alphacodium"]], "An example cell": [[48, "an-example-cell"]], "Analyze and Leverage Diverse Data to its Fullest Potential": [[88, "analyze-and-leverage-diverse-data-to-its-fullest-potential"]], "Appendix": [[74, "appendix"]], "Approach": [[13, "approach"], [14, "approach"], [54, "approach"], [61, "approach"]], "Architecture": [[59, "architecture"], [60, "architecture"], [61, "architecture"], [68, "architecture"]], "Architecture & Tokenizer": [[66, "architecture-tokenizer"]], "Arena-Hard": [[18, "arena-hard"]], "ArmoRM-MoE": [[71, "armorm-moe"]], "Assessment Pipeline": [[76, "assessment-pipeline"]], "Attention": [[11, "attention"], [64, "attention"], [64, "id1"], [65, "attention"], [65, "id1"]], "Attention Is All You Need": [[11, "attention-is-all-you-need"]], "Auditory Input": [[7, "auditory-input"]], "Background": [[115, "background"]], "Background: Rotary Position Embedding (RoPE)": [[110, "background-rotary-position-embedding-rope"], [111, "background-rotary-position-embedding-rope"]], "Background: The REINFORCE Algorithm": [[82, "background-the-reinforce-algorithm"]], "Base": [[10, "base"]], "Base Models": [[66, "base-models"], [67, "base-models"], [100, "base-models"]], "Basic Architecture": [[60, "basic-architecture"]], "Batch Normalization": [[113, "batch-normalization"]], "BatchNorm": [[64, "batchnorm"]], "Benchmark Construction": [[19, "benchmark-construction"], [31, "benchmark-construction"]], "Benchmark Statistics": [[19, "benchmark-statistics"]], "Benchmarking NL-Oriented Instructions to Code Generation": [[19, "benchmarking-nl-oriented-instructions-to-code-generation"]], "Benchmarks": [[16, "benchmarks"]], "BigCodeBench": [[19, "bigcodebench"]], "Boosting Reward Quality with Principles": [[73, "boosting-reward-quality-with-principles"]], "Byte Pair Encoding (BPE)": [[108, "byte-pair-encoding-bpe"]], "CRUXEval": [[21, "cruxeval"]], "Capabilities": [[63, "capabilities"]], "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [[93, "chain-of-thought-prompting-elicits-reasoning-in-large-language-models"]], "Charting the Infinite Data Limit and Overfitting": [[51, "charting-the-infinite-data-limit-and-overfitting"]], "Chat Dialog Format": [[63, "chat-dialog-format"]], "ChatFormat": [[64, "chatformat"]], "Citations": [[47, "citations"]], "Classification Task Identification": [[30, "classification-task-identification"], [42, "classification-task-identification"]], "Clip-Higher": [[72, "clip-higher"]], "Clustering": [[54, "clustering"], [55, "clustering"]], "Code": [[63, "code"]], "Code Alpaca": [[20, "code-alpaca"], [20, "id1"], [39, "code-alpaca"], [39, "id1"]], "Code Correctness Evaluation: HumanEval(+) or MBPP(+)": [[22, "code-correctness-evaluation-humaneval-or-mbpp"]], "Code Llama": [[57, "code-llama"]], "Code Llama: Specializing Llama 2 for code": [[57, "code-llama-specializing-llama-2-for-code"]], "Code-Oriented Design Concepts": [[56, "code-oriented-design-concepts"]], "CodeAct": [[3, "codeact"]], "CodeAct Benefits from Multi-turn Interactions and Existing Software Packages": [[3, "codeact-benefits-from-multi-turn-interactions-and-existing-software-packages"]], "CodeAct Gets More Done with Fewer Interactions": [[3, "codeact-gets-more-done-with-fewer-interactions"]], "CodeAct Makes LLMs Better Agents": [[3, "codeact-makes-llms-better-agents"]], "CodeAct Shows the Promise as a Strong Tool Use Framework": [[3, "codeact-shows-the-promise-as-a-strong-tool-use-framework"]], "CodeContests fine-tuning dataset": [[37, "codecontests-fine-tuning-dataset"]], "Cold Start": [[95, "cold-start"]], "Collection": [[9, "collection"]], "Communication Balance Loss": [[109, "communication-balance-loss"]], "Comparison Between MLA and MHA": [[112, "comparison-between-mla-and-mha"]], "Comparison of Key-Value Cache": [[112, "comparison-of-key-value-cache"]], "Comparisons of Different RM approaches": [[73, "comparisons-of-different-rm-approaches"]], "Constitutional AI: Harmlessness from AI Feedback": [[83, "constitutional-ai-harmlessness-from-ai-feedback"]], "Contents": [[34, "contents"], [35, "contents"]], "Create a notebook with MyST Markdown": [[48, "create-a-notebook-with-myst-markdown"]], "Critiques, Revisions, and Supervised Learning": [[83, "critiques-revisions-and-supervised-learning"]], "DAPO": [[72, "dapo"], [72, "id1"]], "DPO": [[74, "dpo"]], "DPOP": [[75, "dpop"], [75, "id1"]], "Data": [[20, "data"], [36, "data"], [39, "data"]], "Data Collection": [[58, "data-collection"], [100, "data-collection"]], "Data Composition": [[41, "data-composition"], [67, "data-composition"]], "Data Construction": [[59, "data-construction"], [60, "data-construction"]], "Data Generation": [[30, "data-generation"], [42, "data-generation"]], "Data Mixture": [[67, "data-mixture"]], "Data Processing and Quality Control": [[63, "data-processing-and-quality-control"]], "Data Synthesis": [[19, "data-synthesis"]], "Dataset": [[15, "dataset"], [57, "dataset"], [72, "dataset"], [78, "dataset"]], "Datasets": [[54, "datasets"]], "Decontamination": [[41, "decontamination"], [67, "decontamination"]], "Decoupled Rotary Position Embedding": [[112, "decoupled-rotary-position-embedding"]], "DeepCoder": [[94, "deepcoder"]], "DeepSeek V3": [[60, "deepseek-v3"]], "DeepSeek-Coder-V2": [[58, "deepseek-coder-v2"]], "DeepSeek-GRM": [[73, "deepseek-grm"]], "DeepSeek-R1": [[95, "deepseek-r1"]], "DeepSeek-R1-Zero: Reinforcement Learning on the Base Model": [[95, "deepseek-r1-zero-reinforcement-learning-on-the-base-model"]], "DeepSeek-R1: Reinforcement Learning with Cold Start": [[95, "deepseek-r1-reinforcement-learning-with-cold-start"]], "DeepSeek-V2": [[59, "deepseek-v2"]], "DeepSeekMoE": [[109, "deepseekmoe"]], "Derivation of \\pi_{r}": [[74, "derivation-of-pi-r"]], "Design Principles of API-Bank": [[2, "design-principles-of-api-bank"]], "Device-Level Balance Loss": [[109, "device-level-balance-loss"]], "Direct Preference Optimization": [[63, "direct-preference-optimization"], [74, "direct-preference-optimization"]], "Direct extrapolation": [[111, "direct-extrapolation"]], "Discussion": [[59, "discussion"]], "Dynamic Sampling": [[72, "dynamic-sampling"]], "Dynamic Scaling - \u201cDynamic NTK\u201d interpolation": [[110, "dynamic-scaling-dynamic-ntk-interpolation"]], "Efficient Exploration for LLMs": [[76, "efficient-exploration-for-llms"]], "Embeddings and Softmax": [[11, "embeddings-and-softmax"]], "Empirical Results": [[76, "empirical-results"]], "Empirical Results and Basic Power Laws": [[51, "empirical-results-and-basic-power-laws"]], "Encoder and Decoder Stacks": [[11, "encoder-and-decoder-stacks"]], "Episodic Memory": [[7, "episodic-memory"]], "Epistemic Neural Network": [[76, "epistemic-neural-network"]], "EvalPlus": [[22, "evalplus"]], "Evaluation": [[14, "evaluation"], [19, "evaluation"], [26, "evaluation"], [33, "evaluation"], [40, "evaluation"], [45, "evaluation"], [54, "evaluation"], [55, "evaluation"], [66, "evaluation"], [67, "evaluation"], [84, "evaluation"]], "Evaluation Results": [[59, "evaluation-results"], [59, "id3"], [60, "evaluation-results"], [60, "id4"]], "Evaluation System of API-Bank": [[2, "evaluation-system-of-api-bank"]], "Evaluation of LLMs Should Not Ignore Non-Determinism": [[50, "evaluation-of-llms-should-not-ignore-non-determinism"]], "Evol-Instruct": [[33, "evol-instruct"], [45, "evol-instruct"]], "Evol-Instruct Prompts for Code": [[33, "evol-instruct-prompts-for-code"], [45, "evol-instruct-prompts-for-code"]], "Experimental Results": [[50, "experimental-results"], [58, "experimental-results"]], "Experimental Setup": [[31, "experimental-setup"], [82, "experimental-setup"], [89, "experimental-setup"]], "Experimentation Pipeline": [[76, "experimentation-pipeline"]], "Experiments": [[13, "experiments"], [72, "experiments"], [89, "experiments"], [111, "experiments"]], "Expert-Level Balance Loss": [[109, "expert-level-balance-loss"]], "Exploration Algorithms": [[76, "exploration-algorithms"]], "Extending context window of LLMs": [[110, "extending-context-window-of-llms"]], "Extending context window of large language models via position interpolation": [[111, "extending-context-window-of-large-language-models-via-position-interpolation"]], "External Action": [[7, "external-action"]], "FFN": [[116, "ffn"]], "Failure Mode of DPO": [[75, "failure-mode-of-dpo"]], "Features of Swe-Bench": [[31, "features-of-swe-bench"]], "FeedForward": [[64, "feedforward"], [65, "feedforward"]], "Filtering": [[54, "filtering"], [55, "filtering"]], "Filtering and Postprocessing": [[30, "filtering-and-postprocessing"], [42, "filtering-and-postprocessing"]], "Fine-Grained Expert Segmentation": [[109, "fine-grained-expert-segmentation"]], "Fine-tuning": [[54, "fine-tuning"]], "Finetuning the LM to Follow Instructions": [[30, "finetuning-the-lm-to-follow-instructions"], [42, "finetuning-the-lm-to-follow-instructions"]], "Flipping the Labels": [[88, "flipping-the-labels"]], "Flow stages": [[56, "flow-stages"]], "Formulation": [[114, "formulation"], [115, "formulation"]], "Framework": [[12, "framework"]], "From MLE to RL framework": [[49, "from-mle-to-rl-framework"]], "Functional Correctness": [[24, "functional-correctness"]], "GB2312\u3001GBK\u7b49\u5176\u4ed6\u7f16\u7801": [[118, "gb2312gbk"]], "GOLD": [[49, "gold"]], "GPQA": [[27, "gpqa"]], "GPT": [[12, "gpt"]], "GPT2": [[13, "gpt2"]], "GPT3": [[14, "gpt3"]], "GRPO": [[77, "id3"]], "GSM8K": [[27, "gsm8k"]], "Gated Linear Units (GLU) and Variants": [[116, "gated-linear-units-glu-and-variants"]], "General Benchmarks": [[23, "general-benchmarks"]], "General RL": [[68, "general-rl"]], "General form": [[114, "general-form"], [115, "general-form"]], "Generation": [[64, "generation"]], "Generator": [[100, "generator"]], "Gradient of DPO Loss": [[74, "gradient-of-dpo-loss"]], "Group Relative Policy Optimization": [[77, "group-relative-policy-optimization"]], "High-level methodology": [[15, "high-level-methodology"]], "How Various Factors Influence Non-Determinism?": [[50, "how-various-factors-influence-non-determinism"]], "How to Better Model Human Preference?": [[88, "how-to-better-model-human-preference"]], "Human Curation": [[19, "human-curation"]], "Human Evaluation": [[103, "human-evaluation"]], "Human Preference Data Collection": [[62, "human-preference-data-collection"]], "HumanEval": [[24, "humaneval"]], "Hyper-Parameters": [[59, "hyper-parameters"]], "IFEval": [[18, "ifeval"]], "Impacts of Different Data on RM Performance": [[88, "impacts-of-different-data-on-rm-performance"]], "Implementation Details": [[26, "implementation-details"], [40, "implementation-details"]], "Incorporating Judgments for Alignment": [[79, "incorporating-judgments-for-alignment"]], "Inference-Time Scaling with SPCT": [[73, "inference-time-scaling-with-spct"]], "Infilling": [[57, "infilling"]], "Initialization": [[89, "initialization"], [90, "initialization"]], "Input Format": [[31, "input-format"]], "Input Representation": [[13, "input-representation"]], "Installation": [[25, "installation"]], "Instance Generation": [[30, "instance-generation"], [42, "instance-generation"]], "Instruct GPT": [[78, "instruct-gpt"]], "Instruct Models": [[67, "instruct-models"]], "InstructGPT": [[15, "instructgpt"]], "Instruction Following Ability Results": [[89, "instruction-following-ability-results"]], "Instruction Following Training": [[89, "instruction-following-training"]], "Instruction Generation": [[30, "instruction-generation"], [42, "instruction-generation"]], "Instruction Selection": [[90, "instruction-selection"]], "Instruction fine-tuning": [[57, "instruction-fine-tuning"]], "Instruction-tuned Model": [[66, "instruction-tuned-model"]], "Internal Action": [[7, "internal-action"]], "Introduction": [[9, "introduction"], [26, "introduction"], [40, "introduction"], [46, "introduction"], [52, "introduction"], [57, "introduction"], [61, "introduction"], [79, "introduction"], [85, "introduction"], [111, "introduction"]], "Iterative Fine-Tuning": [[62, "iterative-fine-tuning"]], "Iterative RL with GRPO": [[77, "iterative-rl-with-grpo"]], "Iterative Rounds": [[63, "iterative-rounds"]], "Iterative Training": [[90, "iterative-training"]], "Judgment Annotation": [[90, "judgment-annotation"]], "LIMA: Less Is More for Alignment": [[103, "lima-less-is-more-for-alignment"]], "LORA": [[120, "lora"]], "Label Smoothing": [[88, "label-smoothing"]], "Large scale sampling": [[54, "large-scale-sampling"]], "Large-scale Supervision": [[100, "large-scale-supervision"]], "Layer Normalization": [[113, "layer-normalization"]], "LayerNorm": [[64, "layernorm"]], "Learn more": [[47, "learn-more"]], "Learning Pipeline": [[76, "learning-pipeline"]], "Learning from Contrasting": [[79, "learning-from-contrasting"]], "Let\u2019s Verify Step by Step": [[100, "lets-verify-step-by-step"]], "LiveCodeBench": [[25, "livecodebench"]], "Llama": [[61, "llama"]], "Llama 2": [[62, "llama-2"]], "Llama 3": [[63, "llama-3"]], "Llama 3 Source Code": [[65, "llama-3-source-code"]], "Llama Factory": [[119, "llama-factory"]], "Llama implementation": [[111, "llama-implementation"]], "Llama3": [[64, "llama3"]], "Load Balance Consideration": [[109, "load-balance-consideration"]], "Logic-RL": [[96, "logic-rl"]], "Long Context Extension": [[60, "long-context-extension"]], "Long context fine-tuning": [[57, "long-context-fine-tuning"]], "Long-CoT Cold Start": [[68, "long-cot-cold-start"]], "Loss": [[74, "loss"]], "Loss of High Frequency information - \u201cNTK-aware\u201d interpolation": [[110, "loss-of-high-frequency-information-ntk-aware-interpolation"]], "Loss of Relative Local Distances - \u201cNTK-by-parts\u201d interpolation": [[110, "loss-of-relative-local-distances-ntk-by-parts-interpolation"]], "Low-Rank Compression for Queries": [[112, "low-rank-compression-for-queries"]], "Low-Rank Key-Value Joint Compression": [[112, "low-rank-key-value-joint-compression"]], "MATH": [[27, "math"]], "MATH 500": [[27, "math-500"]], "MBPP": [[28, "mbpp"]], "MMLU": [[23, "mmlu"]], "MMLU-Pro": [[23, "mmlu-pro"]], "MMLU-Redux": [[23, "mmlu-redux"]], "Magicoder": [[26, "magicoder"], [40, "magicoder"]], "Main Result": [[83, "main-result"]], "Main Results": [[72, "main-results"], [83, "main-results"]], "Markdown Files": [[47, "markdown-files"]], "Math & Science Benchmarks": [[27, "math-science-benchmarks"]], "Measuring the Strength of Preferences": [[88, "measuring-the-strength-of-preferences"]], "Memory": [[7, "memory"]], "Method": [[83, "method"], [83, "id1"], [90, "method"]], "Methodology": [[52, "methodology"], [84, "methodology"]], "Methods": [[100, "methods"]], "Methods and experimental details": [[15, "methods-and-experimental-details"]], "Mini-Batch Updates": [[82, "mini-batch-updates"]], "Model": [[13, "model"], [64, "model"], [65, "model"]], "Model Accuracy VS. Augmented Data Count": [[106, "model-accuracy-vs-augmented-data-count"]], "Model Accuracy VS. Pre-training Loss": [[106, "model-accuracy-vs-pre-training-loss"]], "Model Accuracy VS. Supervised Data Count": [[106, "model-accuracy-vs-supervised-data-count"]], "Model Architecture": [[11, "model-architecture"]], "Model Averaging": [[63, "model-averaging"]], "Model Fine-tuning (Iterative Training)": [[90, "model-fine-tuning-iterative-training"]], "Model and Architectures": [[14, "model-and-architectures"]], "Modeling": [[63, "modeling"]], "Models": [[15, "models"], [53, "models"]], "Multi-Head Attention": [[11, "multi-head-attention"]], "Multi-Head Latent Attention": [[112, "multi-head-latent-attention"]], "Multi-Token Prediction": [[60, "multi-token-prediction"]], "NLP\u5b9e\u4f8b": [[108, "nlp"]], "Normalization": [[64, "normalization"], [113, "normalization"]], "Notebooks with MyST Markdown": [[48, "notebooks-with-myst-markdown"]], "OOD Generalization": [[100, "ood-generalization"]], "OSS-INSTRUCT: Instruction Tuning from Open Source": [[26, "oss-instruct-instruction-tuning-from-open-source"], [40, "oss-instruct-instruction-tuning-from-open-source"]], "Off-policy policy gradient": [[49, "off-policy-policy-gradient"]], "Offline Reinforcement Learning": [[66, "offline-reinforcement-learning"]], "Online Reinforcement Learning": [[66, "online-reinforcement-learning"]], "OpenCodeReasoning": [[97, "opencodereasoning"]], "OpenCoder": [[41, "opencoder"]], "OpenRLHF": [[80, "openrlhf"], [121, "openrlhf"]], "Optimizer": [[61, "optimizer"]], "Outcome Supervision RL with GRPO": [[77, "outcome-supervision-rl-with-grpo"]], "Outcome-supervised Reward Models (ORMs)": [[100, "outcome-supervised-reward-models-orms"]], "Overall Self-Alignment Algorithm": [[89, "overall-self-alignment-algorithm"]], "Overall System": [[55, "overall-system"]], "Overlong Reward Shaping": [[72, "overlong-reward-shaping"]], "Overview": [[56, "overview"]], "PPO": [[81, "ppo"]], "PPO Review": [[77, "ppo-review"]], "PPO implementation detail": [[80, "ppo-implementation-detail"]], "PPO-Clip Integration": [[82, "ppo-clip-integration"]], "Parameter and Compute Scaling of Transformers": [[51, "parameter-and-compute-scaling-of-transformers"]], "Passive Exploration": [[76, "passive-exploration"]], "Perception": [[7, "perception"]], "Performance with Dataset Size and Compute": [[51, "performance-with-dataset-size-and-compute"]], "Performance with Non-Embedding Parameter Count N": [[51, "performance-with-non-embedding-parameter-count-n"]], "Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero": [[95, "performance-self-evolution-process-and-aha-moment-of-deepseek-r1-zero"]], "Point Estimate": [[76, "point-estimate"]], "Policy and Fine-Tuning": [[55, "policy-and-fine-tuning"]], "Position interpolation": [[110, "position-interpolation"]], "Position-wise Feed-Forward Networks": [[11, "position-wise-feed-forward-networks"]], "Positional Encoding": [[11, "positional-encoding"]], "Positional Interpolation": [[111, "positional-interpolation"]], "Post Training": [[41, "post-training"]], "Post-Training": [[60, "post-training"], [63, "post-training"]], "Post-trained Language Model": [[63, "post-trained-language-model"]], "Post-training": [[66, "post-training"], [67, "post-training"], [68, "post-training"]], "Post-training Data": [[63, "post-training-data"]], "Pre-Training": [[59, "pre-training"], [60, "pre-training"]], "Pre-trained Language Model": [[63, "pre-trained-language-model"]], "Pre-training": [[66, "pre-training"], [67, "pre-training"], [68, "pre-training"]], "Pre-training data": [[61, "pre-training-data"]], "Preference Data": [[63, "preference-data"]], "Preference Labeling with LLMs": [[84, "preference-labeling-with-llms"]], "Preference Optimization": [[70, "preference-optimization"]], "Preliminaries": [[74, "preliminaries"], [87, "preliminaries"], [88, "preliminaries"]], "Preliminaries and Problem Setup": [[99, "preliminaries-and-problem-setup"]], "Preliminaries: Mixture-of-Experts for Transformers": [[109, "preliminaries-mixture-of-experts-for-transformers"]], "Preliminaries: Standard Multi-Head Attention": [[112, "preliminaries-standard-multi-head-attention"]], "Preliminary": [[72, "preliminary"], [115, "preliminary"]], "Pretrain": [[62, "pretrain"]], "Pretraining": [[41, "pretraining"]], "Pretraining Data": [[41, "pretraining-data"]], "Problem Setting": [[79, "problem-setting"]], "Procedural Memory": [[7, "procedural-memory"]], "Process Supervision RL with GRPO": [[77, "process-supervision-rl-with-grpo"]], "Process vs Outcome Supervision": [[100, "process-vs-outcome-supervision"]], "Process-supervised Reward Models (PRMs)": [[100, "process-supervised-reward-models-prms"]], "Prompting Techniques": [[84, "prompting-techniques"]], "Properties of RoPE": [[115, "properties-of-rope"]], "Proposed approach": [[115, "proposed-approach"]], "Quick Start": [[22, "quick-start"]], "Quickly add YAML metadata for MyST Notebooks": [[48, "quickly-add-yaml-metadata-for-myst-notebooks"]], "Qwen 2.5": [[66, "qwen-2-5"]], "Qwen2.5-Coder": [[67, "qwen2-5-coder"]], "Qwen3": [[68, "qwen3"]], "REACT": [[4, "react"]], "REINFORCE++": [[82, "reinforce"]], "REINFORCE++ Enhancements": [[82, "reinforce-enhancements"]], "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED": [[104, "rethinking-data-selection-at-scale-random-selection-is-almost-all-you-need"]], "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold": [[105, "rl-on-incorrect-synthetic-data-scales-the-efficiency-of-llm-math-reasoning-by-eight-fold"]], "RLAIF vs. RLHF": [[84, "rlaif-vs-rlhf"], [84, "id1"]], "RLCD": [[85, "rlcd"], [85, "id1"]], "RLHF": [[62, "rlhf"]], "RMSNorm": [[64, "rmsnorm"], [65, "rmsnorm"], [113, "rmsnorm"]], "RS-DPO": [[86, "rs-dpo"]], "RSO": [[87, "rso"]], "RSO APPROACH": [[87, "rso-approach"]], "Reasoning": [[92, "reasoning"]], "Reasoning RL": [[68, "reasoning-rl"]], "Reasoning data curation to create s1K": [[98, "reasoning-data-curation-to-create-s1k"]], "Reasoning-oriented Reinforcement Learning": [[95, "reasoning-oriented-reinforcement-learning"]], "References": [[101, "references"]], "Reflexion": [[5, "reflexion"]], "Reflexion: reinforcement via verbal reflection": [[5, "reflexion-reinforcement-via-verbal-reflection"]], "Reinforcement Learning": [[58, "reinforcement-learning"], [59, "reinforcement-learning"], [60, "reinforcement-learning"]], "Reinforcement Learning Algorithm": [[95, "reinforcement-learning-algorithm"]], "Reinforcement Learning for all Scenarios": [[95, "reinforcement-learning-for-all-scenarios"]], "Reinforcement Learning from AI Feedback": [[83, "reinforcement-learning-from-ai-feedback"], [84, "reinforcement-learning-from-ai-feedback"]], "Reinforcement learning (RL)": [[78, "reinforcement-learning-rl"]], "Rejection Sampling and Supervised Fine-Tuning": [[95, "rejection-sampling-and-supervised-fine-tuning"]], "Rejective Fine-Tuning (Cold Start)": [[73, "rejective-fine-tuning-cold-start"]], "Related Work": [[91, "related-work"]], "Removing KL Divergence": [[72, "removing-kl-divergence"]], "Response Pair Construction": [[90, "response-pair-construction"]], "Results": [[8, "results"], [15, "results"], [31, "results"], [63, "results"], [84, "results"], [98, "results"]], "Results on Reward Modeling Benchmarks": [[73, "results-on-reward-modeling-benchmarks"]], "Retrieval-Based Approach": [[31, "retrieval-based-approach"]], "Reward": [[49, "reward"]], "Reward Model Architectures and Training": [[76, "reward-model-architectures-and-training"]], "Reward Modeling": [[62, "reward-modeling"], [63, "reward-modeling"], [95, "reward-modeling"]], "Reward Modeling Ability Results": [[89, "reward-modeling-ability-results"]], "Reward Normalization and Clipping": [[82, "reward-normalization-and-clipping"]], "Reward modeling (RM)": [[78, "reward-modeling-rm"]], "RewardBench": [[29, "rewardbench"]], "RoPE": [[64, "rope"], [65, "rope"], [114, "rope"]], "RoPE \u7684\u8fdc\u7a0b\u8870\u51cf": [[110, "rope"]], "Rotary Positional Embeddings (RoPE)": [[115, "rotary-positional-embeddings-rope"]], "Rule-Based RL": [[73, "rule-based-rl"]], "Rule-based Reward Modeling": [[72, "rule-based-reward-modeling"]], "SCoRe: Self-Correction via Multi-Turn Reinforcement Learning": [[99, "score-self-correction-via-multi-turn-reinforcement-learning"]], "SELF-INSTRUCT": [[30, "self-instruct"], [42, "self-instruct"]], "SFT": [[62, "sft"], [102, "sft"], [119, "sft"], [121, "sft"]], "SFT Data": [[63, "sft-data"]], "STATISTICAL REJECTION SAMPLING ALGORITHM": [[87, "statistical-rejection-sampling-algorithm"]], "SWE-Llama: Fine-Tuning Codellama for SWE-bench": [[31, "swe-llama-fine-tuning-codellama-for-swe-bench"]], "SWE-agent": [[8, "swe-agent"]], "SWE-agent: Designing an ACI for Software Engineering": [[8, "swe-agent-designing-an-aci-for-software-engineering"]], "SWE-bench": [[31, "swe-bench"], [31, "id1"]], "SWE-bench Lite": [[31, "swe-bench-lite"]], "SWE-smith": [[9, "swe-smith"]], "SWE-smith: Software Task Generation at Scale": [[9, "swe-smith-software-task-generation-at-scale"]], "Sample Roles and Directives": [[47, "sample-roles-and-directives"]], "Sampling": [[55, "sampling"]], "Scaled Dot-Product Attention": [[11, "scaled-dot-product-attention"]], "Scaling Effect on Non-Determinism": [[50, "scaling-effect-on-non-determinism"]], "Scaling Laws for Neural Language Models": [[51, "scaling-laws-for-neural-language-models"]], "Scaling Laws with Model Size and Training Time": [[51, "scaling-laws-with-model-size-and-training-time"]], "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": [[106, "scaling-relationship-on-learning-mathematical-reasoning-with-large-language-models"]], "Scoring Model": [[55, "scoring-model"]], "Search-R1": [[6, "search-r1"]], "Secrets of RLHF in Large Language Models: Reward Modeling": [[88, "secrets-of-rlhf-in-large-language-models-reward-modeling"]], "Seed-Coder": [[69, "seed-coder"]], "Self-Instruction Creation": [[89, "self-instruction-creation"]], "Self-Principled Critique Tuning (SPCT)": [[73, "self-principled-critique-tuning-spct"]], "Self-Rewarding Language Models": [[89, "self-rewarding-language-models"]], "Self-Taught Evaluators": [[90, "self-taught-evaluators"]], "Self-Training for Preference Modeling": [[91, "self-training-for-preference-modeling"]], "Semantic Memory": [[7, "semantic-memory"]], "Semi-Automatic Program Refactoring and Testing Case Generation": [[19, "semi-automatic-program-refactoring-and-testing-case-generation"]], "SentencePiece": [[117, "sentencepiece"]], "Shared Expert Isolation": [[109, "shared-expert-isolation"]], "Small-scale Synthetic Supervision": [[100, "small-scale-synthetic-supervision"]], "Stage I: Training a Model Initialization to Prevent Collapse": [[99, "stage-i-training-a-model-initialization-to-prevent-collapse"]], "Stage II: Multi-Turn RL with Reward Shaping": [[99, "stage-ii-multi-turn-rl-with-reward-shaping"]], "Stage-1: Multi-Objective Reward Modeling": [[71, "stage-1-multi-objective-reward-modeling"]], "Stage-2: Mixture-of-Experts Aggregation of Reward Objectives": [[71, "stage-2-mixture-of-experts-aggregation-of-reward-objectives"]], "Stanford Alpaca": [[20, "stanford-alpaca"], [39, "stanford-alpaca"]], "Strong-to-Weak Distillation": [[68, "strong-to-weak-distillation"]], "Summarization": [[13, "summarization"]], "Supervised Fine-Tuning": [[58, "supervised-fine-tuning"], [59, "supervised-fine-tuning"], [60, "supervised-fine-tuning"]], "Supervised Fine-tuning": [[66, "supervised-fine-tuning"]], "Supervised Finetuning": [[63, "supervised-finetuning"]], "Supervised fine-tuning": [[12, "supervised-fine-tuning"]], "Supervised fine-tuning (SFT)": [[78, "supervised-fine-tuning-sft"]], "Surface Patterns in Non-Determinism Generation?": [[50, "surface-patterns-in-non-determinism-generation"]], "SwiGLU": [[116, "swiglu"]], "SwiGLU activation function": [[64, "swiglu-activation-function"], [65, "swiglu-activation-function"]], "Swish": [[116, "swish"]], "TACO": [[32, "taco"], [43, "taco"]], "Takeaway": [[58, "takeaway"], [59, "takeaway"], [60, "takeaway"], [63, "takeaway"], [66, "takeaway"], [67, "takeaway"], [114, "takeaway"]], "Takeaways": [[88, "takeaways"], [100, "takeaways"]], "Task-specific input transformations": [[12, "task-specific-input-transformations"]], "Techniques": [[107, "techniques"]], "Temperature Effect on Non-Determinism": [[50, "temperature-effect-on-non-determinism"]], "Test-time scaling": [[98, "test-time-scaling"]], "Textual Input": [[7, "textual-input"]], "The Agent-Computer Interface": [[8, "the-agent-computer-interface"]], "The Factors of Math Reasoning Ability in Supervised LLM": [[106, "the-factors-of-math-reasoning-ability-in-supervised-llm"]], "The GOLD algorithm": [[49, "the-gold-algorithm"]], "The Need for Interpretable Reward Models": [[71, "the-need-for-interpretable-reward-models"]], "The Proposed Flow": [[56, "the-proposed-flow"]], "Thinking Mode Fusion": [[68, "thinking-mode-fusion"]], "Tiktoken": [[64, "tiktoken"]], "Token-Dropping Strategy": [[109, "token-dropping-strategy"]], "Token-Level KL Penalty": [[82, "token-level-kl-penalty"]], "Token-Level Policy Gradient Loss": [[72, "token-level-policy-gradient-loss"]], "Tokenizer": [[64, "tokenizer"], [64, "id2"]], "Training Dataset": [[13, "training-dataset"], [14, "training-dataset"]], "Training Details": [[41, "training-details"], [72, "training-details"]], "Training LIMA": [[103, "training-lima"]], "Training Language Models to Self-Correct via Reinforcement Learning": [[99, "training-language-models-to-self-correct-via-reinforcement-learning"]], "Training Policy": [[67, "training-policy"], [67, "id8"]], "Training Template": [[95, "training-template"]], "Training WizardCoder": [[33, "training-wizardcoder"], [45, "training-wizardcoder"]], "Transformer": [[64, "transformer"], [65, "transformer"]], "Two-stage Instruction-Tuning": [[41, "two-stage-instruction-tuning"]], "UNICODER": [[44, "unicoder"], [44, "id2"]], "UNICODER-INSTRUCT": [[44, "unicoder-instruct"]], "UTF-16\u3001UTF-32\u7b49": [[118, "utf-16utf-32"]], "UTF-8": [[118, "utf-8"]], "Unigram Language Model (ULM)": [[117, "unigram-language-model-ulm"]], "Unpinning Principles from Understanding to Generation": [[73, "unpinning-principles-from-understanding-to-generation"]], "Unsupervised pre-training": [[12, "unsupervised-pre-training"]], "Visual Input": [[7, "visual-input"]], "Weak to Strong Generalization": [[52, "weak-to-strong-generalization"]], "West-of-N": [[91, "west-of-n"]], "West-of-N Self-Training": [[91, "west-of-n-self-training"]], "What is CodeAct?": [[3, "what-is-codeact"]], "What is MyST?": [[47, "what-is-myst"]], "What is the Full Potential of Non-Determinism?": [[50, "what-is-the-full-potential-of-non-determinism"]], "Why KV cache": [[112, "why-kv-cache"]], "Why Layer Normalization": [[113, "why-layer-normalization"]], "Why decoder-only": [[12, "why-decoder-only"]], "WizardCoder": [[33, "wizardcoder"], [45, "wizardcoder"]], "WizardLM": [[33, "wizardlm"], [45, "wizardlm"]], "WordPiece": [[117, "wordpiece"]], "WordPiece, ULM and SentencePiece": [[117, "wordpiece-ulm-and-sentencepiece"]], "YaRN": [[110, "id5"]], "YaRN: Efficient ContextWindow Extension of Large Language Models": [[110, "yarn-efficient-contextwindow-extension-of-large-language-models"]], "methodology": [[78, "methodology"]], "s1: Simple test-time scaling": [[98, "s1-simple-test-time-scaling"]], "unicode": [[118, "unicode"]], "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": [[118, "id1"]], "\u521d\u8bc6BPE": [[108, "bpe"]], "\u603b\u7ed3": [[118, "id2"]], "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff1f": [[108, "id2"]], "\u672c\u5730 Evaluate": [[22, "evaluate"], [25, "evaluate"]], "\u7f16\u7801\u548c\u89e3\u7801": [[108, "id1"]], "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": [[110, "id4"]]}, "docnames": ["agent/0", "agent/agentless", "agent/api-bank", "agent/code-act", "agent/react", "agent/reflexion", "agent/search-r1", "agent/software-survey", "agent/swe-agent", "agent/swe-smith", "base/0", "base/attention", "base/gpt", "base/gpt2", "base/gpt3", "base/instruct-gpt", "bench/0", "bench/aider", "bench/alignment", "bench/bigcodebench", "bench/code-alpaca", "bench/cruxeval", "bench/evalplus", "bench/general", "bench/humaneval", "bench/livecodebench", "bench/magic", "bench/math-science", "bench/mbpp", "bench/reward-bench", "bench/self-instruct", "bench/swe", "bench/taco", "bench/wizard", "content", "content-Copy1", "data/0", "data/alphacode", "data/apps", "data/code-alpaca", "data/magic", "data/opencoder", "data/self-instruct", "data/taco", "data/unicoder", "data/wizard", "intro", "markdown", "markdown-notebooks", "methodology/gold", "methodology/non-determin", "methodology/scaling-law", "methodology/weak-to-strong", "models/0", "models/alphacode", "models/alphacode2", "models/alphacodium", "models/codellama", "models/deepseek-coder-v2", "models/deepseek-v2", "models/deepseek-v3", "models/llama", "models/llama2", "models/llama3", "models/llama3-code copy", "models/llama3-source-code", "models/qwen25", "models/qwen25-coder", "models/qwen3", "models/seed-coder", "preference/0", "preference/armo", "preference/dapo", "preference/deepseek-grm", "preference/dpo", "preference/dpop", "preference/ee", "preference/grpo", "preference/instruct-gpt", "preference/judge", "preference/openrlhf", "preference/ppo", "preference/reinforce++", "preference/rlaif-1", "preference/rlaif-2", "preference/rlcd", "preference/rs-dpo", "preference/rso", "preference/secret-rm", "preference/self-reward", "preference/self-taught", "preference/west-of-n", "reasoning/0", "reasoning/cot", "reasoning/deepcoder", "reasoning/deepseek-r1", "reasoning/logic-rl", "reasoning/opencodereasoning", "reasoning/s1", "reasoning/self-correct-rl", "reasoning/verify", "reference", "sft/0", "sft/lima", "sft/random", "sft/rl-eight-fold", "sft/rs", "techniques/0", "techniques/bpe", "techniques/deepseek-moe", "techniques/extending", "techniques/extending-old", "techniques/mla", "techniques/norm", "techniques/rope", "techniques/rope-old", "techniques/swiglu", "techniques/tokenize", "techniques/unicode-utf8", "tools/llama-factory", "tools/lora", "tools/openrlhf"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["agent/0.ipynb", "agent/agentless.ipynb", "agent/api-bank.ipynb", "agent/code-act.ipynb", "agent/react.ipynb", "agent/reflexion.ipynb", "agent/search-r1.ipynb", "agent/software-survey.ipynb", "agent/swe-agent.ipynb", "agent/swe-smith.ipynb", "base/0.ipynb", "base/attention.ipynb", "base/gpt.ipynb", "base/gpt2.ipynb", "base/gpt3.ipynb", "base/instruct-gpt.ipynb", "bench/0.ipynb", "bench/aider.ipynb", "bench/alignment.ipynb", "bench/bigcodebench.ipynb", "bench/code-alpaca.ipynb", "bench/cruxeval.ipynb", "bench/evalplus.ipynb", "bench/general.ipynb", "bench/humaneval.ipynb", "bench/livecodebench.ipynb", "bench/magic.ipynb", "bench/math-science.ipynb", "bench/mbpp.ipynb", "bench/reward-bench.ipynb", "bench/self-instruct.ipynb", "bench/swe.ipynb", "bench/taco.ipynb", "bench/wizard.ipynb", "content.ipynb", "content-Copy1.ipynb", "data/0.ipynb", "data/alphacode.ipynb", "data/apps.ipynb", "data/code-alpaca.ipynb", "data/magic.ipynb", "data/opencoder.ipynb", "data/self-instruct.ipynb", "data/taco.ipynb", "data/unicoder.ipynb", "data/wizard.ipynb", "intro.md", "markdown.md", "markdown-notebooks.md", "methodology/gold.ipynb", "methodology/non-determin.ipynb", "methodology/scaling-law.ipynb", "methodology/weak-to-strong.ipynb", "models/0.ipynb", "models/alphacode.ipynb", "models/alphacode2.ipynb", "models/alphacodium.ipynb", "models/codellama.ipynb", "models/deepseek-coder-v2.ipynb", "models/deepseek-v2.ipynb", "models/deepseek-v3.ipynb", "models/llama.ipynb", "models/llama2.ipynb", "models/llama3.ipynb", "models/llama3-code copy.ipynb", "models/llama3-source-code.ipynb", "models/qwen25.ipynb", "models/qwen25-coder.ipynb", "models/qwen3.ipynb", "models/seed-coder.ipynb", "preference/0.ipynb", "preference/armo.ipynb", "preference/dapo.ipynb", "preference/deepseek-grm.ipynb", "preference/dpo.ipynb", "preference/dpop.ipynb", "preference/ee.ipynb", "preference/grpo.ipynb", "preference/instruct-gpt.ipynb", "preference/judge.ipynb", "preference/openrlhf.ipynb", "preference/ppo.ipynb", "preference/reinforce++.ipynb", "preference/rlaif-1.ipynb", "preference/rlaif-2.ipynb", "preference/rlcd.ipynb", "preference/rs-dpo.ipynb", "preference/rso.ipynb", "preference/secret-rm.ipynb", "preference/self-reward.ipynb", "preference/self-taught.ipynb", "preference/west-of-n.ipynb", "reasoning/0.ipynb", "reasoning/cot.ipynb", "reasoning/deepcoder.ipynb", "reasoning/deepseek-r1.ipynb", "reasoning/logic-rl.ipynb", "reasoning/opencodereasoning.ipynb", "reasoning/s1.ipynb", "reasoning/self-correct-rl.ipynb", "reasoning/verify.ipynb", "reference.ipynb", "sft/0.ipynb", "sft/lima.ipynb", "sft/random.ipynb", "sft/rl-eight-fold.ipynb", "sft/rs.ipynb", "techniques/0.ipynb", "techniques/bpe.ipynb", "techniques/deepseek-moe.ipynb", "techniques/extending.ipynb", "techniques/extending-old.ipynb", "techniques/mla.ipynb", "techniques/norm.ipynb", "techniques/rope.ipynb", "techniques/rope-old.ipynb", "techniques/swiglu.ipynb", "techniques/tokenize.ipynb", "techniques/unicode-utf8.ipynb", "tools/llama-factory.ipynb", "tools/lora.ipynb", "tools/openrlhf.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [7, 8, 9, 12, 13, 15, 19, 22, 23, 27, 41, 47, 48, 49, 51, 52, 56, 57, 59, 62, 63, 64, 66, 67, 68, 71, 72, 74, 75, 76, 77, 78, 82, 83, 84, 85, 87, 88, 90, 98, 99, 101, 106, 108, 109, 110, 111, 117], "0": [11, 12, 22, 24, 25, 30, 33, 41, 42, 45, 49, 50, 51, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 68, 71, 72, 74, 75, 77, 79, 80, 83, 84, 87, 88, 89, 91, 103, 106, 109, 110, 111, 113, 114, 115, 116, 118, 119, 120], "000": [2, 9, 23, 27, 31, 32, 38, 43, 54, 57, 98, 103], "0000": [111, 118], "0000j": 111, "0001": 118, "0010": 118, "003": [20, 39], "0041": 118, "005": 24, "007f": 118, "0080": 118, "01": [72, 80], "0100j": 111, "012": 72, "01825": [47, 101], "02120": [26, 40, 47, 101], "02155": [47, 101], "02954": [47, 101], "03": 61, "03065": [47, 101], "0314": 18, "03300": [47, 101], "03341": [47, 101], "03374": [47, 101], "03762": [47, 101], "04434": [47, 101], "0461": 111, "04805": [47, 101], "0596": 111, "0596j": 111, "06": 61, "0674": 111, "0674j": 111, "07": 25, "07436": [47, 101], "076": 51, "07911": [47, 101], "07974": [47, 101], "07ff": 118, "08": 72, "0800": 118, "08083": [47, 101], "08361": [47, 101], "08568": [33, 45], "096": [57, 72], "09864": [47, 101], "0xxxxxxx": 118, "1": [1, 2, 9, 11, 12, 15, 18, 20, 22, 24, 25, 26, 30, 31, 32, 33, 35, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 87, 88, 89, 90, 91, 98, 99, 100, 101, 103, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119], "10": [3, 22, 25, 27, 38, 41, 50, 51, 55, 57, 58, 59, 61, 63, 67, 72, 77, 84, 88, 108, 109, 118, 119], "100": [8, 9, 13, 20, 23, 24, 39, 41, 55, 57, 67, 71, 76, 100], "1000": [33, 45, 60, 100, 110, 111], "10000": [11, 55, 64, 65, 110, 111, 114, 115], "100000": 80, "10000000": 118, "100k": 59, "10111000": 118, "1024": [67, 80], "102400": 59, "1048576000": 59, "105": 25, "10509": [47, 101], "10560": [30, 42], "106": 25, "107": 25, "10k": 59, "10x": 14, "10xxxxxx": 118, "11": [25, 115], "1106": [26, 40], "110k": [26, 40], "110xxxxx": 118, "110\u8868\u793a\u9700\u8981\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u5f53\u524d\u5b57\u7b26": 118, "1110": 118, "1110xxxx": 118, "1110\u8868\u793a\u9700\u8981\u4e09\u4e2a\u5b57\u8282": 118, "11110xxx": 118, "11110\u8868\u793a\u9700\u8981\u56db\u4e2a\u5b57\u8282": 118, "117": 25, "12": [23, 25, 27, 31, 51, 55, 59, 108, 115], "12000": 119, "12122": [47, 101], "12186": [47, 101], "12288": 59, "123abc\u4e00\u4e8c\u4e09": 118, "125": [14, 25], "128": [9, 59, 80], "128k": [59, 60, 63], "128\u4f4dascii\u7801\u662f\u6570\u5b57": 118, "12b": 24, "12k": 100, "12n_": 51, "13": [25, 51, 64, 108], "131": 38, "13245": [47, 101], "138": 2, "13b": 57, "13k": 15, "14": [23, 25, 57, 60, 112], "14165": [47, 101], "14168": [47, 101], "14187": [47, 101], "14858": [47, 101], "149225472": 59, "15": [25, 26, 40, 61, 62, 103], "151": [66, 68], "15115": [47, 101], "1536": 59, "15b": [33, 45], "16": [23, 25, 61, 72, 78, 80, 83, 98, 106], "160": 59, "1609": 64, "1612": [47, 101], "164": 24, "16441": [47, 101], "16609": [47, 101], "16k": 63, "17": [24, 25], "1706": [47, 101], "175": [14, 30, 42], "17k": 72, "18": [25, 66], "1810": [47, 101], "18290": [47, 101], "185b": 58, "188743680": 59, "19": [13, 14, 31, 47, 101], "1904": [47, 101], "1909": [47, 101], "195": 31, "198": 27, "1990\u5e74\u5f00\u59cb\u7814\u53d1": 118, "1994": 108, "1_gnu": 25, "1e": [64, 65, 103, 113, 119], "1k": 27, "1l": 86, "1m": 41, "1qvx610cu7": [47, 101], "1t": [59, 63], "1w": 86, "1\u4f4d\u4e3a": 118, "2": [2, 3, 8, 9, 11, 12, 13, 14, 15, 19, 20, 22, 23, 25, 27, 30, 31, 35, 39, 42, 48, 51, 52, 54, 56, 58, 59, 60, 61, 63, 64, 65, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 87, 88, 89, 91, 98, 99, 100, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118], "20": [14, 15, 20, 25, 39, 47, 68, 72, 88, 100, 101], "200": [15, 20, 24, 39, 100], "2000": 61, "2001": [47, 101], "2005": [47, 101], "20050": [47, 101], "2009": [47, 101], "2017": [47, 101], "2019": [47, 101], "2020": [47, 101], "2021": [47, 101], "2022": [47, 101], "2022a": 7, "2023": [7, 47, 58, 101], "2023c": 7, "2024": [25, 47, 67, 72, 101], "20240602": 25, "2025": [47, 101], "2048": [64, 65, 103, 110, 111], "20k": [20, 26, 33, 39, 40, 45, 58], "21": [23, 24, 25, 26, 27, 40, 47, 101, 106, 115], "2104": [47, 101], "2107": [47, 101], "2110": [47, 101], "21326725120": 59, "21b": 59, "22": [15, 25, 47, 101, 115], "2203": [47, 101], "2212": [30, 42], "2294": 64, "23": [11, 12, 18, 25, 27, 47, 60, 61, 66, 101, 106, 108, 110, 112, 114], "2305": [47, 101], "2306": [33, 45], "2308": [47, 101], "2309": [47, 101], "2311": [47, 101], "2312": [26, 40, 47, 101], "232": 38, "235": 68, "235692359680": 59, "235b": 68, "236b": 59, "24": [21, 23, 25, 41, 44, 47, 58, 59, 60, 63, 66, 67, 101, 109, 112], "2401": [47, 101], "2403": [47, 101], "2405": [47, 101], "2406": [47, 101], "2409": [47, 101], "2412": [47, 101], "25": [18, 25, 32, 43, 47, 66, 67, 88, 101, 112], "250": 103, "256": [64, 65, 89], "256\u4f4dascii\u6269\u5c55\u7801\u662fascii": 118, "26": [25, 98], "27": [62, 98], "28": 72, "29": 25, "2900": 111, "290k": 41, "2d": 110, "2d_": 51, "2e": 41, "2i": [11, 57, 115], "2j": [64, 65, 110, 111], "2m": 59, "2n": 51, "2n_": [51, 112], "2t": 115, "2\u62164\u5b57\u8282\u53d8\u957f": 118, "3": [7, 12, 13, 14, 15, 18, 25, 26, 31, 40, 50, 51, 54, 56, 57, 58, 59, 60, 64, 68, 78, 80, 83, 89, 95, 98, 106, 108, 109, 110, 111, 113, 116], "30": [23, 58, 63], "300": 31, "3000": 111, "300m": 58, "30k": 58, "31": 25, "314": 2, "31k": 15, "32": [25, 64, 65, 72, 76, 103, 106, 118], "3200": 76, "32768": [110, 111], "32b": [9, 68, 72, 98], "32k": 60, "33": 23, "338": 58, "33k": 15, "33t": 112, "34": [25, 27], "34b": [21, 57, 80], "35x": 22, "37": 31, "374": 64, "37b": 60, "38": 25, "3822059520": 59, "384": 72, "39": 27, "3m": 59, "4": [15, 18, 23, 25, 26, 27, 40, 51, 52, 57, 61, 63, 64, 65, 72, 75, 76, 78, 80, 84, 89, 100, 106, 108, 111, 112, 113, 118, 119], "40": [9, 71, 83, 88], "400": 18, "405b": 63, "4096": [41, 64, 65, 119], "40k": 58, "41": 25, "421": 38, "426": 28, "43": 25, "438k": 31, "443": [32, 43], "448": 27, "45": [13, 25, 61], "4d": [64, 65], "4e00": 118, "4e00\u57280800": 118, "4e00\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a100": 118, "4k": 60, "4t": 61, "4\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 118, "4\u5b57\u8282\u53d8\u957f": 118, "4\u5b57\u8282\u8868\u793a": 118, "5": [23, 25, 26, 27, 34, 35, 38, 40, 41, 47, 54, 57, 58, 59, 60, 61, 64, 65, 68, 71, 72, 74, 75, 76, 88, 89, 91, 98, 101, 103, 108, 111, 119], "50": [55, 57, 72, 98], "500": 18, "500000": [64, 65], "500b": 57, "50k": 9, "512": [11, 41, 59, 72], "5120": 59, "52": 57, "52k": [20, 30, 39, 42], "54": [25, 54], "540": 62, "5403": 111, "55m": [32, 43], "57": 23, "5963": 64, "59k": 98, "5b": 100, "5e": [41, 80], "5k": 27, "5m": 59, "5pm": [20, 39], "6": [11, 22, 25, 26, 30, 40, 42, 51, 56, 57, 58, 59, 64, 65, 68, 72, 80, 84, 100, 103, 111, 113, 119], "60": [19, 58, 59, 71, 83], "62": [25, 57], "63": 25, "64": [25, 59, 61, 103], "643": 66, "65": 27, "65b": [61, 103], "66": 25, "669": 68, "67": 61, "671b": 60, "67b": 59, "6n": 51, "6nb": 51, "6w": 118, "7": [24, 25, 27, 30, 42, 52, 55, 62, 66, 67, 72, 80, 106, 108, 111], "70": 25, "70b": [57, 62, 63, 80, 89], "72": 25, "72b": 68, "73": 2, "750": 103, "753": 2, "75k": [26, 40, 100], "77": 55, "777": 38, "788m": 60, "7b": [20, 22, 26, 39, 40, 57, 61, 62, 80, 98, 112, 119], "8": [14, 25, 27, 30, 42, 47, 51, 56, 57, 59, 60, 66, 80, 83, 101, 106, 111, 112], "80": [9, 52, 100], "800": 21, "8000": 55, "800k": 100, "80gb": 80, "80k": [26, 40], "80x": 22, "821b": 58, "82k": [30, 42], "83": 64, "8415j": 111, "85": [55, 63], "888": 2, "8b": [50, 63, 80], "8binstruct": 50, "8\u4e2abit\u4f4d\u4e2d\u9ad8\u4f4d\u5fc5\u987b\u7b49\u4e8e0": 118, "8\u4e2abit\u4f4d\u662f\u4e00\u4e2a\u5b57\u8282": 118, "8\u4e3a11100100": 118, "8\u4e3a\u4e09\u5b57\u8282": 118, "8\u4f4d\u53ef\u8868\u793a256\u4e2a\u5b57\u7b26": 118, "8\u548cgbk\u7f16\u7801": 118, "8\u6765\u5b9e\u73b0\u7f16\u7801": 118, "8\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u89e3\u7801\u4f7f\u7528": 118, "8\u7684\u6620\u5c04\u5173\u7cfb\u5982\u4e0b": 118, "8\u7684\u7f16\u7801\u65b9\u5f0f": 118, "8\u7684\u89c4\u5219\u5f88\u7b80\u5355": 118, "8\u7b49": 118, "8\u7f16\u7801": 118, "9": [15, 24, 25, 47, 61, 64, 72, 78, 85, 101, 103, 108, 112], "90": 31, "92": 67, "9297": 111, "95": [25, 61, 103], "97": 19, "974": 28, "9901": 119, "995": 68, "9999": 111, "9e": 80, "A": [7, 8, 13, 20, 27, 30, 39, 41, 42, 47, 49, 50, 55, 62, 64, 65, 66, 68, 71, 72, 76, 77, 82, 83, 84, 87, 90, 91, 95, 98, 101, 108, 109, 110, 115, 116, 120], "And": [77, 106], "As": [1, 7, 49, 52, 55, 56, 58, 62, 68, 72, 75, 76, 77, 91, 95, 100, 109, 112], "At": [8, 11, 13, 30, 42, 49, 54, 60, 62, 68, 90, 100, 110, 111], "By": [14, 58, 60, 63, 64, 68, 72, 76, 88, 110], "FOR": 83, "For": [1, 2, 3, 5, 7, 12, 15, 20, 26, 28, 30, 31, 39, 40, 41, 42, 47, 50, 51, 52, 55, 56, 57, 59, 60, 62, 63, 66, 67, 68, 71, 72, 73, 75, 76, 77, 79, 83, 85, 86, 87, 88, 95, 98, 100, 106, 109, 110, 111, 112, 120], "If": [18, 48, 49, 52, 56, 64, 65, 67, 76, 77, 83, 87, 90, 109, 111, 116], "In": [2, 3, 5, 7, 11, 12, 15, 20, 26, 30, 33, 39, 40, 41, 42, 44, 45, 47, 49, 50, 54, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 83, 84, 87, 88, 89, 90, 91, 93, 95, 101, 103, 106, 109, 110, 111, 112, 114, 115], "It": [15, 18, 19, 20, 23, 33, 39, 45, 47, 51, 52, 56, 57, 59, 62, 63, 64, 74, 77, 83, 98, 99, 109, 111], "Its": 55, "No": [50, 60, 64, 67], "Not": [20, 39], "OF": 83, "Of": [30, 42], "On": [11, 52, 60, 68, 76], "One": [9, 18, 49, 54, 63, 76, 79, 83, 84, 87, 110, 111, 115], "Or": [22, 63], "Such": [5, 47, 72, 90, 101], "That": [11, 48], "The": [1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 19, 20, 21, 23, 24, 26, 27, 28, 30, 33, 37, 38, 39, 40, 41, 42, 44, 45, 47, 48, 50, 51, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 90, 95, 100, 103, 109, 110, 111, 112, 113, 115, 116], "Their": 100, "Then": [1, 15, 26, 31, 40, 63, 75, 76, 77, 83, 84, 87, 98, 109, 112, 114], "There": [19, 110], "Thes": 19, "These": [11, 12, 20, 27, 32, 33, 39, 41, 45, 63, 66, 83, 87, 89, 90], "To": [1, 2, 3, 9, 11, 13, 14, 15, 19, 23, 26, 27, 30, 31, 33, 37, 40, 41, 42, 44, 45, 49, 50, 51, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 71, 72, 73, 77, 78, 79, 82, 84, 87, 89, 91, 95, 98, 100, 109, 110, 113, 116], "With": [23, 27, 48, 56, 73, 110], "_": [11, 15, 30, 33, 42, 44, 45, 49, 57, 60, 62, 64, 65, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 86, 87, 88, 91, 99, 100, 106, 109, 110, 112, 114, 115, 116], "_1": [11, 99], "__init__": [59, 64, 65, 113], "__main__": 22, "__name__": 22, "_bsz": [64, 65], "_h": 11, "_i": 106, "_libgcc_mutex": 25, "_mergeable_rank": 64, "_norm": [64, 65, 113], "_openmp_mutex": 25, "_t": [82, 112], "a100": 80, "a22b": 68, "a_": [49, 77, 82, 98, 111, 115], "a_i": [44, 106], "a_t": 82, "aa": 108, "aaabdaaabac": 108, "ab": [47, 101, 108, 111], "abbrevi": [27, 38, 118], "abil": [1, 2, 8, 13, 23, 26, 27, 40, 52, 58, 59, 66, 68, 72, 75, 77, 87, 93, 95, 100], "abl": [20, 21, 27, 39, 52, 62], "ablat": [41, 98, 100], "about": [8, 11, 15, 20, 26, 31, 39, 40, 47, 48, 52, 55, 56, 57, 59, 76, 88, 98, 109, 111], "abov": [12, 31, 52, 55, 57, 63, 68, 72, 73, 82, 87, 88, 90, 91, 95, 99, 109, 110], "absenc": 60, "absolut": [11, 61, 71, 114], "absorb": 112, "abstract": [7, 9, 13], "abstractset": 64, "ac": 108, "academ": 23, "acceler": [12, 112], "accept": [47, 87], "access": [2, 8, 38, 52, 62, 76, 87, 89, 90, 91, 99], "accommod": [63, 100], "accompani": 79, "accomplish": [50, 63], "accord": [2, 55, 60, 76, 88, 91, 98, 100, 109, 111], "accordingli": 72, "account": [51, 57], "accumul": 56, "accur": [23, 28, 32, 41, 62, 66, 73, 77, 88], "accuraci": [2, 23, 27, 60, 66, 72, 84, 88, 95, 98], "acecod": 7, "achiam": [47, 101], "achiev": [3, 9, 14, 23, 27, 41, 54, 58, 60, 61, 62, 63, 66, 72, 73, 74, 75, 79, 84, 87, 88, 91, 98, 112], "acknowledg": 7, "acquir": [9, 23, 59, 62, 95, 109], "across": [23, 25, 52, 55, 63, 66, 68, 76, 98, 100, 109, 110, 112, 113], "act": [4, 8], "action": [1, 3, 4, 5, 8, 20, 39, 49, 72, 82], "activ": [11, 12, 59, 60, 61, 66, 109, 112, 116], "actor": [5, 77, 80], "actor_learning_r": 80, "actual": [1, 15, 77, 99], "ad": [12, 13, 30, 33, 42, 45, 54, 63, 72, 77, 88, 99, 115], "adam_offload": 80, "adamw": [61, 72, 103], "adapt": [12, 33, 45, 73, 79, 109, 110, 111, 120], "add": [11, 13, 15, 19, 33, 45, 56, 57, 60, 61, 62, 64, 65, 68, 71, 78, 88, 89], "addit": [7, 11, 13, 15, 31, 49, 52, 54, 55, 57, 58, 60, 64, 65, 68, 72, 76, 78, 79, 85, 89, 95, 99, 100, 103, 109, 110, 112, 116, 118], "addition": [1, 12, 23, 30, 41, 42, 60, 68, 76, 109], "additionali": 77, "address": [2, 9, 27, 33, 45, 56, 63, 67, 68, 72, 77, 84, 87], "adher": [52, 66, 67, 68, 72, 95], "aditya": [47, 101], "adjust": [59, 63, 71, 87, 95, 112], "adopt": [20, 26, 31, 37, 39, 40, 50, 54, 59, 60, 67, 68, 73, 95, 112], "advanc": [2, 23, 41, 55, 66], "advantag": [52, 68, 77, 79, 80, 112], "advis": 83, "affect": [34, 41, 50, 109], "affin": [60, 64, 109], "aforement": 84, "after": [8, 12, 13, 30, 33, 42, 45, 50, 54, 55, 58, 60, 61, 62, 63, 64, 67, 68, 72, 75, 76, 77, 78, 84, 87, 88, 89, 95, 98, 100, 109, 110, 111], "again": [8, 11, 84, 116], "against": [15, 18, 37, 56, 67, 83, 85, 98], "agarw": [47, 101], "agent": [1, 5, 9, 67, 76, 82, 87], "aggreg": [9, 55], "aggress": [20, 39], "agnost": [14, 79], "ahm": [47, 101], "ai": [2, 18, 25, 27, 47, 56, 63, 72, 73, 89, 91, 101], "aidan": [47, 101], "aif": 89, "aift": 89, "aim": [1, 19, 27, 49, 50, 68, 72, 77, 87, 89, 90, 99, 109], "aime24": 98, "ainsli": [47, 101], "aiohttp": 25, "aiosign": 25, "aixin": [47, 101], "ajudg": 67, "al": 7, "alec": [47, 101], "alethea": [47, 101], "alex": [47, 101], "algorithm": [15, 24, 30, 32, 42, 43, 54, 55, 56, 58, 59, 61, 62, 63, 66, 67, 72, 74, 77, 108], "alibi": 111, "align": [5, 11, 12, 15, 27, 34, 44, 51, 52, 60, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 82, 84, 87, 109, 110, 111, 112, 114, 115, 116], "align_n": 79, "alignmentrelev": 52, "alik": 57, "all": [1, 3, 9, 13, 15, 20, 24, 28, 33, 37, 39, 44, 45, 47, 48, 49, 51, 54, 55, 58, 59, 62, 63, 64, 67, 72, 74, 75, 76, 77, 78, 82, 83, 84, 86, 87, 88, 99, 100, 101, 103, 106, 109, 110, 111, 112, 113, 116], "allclos": [64, 113], "allevi": 109, "alloc": [67, 72, 95], "allow": [3, 8, 11, 13, 14, 31, 47, 49, 54, 55, 60, 63, 64, 82, 83, 90, 109, 111, 115], "allowed_speci": 64, "allowed_token": 64, "almeida": [47, 101], "almost": [88, 103], "alon": [84, 88, 89, 103], "along": [1, 12, 37, 54, 56, 57, 68], "alongsid": [60, 77], "alpaca": [2, 26, 33, 34, 35, 40, 45], "alpacaev": [50, 89], "alpha": [79, 82, 88, 99, 110], "alpha_": [51, 109], "alphacod": 57, "alreadi": [52, 54, 58, 64, 76, 89], "also": [8, 11, 15, 20, 23, 25, 27, 28, 30, 31, 39, 41, 42, 47, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 74, 75, 77, 78, 83, 89, 90, 91, 98, 109, 110, 112, 116], "altdj": [47, 66, 101, 112], "alter": 56, "altern": [5, 14, 62, 63, 74, 76, 79, 84], "although": [18, 49, 58, 60, 95, 109, 118], "alwai": [54, 63, 79, 88, 109, 110, 111], "amanda": [47, 101], "ambigu": 88, "amc": 27, "american": 118, "amodei": [47, 101], "among": [2, 9, 18, 21, 57, 59, 67, 76, 87, 109, 112], "amount": [7, 41, 51, 55, 59, 63, 89, 95, 98, 100, 106, 110, 112, 116], "an": [1, 2, 3, 5, 7, 9, 11, 12, 13, 14, 15, 18, 19, 20, 23, 24, 26, 30, 31, 33, 39, 40, 41, 42, 45, 47, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 71, 72, 74, 75, 77, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 95, 99, 100, 101, 106, 109, 110, 111, 112], "anaconda3": 25, "analogi": 52, "analysi": [2, 7, 31, 56, 59, 63, 67, 79, 84], "analyz": [41, 67, 106], "anchor": 56, "andi": [47, 101], "andrew": [47, 101], "angela": [47, 101], "angl": [111, 114], "ani": [9, 11, 13, 14, 19, 20, 24, 26, 30, 37, 39, 40, 41, 42, 48, 49, 52, 56, 60, 63, 64, 67, 78, 83, 91, 95, 100, 110, 111, 112, 114, 115], "anlm": 9, "anneal": 41, "annot": [2, 23, 25, 57, 60, 62, 63, 68, 72, 84, 89], "anoth": [9, 20, 39, 49, 54, 56, 62, 77, 79, 84, 88, 111], "answer": [1, 2, 3, 12, 13, 22, 23, 27, 32, 41, 43, 44, 50, 57, 60, 62, 66, 67, 68, 72, 83, 90, 95, 98, 99, 100, 103, 106, 111], "answer_1": 63, "anthrop": [25, 76], "anticip": 67, "anyio": 25, "anywher": [15, 78], "aop": 72, "api": [3, 4, 7, 15, 19, 25, 41, 66, 78], "apicod": 7, "apiretriev": 7, "app": 83, "appear": [37, 51, 56, 72, 111], "append": [30, 41, 42, 64, 65, 80, 83, 87, 98], "appli": [9, 11, 12, 15, 26, 33, 40, 45, 50, 55, 56, 57, 58, 60, 63, 64, 65, 68, 71, 72, 74, 76, 77, 78, 79, 82, 88, 90, 91, 95, 99, 106, 109, 110, 111, 116], "applic": [8, 14, 15, 27, 57, 62, 110, 111], "apply_chat_templ": 80, "apply_rotary_emb": [64, 65, 111], "approach": [5, 7, 9, 26, 30, 40, 41, 42, 49, 51, 55, 57, 59, 60, 62, 63, 67, 71, 72, 74, 79, 82, 84, 85, 89, 90, 91, 95, 98, 99, 109, 110, 111], "appropri": [2, 11, 20, 39, 57, 82], "approx": [51, 60, 110, 114], "approxim": [13, 14, 18, 49, 58, 59, 63, 76, 88, 91, 100, 103, 106, 109, 111], "aptitud": 27, "ar": [2, 3, 5, 7, 11, 12, 13, 14, 15, 18, 19, 20, 21, 24, 26, 27, 30, 31, 33, 38, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87, 88, 89, 90, 93, 100, 101, 103, 106, 109, 110, 111, 112, 113, 115, 118], "arang": [24, 64, 65, 74, 111], "arbitrari": [15, 111], "archit": [47, 101], "architectur": [12, 13, 51, 54, 57, 67, 109, 111, 112, 113, 115, 120], "archiv": 13, "area": [23, 66], "arg": [62, 64, 65, 73, 80, 87, 111], "argmax": 64, "argu": [59, 87], "ariel": [47, 101], "aris": [83, 84], "arithmet": 27, "armando": [47, 101], "armo": 35, "armorm": 50, "around": [11, 18, 112], "arrang": 25, "art": [9, 14, 27, 52, 61, 72], "articl": 13, "artifici": 73, "arvind": [47, 101], "arxiv": [26, 30, 33, 40, 42, 45, 47, 61, 101], "ascent": 82, "ascertain": 76, "ascii\u5c31\u662f\u6700\u521d\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 118, "ascii\u8d77\u521d\u53ea\u89c4\u5b9a\u4e86127\u4e2a\u5b57\u7b26": 118, "ashish": [47, 101], "ask": [1, 8, 9, 15, 19, 20, 28, 30, 39, 42, 56, 62, 63, 78, 84, 90], "askel": [47, 101], "aspect": [56, 66, 79, 89], "assert": [57, 64, 65, 111], "assertionerror": [64, 111], "assess": [2, 5, 23, 24, 27, 33, 45, 63, 67, 68, 86, 98], "assign": [11, 49, 54, 62, 63, 71, 72, 76, 77, 79, 82, 87, 88, 91, 99, 100, 109], "assist": [7, 20, 39, 52, 57, 64, 83, 85, 89, 90], "associ": [57, 72, 87], "assum": [12, 49, 75, 79, 87, 89, 90, 91, 99, 113, 117], "ast": [9, 73, 74, 87, 99, 115], "asymptot": 27, "async": 25, "atcod": [25, 38], "atol": [64, 113], "atom": 3, "att": 109, "attach": 71, "attain": 76, "attempt": [1, 9, 52, 98, 99, 100], "attend": 11, "attent": [12, 13, 14, 34, 35, 47, 51, 59, 60, 66, 68, 75, 101, 109, 110, 111, 113, 114, 115], "attention_bia": 59, "attention_norm": [64, 65], "attn": 51, "attr": 25, "attract": 111, "attribut": [31, 55, 85], "audio": [7, 20, 39], "augment": [2, 89], "auli": [47, 101], "auth": 25, "authent": 79, "author": [74, 89], "auto": [11, 18], "autom": [30, 38, 41, 42, 66], "automat": [1, 3, 7, 8, 9, 18, 26, 30, 33, 40, 42, 45, 63, 67, 68, 71, 85, 109], "autonom": [1, 5, 95], "autoregress": [12, 14, 49, 57, 62, 110], "auxiliari": [12, 52, 54, 60, 99], "avail": [2, 32, 57, 61, 63, 66], "avenu": 15, "averag": [3, 24, 31, 54, 55, 64, 65, 77, 84, 98, 109], "avg": 72, "avoid": [8, 15, 49, 52, 54, 55, 56, 72, 75, 77, 82, 87, 88, 110], "await": [33, 45], "ax": 63, "axi": [64, 113], "b": [12, 47, 49, 51, 64, 65, 76, 83, 90, 98, 99, 101, 110, 116, 120], "b_": [64, 65, 116], "b_1": 11, "b_2": 11, "b_i": 60, "b_j": 60, "babuschkin": [47, 101], "backbon": 71, "backend": 22, "background": 24, "backpropag": 62, "backtransl": 63, "backward": 51, "bad": [49, 52, 63], "bag": 62, "bai": [47, 101], "baker": [47, 101], "balaji": [47, 101], "balanc": [11, 60, 63, 67, 68, 72, 90], "band": 14, "bank": 3, "bao": [47, 101], "baosong": [47, 101], "baptist": [47, 101], "bar": 110, "barn": [47, 101], "basart": [47, 101], "base": [1, 2, 5, 7, 9, 11, 12, 13, 15, 19, 20, 26, 27, 30, 33, 35, 39, 40, 41, 42, 45, 48, 49, 52, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 68, 71, 74, 76, 77, 78, 79, 83, 87, 88, 89, 90, 91, 98, 99, 106, 110, 111, 114, 115, 118, 119], "baselin": [18, 27, 50, 72, 89, 90, 100], "basi": [64, 111], "basic": [27, 28, 34, 56, 66, 67], "basu": [47, 101], "batch": [15, 20, 39, 41, 51, 57, 61, 62, 63, 64, 68, 72, 76, 78, 103, 112], "batchnorm1d": [64, 113], "batchnorm2d": 64, "bavarian": [47, 101], "bax": 120, "bbc": [47, 66, 101], "bbpe": [59, 66], "becaus": [11, 20, 30, 39, 42, 56, 63, 71, 83, 95, 113], "becom": [75, 84, 99, 109, 111, 112], "been": [3, 5, 31, 49, 55, 56, 59, 60, 64, 66, 76, 77, 88, 91], "befor": [2, 30, 37, 42, 52, 54, 58, 62, 67, 85, 110, 111], "begin": [1, 2, 11, 12, 13, 15, 51, 57, 60, 62, 63, 64, 65, 68, 72, 73, 74, 75, 76, 77, 78, 83, 87, 91, 95, 109, 110, 111, 112, 114, 115, 116], "begin_of_text": 64, "behav": [52, 55, 111], "behavior": [13, 15, 27, 49, 52, 55, 56, 67, 72, 73, 83, 95, 111, 113], "behaviour": 54, "behind": 111, "bei": [47, 101], "beichen": [47, 101], "being": [11, 14, 26, 40, 47, 54, 63, 91], "believ": 71, "belong": 109, "below": [20, 26, 39, 40, 52, 57, 75, 82, 88], "bench": [9, 34], "benchmark": [2, 3, 9, 13, 14, 21, 32, 33, 43, 45, 47, 52, 58, 59, 63, 98, 101, 112], "benefici": [11, 56, 68, 88], "benefit": [8, 13, 62, 88, 106], "benfeng": [47, 101], "benjamin": [47, 101], "berner": [47, 101], "bert": [13, 47, 101], "besid": [68, 72, 73], "best": [3, 15, 27, 41, 50, 51, 54, 55, 56, 61, 62, 63, 67, 73, 76, 78, 88, 89, 91, 98, 99, 100], "bestof": 50, "beta": [15, 62, 64, 74, 75, 77, 78, 82, 87, 110, 113, 116], "beta_": [61, 99], "beta_1": 103, "beta_2": 103, "better": [15, 23, 52, 55, 56, 58, 60, 61, 62, 63, 66, 67, 75, 82, 83, 84, 87, 90, 98, 100, 106, 112], "between": [7, 11, 15, 20, 23, 26, 27, 39, 40, 44, 49, 50, 52, 54, 55, 57, 59, 62, 63, 64, 65, 72, 74, 75, 77, 78, 82, 83, 84, 87, 88, 89, 95, 99, 100, 106, 109, 110, 113, 114, 115, 116], "beyond": [25, 52, 84, 109, 111], "bf16": [80, 119], "bi": [47, 101], "bia": [59, 60, 64, 65, 66, 68, 71, 84, 90, 99, 116], "bias": [30, 42, 49], "bib": 47, "bibliographi": 47, "bibtex": 47, "bidirect": [47, 101], "bigger": [15, 110], "biggest": 55, "bilinear": 116, "billion": [14, 68], "bin": [47, 101], "binari": [5, 62, 63, 73, 84, 88], "bing": [47, 101], "bingxuan": [47, 101], "binom": [15, 24, 78, 98], "binyuan": [47, 101], "biologi": [23, 27], "bit": [76, 110], "black": 51, "bleu": 49, "blind": 23, "block": [12, 13, 22, 48, 57, 109], "blog": [15, 47, 67, 77, 81, 101], "blue": [33, 45], "bm25": [7, 31], "bmr": [14, 15, 47, 101], "bn": [64, 113], "bo": [47, 64, 101], "bob": [47, 101], "bodi": [24, 118], "bofei": [47, 101], "boltzmann": 76, "bonu": 99, "book": [13, 47, 48, 61], "bool": 64, "bootstrap": [26, 30, 40, 42, 52], "bos_id": 64, "both": [2, 8, 11, 14, 18, 21, 23, 26, 27, 40, 47, 50, 54, 57, 60, 62, 63, 66, 67, 68, 77, 78, 79, 83, 84, 85, 89, 91, 99, 100, 110, 111, 112, 113], "boto3": 25, "botocor": 25, "bottleneck": 112, "bottom": [11, 88], "bound": [50, 82, 109, 111], "boundari": [26, 30, 40, 42, 110], "bowen": [47, 101], "box": [27, 47, 60, 95], "boyang": [47, 101], "bpe": [13, 57, 61], "bpe\u6bcf\u4e00\u6b65\u90fd\u5c06\u6700\u5e38\u89c1\u7684\u4e00\u5bf9\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u66ff\u6362\u4e3a\u8be5\u6570\u636e\u4e2d\u6ca1\u6709\u51fa\u73b0\u8fc7\u7684\u4e00\u4e2a\u65b0\u5355\u4f4d": 108, "bpe\u9009\u62e9\u9891\u6570\u6700\u9ad8\u7684\u76f8\u90bb\u5b50\u8bcd\u5408\u5e76": 117, "bradlei": [15, 71, 74, 87, 88], "brahma": [47, 101], "brainstorm": 90, "branch": 63, "breadth": [23, 33, 45], "break": [9, 30, 42, 64, 87], "breviti": [109, 112], "bridg": [23, 49, 67], "brief": [14, 19], "bright": 27, "bring": 77, "broad": [30, 42, 68], "broadcast": 111, "broader": [23, 25], "broadli": [14, 68], "brockman": [47, 101], "brook": [47, 101], "brown": [47, 101], "brundag": [47, 101], "brute": 56, "bsz": [64, 65], "bt": 87, "bucket": 63, "budget": [54, 55, 57, 61, 66, 68, 98, 109], "buffer": [76, 80], "bug": [1, 9, 19, 31, 56, 80], "build": [1, 8, 9, 13, 23, 25, 47, 50, 58, 63, 64, 66, 67, 71, 85, 89, 90], "built": [5, 8, 48, 59, 62, 67], "bullet": 56, "burda": [47, 101], "burden": 77, "burn": [47, 101], "busi": 23, "byte": [13, 47, 57, 59, 61, 66, 68, 101], "bzip2": 25, "c": [12, 21, 24, 51, 54, 55, 59, 62, 63, 64, 65, 67, 73, 76, 88, 110, 111, 112, 113, 116], "c4": 61, "c_": [51, 59], "ca": 25, "cach": [22, 64, 65, 66, 72], "cache_k": [64, 65], "cache_len": [64, 65], "cache_v": [64, 65], "cachecontrol": 25, "cachetool": 25, "cai": [47, 83, 101], "caichat": 80, "calcul": [2, 7, 24, 27, 59, 64, 65, 72, 76, 77, 82, 83, 84, 88, 106, 109, 111, 113], "calibr": [50, 83], "call": [2, 3, 5, 8, 11, 13, 14, 15, 19, 24, 33, 45, 47, 49, 52, 56, 60, 62, 63, 64, 78, 79, 83, 87, 93, 100, 111, 112, 116], "can": [2, 3, 7, 8, 11, 12, 14, 15, 19, 24, 25, 26, 27, 30, 31, 40, 41, 42, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 63, 66, 67, 68, 71, 72, 74, 75, 76, 77, 78, 79, 82, 83, 84, 87, 88, 89, 90, 91, 95, 98, 100, 101, 106, 109, 110, 111, 112, 113, 115, 116, 117], "cancel": 74, "candid": [9, 31, 54, 55, 63, 67, 68, 76, 84, 87, 89, 91, 106], "cannot": [19, 20, 27, 39, 49, 52, 111, 112], "canon": 84, "capabl": [2, 18, 19, 25, 26, 27, 33, 40, 41, 44, 45, 50, 52, 57, 60, 62, 66, 67, 68, 79, 89, 95, 111], "capac": [12, 76, 109], "captur": [88, 95, 109], "cardin": [55, 76], "care": [52, 63, 98], "carefulli": [23, 59, 63, 66, 68, 103], "carlo": [49, 77], "carr": [47, 101], "carri": [60, 112], "carrol": [47, 101], "cascad": 57, "case": [7, 15, 20, 26, 28, 30, 37, 38, 39, 40, 41, 42, 49, 54, 55, 56, 57, 58, 60, 62, 67, 68, 72, 73, 75, 79, 83, 91, 95, 98, 109, 110], "cast": 64, "catastroph": 111, "catch": 63, "categor": [55, 63, 67, 88, 90], "categori": [8, 18, 68, 90], "caus": [23, 64, 74, 75, 85, 109], "causal": [12, 57], "cd": [22, 25], "cdot": [11, 59, 72, 74, 75, 79, 87, 99, 109, 110, 115, 116], "ce": 76, "ceas": 51, "ceil": 52, "cell": 64, "central": 88, "centroid": 109, "certain": [12, 49, 60, 63, 72, 90, 91, 109, 110, 111], "certif": 25, "certifi": 25, "cffi": 25, "cfg": 22, "cgrs19": [14, 47, 101], "chai": [47, 101], "chain": [5, 7, 23, 60, 83, 84, 90, 106], "chainof": 106, "challeng": [2, 18, 19, 20, 23, 27, 32, 39, 43, 52, 56, 63, 66, 67, 68, 72, 74, 88, 90, 95, 100], "chan": [47, 101], "chanc": [23, 56], "chang": [8, 20, 25, 31, 39, 47, 73, 85, 99, 101], "changhan": [47, 101], "changyu": [47, 101], "channel": [25, 64], "chantzi": [47, 101], "charact": [56, 57, 118], "character": [51, 59, 66], "characterist": [7, 33, 45, 59], "charset": [25, 118], "chat": [19, 47, 58, 59, 62, 64, 68, 101], "chat_complet": 64, "chatbot": 18, "chatgpt": [26, 40, 52], "cheaper": 18, "check": [9, 15, 19, 28, 38, 41, 57, 63, 66, 67, 98, 99, 100], "checker": 8, "checklist": [67, 68], "checkpoint": [47, 58, 60, 62, 63, 64, 66, 80, 95, 101], "chelsea": [47, 101], "chemistri": [23, 27], "chen": [47, 101], "chenggang": [47, 101], "chengpeng": [47, 101], "chengqi": [47, 101], "chengqiang": [47, 101], "chengyuan": [47, 101], "chess": [47, 52, 101], "child": [47, 101], "chines": 59, "cho": [47, 101], "choic": [12, 23, 27, 41, 49, 62, 75, 76, 83, 87, 100, 115], "chong": [47, 101], "choos": [31, 33, 45, 54, 56, 62, 83, 88, 90, 98, 100, 110], "chose": 11, "chosen": [51, 62, 63, 71, 88], "chosen_1": 63, "chosen_2": 63, "christiano": [47, 101], "christoph": [47, 101], "chu": [47, 101], "chuanqi": [47, 101], "chunqiu": [47, 101], "ci": 111, "cite": 47, "ckb": [27, 47, 101, 106], "ckpt_dir": 64, "ckpt_path": 64, "cl": [26, 40], "clamp": 83, "clarifi": 51, "clariti": [60, 67], "clark": [47, 101], "class": [1, 9, 25, 30, 42, 59, 64, 65, 75, 113], "classic": 82, "classif": [12, 20, 39, 52, 63, 88, 98, 100], "classifi": [25, 54, 63, 67, 79, 90, 98], "claud": [58, 98], "clean": [41, 58, 62, 63, 67], "clear": [67, 80, 88, 111], "clearli": [56, 58], "clemen": [47, 101], "cleo": 25, "clever": 74, "cli": [22, 80], "client": 25, "clip": [61, 77], "clone": [22, 25], "close": [1, 5, 26, 40, 49, 55, 56, 58, 60, 64, 83], "closer": 87, "closest": 56, "cluster": 63, "cly": [47, 67, 101], "cnn": 13, "co": [11, 57, 64, 65, 110, 111, 114, 115], "coars": [63, 67], "cobb": [47, 101], "code": [1, 3, 7, 8, 9, 21, 24, 25, 26, 31, 32, 34, 35, 38, 40, 41, 43, 44, 47, 48, 50, 52, 54, 55, 58, 59, 60, 61, 66, 67, 68, 90, 95, 101, 118], "code1": 25, "code2": 25, "code_alpaca_20k": [20, 39], "code_generation_lit": 25, "code_list": 25, "codealpaca": [20, 26, 34, 35, 39, 40], "codebas": [1, 9, 31], "codebert": 67, "codecontest": [54, 55], "codeforc": [25, 37, 38, 54, 55], "codegen": 22, "codegener": 25, "codellama": [26, 40], "codenet": 37, "codeqwen1": 67, "coder": [26, 34, 35, 40, 41, 47, 60, 66, 101, 119], "codewar": 38, "codex": [24, 34, 57], "coeffici": [15, 71, 74, 78, 82, 111], "cognit": 95, "coher": [25, 84], "collabor": 67, "collaps": 72, "collect": [13, 15, 25, 26, 30, 31, 40, 41, 42, 57, 59, 61, 63, 64, 67, 68, 78, 79, 80, 83, 90, 91, 95, 106], "collin": [47, 101], "colon": 85, "com": [22, 25], "combin": [1, 4, 7, 9, 13, 15, 20, 26, 39, 40, 41, 55, 56, 57, 60, 62, 63, 67, 68, 72, 78, 79, 84, 86, 87, 95, 109, 110], "come": [11, 15, 20, 30, 39, 42, 58, 110, 111], "command": [8, 25, 48], "commbal": 109, "comment": [57, 63, 67], "commit": 9, "common": [13, 15, 25, 49, 56, 58, 63, 67, 71, 76, 109], "commoncrawl": 61, "commonli": [2, 26, 40, 41], "commonmark": 47, "commun": [41, 60, 95, 103, 118], "commut": 112, "compact": 8, "compar": [3, 7, 18, 23, 41, 49, 50, 58, 60, 63, 66, 67, 68, 72, 75, 76, 77, 79, 89, 91, 98, 99, 100, 116], "comparison": [15, 50, 57, 58, 59, 65, 78, 79, 83, 87, 88], "compat": [11, 57, 111, 113], "compet": [14, 63], "competit": [11, 14, 25, 27, 37, 54, 55, 60, 72, 98], "competitor": 15, "compil": [7, 58, 59, 60, 63, 95], "complementari": 60, "complet": [1, 7, 15, 19, 20, 24, 33, 39, 41, 45, 50, 56, 57, 60, 62, 63, 64, 67, 74, 75, 78], "complex": [1, 3, 8, 9, 12, 19, 23, 26, 33, 40, 45, 52, 57, 63, 64, 65, 66, 67, 68, 77, 82, 93, 95, 110, 111, 115], "complex64": [64, 65, 111], "compli": 55, "complic": [33, 45, 52, 77], "compon": [5, 41, 55, 62, 64, 65, 66, 88, 89, 116], "compos": [11, 27, 109], "composit": [3, 63], "comprehens": [2, 13, 19, 24, 33, 45, 60, 66, 68, 79, 82], "compress": [59, 108], "compris": [23, 59, 60, 63, 66, 67, 76, 109], "comput": [11, 21, 23, 24, 41, 52, 55, 57, 61, 62, 64, 65, 66, 67, 73, 76, 77, 82, 83, 84, 86, 95, 98, 100, 109, 110, 111, 112, 113, 115, 116, 118], "concat": 11, "concaten": [11, 30, 42, 62, 84, 99], "concept": [57, 67], "concis": [8, 60, 66, 76], "conclud": 59, "conclus": [59, 112], "concret": [33, 45, 72, 99], "concurr": 56, "conda": 25, "condit": [2, 5, 12, 30, 42, 49, 54, 79], "conduct": [7, 55, 59, 63, 73, 79, 84, 87, 100, 111], "conduct_rejection_sampl": 87, "confer": [47, 79, 101], "confid": [52, 83, 91], "config": [59, 109], "configur": [50, 59], "confin": 62, "conform": 63, "confus": 72, "conjug": 115, "conjunct": 8, "connect": 11, "consecut": [26, 40, 55], "consequ": [63, 79], "consid": [3, 24, 31, 49, 52, 63, 67, 68, 71, 72, 75, 76, 79, 83, 84, 87, 88, 90, 110, 111], "consider": [58, 72, 79], "consist": [1, 2, 11, 12, 15, 21, 23, 26, 27, 31, 37, 38, 40, 52, 57, 58, 59, 67, 71, 72, 74, 78, 82, 91, 95, 106, 109, 113], "console_script": 22, "consolid": [3, 109], "constant": [2, 49, 72, 109, 110, 115, 116], "constitut": 73, "constrain": [3, 72, 74, 82, 87, 98], "constraint": [33, 45, 56, 62], "construct": [2, 9, 18, 21, 33, 44, 45, 57, 58, 67, 68, 73, 79, 85, 87, 89, 95, 109], "consum": [11, 91], "contain": [1, 2, 3, 11, 13, 15, 18, 19, 20, 22, 23, 26, 27, 28, 30, 31, 39, 40, 41, 42, 52, 54, 55, 56, 57, 59, 61, 62, 63, 64, 67, 72, 73, 85, 98, 100, 106, 111, 112], "container": 63, "contamin": [25, 31, 47, 101], "content": [1, 7, 20, 39, 41, 47, 48, 64, 79, 83], "contest": [25, 55], "context": [5, 7, 8, 12, 13, 19, 20, 30, 31, 39, 41, 42, 49, 51, 59, 63, 68, 71, 77, 79, 83, 84, 85, 109, 115], "context_messag": 80, "contextu": 41, "contextwindow": 60, "contigu": [12, 64, 65], "continu": [2, 7, 11, 15, 25, 26, 27, 31, 40, 56, 63, 67, 71, 77, 78, 83, 87, 88], "contrast": [14, 23, 49, 56, 85, 91, 111], "contribut": [31, 41, 72, 82, 88], "control": [3, 7, 15, 52, 64, 68, 74, 78, 84, 98], "convei": 79, "convent": 112, "converg": [12, 109, 113], "convers": [51, 63, 64, 72, 83, 111], "convert": [7, 11, 48, 84, 87], "convinc": 100, "convolut": [11, 47, 101], "cookbook": 41, "coordin": 110, "copi": 24, "core": [5, 13, 18, 25, 52, 112], "corpora": [41, 67], "corpu": [12, 14, 26, 40, 58, 59, 60, 67, 76, 111], "corr": 71, "correct": [2, 3, 7, 8, 19, 28, 34, 35, 41, 47, 49, 54, 55, 56, 57, 60, 63, 66, 67, 71, 72, 73, 75, 79, 90, 95, 98, 100, 101, 106], "correctli": [27, 56, 68, 91, 99, 111], "correl": [14, 18, 71, 79, 89, 106], "correspond": [9, 11, 15, 19, 27, 30, 33, 41, 42, 45, 49, 55, 56, 57, 58, 60, 64, 65, 71, 73, 74, 77, 79, 87, 111, 114, 115], "correspondingli": 77, "cosin": [11, 41, 61, 63, 119], "cost": [20, 39, 58, 60, 109], "costli": 109, "cot": [7, 23, 34, 35, 72, 83, 84, 95], "could": [50, 52, 54, 55, 63, 71, 73, 82, 88, 91, 98, 111], "count": [24, 41, 98], "counteract": [11, 63], "counterclockwis": 114, "counterpart": [62, 63], "coupl": [60, 99], "cover": [23, 56, 63, 67, 68, 89, 109], "coverag": [30, 42, 58, 66, 84, 91], "cpu": 64, "cr": 76, "crack": 35, "craft": 76, "crashtest": 25, "crawl": [9, 13, 58, 67], "creat": [9, 13, 15, 20, 25, 27, 30, 31, 33, 39, 41, 42, 45, 52, 57, 58, 63, 66, 67, 85, 89], "creation": 56, "creativ": [52, 60], "credit": [49, 82], "criteria": [62, 63, 66, 68, 85, 98], "critic": [54, 58, 66, 77, 80, 82, 99], "critic_learning_r": 80, "critiqu": [34, 35, 79], "crmsnorm": [47, 101], "cross": [19, 31, 51, 54, 63, 73, 76, 84], "cross_entropi": 64, "crowd": 28, "crowdwork": 83, "crucial": [5, 41, 58, 59, 67, 68], "crux": 35, "cruxev": [47, 101], "cryptographi": 25, "ctj": [24, 47, 101], "ctx": 51, "cu12": 25, "cubla": 25, "cuda": [25, 64], "cudnn": 25, "cufft": 25, "cui": [47, 101], "cum": [47, 101], "cumbersom": 76, "cumsum": 64, "cumul": [64, 82], "cup": 106, "cupti": 25, "cur_po": 64, "curand": 25, "curat": [3, 23, 37, 38, 41, 54, 59, 60, 63, 67, 68, 71, 95, 103], "curiou": [18, 88], "current": [1, 2, 5, 7, 9, 13, 14, 15, 20, 32, 33, 39, 41, 45, 49, 66, 76, 77, 78, 87, 90, 98, 100, 110, 112], "curv": [51, 62], "cusolv": 25, "cuspars": 25, "custom": [15, 68], "custom_evalu": 25, "custom_output_fil": 25, "cut": [64, 79], "cutoff_len": 119, "cycl": 63, "d": [15, 22, 33, 45, 47, 48, 49, 51, 57, 62, 64, 65, 71, 72, 74, 75, 76, 77, 78, 84, 85, 86, 87, 88, 91, 99, 101, 106, 108, 109, 110, 111, 112, 114, 115, 120], "d_": [11, 15, 44, 51, 59, 62, 78, 87, 88, 112, 116], "d_c": [59, 112], "d_h": [59, 112], "d_k": 11, "d_v": 11, "dab": [47, 59, 101], "dai": [47, 101], "daili": [2, 13], "dalf": [47, 58, 59, 60, 101, 109, 112], "damai": [47, 101], "dan": [47, 101], "dang": [47, 101], "danger": 83, "daniel": [47, 101], "dario": [47, 101], "data": [3, 7, 9, 12, 13, 14, 15, 26, 31, 33, 34, 35, 37, 38, 40, 45, 49, 50, 52, 57, 66, 68, 71, 73, 74, 76, 77, 78, 79, 83, 85, 86, 87, 89, 90, 91, 95, 99, 108, 111, 113], "databas": 7, "dataclass": [64, 65], "datalabel": 100, "dataset": [2, 9, 12, 20, 22, 23, 24, 25, 26, 27, 28, 32, 33, 35, 39, 40, 41, 43, 44, 45, 52, 55, 58, 59, 60, 61, 62, 63, 66, 67, 68, 71, 76, 77, 79, 86, 87, 88, 89, 91, 95, 98, 99, 100, 106, 119], "date": 41, "dateutil": 25, "dauphin": [47, 101], "dave": [47, 101], "david": [47, 101], "davinci": [20, 39], "dawn": [47, 101], "daya": [47, 101], "dayiheng": [47, 101], "dclt19": [13, 47, 101], "ddot": [114, 115], "de": [47, 57, 101], "deal": 90, "debat": 59, "debias": 66, "debug": [33, 45, 63, 67], "debugg": 71, "decad": 27, "decai": [61, 103, 111, 115], "decid": [1, 58, 67, 89, 95, 100, 109], "decis": [5, 7, 49, 56, 71], "declar": 1, "declin": [33, 45, 59], "decod": [13, 20, 26, 39, 40, 50, 54, 64, 66, 71, 84, 98, 106], "decompos": 62, "decomposit": 120, "decoupl": [59, 60, 72], "decreas": [23, 50, 51, 60, 72, 74, 75, 79, 87, 109], "dedic": 109, "deduc": 99, "dedupl": [15, 41, 57, 58, 63, 106], "deem": 90, "deep": [47, 101], "deepen": [33, 45], "deepseek": [26, 34, 35, 40, 47, 72, 77, 101, 109, 112, 119], "deepseekcod": [60, 119], "deepseekmath": 58, "deepseekmo": [59, 60], "deepseekv2attent": 59, "deepseekv2config": 59, "deepseekv2forcausallm": 59, "deepseekv2mlp": 59, "deepseekv2model": 59, "deepseekv2pretrainedmodel": 59, "deepseekv2rmsnorm": 59, "deepspe": 119, "def": [22, 24, 59, 64, 65, 87, 111, 113], "default": [18, 25, 48, 64, 68, 72, 111], "defin": [2, 3, 30, 41, 42, 48, 49, 51, 52, 62, 63, 64, 65, 66, 67, 68, 73, 74, 82, 89, 106, 110, 111, 114, 115, 116], "definit": [44, 110], "degener": 74, "degrad": [60, 63], "degre": [14, 62], "dejian": [47, 101], "deli": [47, 101], "deliber": 100, "delimit": [12, 98], "deliv": 63, "delta": [49, 62, 120], "delta_": [77, 82], "delta_t": 82, "demonstr": [2, 3, 5, 12, 13, 14, 15, 19, 23, 49, 50, 60, 66, 67, 72, 76, 78, 79, 88, 93, 95, 103, 110, 111, 112], "deng": [47, 101], "dengr": [47, 101], "denni": [47, 101], "denomin": 49, "denot": [44, 49, 51, 54, 57, 71, 73, 75, 76, 82, 87, 88, 99, 109, 112, 113, 115], "dens": [7, 14, 63, 66, 68, 112], "densifi": 60, "densiti": 87, "depend": [12, 14, 25, 41, 47, 51, 64, 65, 74, 76, 79, 91, 98, 110, 111, 113, 114, 115], "depict": [13, 83, 95], "deploi": [63, 109], "deploy": 112, "depth": [33, 45], "deriv": [49, 57, 60, 87, 89, 111], "descend": 64, "descent": 12, "describ": [11, 12, 20, 31, 39, 56, 63, 84, 89, 110], "descript": [1, 28, 31, 44, 54, 55, 56, 63, 85], "description2cod": 37, "design": [7, 19, 23, 28, 32, 41, 43, 44, 60, 66, 68, 75, 83, 85, 95, 100, 109, 112], "desir": [15, 49, 63, 79, 85, 87], "despit": [9, 14, 52, 60, 78, 79, 82], "destabil": 82, "detail": [1, 13, 48, 55, 56, 63, 65, 66, 67, 77, 79, 81, 82], "detect": [8, 30, 42, 54, 63, 66, 79], "determin": [60, 63, 66, 67, 73, 76, 91], "determinist": [50, 60, 95], "detoken": 117, "devbal": 109, "develop": [1, 2, 8, 41, 52, 57, 60, 66, 68, 73, 83, 87, 90, 95, 98, 99], "deviat": [50, 64, 74, 77, 82, 88], "devic": [60, 64, 65, 111, 118], "devis": [9, 26, 27, 40], "devlin": [47, 101], "dfag17": [47, 66, 101], "dhariw": [47, 101], "diagon": [57, 64, 65], "dialog": [64, 68], "dialogu": [2, 7, 57, 62, 63], "diamond": 27, "dict": 64, "dictionari": [20, 39, 87], "did": [67, 84], "diff": 9, "differ": [3, 7, 9, 11, 14, 15, 20, 21, 23, 30, 39, 42, 47, 49, 50, 52, 54, 55, 56, 57, 59, 61, 62, 63, 65, 66, 67, 72, 74, 75, 76, 77, 78, 79, 80, 83, 85, 87, 100, 106, 109, 110, 112, 114, 115], "differenti": 85, "difficult": [27, 52, 56, 106], "difficulti": [23, 27, 32, 33, 41, 43, 45, 55, 63, 67, 98], "digit": 7, "dill": 25, "dim": [64, 65, 111, 113], "dimens": [11, 51, 57, 59, 64, 65, 71, 75, 109, 110, 111, 112, 113, 115, 116], "dimension": [7, 11, 71, 114, 115], "diminish": [79, 106], "ding": [47, 101], "diogo": [47, 101], "direct": [14, 23, 27, 33, 45, 48, 56, 66, 67, 79, 84, 85, 86, 87, 95, 101], "directli": [7, 12, 19, 24, 26, 40, 50, 57, 58, 63, 68, 72, 74, 77, 82, 84, 87, 98, 99, 110, 111, 115, 117], "directori": 64, "disagr": 63, "disagre": 90, "disallowed_speci": 64, "disallowed_token": 64, "disanalogi": 52, "discard": [20, 39, 63, 67, 90], "discontinu": [33, 45], "discount": 82, "discrep": [49, 54, 62, 88], "discret": [4, 62], "discrimin": [12, 54], "discuss": [57, 83, 100, 115], "disjoint": 31, "displai": [48, 79], "dispref": [74, 75], "disproportion": [63, 72], "distanc": [75, 111], "distil": [26, 40, 62, 85, 91], "distinct": [2, 5, 59, 60, 66, 68, 76, 79, 88, 106], "distinguish": [73, 76, 87], "distlib": 25, "distort": 113, "distract": 82, "distribut": [12, 14, 15, 33, 41, 45, 49, 54, 57, 60, 62, 64, 71, 72, 74, 76, 77, 78, 82, 83, 84, 87, 88, 90, 91, 95, 98, 99, 100, 109], "distro": 25, "div_": 64, "diverg": [15, 62, 68, 74, 77, 82], "divers": [12, 13, 15, 19, 20, 23, 30, 31, 32, 33, 39, 41, 42, 43, 45, 50, 54, 55, 56, 57, 60, 63, 66, 67, 68, 89, 90, 95, 98], "divid": [2, 7, 11, 54, 56, 66, 68, 77, 114, 115], "divis": 55, "dkv": 112, "do": [1, 14, 20, 21, 26, 30, 31, 39, 40, 42, 47, 49, 52, 55, 56, 58, 62, 63, 64, 65, 68, 78, 90, 95, 98, 99, 100, 110, 112], "do_train": 119, "docker": 9, "docstr": [9, 19, 24, 57], "doctyp": 118, "document": [7, 12, 13, 26, 31, 40, 47, 48, 57, 63, 67, 111], "doe": [1, 15, 30, 42, 57, 60, 64, 67, 74, 82, 88, 106, 111, 112, 113], "doesn": 111, "domain": [2, 13, 23, 27, 33, 45, 49, 60, 66, 68, 73, 95, 98], "domin": 49, "don": 82, "done": [33, 45, 67], "dong": [47, 101], "dongji": [47, 101], "dot": [12, 49, 64, 65, 67, 75, 77, 79, 86, 89, 90, 109, 110, 111, 112, 114, 115, 117], "doubl": [56, 76, 106], "down": [55, 110, 111, 113], "down_proj": 59, "downstream": [7, 14, 63, 120], "dpo": [34, 35, 50, 63, 66, 67, 80, 87, 89, 90], "dpop": [34, 63], "dq": 112, "dr": 13, "draw": [7, 26, 40, 87], "drawback": 95, "drawn": [66, 76], "drive": 54, "driven": [7, 68], "drop": [23, 60], "drop_last": 80, "dschat": 80, "dtype": [64, 65], "du": [47, 101], "duan": [47, 101], "due": [41, 56, 60, 67, 71, 72, 109, 111, 113], "dulwich": 25, "duplic": 57, "dure": [3, 7, 11, 12, 20, 23, 32, 39, 41, 49, 51, 54, 57, 58, 60, 62, 63, 66, 67, 68, 72, 74, 82, 83, 95, 100, 103, 106, 109, 111, 112, 113], "dynam": [63, 79], "dz": 76, "e": [1, 2, 3, 4, 12, 15, 20, 21, 22, 24, 25, 26, 30, 39, 40, 42, 49, 52, 60, 62, 63, 64, 65, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87, 88, 89, 90, 95, 98, 99, 108, 109, 110, 111, 113], "e501": 64, "e_": 90, "e_j": 106, "each": [1, 3, 8, 9, 11, 12, 13, 15, 18, 20, 23, 24, 26, 27, 28, 30, 31, 32, 33, 38, 39, 40, 41, 42, 43, 45, 49, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 72, 73, 75, 76, 77, 78, 82, 83, 84, 85, 86, 87, 88, 89, 90, 98, 99, 100, 106, 109, 110, 111, 112, 113, 120], "earli": [83, 98], "earlier": [15, 62, 63, 83, 98], "easi": [8, 18, 19, 49, 52, 56, 57, 67, 80, 87], "easier": [12, 52, 56, 72, 87, 111], "easili": [11, 21, 26, 40, 54, 68], "eason": 21, "echo": [64, 106], "econom": [23, 47, 59, 60, 101], "ecosystem": [9, 47], "ecut": 21, "edg": 67, "edit": [1, 8, 9, 20, 28, 31, 39, 56, 63, 75, 99], "editor": [8, 57], "educ": [41, 67], "edward": [47, 101], "ee": [34, 35], "effect": [2, 7, 8, 11, 26, 32, 40, 41, 52, 56, 58, 60, 66, 72, 73, 75, 77, 82, 84, 87, 88, 89, 103, 106, 111, 114, 115], "effici": [8, 12, 47, 55, 59, 60, 66, 68, 77, 82, 100, 101, 109, 112], "effort": [41, 58, 59, 60, 91], "eft": 89, "either": [3, 20, 39, 55, 59, 62, 63, 68, 79, 82, 99, 100], "electron": 118, "element": [11, 15, 57, 78, 111, 112, 114, 115], "elementari": [23, 27], "elev": 59, "elicit": [52, 76, 83, 84], "elimin": [31, 33, 45, 82], "elizabeth": [47, 101], "elment": 64, "elo": 83, "els": [59, 64, 65, 83, 91, 111], "em": 5, "embed": [1, 12, 47, 57, 59, 61, 64, 65, 66, 68, 101, 114], "embed_token": 59, "emerg": 93, "emit": [3, 75], "emphas": [13, 68, 99], "empir": [13, 49, 52, 106, 110, 111], "emploi": [1, 2, 3, 9, 11, 15, 18, 26, 33, 40, 41, 45, 50, 57, 58, 59, 60, 63, 64, 66, 67, 68, 71, 77, 88, 95, 109], "empow": [33, 45, 47, 101], "empti": [20, 39, 109], "emptyset": 91, "enabl": [2, 3, 4, 7, 14, 27, 56, 57, 60, 73, 79, 95, 109, 110, 111, 114, 115], "encod": [12, 13, 30, 42, 54, 57, 59, 61, 64, 66, 68, 110, 111, 114, 115, 118], "encode_dialog_prompt": 64, "encode_head": 64, "encode_messag": 64, "encoding_for_model": 64, "encompass": 58, "encount": [11, 63, 68, 109], "encourag": [13, 30, 31, 42, 49, 52, 55, 63, 68, 73, 85, 98], "end": [8, 11, 12, 15, 18, 20, 26, 30, 39, 40, 42, 51, 55, 57, 60, 62, 64, 65, 72, 73, 74, 75, 77, 78, 83, 84, 85, 87, 91, 98, 99, 100, 103, 109, 110, 111, 112, 114, 115, 116], "end_dat": 25, "end_header_id": 64, "end_of_text": 64, "enforc": [95, 98, 111], "engin": [2, 9, 23, 31, 41, 67, 80], "english": [20, 39, 59], "enhanc": [2, 19, 23, 26, 40, 41, 44, 47, 50, 59, 60, 66, 67, 68, 72, 88, 101], "enlarg": 106, "enlighten": [26, 40], "enlist": 60, "enough": [14, 21, 52, 59, 62, 75, 87, 112], "enrich": 19, "ensembl": [50, 88], "ensur": [2, 5, 11, 15, 21, 27, 28, 32, 33, 45, 54, 60, 62, 63, 66, 67, 68, 75, 82, 91, 100, 109, 113], "entail": 12, "enter": 1, "entir": [37, 61, 99, 100, 113], "entiti": 9, "entri": [26, 28, 40, 41, 57, 64, 65], "entropi": [51, 54, 63, 68, 72, 73, 76, 84], "entry_point": 22, "enumer": [64, 65, 111], "env": 25, "environ": [3, 4, 7, 8, 9, 15, 25, 49, 63, 67, 78, 82], "eo": [64, 82], "eos_id": 64, "eos_idx": 64, "eos_reach": 64, "eot_id": 64, "ep": [64, 65, 113], "episod": [15, 78, 80], "epoch": [33, 41, 45, 59, 61, 62, 76, 78, 80, 95, 100, 103], "epsilon": [64, 65, 72, 77, 82, 113], "epsilon_": 72, "equal": [49, 61, 72, 110, 112, 114], "equat": [87, 99, 106, 115], "equip": [98, 99, 112, 118], "equival": [13, 47, 54, 56, 85, 87, 101, 109], "erhang": [47, 101], "eric": [47, 101], "ermon": [47, 101], "errant": 9, "error": [2, 3, 8, 30, 42, 52, 56, 63, 64, 67, 77, 82, 116], "especi": [8, 30, 42, 106, 113], "essenti": [54, 56, 79], "est": 108, "establish": [60, 68, 87, 98], "estat": 108, "estim": [24, 49, 51, 55, 62, 74, 77, 82, 87, 108], "estrang": 108, "et": 7, "etc": [7, 20, 30, 39, 42, 59], "ethic": [23, 83], "eval": [18, 21, 34, 35, 76], "eval_step": 80, "evalperf": 22, "evalplu": [26, 35, 40], "evalu": [3, 5, 7, 18, 20, 23, 24, 31, 32, 39, 43, 47, 49, 51, 52, 58, 62, 72, 83, 86, 88, 89, 95, 98, 99, 100, 101, 106, 112], "evan": [47, 101], "evas": 83, "even": [1, 3, 14, 33, 45, 49, 52, 60, 63, 67, 74, 75, 87, 111, 112, 114, 115], "evenli": [38, 55], "event": [15, 76, 77], "everi": [2, 11, 14, 27, 30, 42, 84, 110, 113], "evid": [52, 111], "evol": [26, 40, 41], "evolut": [33, 45], "evolutionari": [33, 45], "evolv": [33, 45], "exact": [3, 5, 27, 57], "exactli": [31, 49, 82], "exam": 23, "examin": [1, 19, 73], "exampl": [5, 7, 14, 15, 19, 20, 24, 26, 30, 31, 39, 40, 41, 42, 47, 49, 52, 54, 56, 57, 59, 62, 63, 66, 71, 74, 75, 79, 83, 84, 85, 88, 89, 90, 91, 95, 98, 103, 110, 111, 113], "exce": [20, 39, 50, 64, 98], "exceed": [110, 111], "excel": 60, "except": [7, 14, 33, 45, 50, 59, 60, 63, 64, 75, 112], "exceptiongroup": 25, "excess": [60, 72, 82], "exchang": 103, "exclud": [68, 72], "exclus": [23, 61, 100], "execut": [1, 3, 9, 19, 21, 25, 31, 41, 47, 48, 54, 55, 57, 63, 66, 67, 101, 111], "executor": 67, "exemplar": [84, 93], "exemplifi": 85, "exhibit": [59, 72, 79, 95, 99], "exist": [1, 2, 7, 9, 23, 24, 26, 30, 37, 40, 42, 54, 63, 67, 90, 98, 110, 111, 117], "exit": 98, "exp": [15, 64, 65, 71, 74, 87, 115, 116], "expand": [60, 66, 68], "expans": 111, "expbal": 109, "expect": [5, 15, 30, 42, 49, 55, 60, 63, 67, 72, 77, 79, 82, 83, 106, 111], "expens": [52, 57, 74, 91], "experi": [7, 11, 12, 15, 27, 33, 45, 59, 62, 63, 73, 74, 76, 78, 80, 83, 84, 88, 100, 103], "experience_mak": 80, "experiment": [23, 41], "expert": [27, 47, 59, 60, 63, 67, 68, 101], "expert1": 109, "expert2": 109, "expert3": 109, "expertis": 63, "explain": [56, 63, 67, 71, 84], "explan": [63, 84], "explicit": [4, 7, 13, 60, 110, 111, 114, 115], "explicitli": [20, 39, 62, 83, 85, 99], "exploit": [14, 68, 72], "explor": [5, 7, 56, 62, 68, 72, 73, 77, 79, 93, 95], "exponenti": 111, "export": 25, "express": [3, 14, 24, 74, 76], "extend": [4, 9, 35, 57, 59, 60, 63, 64, 66, 80, 91, 95], "extens": [3, 19, 25, 47, 56, 66, 79, 111], "extern": [2, 41, 95], "extra": [12, 21, 56, 98, 110, 111], "extract": [7, 26, 40, 63, 71, 73, 84], "extractor": 71, "extrapol": [11, 110], "extrem": [11, 27, 49, 52, 60], "f": [22, 64, 65, 98, 108, 110, 111, 116], "f2p": 9, "f_": [71, 73, 91, 109, 114, 115], "face": [88, 95], "facilit": [11, 54, 68, 79, 82], "fact": 111, "factor": [11, 51, 67, 71, 82, 109, 110, 111, 116], "factual": [66, 95], "fail": [5, 9, 31, 56, 63, 66, 67], "failur": [52, 63, 67], "fair": 112, "faith": 63, "faithfulli": [52, 79], "fake": 79, "fals": [59, 64, 65, 113], "famili": [52, 55, 57, 111], "fan": [47, 101], "fangyun": [47, 101], "fanjia": [47, 101], "far": [5, 63, 72, 76, 82], "fashion": [30, 42, 99], "fast": 64, "fastavro": 25, "faster": [18, 72], "fastjsonschema": 25, "faulti": 63, "favor": [71, 98], "feasibl": 5, "featur": [52, 57, 64, 71, 80, 113], "februari": 67, "fed": [12, 67], "federico": [47, 101], "feed": [51, 64, 65, 66, 109, 116], "feed_forward": [64, 65], "feedback": [5, 7, 8, 15, 47, 52, 57, 58, 59, 60, 63, 66, 67, 74, 76, 79, 87, 89, 91, 95, 100, 101], "feedforward": 12, "fei": [47, 101], "felip": [47, 101], "feng": [47, 101], "few": [13, 14, 15, 23, 30, 42, 47, 54, 55, 57, 83, 84, 89, 91, 93, 100, 101], "fewer": [56, 59, 110, 111], "ff": [51, 116], "ffff": 118, "ffff\u7684\u8303\u56f4": 118, "ffn": [11, 59, 60, 64, 65, 66, 109], "ffn_norm": [64, 65], "fiction": 13, "field": [2, 20, 27, 30, 32, 39, 42, 43, 67], "fifo": 76, "fig": 3, "figur": [1, 7, 8, 11, 51, 58, 60, 62, 68, 76, 79, 83, 95, 106], "file": [1, 8, 9, 20, 25, 31, 39, 41, 48, 57, 64, 67], "filelock": 25, "filenam": 8, "fill": [3, 57, 60, 62], "filter": [15, 21, 26, 31, 40, 41, 58, 59, 63, 66, 67, 68, 72, 73, 90, 91, 98, 100, 106], "fim": [60, 67], "final": [1, 9, 11, 12, 13, 15, 27, 30, 31, 33, 42, 44, 45, 49, 55, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 78, 79, 82, 83, 84, 85, 86, 87, 89, 90, 91, 95, 98, 100, 109], "find": [8, 20, 23, 31, 39, 50, 51, 52, 54, 55, 59, 62, 63, 72, 78, 83, 84, 87, 89, 95, 98, 99, 100, 106, 112], "find_fil": 8, "fine": [7, 14, 15, 20, 32, 33, 39, 41, 43, 45, 63, 67, 68, 74, 77, 79, 85, 86, 87, 89, 99, 100, 103, 106, 110, 111], "finer": 109, "finest": 108, "finetun": [14, 26, 33, 40, 45, 52, 66, 83, 91, 98, 100], "finetuning_typ": 119, "finn": [47, 101], "fire": 22, "first": [1, 2, 3, 7, 11, 12, 13, 15, 21, 26, 30, 40, 41, 42, 49, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 72, 73, 74, 75, 76, 78, 79, 80, 84, 87, 88, 89, 90, 95, 98, 99, 100, 106, 109, 112, 115, 116], "first_k_dense_replac": 59, "firstli": 56, "fit": [31, 51, 76, 80, 87, 111], "five": [33, 45, 67], "fix": [1, 11, 15, 31, 51, 56, 63, 76, 78, 100, 110, 113], "flag": [64, 68], "flagopen": 32, "flagship": 68, "flash": [34, 35], "flash_attn": 80, "flatten": [64, 65, 111], "flavor": 47, "flaw": 67, "flexibl": [3, 73, 109], "flexibli": 109, "flip": [79, 99], "float": [64, 65, 87, 111, 113], "float32": [64, 65], "flow": [3, 7], "fluenci": 49, "focu": [20, 31, 39, 41, 49, 61, 66, 68, 76, 100], "focus": [18, 23, 25, 32, 41, 43, 58, 60, 66, 79, 95], "fold": 19, "follow": [1, 2, 7, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 25, 26, 27, 31, 33, 39, 40, 45, 47, 48, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 74, 75, 77, 78, 79, 82, 83, 84, 85, 87, 88, 90, 95, 101, 103, 109, 110, 111, 112], "fool": 100, "foral": [12, 73], "forc": [27, 54, 56, 98, 99], "forcefulli": 98, "forecast": 2, "forgo": 76, "form": [7, 11, 33, 45, 55, 57, 60, 74, 76, 82, 85, 89, 100, 110, 111], "formal": [73, 77], "format": [1, 3, 4, 25, 27, 30, 33, 42, 45, 57, 60, 83, 95], "formatt": 64, "former": [1, 4, 73], "formul": [49, 73, 74, 82, 88, 109], "fortun": 74, "forum": [47, 101, 103], "forward": [51, 64, 65, 66, 109, 110, 113, 116, 120], "foster": 73, "fotio": [47, 101], "found": [7, 11, 12, 15, 23, 30, 42, 54, 55, 56, 62, 67, 73, 83, 110, 111], "foundat": [26, 33, 40, 45, 57, 61, 63, 67, 68, 82], "four": [9, 13, 23, 33, 45, 57, 62, 63, 68, 88, 95, 112], "frac": [11, 15, 24, 49, 51, 64, 65, 71, 72, 74, 75, 77, 78, 79, 82, 87, 88, 98, 109, 110, 111, 112, 113, 114, 115, 116, 117], "fraction": 24, "framework": [5, 7, 22, 30, 42, 59, 60, 66, 67, 68, 79], "fraser": [47, 101], "free": [25, 47, 60, 67, 90, 101], "freez": [71, 120], "freq": [64, 65, 111], "freqs_ci": [64, 65, 111], "frequenc": [11, 57, 109, 111, 114, 115], "frequent": [110, 111], "fresh": 100, "friendli": 83, "from": [2, 5, 7, 8, 9, 11, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31, 33, 34, 37, 38, 39, 41, 42, 44, 45, 47, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 74, 75, 76, 77, 78, 82, 85, 86, 87, 88, 89, 90, 91, 95, 98, 99, 100, 101, 103, 106, 109, 110, 111, 112, 113, 115, 117, 118], "frontier": 27, "frozen": 72, "frozenlist": 25, "fsdp": 98, "fsfairx": 50, "fsspec": 25, "fu": [47, 101], "fulfil": [2, 79], "fuli": [47, 101], "full": [52, 56, 57, 58, 60, 64, 65, 80, 119], "fulli": [3, 11, 20, 39, 44, 52, 60, 67, 72], "function": [1, 3, 5, 8, 9, 11, 14, 15, 19, 21, 28, 31, 47, 49, 52, 56, 57, 61, 62, 66, 67, 68, 72, 73, 74, 75, 76, 77, 78, 79, 82, 87, 88, 98, 99, 110, 111, 113, 114, 115, 116], "fundament": [14, 52, 68], "further": [20, 26, 39, 40, 41, 50, 55, 57, 58, 59, 62, 63, 66, 67, 68, 73, 76, 77, 91, 109, 111, 115], "furthermor": [60, 68, 72, 83], "futur": [1, 2, 52, 59, 60], "g": [2, 3, 4, 25, 26, 30, 40, 42, 60, 62, 63, 67, 68, 71, 72, 77, 84, 85, 87, 90, 95, 98, 99, 110, 114, 115], "g_": [60, 71, 109], "g_t": 82, "gabriel": [47, 101], "gae": [77, 82], "gain": [12, 14, 26, 40, 56, 62, 67, 79, 84], "gamma": [15, 49, 60, 64, 65, 77, 78, 79, 82, 110, 113], "gao": [47, 101], "gap": [3, 23, 26, 40, 49, 50, 52, 63, 67, 86], "gate": [47, 60, 71, 101, 109], "gate_proj": 59, "gather": [62, 64, 66], "gating_dim": 109, "gaussian": 116, "gave": [20, 39], "gb2312\u56e0\u4e3a\u53ea\u8868\u793a\u666e\u901a\u6570\u5b57": 118, "gbk\u662fascii": 118, "ge": [24, 30, 42, 47, 71, 73, 75, 77, 87, 101], "geglu": 116, "gelu": 116, "gemini": [55, 58, 76], "gen": 64, "gener": [2, 3, 4, 5, 7, 8, 11, 12, 13, 14, 15, 20, 21, 24, 25, 26, 31, 32, 33, 39, 40, 41, 43, 44, 45, 47, 49, 54, 55, 56, 57, 58, 59, 60, 62, 63, 66, 67, 72, 74, 75, 76, 77, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 98, 99, 101, 106, 110, 112], "generalist": 73, "generate_kwarg": 80, "generate_max_len": 80, "generation_logprob": 64, "generation_token": 64, "generativeai": 25, "generativelanguag": 25, "geometr": [11, 115], "geometri": 63, "get": [7, 27, 47, 48, 49, 57, 67, 71, 87], "get_unique_el": 57, "gg": 51, "gibb": 74, "gibberish": [49, 72], "girish": [47, 101], "git": [22, 25], "github": [9, 20, 22, 25, 31, 32, 39, 41, 54, 58, 61, 64, 65, 66, 67], "give": [12, 68, 89, 90, 111], "given": [2, 5, 8, 9, 11, 12, 15, 19, 20, 30, 31, 33, 39, 42, 45, 49, 51, 52, 54, 56, 57, 61, 62, 63, 64, 65, 66, 67, 71, 73, 74, 75, 76, 77, 78, 84, 85, 87, 89, 90, 91, 99, 100, 106, 110, 111], "glob": 64, "global": 68, "glu": [64, 65], "go": [80, 82], "goal": [12, 56, 67, 72, 74, 87, 90, 98, 99], "gold": [34, 54, 55], "gomez": [47, 101], "good": [21, 34, 49, 52, 54, 60, 63, 77, 87, 90], "googl": [22, 25], "googleapi": 25, "google\u7684bert\u6a21\u578b\u5728\u5206\u8bcd\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662fwordpiece\u7b97\u6cd5": 117, "goto": 8, "gpt": [13, 14, 15, 18, 20, 26, 27, 34, 35, 39, 40, 47, 52, 63, 64, 89, 100, 101, 106], "gpt2": 34, "gpt3": 34, "gpt4": 58, "gpu": [60, 98, 119], "gqa": [47, 66, 101], "grade": [5, 27], "gradient": [11, 12, 15, 61, 75, 76, 78, 82], "gradient_accumulation_step": 119, "gradient_checkpoint": 80, "gradual": 57, "grai": [47, 101], "grain": [7, 32, 43, 63, 68, 79], "gram": [41, 67], "grammar": [30, 42], "grammat": [30, 42], "grangier": [47, 101], "granular": 23, "graph": 7, "graphic": 27, "great": 64, "greater": 23, "greatli": [14, 120], "greedi": [13, 22, 26, 40, 50, 63, 64, 106], "greg": [47, 101], "gretchen": [47, 101], "grid": 111, "grl": [21, 47, 101], "ground": [3, 19, 28, 38, 52, 58, 59, 60, 67, 72, 73, 74, 87, 90], "group": [54, 55, 58, 59, 60, 64, 66, 67, 68, 72, 88, 95, 109, 112], "grow": [11, 14, 76], "grpcio": 25, "grpo": [34, 35, 58, 66, 68, 72, 73], "gsm8k": [34, 50, 67, 106], "gu": [47, 101], "guan": [47, 101], "guangbo": [47, 101], "guant": [47, 101], "guarante": [24, 73, 75, 77, 109], "guard": 37, "guardrail": 8, "guess": 23, "guid": [30, 42, 50, 73, 87, 88, 95], "guo": [47, 101], "guowei": [47, 101], "guss": [47, 101], "h": [11, 47, 59, 62, 64, 65, 101, 109, 110, 112, 120], "h06a4308_0": 25, "h100": 98, "h11": 25, "h1181459_1": 25, "h1234567_1": 25, "h39e8969_0": 25, "h5eee18b_0": 25, "h5eee18b_1": 25, "h5eee18b_6": 25, "h6a678d5_0": 25, "h6a678d5_1": 25, "h800": 60, "h955ad1f_1": 25, "h_": [12, 111], "h_j": 111, "h_n": 12, "ha": [2, 3, 7, 9, 11, 13, 14, 15, 18, 27, 30, 42, 49, 52, 58, 59, 62, 63, 64, 65, 66, 72, 76, 77, 88, 91, 99, 106, 110, 112, 116], "hack": [60, 62, 71, 72, 83, 95], "had": [15, 28, 54], "half": [52, 54, 57], "hallucin": 67, "hallucinatori": 59, "halt": 68, "halv": 11, "ham": 75, "han": [47, 101], "hand": [24, 28, 51, 52, 60, 68, 76], "handl": [7, 12, 67, 68], "handwritten": 24, "hanq": [47, 101], "hanwei": [47, 101], "hao": [47, 101], "haoran": [47, 101], "haowei": [47, 101], "haoyu": [47, 101], "happen": 111, "har": 60, "hard": [55, 56, 74, 85, 112], "harder": 55, "harm": [83, 85], "harmless": [66, 84, 85, 89], "harri": [47, 101], "hasten": 8, "hat": [49, 72, 74, 77, 82, 88, 99], "have": [1, 2, 5, 7, 11, 12, 13, 24, 26, 27, 30, 31, 40, 42, 48, 49, 51, 52, 55, 56, 58, 60, 62, 63, 66, 68, 71, 72, 74, 75, 83, 87, 88, 89, 90, 98, 103, 106, 109, 110, 111, 113, 116], "hbb": [23, 47, 101], "hd_": 11, "he": [47, 101], "head": [12, 47, 51, 59, 60, 64, 65, 89, 101, 110, 111, 118], "head_dim": [64, 65], "header": [1, 9], "health": 23, "heart": 90, "heavi": [51, 99, 112], "hebgen": [47, 101], "heewoo": [47, 101], "heidi": [47, 101], "height": 64, "held": 14, "help": [5, 7, 8, 12, 15, 27, 47, 56, 57, 59, 60, 62, 63, 66, 67, 71, 76, 78, 83, 85, 89, 110], "helpfulli": 78, "helpsteer2": 34, "henc": [3, 58, 74, 89], "henceforth": 9, "hendryck": [47, 101], "henighan": [47, 101], "henriqu": [47, 101], "herbert": [47, 101], "herd": 63, "here": [11, 14, 20, 33, 39, 45, 47, 49, 51, 61, 62, 63, 106, 110, 111], "hess": [47, 101], "heurist": [15, 26, 27, 30, 40, 42], "hf": 87, "hh": 83, "hidden": [59, 64, 65, 71, 109, 110, 116], "hidden_dim": [64, 65], "hidden_s": [59, 109], "hierarch": 1, "high": [7, 12, 19, 24, 26, 27, 31, 40, 41, 49, 50, 54, 60, 62, 63, 66, 67, 68, 71, 72, 73, 75, 76, 82, 88, 89, 90, 91, 99, 103, 108, 114, 115], "highconfid": 91, "higher": [3, 32, 43, 50, 55, 56, 60, 63, 66, 67, 76, 79, 88, 109, 110], "highest": [7, 18, 20, 27, 33, 39, 45, 50, 60, 63, 76, 88, 89, 108, 109, 114], "highli": [27, 52, 67, 71, 90, 91, 100], "highlight": [2, 41], "highqual": 60, "hilton": [47, 101], "hinder": [82, 88], "hing": 74, "histor": 77, "histori": [5, 8, 23, 49], "hoc": 84, "hold": [51, 100], "holdgraf_evidence_2014": 47, "holist": [25, 47, 101], "home": 25, "homepag": 72, "honesti": 71, "hongcheng": [47, 101], "honghui": [47, 101], "hongyi": [47, 101], "hood": [26, 40], "hook": 25, "hope": 27, "hotfix": 25, "hou": [47, 101], "hour": 60, "hous": 58, "how": [2, 8, 15, 18, 23, 27, 31, 48, 49, 52, 55, 63, 67, 68, 71, 73, 74, 77, 84, 85, 93, 95, 100, 106, 111], "howev": [1, 2, 24, 30, 42, 49, 50, 52, 59, 62, 63, 71, 72, 74, 78, 79, 85, 87, 88, 98, 109, 110, 111, 113, 115], "hstack": [64, 65], "html": 118, "http": [22, 25, 26, 30, 33, 40, 42, 45, 47, 101], "httpcore": 25, "httplib2": 25, "httpx": 25, "hu": [47, 101], "huajian": [47, 101], "huan": [47, 101], "huang": [47, 101], "huazuo": [47, 101], "hub": 25, "huge": [56, 111], "huggingfac": [25, 80], "hugh": [47, 101], "hui": [47, 101], "human": [7, 8, 14, 15, 18, 21, 23, 27, 28, 30, 33, 38, 42, 45, 47, 49, 52, 57, 59, 60, 63, 66, 67, 74, 76, 78, 79, 83, 84, 85, 86, 87, 89, 90, 91, 95, 100, 101], "humanev": [19, 33, 35, 41, 45, 50, 67], "humanevalplu": 22, "humanevalplus_releas": 22, "hundr": [60, 111], "hunter": [47, 101], "hurt": 67, "hybrid": 7, "hybridengin": 80, "hyc": [47, 67, 101], "hyper": [60, 61, 64, 65, 66, 68, 72, 77, 79], "hyperparamet": [51, 55, 63, 66, 72, 75, 76, 79, 82, 103], "hypothes": 11, "hypothesi": 14, "i": [1, 2, 5, 7, 8, 9, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 87, 88, 89, 90, 91, 95, 98, 100, 101, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118], "i_": [30, 42], "i_t": [30, 42], "icl": [7, 106], "id": [15, 47, 64, 101], "id1": 25, "id2": 25, "idea": [79, 91, 110, 111], "ideal": [2, 20, 23, 39, 111], "ident": [11, 66, 72, 74, 76, 90, 100, 109], "identif": 67, "identifi": [2, 9, 15, 18, 19, 23, 30, 42, 50, 66, 67, 68, 72, 73, 76, 79, 83, 85, 88, 91], "idf": 7, "idna": 25, "ifev": 59, "ifstat": 3, "ift": 89, "ignor": [7, 49, 54, 64, 111], "ignore_index": 64, "igor": [47, 101], "ij": 106, "ik_": [64, 65, 110, 111], "illeg": 83, "illia": [47, 101], "illustr": [1, 8, 52, 58, 60, 62, 64, 65, 68, 95], "ilya": [47, 101], "im": [64, 65, 110, 111], "imag": [2, 7, 9, 51, 98], "imaginari": [110, 111], "imbal": [60, 109], "imit": 52, "immedi": 68, "impact": [41, 50, 55, 67, 72, 100, 110], "imped": 72, "imper": [20, 39], "imperfect": 91, "implement": [2, 15, 19, 24, 33, 45, 59, 60, 61, 66, 67, 68, 82, 91], "impli": 72, "implicit": [7, 74], "implicitli": [52, 74, 99], "import": [3, 8, 19, 22, 24, 41, 49, 52, 62, 64, 65, 74, 87, 89, 90, 103, 111, 113], "importantli": [67, 74, 98, 112], "importlib": 25, "impress": 67, "improv": [12, 14, 26, 40, 44, 47, 49, 52, 54, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 73, 75, 77, 84, 88, 89, 90, 91, 93, 95, 98, 99, 100, 101, 106, 113], "inabl": 72, "inappropri": 79, "incentiv": 99, "includ": [2, 5, 7, 9, 12, 20, 23, 24, 27, 31, 32, 33, 37, 38, 39, 41, 43, 45, 48, 50, 51, 52, 54, 55, 57, 59, 60, 62, 63, 64, 66, 67, 68, 74, 83, 86, 87, 110, 111, 113, 119], "inclus": 67, "incomplet": 68, "incorpor": [4, 11, 41, 60, 62, 63, 66, 72, 77, 82, 114, 115], "incorrect": [54, 56, 88, 91, 99, 100], "incorrectli": [27, 74], "increas": [23, 26, 33, 40, 41, 45, 55, 57, 60, 63, 68, 72, 74, 75, 79, 106, 109, 111, 115], "increasingli": 95, "increment": 110, "inde": 79, "indent": 67, "independ": [30, 42, 57, 98, 113, 117], "index": [64, 65, 76, 77, 110, 111, 112], "indic": [15, 23, 55, 64, 71, 76, 79, 82, 85, 98, 106, 110, 111, 112, 114], "individu": [51, 72, 73, 113, 114, 115], "induc": [13, 60, 87], "inequ": 74, "inf": [64, 65], "infer": [7, 20, 39, 41, 49, 57, 59, 60, 61, 63, 64, 72, 79, 80, 84, 87, 90, 109, 111, 112, 113], "inference_mod": [64, 65], "infin": 41, "inflat": 67, "influenc": [72, 73, 106], "infomax": 76, "inform": [1, 2, 7, 8, 11, 15, 20, 27, 39, 41, 47, 48, 54, 62, 63, 66, 77, 88, 101, 109, 111, 114, 115, 118], "infrastructur": 111, "infti": 51, "inher": [12, 15], "inherit": 71, "init": 48, "init_kl_coef": 80, "initi": [2, 15, 26, 30, 33, 40, 42, 45, 56, 57, 59, 62, 63, 64, 68, 72, 74, 76, 78, 83, 85, 91, 95, 103], "inject": [11, 110, 111, 120], "inlin": [47, 74], "inner": [114, 115], "innov": [59, 68, 112], "input": [1, 2, 11, 15, 20, 21, 26, 30, 33, 39, 40, 42, 45, 47, 54, 55, 56, 57, 61, 62, 64, 65, 67, 73, 75, 76, 78, 79, 82, 84, 87, 90, 103, 110, 111, 112, 113, 114, 115, 116, 117], "input_kei": 80, "input_text_mask": 64, "inputgen": 22, "inputoutput": 56, "insert": [11, 47, 54, 64, 68, 76], "insid": 77, "insight": [8, 74], "inspect": 28, "inspir": [26, 40, 73], "inst": 57, "instabl": [24, 82, 113], "instag": 63, "instal": [9, 22], "instanc": [3, 9, 12, 20, 31, 39, 59, 60, 64, 71, 83, 95], "instead": [11, 13, 15, 20, 24, 33, 39, 45, 52, 55, 57, 61, 64, 65, 72, 76, 77, 79, 82, 83, 91, 110, 111, 113, 115], "instil": 68, "instruciton": [20, 39], "instruct": [2, 3, 8, 9, 14, 15, 18, 20, 31, 34, 35, 39, 47, 48, 50, 52, 58, 59, 62, 63, 68, 71, 73, 79, 83, 84, 88, 95, 98, 99, 101, 103], "instructgpt": 78, "instruction_prefix": 22, "instructionfollow": 89, "int": [59, 64, 65, 87, 111, 113], "int_": 76, "integ": [64, 72], "integr": [4, 8, 23, 60, 66, 67, 68, 73], "intend": 72, "intens": [59, 67], "intent": [15, 19, 88], "intention": 79, "interact": [4, 7, 8, 49, 63, 64, 65, 76, 79, 82, 113], "interc": [71, 109, 110, 111, 112, 114], "interchang": 118, "interdepend": 113, "interest": [52, 63, 87], "interesting": 49, "interestingli": 67, "interfac": 15, "interfer": 113, "interleav": 99, "interlm2": 34, "intermedi": [44, 51, 52, 58, 59, 60, 68, 93, 95, 100, 109], "intermediate_s": 59, "intern": [52, 60, 63], "internet": 78, "interpol": 57, "interpret": [15, 41, 62, 77], "interv": 106, "intervent": 98, "interview": [2, 57], "intric": 66, "intrigu": 95, "intrins": 95, "introduc": [2, 3, 8, 9, 18, 23, 26, 27, 30, 40, 41, 42, 44, 49, 55, 60, 63, 64, 66, 67, 68, 72, 73, 77, 84, 87, 95, 109, 110, 111, 113], "introduct": 84, "intuit": [49, 52, 74, 115], "invas": 83, "invert": 9, "invest": [59, 76, 110, 111], "investig": [60, 72, 73, 79, 100, 103, 106], "invok": 2, "involv": [20, 27, 39, 51, 60, 63, 68, 109], "ion": [47, 101], "ip": 84, "ipo": 74, "ipynb": 47, "iq_": [64, 65, 110, 111], "irrelev": 41, "is_safeti": 62, "ise": 22, "isequival": 72, "isin": 64, "isol": 67, "issu": [1, 9, 13, 19, 31, 58, 60, 63, 71, 83, 84, 95, 99, 109, 111, 113], "item": [80, 87], "iter": [8, 15, 30, 33, 42, 45, 56, 64, 66, 76, 78, 79, 87, 88, 89, 99], "itertool": 25, "its": [3, 5, 9, 14, 26, 28, 30, 31, 40, 42, 52, 54, 55, 57, 59, 60, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 79, 82, 83, 87, 89, 95, 98, 99, 100, 106, 109, 110, 111, 112, 113, 115, 116], "itself": [30, 42, 58, 68, 89, 99], "ix_": [64, 65, 110, 111], "j": [47, 49, 60, 64, 65, 72, 73, 75, 77, 79, 82, 90, 101, 109, 110, 111, 112, 115], "j_": [77, 90], "j_1": 79, "j_q": 79, "jack": [47, 101], "jacob": [47, 101], "jain": [47, 101], "jakob": [47, 101], "jame": [47, 101], "jan": [47, 101], "jaraco": 25, "jare": [47, 101], "java": 67, "javascript": 67, "jeepnei": 25, "jeff": [47, 101], "jeffrei": [47, 101], "jerri": [47, 101], "jgzp23": [47, 66, 101], "jhg": [25, 47, 101], "ji": [47, 101], "jiaheng": [47, 101], "jiajun": [47, 101], "jian": [47, 101], "jiang": [47, 101], "jianhong": [47, 101], "jianlin": [47, 101], "jianwei": [47, 101], "jianxin": [47, 101], "jianzhong": [47, 101], "jiaqi": [47, 101], "jiashi": [47, 101], "jiatao": [47, 101], "jiawei": [47, 101], "jiaxi": [47, 101], "jie": [47, 101], "jin": [47, 101], "jingren": [47, 101], "jingxiang": [47, 101], "jingyang": [47, 101], "jinja2": 25, "jinz": [47, 101], "jmespath": 25, "joblib": 25, "john": [47, 101], "jointli": 11, "jone": [47, 101], "jong": [47, 101], "joseph": [47, 101], "josh": [47, 101], "joshua": [47, 101], "json": [3, 20, 39, 59, 64, 119], "jsonl": 22, "jsonlin": 25, "judg": [18, 35, 55, 56, 63, 79, 89, 90], "judgement": 79, "judgment": [49, 67], "jun": [47, 101], "junji": [47, 101], "junxiao": [47, 101], "junyang": [47, 101], "jupyt": [47, 48], "jupyterbook": 47, "jupytext": 48, "just": [8, 23, 25, 47], "k": [7, 11, 12, 13, 15, 24, 27, 33, 45, 47, 54, 60, 62, 63, 64, 65, 71, 73, 75, 76, 78, 82, 86, 101, 106, 109, 110, 111, 112, 114, 115, 120], "k_": [60, 64, 65, 73, 77, 109, 110, 111], "k_1": 77, "k_i": 77, "k_r": [60, 109], "kai": [47, 101], "kaig": [47, 101], "kaiser": [47, 101], "kang": [47, 101], "kaplan": [47, 101], "karl": [47, 101], "karma": 13, "katarina": [47, 101], "kati": [47, 101], "katti": 38, "ke": [47, 101], "keep": [8, 9, 55, 59, 60, 62, 63, 67, 72, 99, 109, 116], "keepdim": [64, 65, 113], "kei": [2, 7, 11, 27, 41, 52, 55, 56, 57, 59, 60, 64, 65, 66, 67, 68, 72, 79, 82, 87, 106, 110, 111, 113, 114, 115], "kelton": [47, 101], "keme": [47, 101], "kenton": [47, 101], "keqin": [47, 101], "kernel": 48, "kexin": [47, 101], "keyr": 25, "keyword": 18, "khlaaf": [47, 101], "kind": [9, 15, 47, 79], "king": [47, 101], "kl": [15, 62, 68, 74, 77, 78, 87], "kmh": [14, 47, 101], "knew": 49, "knight": [47, 101], "know": [49, 52, 106], "knowledg": [3, 7, 23, 26, 40, 41, 56, 62, 103, 109, 114, 115], "known": [2, 49, 64, 65, 88, 111], "kosaraju": [47, 101], "koushik": [47, 101], "kpc": 7, "kr": 112, "kristina": [47, 101], "krueger": [47, 101], "kto": [34, 50], "kv": [59, 66], "kv_a_layernorm": 59, "kv_a_proj_with_mqa": 59, "kv_b_proj": 59, "kv_lora_rank": 59, "kw_": 11, "kyunghyun": [47, 101], "l": [12, 15, 30, 42, 44, 47, 49, 51, 62, 64, 65, 73, 74, 75, 76, 77, 78, 82, 87, 88, 89, 90, 91, 99, 101, 108, 109, 110, 111, 112, 113], "l_": [12, 72, 74, 79, 88], "l_1": 79, "l_2": 79, "label": [12, 14, 15, 30, 32, 42, 43, 52, 58, 59, 62, 63, 66, 78, 83, 85, 87, 90, 91, 100, 106], "labor": 67, "lack": [72, 87], "lambda": [12, 75, 76, 77, 79, 82, 110, 111], "lambda_": [71, 110], "land": 83, "langl": [64, 65, 110, 111, 115], "languag": [4, 5, 7, 9, 12, 13, 14, 15, 18, 19, 20, 23, 24, 27, 30, 31, 39, 41, 42, 46, 47, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 67, 74, 76, 78, 91, 95, 98, 100, 101, 103, 109, 114, 115], "larg": [5, 7, 11, 12, 13, 14, 15, 18, 19, 21, 24, 30, 31, 41, 42, 46, 47, 49, 52, 55, 59, 60, 62, 63, 64, 65, 67, 68, 72, 74, 75, 76, 78, 82, 91, 95, 101, 103, 109, 112, 115], "larger": [9, 13, 31, 32, 43, 62, 63, 98, 100, 111, 115], "largest": [13, 32, 54, 55, 61, 62, 63], "last": [11, 14, 54, 63, 64, 68, 71, 77, 83, 100], "latent": [59, 60], "later": [30, 42, 63, 98], "latest": [9, 22, 62, 63], "latex": 27, "latter": 4, "law": [14, 23, 47, 52, 66, 68, 101, 112], "layer": [11, 12, 13, 14, 15, 51, 54, 59, 61, 64, 65, 66, 71, 78, 80, 109, 110, 111, 112, 116, 120], "layer_id": [64, 65], "layer_idx": 59, "layernorm": [11, 113], "lcb": 25, "lcb_runner": 25, "lcft": 63, "ld_impl_linux": 25, "le": [24, 33, 45, 47, 60, 72, 75, 98, 101, 109, 111, 116], "lead": [41, 49, 52, 56, 57, 60, 61, 63, 72, 75, 83, 100, 110, 111, 113], "leakag": [37, 52, 67], "lean": [47, 101], "learn": [3, 5, 7, 11, 12, 13, 14, 15, 23, 27, 41, 49, 50, 51, 52, 54, 57, 61, 64, 65, 67, 68, 72, 73, 74, 77, 82, 85, 87, 88, 89, 101, 103, 109, 116], "learnabl": [64, 68], "learner": [13, 14, 47, 101], "learning_r": 119, "least": [13, 14, 18, 31, 55, 83], "leather": [47, 101], "leav": [54, 56, 72], "lebr\u00f3n": [47, 101], "lecong": [47, 101], "led": [62, 63, 83], "lee": [47, 101], "leed": 109, "leetcod": [25, 35, 58, 60, 95], "left": [11, 15, 24, 49, 51, 55, 57, 64, 65, 71, 72, 74, 75, 77, 78, 79, 82, 84, 87, 99, 110, 111, 112, 114, 115, 117], "leftarrow": [82, 112], "legal": 83, "lei": [47, 101], "leik": [47, 101], "len": [64, 80, 87], "length": [11, 51, 57, 59, 60, 62, 63, 64, 68, 71, 72, 75, 79, 84, 98, 109, 110, 111, 112, 113], "lengthen": 98, "lengthi": 56, "less": [11, 15, 20, 30, 34, 35, 39, 42, 50, 58, 63, 72, 76, 77, 83, 88, 100, 106, 110], "let": [1, 27, 47, 48, 49, 59, 71, 73, 75, 82, 83, 87, 91, 101, 110, 112, 114, 115], "level": [13, 19, 23, 27, 28, 32, 33, 41, 43, 45, 47, 49, 52, 55, 57, 59, 60, 62, 63, 66, 67, 68, 76, 100, 101], "leverag": [2, 26, 30, 40, 42, 56, 60, 62, 66, 95, 111, 114, 115], "lex": 111, "leyi": [47, 101], "lezama": [47, 101], "li": [7, 47, 101], "liang": [47, 101], "libffi": 25, "libgcc": 25, "libgomp": 25, "librari": [3, 19, 41, 57], "libstdcxx": 25, "libuuid": 25, "lie": [83, 112], "lightman": [47, 101], "lightweight": 68, "like": [1, 2, 7, 8, 12, 19, 20, 23, 39, 47, 48, 49, 52, 56, 60, 66, 67, 75, 76, 83, 85, 90, 95, 100], "likelihood": [12, 49, 50, 54, 74, 75, 84, 87, 88, 91, 100], "limit": [1, 3, 5, 9, 14, 15, 30, 42, 52, 54, 55, 58, 60, 62, 63, 68, 72, 76, 84, 87, 103, 109, 110, 111, 112], "lin": [47, 101], "line": [1, 8, 9, 26, 30, 31, 33, 40, 42, 45, 47, 48, 51, 52, 57, 64], "linear": [11, 12, 57, 59, 61, 62, 64, 65, 66, 71, 72, 98, 106, 111, 115], "linearli": [11, 55, 103], "lingm": [47, 101], "link": 13, "linter": 63, "linzheng": [47, 101], "liqun": [47, 101], "list": [1, 20, 33, 39, 45, 55, 56, 57, 64, 80, 87, 106, 108], "liter": 64, "littl": 67, "litwin": [47, 101], "liu": [47, 101], "livecodebench": [34, 35, 47, 101], "liyu": [47, 101], "lkb": [27, 47, 101], "ll": [47, 64, 112, 120], "llama": [20, 21, 34, 39, 50, 64, 80, 89, 103, 106, 110, 113], "llama2": [34, 62, 106], "llama3": [34, 35, 65], "llion": [47, 101], "llm": [1, 2, 4, 5, 7, 18, 19, 25, 26, 33, 40, 41, 44, 45, 46, 47, 56, 57, 62, 63, 67, 71, 73, 74, 75, 77, 79, 82, 85, 89, 90, 95, 99, 101, 111], "llm4code": 22, "lm": [8, 9, 13, 31, 78], "lm_head": 59, "ln": [47, 64, 76, 101, 111, 113], "load": [60, 64, 68], "load_checkpoint": 80, "load_state_dict": 64, "load_tiktoken_bp": 64, "local": [1, 14, 99], "localhost": 119, "locat": [1, 8, 57, 111], "log": [12, 13, 15, 49, 55, 62, 64, 74, 75, 77, 78, 79, 82, 83, 84, 87, 88, 99, 100, 106, 117], "logging_step": [80, 119], "logic": [56, 60, 66, 67, 68, 95], "logist": 88, "logit": [54, 62, 64, 68, 74, 75, 110], "logprob": 64, "logprobs_i": 64, "long": [5, 12, 15, 20, 31, 39, 47, 63, 64, 67, 72, 75, 95, 98, 101, 110, 111, 115], "longer": [11, 57, 59, 71, 72, 75, 84, 98, 103, 110, 111], "longterm": [47, 101], "look": 56, "loop": 3, "loos": 111, "lora": [34, 35], "lose": 89, "loss": [14, 15, 49, 51, 52, 54, 59, 60, 62, 63, 68, 71, 73, 75, 76, 77, 78, 79, 84, 88, 103], "lot": [47, 110], "low": [21, 30, 41, 42, 47, 49, 62, 67, 72, 73, 75, 77, 91, 98, 101, 110, 115, 120], "lower": [3, 19, 20, 39, 72, 75, 106, 110], "lowest": [88, 89, 108, 109, 110], "lr": 41, "lr_scheduler_typ": 119, "lu": [47, 101], "luan": [47, 101], "lukasz": [47, 101], "luke": [47, 101], "luo": [47, 101], "lxwz23": [22, 47, 101], "lynx": 2, "m": [12, 25, 30, 42, 47, 60, 62, 64, 65, 73, 75, 76, 79, 87, 88, 101, 109, 110, 111, 114, 115], "m3toolev": 3, "m_": 87, "m_0": 89, "m_1": 89, "m_2": 89, "m_3": 89, "m_t": 89, "ma": [47, 101], "machin": [11, 13, 47, 57, 101], "maddi": [47, 101], "made": [33, 45, 66, 76, 84, 88], "magic": [34, 35], "magicod": [22, 41, 47, 63, 67, 101], "magnitud": [9, 11, 13, 14, 52, 54, 111, 112], "mai": [11, 19, 41, 50, 52, 56, 58, 60, 63, 72, 75, 77, 83, 84, 85, 88, 95, 109, 111], "mail": 13, "main": [22, 25, 50, 52, 55, 56, 57, 61, 62, 63, 73], "mainli": [52, 56, 60, 67, 73, 88, 95], "mainstream": [7, 67], "maintain": [58, 59, 60, 62, 66, 67, 68, 82, 109], "major": [27, 63, 67, 85, 98, 100], "make": [2, 5, 7, 8, 11, 12, 15, 20, 23, 30, 31, 32, 39, 42, 49, 52, 55, 57, 64, 65, 66, 71, 72, 74, 76, 79, 80, 83, 89, 95, 98, 99, 111, 113, 114, 115], "make_experience_list": 80, "malform": 8, "man": [47, 101], "manag": [8, 25], "mani": [4, 13, 14, 27, 30, 31, 42, 47, 48, 57, 67, 78, 111, 118], "mann": [47, 101], "manner": [89, 90], "manta": [47, 101], "manual": [9, 28, 30, 42, 68, 72, 103], "map": 11, "map_loc": 64, "margin": [33, 45, 50, 62, 63], "mark": [47, 57, 63, 101], "markdown": [22, 58], "markdownfil": 48, "markedli": 47, "markup": 47, "markupsaf": 25, "mask": [11, 54, 57, 63, 64, 65, 72], "mass": [33, 45, 49, 64], "massiv": [23, 47, 66, 67, 101], "master_port": 119, "match": [3, 5, 27, 32, 43, 60, 64, 66, 99, 110, 111, 112], "mateusz": [47, 101], "math": [23, 47, 58, 59, 60, 64, 65, 66, 67, 68, 72, 75, 77, 95, 98, 100, 101], "mathbb": [11, 15, 24, 49, 62, 71, 72, 74, 75, 77, 78, 79, 82, 87, 88, 98, 99, 109, 110, 112, 114, 115, 120], "mathbf": [11, 49, 57, 60, 64, 65, 73, 77, 79, 82, 109, 110, 111, 112, 113, 114, 115], "mathcal": [12, 44, 49, 62, 71, 72, 74, 75, 76, 86, 87, 88, 90, 91, 98, 99, 106, 109, 112, 116], "mathemat": [23, 24, 27, 47, 58, 59, 60, 63, 66, 67, 74, 77, 98, 101], "mathmix": 100, "mathrm": 86, "matmul": [64, 65], "matplotlib": 74, "matric": [11, 64, 65, 112, 116, 120], "matrix": [11, 12, 57, 64, 65, 112, 114, 115, 116], "matthew": [47, 101], "matthia": [47, 101], "max": [11, 62, 64, 65, 72, 75, 87, 91, 98, 99, 110, 116], "max_": [73, 74, 87, 98, 111], "max_batch_s": [64, 65], "max_epoch": 80, "max_gen_len": 64, "max_prompt_len": 64, "max_reward": 87, "max_sampl": 80, "max_seq_len": [64, 65], "maxim": [12, 15, 20, 26, 33, 39, 40, 45, 49, 55, 61, 72, 74, 76, 77, 78, 87, 91, 99, 100, 110, 111], "maximum": [3, 49, 54, 57, 62, 63, 64, 72, 73, 74, 76, 87, 98, 110, 111, 112], "mayer": [47, 101], "mazeika": [47, 101], "mbox": [82, 115], "mbpp": [33, 34, 35, 41, 45, 67], "mbppplu": 22, "mbppplus_releas": 22, "mccandlish": [47, 101], "mceval": [41, 47, 67, 101], "mcgrew": [47, 101], "md": [47, 48], "me": 83, "mean": [11, 62, 64, 65, 72, 75, 76, 77, 82, 88, 89, 109, 113, 115], "meaning": 56, "meansquar": [64, 65, 113], "meanwhil": [110, 111, 114, 115], "measur": [15, 23, 47, 49, 54, 63, 77, 84, 91, 98, 101, 103], "mechan": [11, 55, 60, 66, 67, 68, 72, 77, 82, 109, 113, 114, 115], "media": 13, "median": 62, "medium": 57, "mei": [47, 101], "melani": [47, 101], "mem": 5, "memori": [5, 11, 12, 21, 77, 112], "men": [47, 101], "meng": [47, 101], "mention": [18, 68], "merg": [31, 33, 45], "mergeable_rank": 64, "messag": [8, 56, 64], "met": 63, "meta": [64, 73, 118], "metadata": [25, 55], "method": [7, 14, 26, 31, 33, 40, 41, 45, 50, 60, 62, 63, 64, 66, 67, 73, 74, 76, 79, 82, 85, 88, 93, 98, 110, 111, 114, 115], "methodologi": [60, 95], "meticul": [59, 67], "metric": [2, 7, 24, 33, 45, 49, 52, 54, 71, 84, 98, 106], "miao": [47, 101], "miaojun": [47, 101], "michael": [47, 101], "michiel": [47, 101], "micro_rollout_batch_s": 80, "micro_train_batch_s": 80, "middl": [27, 30, 42, 57, 60], "might": [18, 63, 103, 113], "mikhail": [47, 101], "mile": [47, 101], "miller": [47, 101], "million": [13, 14, 52, 54, 55, 57, 63, 66, 67], "min": [64, 71, 72, 77, 82, 87, 98, 120], "min_": 74, "min_prompt_len": 64, "mine": 87, "ming": [47, 101], "mingchuan": [47, 101], "mingfeng": [47, 101], "minghua": [47, 101], "minghui": [47, 101], "mingm": [47, 101], "mini": [64, 72, 113], "minim": [60, 68, 74, 76, 98, 110, 111], "minimis": [54, 75], "minimum": [74, 82, 98], "minor": 99, "minu": 64, "minut": [21, 98], "mira": [47, 101], "misalign": 79, "mishkin": [47, 101], "mishra": [47, 101], "mismatch": [75, 99], "misra": [47, 101], "miss": 57, "mistak": [8, 56, 79, 99], "mistralai": 25, "mitchel": [47, 101], "mitig": [8, 15, 41, 59, 60, 63, 67, 71, 77, 78, 82, 84, 88, 91, 99, 109, 111], "mix": [15, 54, 57, 58, 63, 67, 78, 87, 95], "mixtral": 80, "mixtur": [47, 59, 60, 66, 68, 80, 101], "mk": 109, "ml": [14, 111], "mla": [35, 59, 60], "mle": [74, 79, 87], "mlp": 71, "mmlu": 50, "mn": 109, "modal": 7, "mode": [7, 52, 74], "model": [2, 3, 5, 7, 8, 9, 12, 18, 19, 20, 21, 22, 23, 24, 26, 27, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 52, 54, 56, 57, 58, 59, 60, 61, 68, 74, 75, 77, 80, 82, 83, 84, 85, 86, 87, 98, 101, 103, 109, 112, 113, 114, 115, 120], "model_arg": 64, "model_name_or_path": 119, "modelarg": [64, 65], "modern": [52, 118], "modest": 100, "modif": [9, 12, 13, 20, 33, 39, 45, 54, 63, 110], "modifi": [1, 9, 11, 20, 39, 57, 62, 63, 85, 89, 90, 99, 111, 120], "modul": [7, 9, 25, 41, 59, 64, 65, 67, 109, 113], "modular": 56, "modulelist": [64, 65], "modulenotfounderror": 64, "moe": [35, 59, 60, 66, 68, 109, 112], "moe_intermediate_s": 59, "moegat": 109, "mohammad": [47, 101], "monoton": 87, "mont": [49, 77], "month": 62, "more": [1, 8, 9, 11, 12, 13, 14, 15, 18, 19, 20, 22, 23, 25, 26, 27, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 45, 48, 52, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 78, 79, 81, 83, 85, 87, 88, 95, 100, 106, 109, 110, 112], "moreov": [3, 47, 59, 72, 99], "morikawa": [47, 101], "most": [1, 3, 7, 8, 9, 11, 13, 14, 27, 41, 47, 50, 57, 60, 62, 63, 64, 67, 71, 79, 89, 100, 109, 111, 118], "mostli": [28, 63], "motiv": [13, 74, 87, 91, 98], "move": [8, 13, 57, 82], "mpmath": 25, "msc": 98, "msgpack": 25, "mt": 109, "mtp": 60, "mu_": 82, "mu_a": 82, "much": [19, 20, 31, 39, 52, 57, 63, 72, 74, 83, 100, 110, 111, 115], "multi": [12, 34, 47, 51, 57, 59, 61, 63, 64, 65, 67, 68, 101], "multidict": 25, "multihead": 11, "multilingu": [47, 63, 66, 67, 101], "multinomi": 64, "multipl": [1, 2, 3, 9, 15, 23, 27, 30, 41, 42, 44, 50, 56, 60, 63, 64, 65, 67, 68, 76, 80, 83, 89, 98, 99, 109, 110, 112, 115], "multiple_of": [64, 65], "multipli": [11, 60, 71, 114, 115], "multiprocess": 25, "multistag": 66, "multitask": [13, 23, 47, 57, 101], "murati": [47, 101], "murtadha": [47, 101], "must": [2, 11, 47, 49, 51, 57, 68, 75, 98, 100, 110, 111], "my": 83, "n": [1, 11, 12, 22, 24, 25, 33, 34, 35, 44, 45, 47, 49, 50, 54, 57, 60, 64, 65, 68, 73, 76, 79, 87, 89, 90, 99, 100, 101, 108, 109, 110, 111, 113, 114, 115, 116, 117], "n_": [30, 42, 51, 73, 112], "n_h": [59, 112], "n_head": [64, 65], "n_layer": [64, 65], "n_routed_expert": [59, 109], "n_shared_expert": 59, "n_t": [30, 42], "n_vocab": 64, "n_word": 64, "nabla_": [49, 74, 75, 82], "naiv": [52, 72, 74, 106, 109], "nakano": [47, 101], "naman": [47, 101], "name": [7, 25, 33, 37, 45, 54, 56, 64, 67, 74, 116], "nano": 76, "narrow": [14, 26, 40], "nativ": 63, "natur": [4, 7, 13, 14, 18, 19, 30, 42, 52, 54, 56, 57, 58, 63, 64, 67, 68, 84, 93, 95, 110, 111, 113], "navig": 8, "nccl": 25, "ncurs": 25, "nderstand": 21, "ndim": [64, 65, 111], "ne": [73, 75, 106], "nearbi": 114, "nearli": [11, 13, 52, 67, 72, 76], "necess": 59, "necessari": [5, 71, 72, 89, 103], "necessit": 109, "necssari": [20, 39], "need": [1, 2, 8, 14, 19, 30, 41, 42, 47, 48, 52, 56, 58, 59, 62, 63, 64, 65, 77, 82, 88, 101, 106, 111, 112], "neelakantan": [47, 101], "neg": [49, 66, 67, 71, 75, 79, 85, 88, 91, 99, 100, 106], "negligibli": 62, "neighbor": 83, "net": [47, 101], "network": [12, 47, 61, 64, 65, 66, 71, 82, 101, 109, 116], "networkx": 25, "neural": [11, 12, 47, 64, 65, 95, 101, 116, 117], "neutral": 100, "never": 109, "new": [7, 8, 9, 11, 13, 14, 15, 20, 23, 25, 26, 30, 33, 37, 39, 40, 42, 45, 52, 54, 55, 57, 62, 63, 64, 65, 66, 71, 75, 76, 77, 78, 82, 89, 98, 106, 108, 116], "newli": [33, 37, 45], "newlygener": [30, 42], "next": [1, 11, 12, 25, 30, 42, 49, 54, 56, 63, 68, 76, 78, 83, 89, 90, 111, 115], "next_token": 64, "ng": 25, "ni": [47, 101], "nichol": [47, 101], "nichola": [47, 101], "nick": [47, 101], "nie": [47, 101], "niki": [47, 101], "nikola": [47, 101], "ning": [47, 101], "nl": 86, "nll": 63, "nlp": [12, 14, 15, 52, 78, 108, 113], "nn": [59, 64, 65, 109, 111, 113], "no_think": 68, "noam": [47, 101], "node": [60, 109], "nois": [72, 88], "noisi": [58, 88, 90, 91], "non": [14, 20, 27, 30, 39, 42, 60, 61, 66, 68, 71, 72, 83, 87, 95, 98, 115], "none": [59, 64, 65], "nonlinear": [64, 65, 116], "noqa": 64, "norm": [64, 65, 68], "norm_ep": [64, 65], "normal": [11, 13, 25, 61, 65, 66, 68, 77, 80, 83, 84, 88, 109], "normalize_reward": 80, "normalized_shap": 64, "notabl": [18, 50, 58, 71, 111], "note": [46, 47, 51, 56, 60, 64, 74, 75, 76, 77, 90], "notebook": 47, "notin": [79, 87], "novel": [7, 9, 26, 33, 40, 45, 73, 79, 87, 90, 114, 115], "novelti": 24, "novemb": 58, "now": [56, 59, 68, 71, 74, 75, 90, 99, 111], "np": [24, 74, 87], "nuanc": [5, 66, 95], "nucleu": 64, "num": 112, "num_attention_head": 59, "num_base_token": 64, "num_channel": 64, "num_episod": 80, "num_experts_per_tok": 59, "num_featur": [64, 113], "num_head": 59, "num_reserved_special_token": 64, "num_sampl": [64, 87], "num_step": 11, "num_train_epoch": 119, "number": [2, 3, 12, 14, 15, 24, 30, 33, 42, 45, 50, 51, 52, 54, 57, 58, 59, 64, 68, 72, 76, 77, 87, 98, 100, 109, 110, 111, 112, 113, 115, 116, 120], "numer": [24, 75, 82, 106], "numpi": [24, 25, 74, 87], "nvidia": [25, 98], "nvjitlink": 25, "nvrtc": 25, "nvtx": 25, "nw": 86, "o": [11, 21, 77, 85, 108, 112, 115], "o1": [34, 98], "o_": [59, 72, 77], "o_1": [77, 85], "o_2": [77, 85], "o_g": 77, "o_i": 72, "o_proj": 59, "obei": 112, "object": [3, 12, 15, 44, 49, 54, 55, 57, 60, 62, 66, 68, 72, 74, 77, 78, 79, 82, 87, 91, 109], "observ": [3, 4, 5, 8, 33, 41, 45, 50, 52, 56, 59, 63, 68, 71, 72, 76, 84, 88, 95, 103, 106, 110, 112], "obstacl": [2, 49], "obtain": [1, 7, 11, 12, 20, 26, 33, 39, 40, 45, 55, 58, 59, 63, 66, 67, 71, 72, 76, 84, 87, 98, 99, 106], "obviou": 49, "occasion": [14, 63], "occur": 95, "occurr": 95, "od": 21, "off": [30, 42, 47, 48, 50, 68, 72, 79, 84], "offer": [9, 67, 76, 79, 84], "offici": 72, "offlin": [34, 35, 49, 54, 59, 67, 79], "offset": 11, "often": [12, 14, 30, 42, 49, 56, 72, 79, 84, 85, 88, 91, 113], "ofthought": 93, "oj": 7, "ol": 108, "old": [72, 77, 82, 108], "older": [41, 108], "oliveira": [47, 101], "omit": [59, 109, 112, 116], "onc": [11, 20, 31, 33, 39, 45, 51, 68, 112], "one": [1, 3, 9, 11, 14, 15, 18, 30, 31, 33, 41, 42, 45, 47, 49, 50, 52, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 71, 73, 75, 76, 77, 79, 84, 85, 87, 89, 98, 100, 106, 109, 111, 113, 116], "ones": [11, 37, 59, 62, 63, 64, 65, 67, 91, 98, 109, 111, 113], "ones_lik": [64, 65, 111], "onli": [9, 14, 15, 19, 20, 21, 23, 27, 30, 39, 41, 42, 52, 54, 55, 57, 60, 62, 63, 64, 65, 67, 71, 73, 74, 75, 77, 79, 83, 85, 89, 90, 91, 98, 99, 100, 103, 110, 111, 112, 114, 115], "onlin": [34, 35, 37, 55, 59, 72, 73, 79], "open": [8, 9, 18, 20, 31, 33, 35, 38, 39, 41, 45, 47, 60, 64, 66, 67, 72, 89, 95, 101], "openai": [13, 15, 25, 27, 47, 64, 78, 101], "opencod": 35, "openr1": 35, "openreview": [47, 101], "opensourc": 66, "openssl": 25, "oper": [1, 7, 12, 27, 33, 45, 68, 76, 82, 111, 113], "opportun": 76, "oppos": [57, 116], "opposit": [79, 85], "optim": [1, 7, 12, 15, 20, 34, 39, 47, 49, 50, 51, 56, 58, 59, 60, 62, 66, 67, 68, 72, 73, 76, 78, 82, 86, 87, 90, 95, 99, 101, 111], "optima": 99, "optimis": 75, "option": [20, 22, 39, 49, 59, 64, 65, 83, 84, 98, 111], "opu": 58, "oracl": [31, 49, 50, 99], "order": [9, 11, 12, 13, 14, 15, 52, 54, 55, 56, 57, 59, 62, 74, 78, 83, 84, 88, 89, 90, 109, 110, 111, 112, 114, 115], "org": [26, 30, 33, 40, 42, 45, 47, 101], "organ": [67, 74], "origin": [1, 13, 22, 23, 30, 33, 42, 45, 55, 56, 60, 61, 62, 63, 71, 72, 73, 79, 84, 88, 89, 90, 109, 110, 111, 115, 116], "orjson": 25, "orthogon": [26, 40], "oss": [47, 101], "other": [2, 7, 11, 12, 15, 23, 33, 38, 45, 47, 48, 49, 52, 56, 57, 59, 60, 63, 64, 65, 67, 68, 76, 79, 87, 89, 91, 99, 101, 106, 109, 113, 116, 118], "otherwis": [49, 60, 62, 72, 73, 79, 87, 100, 109, 110], "otim": [64, 65, 116], "our": [1, 2, 3, 11, 12, 13, 15, 19, 20, 21, 23, 26, 27, 30, 31, 33, 39, 40, 41, 42, 45, 49, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 72, 74, 75, 76, 77, 78, 83, 84, 86, 88, 89, 90, 95, 98, 99, 100, 106, 111, 114, 115, 120], "ourselv": 55, "out": [15, 31, 55, 62, 63, 64, 65, 72, 73, 76, 78, 98, 106, 110, 111, 112], "out_logprob": 64, "out_token": 64, "outbound": 13, "outcom": [72, 73, 95], "outdat": 41, "outer": [64, 65, 111], "outermost": 80, "outlier": 82, "outlin": [33, 45, 88, 95], "outperform": [50, 52, 57, 58, 59, 60, 67, 84, 100, 106], "output": [1, 3, 5, 7, 9, 11, 12, 15, 20, 21, 25, 26, 30, 39, 40, 42, 48, 49, 50, 51, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 77, 78, 79, 85, 88, 90, 91, 103, 109, 112, 113, 115], "output_dir": 119, "outsid": 88, "ouyang": [47, 101], "over": [11, 12, 13, 14, 15, 23, 25, 49, 51, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 72, 76, 77, 78, 79, 80, 84, 88, 89, 91, 99, 100, 112, 113, 115], "overal": [11, 12, 30, 41, 42, 51, 54, 60, 63, 71, 72, 77, 79, 84], "overcom": 2, "overconfid": 88, "overfit": [32, 78, 88], "overlap": [41, 67], "overli": 68, "overload": 60, "oversight": 27, "overthink": 60, "overview": [1, 47, 64, 65], "overwrite_cach": 119, "owj": [15, 47, 101], "own": [8, 63, 79, 83, 89, 99, 100], "p": [12, 15, 44, 49, 50, 62, 64, 74, 76, 77, 79, 85, 87, 115, 117], "p_": [49, 73, 76, 88, 91, 99, 109], "p_1": 99, "p_i": [44, 73], "pa": 44, "pack": [11, 119], "packag": [25, 31, 41], "pad": 113, "pad_id": 64, "padding_idx": 59, "page": [7, 47, 48], "pain": 9, "paino": [47, 101], "pair": [11, 12, 13, 15, 20, 21, 31, 39, 41, 49, 52, 56, 57, 59, 61, 66, 67, 68, 72, 76, 78, 79, 83, 84, 85, 86, 87, 88, 89, 91, 98, 99], "pairwis": [15, 62, 71, 73, 85, 86, 87, 89, 90], "palm": [64, 65], "pamela": [47, 101], "pan": [47, 101], "panda": 25, "panpan": [47, 101], "paper": [5, 7, 15, 24, 26, 27, 30, 33, 40, 42, 45, 46, 49, 55, 56, 57, 63, 106, 111], "par": 84, "paradigm": [14, 73, 79], "parallel": [11, 54, 64, 67, 98, 109, 113], "paralleliz": 11, "param": [24, 64, 65], "paramet": [7, 11, 12, 13, 14, 15, 26, 40, 41, 50, 55, 57, 60, 61, 62, 63, 64, 65, 66, 68, 71, 72, 74, 75, 76, 77, 78, 79, 82, 87, 88, 103, 106, 109, 110, 111, 112, 113, 114, 115, 116, 120], "parameter": [51, 73, 91], "parametr": 74, "parenthes": 85, "parmar": [47, 101], "pars": [63, 67], "parsed_arg": 22, "parser": 63, "part": [52, 57, 67, 76, 109, 115], "partial": [49, 56], "particip": [28, 54, 55], "particular": [11, 63, 64, 65, 72, 74, 76, 77, 93, 110, 116], "particularli": [25, 79, 95], "partit": [74, 88, 109], "pass": [9, 12, 21, 24, 28, 31, 33, 41, 45, 51, 54, 56, 57, 58, 63, 64, 65, 66, 68, 71, 110, 116, 120], "pass_at_k": 24, "past": [76, 82], "pat_str": 64, "patch": [1, 9, 31], "path": [8, 48, 64, 106], "path_to_custom_output": 25, "pattern": [14, 60, 64, 68, 72, 73], "paul": [47, 101], "pavlov": [47, 101], "pbar": 80, "pdf": [26, 30, 33, 40, 42, 45], "pe_": 11, "peak": [20, 39], "pearson": 71, "pebbl": 25, "pei": [47, 101], "peiyi": [47, 101], "penal": [52, 72, 88], "penalti": [15, 62, 71, 72, 77, 78, 99], "peng": [47, 101], "per": [9, 15, 23, 24, 49, 51, 54, 55, 59, 64, 68, 77, 78, 85, 86, 89, 100, 112], "per_device_train_batch_s": 119, "percent": 83, "percentag": [54, 84], "perceptu": 49, "perfect": [63, 89], "perform": [3, 9, 11, 13, 14, 15, 18, 19, 20, 21, 23, 26, 27, 39, 40, 41, 50, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 73, 76, 78, 79, 84, 87, 89, 91, 93, 98, 100, 103, 106, 109, 110, 112, 113], "period": [57, 59, 115], "permit": [20, 39], "permut": [64, 113], "perplex": 110, "persist": 5, "person": [15, 83], "perspect": [14, 72, 115], "peter": [47, 101], "petroski": [47, 101], "petrov": [47, 101], "pexpect": 25, "pgr": 52, "phase": [1, 30, 41, 42, 56, 57, 60, 62, 66, 68, 74, 83, 95], "phd": 27, "phenomenon": [52, 71, 72, 95], "phi": [15, 71, 74, 77, 78, 84, 90, 116], "phi4": 34, "philipp": [47, 101], "philosophi": 23, "php": 63, "phrase": 12, "physic": [23, 27], "pi": [11, 15, 49, 62, 74, 76, 78, 82, 87, 88, 91, 99, 106, 110, 111], "pi_": [15, 49, 62, 72, 75, 77, 78, 82, 87, 91, 99, 106], "piao": [47, 101], "pick": [50, 54], "piec": [3, 61, 63, 83, 84, 98], "piecewis": 62, "pii": 15, "pile": 111, "pinto": [47, 101], "pioneer": 60, "pip": [22, 25], "pipelin": [9, 18, 20, 31, 39, 41, 58, 60, 66, 68, 74, 85, 95, 100], "pivot": [2, 50], "pkginfo": 25, "place": [64, 65, 73, 85, 116], "placehold": [20, 39], "plai": [5, 50, 58, 59, 60], "plain": [15, 56], "plan": [2, 60, 111], "plane": 115, "plappert": [47, 101], "platform": [7, 13, 25, 37, 54, 55], "platformdir": 25, "playground": 15, "pleas": [22, 83], "plethora": 63, "plot": [51, 74, 76], "plot_loss": 119, "plt": 74, "plu": 25, "plugin": 25, "pm": 91, "pmatrix": [57, 114, 115], "po": 11, "poetri": 25, "point": [9, 11, 41, 50, 55, 56, 59, 62, 67, 72, 89, 95, 111], "pointwis": [73, 87], "polar": [64, 65, 110, 111], "polici": [15, 58, 59, 60, 62, 63, 66, 68, 74, 76, 78, 82, 83, 84, 87, 91, 95, 99], "polit": 83, "polosukhin": [47, 101], "pond": [47, 101], "pool": [2, 30, 42, 54, 87, 90, 91, 98], "poor": [56, 60, 76, 95, 113], "poorli": 52, "pop": 87, "popular": [18, 31, 52], "portion": [9, 57, 63, 67, 95], "posit": [8, 12, 47, 52, 57, 60, 61, 64, 65, 66, 68, 75, 77, 79, 82, 84, 85, 89, 90, 91, 98, 100, 101, 103, 113, 114, 116], "positionwis": 11, "possess": 89, "possibl": [13, 30, 31, 42, 52, 55, 56, 60, 61, 63, 68, 72, 76, 83, 85, 86, 90, 99, 100], "possibli": [41, 67, 83], "post": 84, "post0": 25, "postpon": 56, "potenti": [2, 14, 15, 44, 56, 59, 62, 67, 72, 73, 79, 84, 95], "pow": [64, 65, 113], "power": [8, 14, 26, 40, 47, 54, 55, 64, 65, 72, 95, 101], "ppo": [15, 34, 35, 58, 62, 72, 78, 85], "ppo_train": 80, "pq": 44, "pr": [9, 31], "practic": [11, 14, 19, 41, 49, 52, 56, 67, 71, 74, 76, 88, 91, 109, 111], "practition": [26, 40], "prafulla": [47, 101], "pranav": [47, 101], "pre": [3, 11, 14, 19, 35, 37, 41, 47, 54, 56, 58, 64, 71, 73, 83, 98, 101, 108, 110, 111, 114, 115, 117], "preambl": 84, "preced": [12, 62], "precis": [19, 49, 57, 79], "precomput": 111, "precompute_freqs_ci": [64, 65, 111], "predecessor": [66, 67], "predefin": [26, 40, 82, 86, 95], "predicetd": 73, "predict": [2, 11, 12, 15, 21, 25, 52, 54, 55, 57, 64, 68, 71, 73, 76, 78, 88, 91, 99, 100, 111], "predominantli": 57, "prefer": [15, 18, 34, 35, 47, 49, 50, 58, 59, 60, 66, 67, 71, 75, 76, 78, 83, 85, 86, 87, 89, 90, 95, 99, 100, 101, 111, 113], "prefix": [15, 25, 30, 42, 49, 57, 100], "preliminari": [59, 73, 95], "prepend": [64, 83], "prescrib": 76, "presenc": [48, 67], "present": [7, 8, 15, 56, 60, 63, 76, 78, 79, 82, 83, 84, 90, 100, 110, 111], "preserv": [67, 110, 111], "pressur": 110, "pretrain": [14, 15, 23, 30, 42, 52, 57, 59, 67, 73, 78, 80, 83, 89, 100, 103, 110, 111, 120], "pretrained_weight": 119, "prev_po": 64, "prevent": [11, 57, 60, 82], "preview": 98, "previou": [1, 7, 8, 9, 11, 14, 30, 33, 42, 45, 59, 63, 64, 65, 66, 76, 79, 99, 110, 111], "previous": 11, "primari": 68, "primarili": [15, 27, 58, 63, 66, 78, 79], "princip": 109, "principl": [8, 83, 85], "print": [19, 48, 64], "prior": [5, 8, 13, 14, 27, 41, 62, 74, 79, 83, 91], "priorit": [63, 66], "privaci": 83, "privat": 2, "prm800k": 100, "pro": [55, 58, 76], "prob": 64, "probabl": [11, 12, 15, 24, 49, 50, 64, 72, 74, 75, 76, 77, 79, 82, 83, 84, 87, 91, 100], "problem": [9, 14, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 37, 38, 40, 41, 43, 47, 52, 54, 55, 56, 57, 60, 63, 67, 68, 72, 74, 87, 88, 95, 98, 100, 101], "probs_idx": 64, "probs_sort": 64, "probs_sum": 64, "proce": [33, 45], "procedur": [9, 12, 15, 31, 52, 55, 75, 76, 78, 84, 89], "process": [1, 5, 7, 13, 19, 30, 33, 41, 42, 45, 47, 49, 50, 52, 56, 58, 59, 60, 64, 66, 67, 68, 71, 72, 73, 76, 79, 82, 98, 101, 111, 113, 115, 117], "processor": 8, "prod": 24, "produc": [3, 5, 11, 12, 15, 20, 26, 30, 31, 33, 39, 40, 42, 45, 49, 50, 54, 55, 56, 59, 60, 63, 64, 67, 68, 71, 76, 78, 79, 84, 85, 88, 91, 99, 103, 112], "product": [24, 49, 64, 65, 114, 115, 116], "profession": [23, 57], "profici": 59, "program": [7, 24, 28, 37, 38, 41, 54, 55, 56, 57, 58, 60, 63, 67], "programm": [21, 28, 38], "programmat": [9, 24], "progress": [9, 11, 38, 56, 60, 62, 72, 76, 77], "project": [1, 11, 54, 112], "promin": [33, 45], "promis": [13, 14, 50, 67, 84, 98], "promot": [30, 42], "prompt": [1, 3, 4, 5, 7, 8, 9, 15, 18, 20, 22, 23, 24, 26, 30, 31, 39, 40, 41, 42, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 68, 71, 72, 76, 78, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 95, 103], "prompt_data": 80, "prompt_max_len": 80, "prompt_token": 64, "prompts_dataload": 80, "prone": [32, 88], "prop": 61, "propag": 8, "proper": [19, 67, 71, 73], "properli": [47, 62], "properti": [111, 114], "proport": [57, 59, 67, 75, 109], "propos": [3, 5, 7, 11, 30, 42, 49, 52, 57, 64, 65, 67, 71, 72, 73, 74, 77, 79, 87, 90, 91, 98, 99, 106, 109, 112, 116, 120], "proprietari": [57, 66], "propto": 75, "proto": 25, "protobuf": 25, "protocol": [41, 63], "prove": [41, 115], "proven": [58, 77], "provid": [1, 2, 3, 7, 8, 9, 12, 15, 20, 22, 23, 24, 25, 28, 31, 32, 39, 43, 52, 57, 58, 60, 62, 64, 67, 74, 75, 77, 79, 88, 89, 93, 95, 98, 100, 111, 115], "proxim": 77, "prune": 28, "pseudo": 91, "pseudocod": 44, "pseudolabel": 91, "psi": [74, 77, 87, 88], "psi_": 88, "psm": 57, "psychologi": 23, "pth": 64, "ptimiz": 72, "ptx": [15, 78], "ptyprocess": 25, "public": [15, 54, 55, 56, 58, 67, 78], "publicli": [57, 61, 66], "pull": [9, 31], "punish": 72, "punit": 72, "pure": 95, "puri": [47, 101], "purpos": [3, 9, 31, 47, 52, 57, 103, 111], "pursu": 27, "push": [11, 26, 40, 79], "put": [20, 30, 39, 42, 49, 54, 95], "puzzl": [52, 60], "py": [22, 119], "py310h06a4308_0": 25, "pyarrow": 25, "pyasn1": 25, "pycpars": 25, "pydant": 25, "pydoc": 41, "pyext": 25, "pypars": 25, "pyplot": 74, "pyproject": 25, "python": [3, 9, 21, 22, 25, 26, 28, 31, 40, 41, 54, 55, 57, 63, 67, 106], "pytorch": 98, "pytz": 25, "pyyaml": 25, "q": [11, 15, 44, 47, 49, 64, 65, 66, 67, 72, 77, 79, 101, 106, 110, 111, 112, 114, 115], "q_": [64, 65, 110, 111], "q_0": [64, 65], "q_1": [64, 65], "q_2": [64, 65], "q_3": [64, 65], "q_a_layernorm": 59, "q_a_proj": 59, "q_b_proj": 59, "q_head_dim": 59, "q_i": [44, 106], "q_lora_rank": 59, "qa": [41, 44, 61, 95], "qihao": [47, 101], "qime": [47, 101], "qin": [47, 101], "qinyu": [47, 101], "qiu": [47, 101], "qiufeng": [47, 101], "qiushi": [47, 101], "qk": [11, 68], "qk_nope_head_dim": 59, "qk_rope_head_dim": 59, "qkv": [66, 68], "qlora": 80, "qpa": 44, "qr": 112, "qu": [47, 101], "quad": [12, 51, 60, 62, 72, 73, 88, 91, 109, 110, 111], "qualiti": [5, 11, 13, 19, 26, 27, 30, 31, 32, 34, 40, 41, 42, 43, 44, 49, 55, 59, 60, 62, 66, 67, 68, 71, 72, 84, 85, 86, 89, 90, 91, 98, 110, 111], "quan": [47, 101], "quantifi": [88, 98], "quantil": 91, "quantiti": [34, 63], "quartil": 63, "queri": [2, 11, 15, 18, 41, 47, 57, 59, 64, 65, 66, 67, 68, 73, 76, 77, 88, 91, 101, 110, 111, 114, 115], "query_1": 63, "query_2": 63, "question": [1, 2, 12, 13, 20, 22, 23, 27, 28, 31, 33, 39, 41, 44, 45, 50, 56, 57, 60, 67, 72, 77, 84, 98, 100, 103, 106, 110, 111], "question_id": 25, "quickli": [8, 72], "quit": [56, 58], "qw_": 11, "qwen": [34, 47, 68, 72, 101], "qwen2": [34, 35, 47, 66, 68, 72, 98, 101], "qwq": 68, "qy": [47, 66, 67, 101], "r": [11, 15, 21, 33, 45, 47, 49, 57, 59, 60, 62, 63, 64, 71, 72, 75, 76, 77, 82, 87, 88, 99, 101, 106, 109, 110, 112, 114, 115, 120], "r1": [35, 60, 72], "r_": [15, 49, 59, 62, 71, 72, 73, 74, 76, 77, 78, 82, 84, 87, 88, 89, 106, 114, 115], "r_1": [73, 77], "r_h": 62, "r_i": [72, 73, 77, 106], "r_l": 73, "racist": 83, "radford": [47, 101], "rafael": [47, 101], "rafailov": [47, 101], "rai": [47, 101], "rais": [1, 23, 64, 111], "ramesh": [47, 101], "ramp": 110, "ran": 55, "rand_prompt": 80, "randn": [64, 113], "random": [9, 13, 23, 26, 40, 54, 55, 64, 76, 87, 88, 90, 98], "randomli": [9, 21, 23, 26, 33, 40, 45, 54, 57, 67, 68, 83, 85], "rang": [8, 12, 14, 15, 23, 25, 26, 40, 52, 57, 61, 62, 63, 64, 65, 68, 72, 80, 82, 83, 84, 108, 111], "rangl": [64, 65, 110, 111, 115], "rank": [1, 15, 50, 54, 56, 62, 63, 74, 78, 87, 88, 89, 120], "rapid": 68, "rapidfuzz": 25, "rapidli": 79, "rate": [3, 9, 41, 52, 54, 55, 56, 59, 61, 62, 63, 68, 71, 72, 76, 78, 82, 84, 100, 103], "rater": 76, "rather": [74, 85, 95], "ratio": [60, 67, 75, 82, 110], "rational": 84, "raul": [47, 101], "raw": [58, 117], "re": [3, 56, 64, 65, 74, 87, 110, 111, 115], "reach": [3, 14, 27, 30, 42, 55, 56, 62, 68, 100, 109], "react": 5, "read": [13, 64], "readabl": [63, 95], "readlin": 25, "real": [3, 31, 41, 57, 80, 103, 111, 115], "realist": [19, 20, 27, 39], "realiti": [87, 111], "realiz": 12, "realli": [1, 47, 101], "realm": [26, 33, 40, 45], "realworld": 41, "rearrang": [74, 87], "reason": [4, 5, 7, 14, 23, 24, 33, 35, 45, 47, 49, 50, 56, 57, 59, 60, 63, 66, 72, 75, 77, 84, 90, 100, 101, 111, 113], "recal": [49, 63, 76, 79], "receiv": [3, 7, 8, 13, 49, 62, 76, 109], "recent": [2, 5, 9, 14, 54, 55, 61, 62, 63, 64, 71, 78], "recip": [57, 63, 90], "recogn": 8, "recommend": [18, 89], "record": 7, "recov": [8, 52, 76], "recoveri": 8, "rectifi": [64, 65, 116], "recurr": 11, "red": [33, 45, 112], "reddit": 13, "reduc": [13, 20, 23, 39, 41, 49, 50, 62, 75, 99, 109, 111, 112, 116, 120], "reduct": [64, 75], "redund": [55, 60, 109], "reevalu": 95, "ref": [74, 75, 77, 99], "refer": [8, 9, 15, 28, 31, 32, 47, 49, 57, 62, 63, 68, 71, 72, 74, 75, 76, 77, 83, 89, 98, 100, 110], "refin": [19, 60, 63, 76], "reflect": [28, 41, 56, 79, 98], "regard": [7, 72], "regardless": [71, 72], "regener": 41, "regex": 64, "regim": 100, "region": [11, 49, 82, 111], "reglu": [64, 65, 116], "regress": [1, 11, 15, 57, 62, 63, 71, 78], "regul": 72, "regular": [47, 63, 66, 76, 77], "regularli": [60, 67], "rehears": 57, "reiichiro": [47, 101], "reinforc": [15, 52, 57, 74, 77, 85, 100, 103], "reject": [34, 35, 57, 60, 62, 63, 67, 68, 71, 86, 88, 90, 91, 106], "rejected_1": 63, "rejected_2": 63, "rel": [1, 11, 15, 50, 54, 58, 59, 60, 64, 65, 66, 72, 75, 83, 95, 103, 111, 114, 115], "relat": [7, 20, 25, 39, 41, 50, 57, 58, 60, 66, 67, 77, 87, 106, 109, 112, 115], "relationship": [47, 101], "releas": [20, 22, 39, 41, 57], "relev": [1, 7, 8, 31, 52, 56, 66, 67, 72, 90, 91, 100], "reli": [26, 40, 49, 52, 55, 56, 60, 91, 98, 113], "reliabl": [8, 9, 21, 23, 27, 52, 59, 60, 66, 95, 100], "relianc": 113, "relu": [11, 61, 64, 65, 74, 116], "remain": [2, 9, 30, 31, 42, 51, 52, 54, 55, 68, 75, 88, 91, 100], "remark": [95, 103], "remind": [20, 39], "remov": [15, 33, 41, 45, 55, 57, 61, 63, 67, 68, 78, 83, 87, 90, 106], "ren": [7, 47, 101], "render": 47, "renorm": 64, "reorder": 57, "repair": [1, 25], "reparameter": 74, "repeat": [4, 8, 20, 30, 39, 42, 56, 72, 98], "repeatedli": 54, "repetit": [13, 72], "replac": [8, 61, 64, 65, 66, 83, 84, 111, 116], "replai": [76, 77, 80], "replay_buff": 80, "replic": 1, "repo": [31, 63, 67], "report": [24, 47, 67, 72, 88, 101, 106], "repositori": [1, 8, 9, 25, 31, 41, 54, 57, 58, 67], "repres": [8, 11, 30, 33, 42, 45, 49, 57, 63, 64, 65, 75, 82, 88, 109, 110, 111, 115, 116, 118], "represent": [9, 11, 44, 52, 54, 60, 64, 65, 68, 74, 84, 115, 116], "reproduc": [2, 41], "reproduct": [1, 9], "request": [2, 9, 20, 25, 31, 39, 83, 89], "requir": [1, 2, 3, 9, 11, 12, 14, 20, 21, 31, 39, 52, 55, 56, 57, 60, 62, 63, 64, 76, 87, 95, 109, 110, 111, 112, 113, 114, 115], "rerank": 55, "resampl": [66, 76], "rescal": 111, "research": [2, 27, 41, 62, 79], "reserv": [59, 68], "reserved_special_token_": 64, "reserved_special_token_0": 64, "reserved_special_token_1": 64, "reserved_special_token_2": 64, "reserved_special_token_3": 64, "reserved_special_token_4": 64, "reshap": [64, 65, 111], "reshape_for_broadcast": [64, 65, 111], "residu": [11, 51], "resolv": [1, 9, 31, 54, 71], "resort": 95, "resourc": [56, 62, 67, 98], "respect": [11, 15, 50, 72, 75, 77, 78, 79, 82, 84, 85, 88, 109, 112], "respond": 68, "respons": [8, 15, 18, 20, 22, 25, 33, 39, 41, 45, 50, 59, 60, 62, 63, 64, 66, 67, 68, 71, 72, 73, 76, 77, 78, 79, 82, 83, 84, 86, 87, 88, 89, 91, 95, 99, 103, 109], "response_candid": 87, "response_reward": 87, "rest": 48, "restrict": [3, 49, 60, 72, 75, 82], "result": [1, 3, 11, 13, 14, 23, 24, 26, 32, 40, 41, 49, 52, 55, 56, 57, 62, 67, 77, 79, 87, 88, 95, 100, 106, 109, 110, 111, 112, 114, 115], "retain": [41, 57, 60, 63, 67, 83, 91], "retriev": [1, 2, 7, 41], "return": [24, 49, 64, 65, 79, 82, 87, 111, 113], "reus": [66, 95, 111], "reveal": [60, 63], "revers": 84, "review": [66, 74], "revis": [9, 63, 99], "reward": [5, 15, 34, 35, 47, 50, 52, 56, 57, 58, 59, 60, 66, 68, 74, 77, 79, 80, 84, 86, 87, 90, 91, 101], "reward_pretrain": 80, "rewon": [47, 101], "rewrit": [9, 83], "rft": [34, 73, 106], "rho": 106, "rho_": 87, "rich": [7, 41], "right": [11, 15, 24, 49, 51, 57, 64, 65, 71, 72, 74, 75, 77, 78, 79, 82, 84, 87, 99, 100, 110, 111, 112, 115, 117], "rigor": [7, 19, 22, 23, 41, 47, 68, 101], "risk": [31, 60, 67], "rl": [5, 15, 34, 35, 54, 58, 59, 60, 62, 66, 72, 74, 82, 83, 84, 85, 91, 95, 100], "rlaif": [35, 83, 85, 91], "rlcd": [34, 35, 91], "rlhf": [52, 57, 71, 72, 74, 76, 78, 80, 83, 87], "rlhf1": 35, "rlhf2": 35, "rm": [15, 34, 52, 59, 60, 62, 63, 71, 80, 84, 86], "rm_": 59, "rmboost": 34, "rmsnorm": [47, 59, 61, 66, 68, 101], "roberta": 63, "robust": [30, 31, 41, 42, 56, 58, 66, 83], "roform": [47, 101], "role": [3, 5, 50, 58, 59, 60, 64], "rollout": [68, 72, 99], "rollout_batch_s": 80, "room": 56, "rope": [34, 35, 57, 60, 61, 66, 112], "rope_theta": [64, 65], "rotari": [47, 57, 61, 66, 68, 101, 114], "rotat": [57, 114, 115], "roug": [30, 42], "roughli": [4, 51, 55, 61, 88, 100], "round": [33, 45, 55], "rout": [59, 60, 109], "row": [64, 65, 111], "rozi\u00e8r": [47, 101], "rsa": 25, "rsm": [47, 63, 66, 101], "rso": [34, 35], "rsqrt": [64, 65, 113], "rtol": [64, 113], "rtx4090": 80, "ruan": [47, 101], "rui": [47, 101], "ruiqi": [47, 101], "ruizh": [47, 101], "rule": [27, 56, 58, 59, 60, 63, 68, 95], "rulebas": 60, "run": [9, 21, 48, 56, 57, 63, 75, 83, 98, 99], "runji": [47, 101], "runnabl": 2, "runner": 25, "runtim": [25, 55], "runxin": [47, 101], "ruyi": [47, 101], "rwc": [13, 14, 47, 101], "rx": 76, "ryan": [47, 101], "ryder": [47, 101], "s3transfer": 25, "s_": [49, 60, 73, 75, 82, 109, 111], "s_1": [67, 73, 111], "s_2": 111, "s_i": 73, "s_j": 73, "s_n": 67, "s_t": 82, "safe": 78, "safeti": [52, 57, 59, 62], "sahil280114": [20, 39], "sai": 83, "salienc": 52, "salient": 52, "sam": [47, 101], "same": [9, 11, 14, 33, 41, 45, 47, 54, 55, 56, 57, 58, 59, 67, 68, 72, 74, 75, 83, 85, 87, 88, 89, 95, 106, 109, 110, 111, 112, 113], "sampl": [1, 7, 13, 21, 22, 23, 24, 26, 30, 31, 33, 34, 35, 40, 41, 42, 45, 49, 50, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 73, 74, 76, 77, 82, 83, 84, 85, 86, 89, 90, 91, 98, 100, 103, 106, 113], "sample_top_p": 64, "sandbox": [66, 67], "sandhini": [47, 101], "sanghai": [47, 101], "sanit": 22, "sastri": [47, 101], "satisfactori": [59, 79], "satisfi": [68, 79], "saunder": [47, 101], "save": [56, 112], "save_path": 80, "save_step": [80, 119], "scail": [82, 98], "scalabl": [9, 12, 27, 67, 73, 79, 82, 84], "scalar": [15, 62, 71, 73, 78, 79], "scale": [12, 14, 30, 31, 32, 41, 42, 43, 47, 52, 62, 64, 65, 66, 67, 68, 72, 74, 79, 82, 95, 101, 103, 111, 112], "scan": 51, "scarciti": 67, "scenario": [2, 3, 25, 41, 67, 68, 72], "schedul": [41, 61, 68], "scheme": [62, 76, 118], "school": 27, "schulman": [47, 101], "scienc": [23, 41, 61], "scientif": 41, "scope": [31, 60], "score": [19, 23, 60, 62, 63, 64, 65, 66, 67, 68, 71, 73, 76, 77, 78, 82, 83, 84, 85, 87, 88, 89, 91, 100, 109, 110, 111], "scorer": 67, "scott": [47, 101], "scrape": [13, 31, 37, 54, 72], "scratch": [34, 88, 110, 111], "script": [22, 119], "scroll_down": 8, "scroll_up": 8, "scy": [44, 47, 67, 101], "se": [7, 9], "search": [2, 4, 7, 8, 55, 56, 100], "search_dir": 8, "search_fil": 8, "seattl": 108, "second": [2, 11, 13, 20, 21, 39, 41, 49, 55, 59, 60, 67, 76, 84, 99, 116], "secret": [34, 35], "secretli": [47, 101], "secretstorag": 25, "section": [41, 58, 72, 83, 95, 111, 115], "secur": 67, "see": [18, 21, 23, 47, 48, 49, 51, 63, 65, 75, 81, 84, 111], "seed": [19, 20, 26, 30, 39, 40, 41, 42, 67, 89, 90], "seek": [62, 98], "seem": 8, "seen": [63, 91], "segment": [27, 62, 117], "segmentatio": 68, "select": [1, 7, 18, 21, 31, 33, 41, 45, 50, 54, 55, 56, 57, 60, 62, 63, 64, 71, 72, 76, 78, 100, 103, 106, 109], "selector": 100, "self": [5, 11, 12, 13, 15, 20, 22, 25, 26, 28, 31, 34, 35, 39, 40, 47, 57, 59, 63, 64, 65, 67, 77, 80, 101, 109, 110, 111, 113, 114, 115], "selfattent": 115, "selfinstruct": [30, 42], "semant": [28, 54, 55, 56, 63, 67, 90], "semi": [30, 42, 73], "sen": [47, 101], "send": [51, 76, 109], "sensit": [15, 23, 112, 113], "sent": [41, 60, 109], "sentenc": [11, 12, 13, 20, 39, 41, 61, 84, 117], "separ": [11, 18, 55, 57, 62, 100], "seq_len": [64, 113], "seqlen": [64, 65], "sequenc": [7, 11, 12, 27, 47, 49, 57, 60, 62, 64, 65, 66, 68, 72, 76, 79, 87, 89, 101, 109, 110, 112, 113, 114, 115, 116, 117], "sequenti": [49, 76, 98], "seri": [26, 40, 61, 66, 67, 68, 89, 93, 100], "serv": [5, 19, 41, 47, 50, 60, 73, 76, 88, 109], "servic": 66, "set": [1, 2, 9, 11, 14, 15, 18, 19, 20, 21, 23, 24, 27, 30, 31, 32, 33, 38, 39, 41, 42, 43, 45, 49, 50, 52, 54, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 72, 73, 76, 77, 78, 83, 87, 88, 89, 90, 98, 100, 103, 106, 109, 110, 111, 115], "setup": [3, 5, 22, 52], "setuptool": 25, "seventh": [47, 101], "sever": [8, 9, 24, 50, 54, 55, 57, 58, 62, 63, 66, 67, 76, 95, 113], "sexist": 83, "sft": [15, 34, 35, 41, 59, 60, 66, 67, 68, 74, 75, 77, 80, 82, 84, 86, 87, 88, 89, 95, 99, 106], "sh": 80, "sha": [47, 101], "shallow": 71, "shang": [47, 101], "shanghao": [47, 101], "shanghaoran": [47, 101], "shangyan": [47, 101], "shanhuang": [47, 101], "shantanu": [47, 101], "shao": [47, 101], "shaoq": [47, 101], "shape": [51, 64, 65, 111, 113], "share": [11, 15, 38, 59, 60, 68, 95, 112], "sharegpt": 41, "sharma": [47, 101], "shazeer": [47, 101], "shelf": [50, 79, 84], "shellingham": 25, "shen": [47, 101], "shengfeng": [47, 101], "shengguang": [47, 101], "shift": [41, 73, 100], "shiji": [47, 101], "shirong": [47, 101], "shiyu": [47, 101], "short": [5, 21, 28, 31, 60, 111], "shorter": [50, 72], "shot": [14, 15, 19, 23, 30, 42, 47, 83, 84, 89, 91, 100, 101, 106], "should": [1, 2, 8, 14, 20, 21, 27, 39, 48, 51, 52, 55, 75, 79, 83, 85, 87, 112], "show": [1, 11, 14, 15, 19, 23, 47, 48, 49, 57, 61, 63, 74, 75, 79, 83, 87, 88, 89, 93, 95, 100, 111, 112, 115], "shown": [7, 11, 15, 24, 26, 40, 41, 49, 52, 77, 78, 84, 88, 91], "shuai": [47, 101], "shuang": [47, 101], "shuffl": [33, 45], "shuip": [47, 101], "shukai": [47, 101], "shunfeng": [47, 101], "shusheng": [47, 101], "shyam": [47, 101], "sida": [47, 101], "siddhartha": [47, 101], "sidestep": 76, "sigler": [47, 101], "sigma": [15, 62, 64, 65, 74, 75, 78, 84, 87, 88, 116], "sigma_": 82, "sigmoid": [64, 65, 74, 87, 116], "signal": [5, 30, 42, 49, 56, 58, 60, 63, 66, 72, 84, 85, 95], "signatur": [24, 28, 41, 55, 57], "signific": [9, 13, 23, 41, 59, 62, 63, 66, 110, 111, 112, 113], "significantli": [11, 19, 20, 23, 26, 39, 40, 44, 50, 56, 57, 59, 62, 63, 66, 68, 72, 73, 75, 83, 88, 93, 100, 112], "silu": [64, 65], "sim": [15, 49, 51, 62, 72, 73, 74, 75, 77, 78, 87, 88, 91, 99, 116], "simen": [47, 101], "similar": [7, 8, 14, 18, 23, 30, 42, 47, 54, 55, 63, 67, 68, 83, 85, 100, 106, 110], "similarili": [110, 112], "similarli": [11, 55, 60, 75, 89, 91, 95], "simpl": [8, 9, 11, 14, 20, 24, 26, 33, 39, 40, 45, 47, 51, 52, 54, 60, 64, 65, 73, 74, 84, 91, 93, 115, 117], "simpler": [12, 49, 74], "simplest": 98, "simpli": [9, 15, 20, 39, 52, 71, 98, 99, 110], "simplic": [12, 56, 82], "simplifi": [20, 24, 33, 39, 45, 64, 106], "simplist": [1, 3], "simul": [54, 76, 85], "simultan": [11, 51, 73, 89], "sin": [11, 57, 64, 65, 110, 111, 114, 115], "sinan": [47, 101], "sinc": [1, 11, 12, 49, 52, 55, 58, 64, 65, 67, 74, 75, 77, 83, 84, 87, 109, 111, 112, 113], "sine": 11, "singl": [2, 13, 15, 20, 24, 28, 39, 54, 55, 56, 57, 60, 78, 85, 90, 100, 109], "sinusoid": [11, 115], "site": 38, "situat": 109, "six": [25, 33, 45, 63], "size": [12, 13, 14, 32, 41, 43, 47, 57, 59, 61, 64, 65, 66, 68, 72, 77, 79, 88, 101, 103, 109, 110, 111, 112, 113], "skeleton": 1, "sketch": 7, "skill": [27, 32, 43, 57, 67, 89], "skywork": 34, "sl": 83, "slama": [47, 101], "slice": 112, "slight": 47, "slightli": [62, 63], "slope": 98, "slow": 113, "slowli": [110, 111], "slp": [47, 60, 66, 101, 110, 112, 114], "small": [11, 21, 30, 42, 47, 52, 54, 56, 57, 63, 67, 82, 89, 95, 98, 110, 111, 112, 113, 115], "smaller": [1, 50, 61, 62, 99, 100, 103, 109, 110, 112, 114], "smallest": [13, 54, 64], "smallscal": 100, "smarter": 52, "smooth": [14, 33, 45], "snapshot": [54, 83], "sniffio": 25, "snippet": [1, 19, 26, 40, 41, 57, 63, 66, 67], "so": [2, 5, 15, 21, 48, 54, 56, 62, 63, 73, 75, 76, 77, 83, 89, 109, 110, 111, 112], "social": [13, 23], "soft": [56, 72, 84, 88], "softmax": [12, 64, 65, 84, 109, 110, 112], "softwar": [1, 31, 41], "solar": [47, 101], "sole": [11, 49, 62, 72, 79], "solid": 112, "solut": [3, 5, 9, 19, 22, 26, 27, 28, 31, 32, 37, 38, 40, 43, 44, 54, 55, 56, 57, 63, 68, 71, 74, 84, 90, 98, 100, 112, 113, 115], "solv": [1, 3, 19, 22, 23, 24, 27, 28, 31, 47, 50, 54, 55, 56, 57, 63, 95, 99, 100, 101], "solvabl": 28, "some": [11, 12, 20, 39, 47, 54, 56, 58, 62, 63, 68, 71, 76, 79, 87, 91, 109], "someon": 83, "someth": 14, "sometim": [14, 41], "song": [47, 101], "sonnet": 98, "sophist": 68, "sort": [63, 64, 76], "sound": 72, "sourc": [1, 9, 13, 18, 24, 28, 31, 33, 41, 45, 47, 57, 58, 60, 63, 64, 66, 67, 72, 87, 95, 101], "space": [3, 4, 13, 33, 45, 55, 56, 114, 115], "span": [2, 23, 27, 47, 52, 57, 67, 68, 98], "spars": [5, 7, 14, 31, 47, 56, 101], "speak": 87, "spearman": 71, "special": [2, 8, 23, 47, 62, 64, 66, 68, 91, 100, 109], "special_token": 64, "specif": [1, 2, 4, 5, 7, 8, 14, 15, 20, 33, 39, 41, 45, 47, 49, 50, 56, 57, 60, 63, 64, 66, 67, 68, 73, 74, 75, 83, 87, 88, 89, 98, 100, 109, 110, 111], "specifi": [28, 64, 95, 98], "speech": 7, "speed": [15, 60, 78], "spent": 58, "sphinx": 47, "split": [15, 19, 37, 38, 55, 57, 64, 65], "split_experience_batch": 80, "spm": 57, "spot": 23, "spread": 110, "spuriou": 14, "sqlite": 25, "sqrt": [11, 64, 65, 88, 110, 111, 112, 113, 115], "squre": 64, "src": 119, "sse": 25, "stabil": [23, 61, 62, 64, 68, 72, 77, 82, 113], "stabl": [22, 24, 50, 66, 68, 82], "stack": [26, 40, 103, 109], "stackexchang": 61, "stage": [12, 31, 57, 59, 60, 62, 63, 66, 67, 68, 77, 88, 95, 98, 103, 110, 111, 119], "stai": 49, "stale": 84, "stand": 47, "standalon": 57, "standard": [12, 27, 28, 30, 38, 42, 50, 51, 54, 57, 58, 63, 64, 66, 67, 75, 76, 77, 79, 82, 84, 85, 88, 100, 103, 109, 118], "star": [41, 99], "starcod": [26, 33, 40, 45, 57], "starcoderdata": [26, 40], "starkli": 23, "start": [15, 30, 31, 33, 42, 45, 47, 48, 50, 55, 56, 57, 64, 74, 76, 78, 87, 89], "start_header_id": 64, "start_po": [64, 65], "starter": 47, "state": [5, 8, 9, 14, 15, 27, 49, 52, 61, 71, 72, 82, 83, 109, 110], "statement": [9, 28, 54, 57], "static": [49, 63, 66], "staticmethod": 64, "statist": 113, "statu": [5, 25, 31, 80], "std": [64, 72, 77, 88, 113], "steadi": 51, "steadili": 68, "steer": [52, 63, 76, 91], "stefano": [47, 101], "steinhardt": [47, 101], "stem": [23, 66, 68], "step": [4, 8, 9, 11, 15, 27, 30, 33, 34, 35, 41, 42, 45, 47, 49, 51, 55, 56, 57, 59, 60, 61, 62, 63, 68, 72, 77, 78, 80, 83, 84, 90, 93, 95, 101, 103, 110, 111], "stepbi": 100, "steven": [47, 101], "still": [14, 52, 54, 58, 60, 74, 84, 111], "stochast": 12, "stoica": [47, 101], "stop": [51, 62, 68], "stop_token": 64, "store": [5, 7, 47, 67, 87], "str": [64, 87], "straightforward": [12, 18, 27, 49, 63, 79, 87, 95, 106, 110, 111], "straightforwardli": 71, "strateg": [60, 63], "strategi": [9, 41, 50, 57, 59, 60, 62, 66, 71, 72, 73, 80, 91, 99, 110, 112], "stream": 51, "streamlin": [33, 45], "strength": [15, 60, 63, 76, 78, 79], "strict": [30, 37, 42, 64], "strictli": 89, "string": [8, 64, 84, 98, 99], "stringent": [63, 68], "strip": [22, 64], "strong": [47, 59, 60, 71, 79, 88, 95, 98, 100, 101, 103, 110, 111], "stronger": [26, 40, 52, 60, 112], "strongest": 27, "strongli": [83, 103], "structur": [1, 7, 11, 12, 47, 56, 84, 109], "struggl": [8, 14, 50, 88, 95], "stuck": 49, "student": [26, 27, 40, 52, 67, 68], "studi": [7, 14, 30, 42, 51, 52, 66, 76, 79], "style": [9, 23, 57, 63], "su": [47, 101], "sub": [11, 13, 56, 58, 61, 64, 68, 87, 113, 114, 115], "subbiah": [47, 101], "subdirectori": 8, "subject": [23, 57, 98], "sublay": 11, "submiss": [1, 54, 55], "submit": [3, 15, 55, 76, 78], "suboptim": [41, 113], "subsequ": [11, 57, 62, 63, 64, 65, 76, 77, 89, 116], "subset": [13, 15, 27, 28, 31, 51], "subspac": 11, "substanti": [14, 20, 33, 39, 45, 52, 77, 79, 99], "substitut": [59, 74, 79, 109], "subtract": 77, "subword": [47, 101, 117], "succ": [15, 74, 87, 88, 91], "succeed": 56, "success": [3, 5, 23, 24, 52, 56, 62, 67, 89, 90], "successfulli": [41, 72], "suchir": [47, 101], "sufeng": [47, 101], "suffer": [60, 72, 82, 95, 99], "suffici": [14, 15, 54, 62, 67, 75, 77, 93, 111], "suffix": 57, "suggest": [14, 50, 67, 74, 75, 79, 84, 103, 116], "suit": [9, 12], "suitabl": [57, 71, 88], "sujoi": [47, 101], "sum": [11, 49, 60, 64, 71, 73, 76, 77, 82, 109, 115], "sum_": [12, 49, 64, 65, 72, 73, 74, 77, 79, 82, 84, 87, 88, 98, 99, 109, 110, 111, 112, 115, 117], "sumit": [47, 101], "summar": 111, "summari": [13, 84], "sun": [47, 101], "sup": 34, "super": [59, 64, 65, 113], "superalign": 52, "superhuman": 52, "superior": [11, 50, 58, 72, 89], "supervis": [13, 14, 15, 27, 30, 31, 42, 49, 52, 57, 67, 74, 85, 86, 87, 89, 91, 98, 103, 114, 115], "supervison": 52, "supervisor": 52, "supplement": 63, "suppli": 106, "support": [3, 48, 57, 59, 63, 67, 80, 118], "suppos": [71, 79, 109], "suppress": [72, 98], "sure": [20, 39, 57, 83], "surfac": [55, 85, 100], "surpass": [14, 27, 33, 45, 67, 86], "surpris": [15, 63, 77], "surprisingli": 75, "surrog": 77, "surround": [57, 59], "survei": 7, "suspect": [11, 83], "suspici": 1, "sutskev": [47, 101], "swaroop": [47, 101], "swiglu": [61, 66, 68], "swish": [34, 64, 65], "symbol": 11, "sympi": 25, "syncheck": 22, "synnaev": [47, 101], "syntact": [54, 63], "syntax": [7, 8, 9, 47, 63, 67], "synthes": [9, 19, 41, 66, 67], "synthesi": [41, 57, 67], "synthet": [26, 40, 63, 66, 67, 86, 90, 91], "system": [7, 8, 14, 27, 41, 47, 60, 63, 64, 68, 72, 76, 95, 98, 101, 110], "systemat": 79, "t": [11, 12, 30, 33, 41, 42, 45, 47, 49, 54, 60, 64, 65, 72, 77, 79, 82, 89, 101, 108, 109, 110, 111, 112, 115], "t1": [64, 113], "t2": [64, 113], "t_": [75, 117], "t_1": 117, "t_2": 117, "t_n": 117, "tabl": [13, 85, 112], "tackl": 55, "taco": 35, "tag": [54, 55, 57, 67, 95], "tail": 67, "tailor": [55, 60, 76], "take": [1, 7, 8, 9, 15, 26, 27, 40, 49, 57, 64, 65, 71, 74, 75, 76, 78, 79, 82, 87, 89, 90, 91, 100, 114, 115, 116], "taken": 49, "talent": 27, "tan": [47, 101], "tang": [47, 101], "tao": [47, 101], "target": [12, 55, 63, 64, 79, 83, 87, 100, 106, 109, 111], "task": [3, 4, 5, 7, 8, 11, 13, 14, 15, 19, 20, 21, 23, 24, 26, 28, 31, 32, 39, 40, 41, 43, 49, 50, 52, 54, 56, 57, 59, 60, 63, 67, 68, 72, 77, 79, 82, 83, 84, 88, 95, 100, 110, 111, 113, 120], "task_id": 22, "taskspecif": 13, "tau": [49, 76, 99], "taught": 35, "td": [77, 82], "teach": [5, 52, 62, 103], "teacher": [26, 40, 41, 68], "team": [15, 78], "technic": [47, 52, 101], "techniqu": [7, 20, 33, 34, 35, 39, 45, 49, 50, 52, 56, 62, 63, 72, 82, 88, 110, 111], "technologi": 7, "teddi": [47, 101], "telecommun": 118, "tell": [52, 74], "temper": 54, "temperatur": [25, 41, 54, 55, 60, 64, 66, 72, 76, 106, 110], "templat": [4, 26, 30, 33, 40, 41, 42, 45, 68, 119], "tempor": 37, "ten": [14, 23, 57, 62, 67, 111], "tend": [72, 76, 84], "tensor": [64, 65, 111], "term": [5, 12, 15, 24, 56, 58, 60, 62, 66, 72, 73, 74, 77, 79, 100, 111, 115, 116], "termin": [3, 49, 98], "terri": [15, 71, 74, 87, 88], "test": [1, 3, 9, 13, 14, 15, 22, 23, 24, 25, 27, 28, 31, 32, 37, 38, 41, 43, 51, 52, 54, 55, 56, 57, 58, 60, 63, 66, 67, 68, 89, 95, 99, 100, 106], "tester": 63, "text": [3, 5, 7, 9, 11, 12, 13, 14, 15, 20, 24, 28, 31, 39, 47, 48, 49, 51, 57, 58, 60, 62, 64, 65, 67, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 87, 88, 89, 91, 98, 99, 100, 103, 106, 109, 110, 111, 112, 116, 117, 118], "text_complet": 64, "textbf": 49, "textbook": 23, "textto": 2, "textual": 12, "tezak": [47, 101], "tf": 7, "th": [33, 45, 73, 75, 77, 89, 109, 110, 111, 112], "than": [9, 11, 13, 14, 18, 19, 20, 22, 26, 30, 31, 39, 40, 41, 42, 50, 52, 54, 55, 56, 57, 59, 61, 63, 71, 72, 74, 75, 83, 84, 85, 87, 88, 100, 103, 106, 109, 110, 111, 112], "thank": [3, 79], "thei": [2, 8, 13, 15, 26, 40, 47, 52, 54, 57, 62, 63, 68, 88, 89, 90, 98, 100, 109, 112, 113, 116, 118], "them": [2, 8, 12, 15, 30, 42, 52, 55, 56, 58, 59, 63, 66, 72, 85, 87, 90, 95, 109, 112, 113, 115], "themselv": [7, 15, 52, 73, 78], "theoret": [41, 75], "therebi": [60, 72, 109], "therefor": [26, 30, 40, 42, 55, 58, 59, 60, 62, 68, 72, 75, 77, 79, 88, 100, 111, 112], "theta": [12, 15, 49, 57, 62, 64, 65, 71, 72, 73, 74, 75, 76, 77, 78, 82, 91, 99, 110, 111, 114, 115], "theta_": [57, 64, 65, 72, 75, 77, 82, 110, 111, 114, 115], "theta_0": [64, 65, 111], "theta_1": [64, 65, 111], "theta_d": 110, "theta_j": [64, 65], "thi": [1, 2, 3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 20, 23, 24, 26, 27, 30, 31, 32, 33, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 87, 88, 89, 90, 91, 95, 98, 99, 100, 106, 109, 110, 111, 112, 113, 115], "thing": [48, 83], "think": [4, 83, 95, 98, 109, 111], "third": [2, 11, 21], "thirti": [47, 101], "thompson": 76, "thorough": [59, 63], "thoroughli": 60, "thorp": [47, 101], "those": [11, 15, 18, 31, 47, 50, 54, 58, 60, 62, 63, 66, 68, 72, 76, 90, 100, 109], "though": [7, 24], "thought": [4, 5, 8, 23, 60, 63, 83, 84, 106], "thousand": [14, 54, 55, 57, 62, 63, 111], "three": [1, 2, 3, 5, 7, 14, 15, 19, 24, 25, 28, 41, 49, 52, 57, 63, 67, 68, 73, 74, 78, 79, 84, 87, 88, 98, 100, 112, 116], "threshold": [63, 64, 68, 86, 91], "through": [2, 7, 12, 23, 26, 33, 40, 45, 63, 64, 65, 66, 67, 71, 72, 73, 79, 82, 84, 87, 91, 95, 98, 103, 110, 111, 112, 114, 115, 116], "throughout": [63, 95], "thu": [33, 45, 49, 51, 52, 62, 64, 65, 71, 72, 76, 82, 85, 87, 89, 99, 110], "tian": [47, 101], "tianhang": [47, 101], "tianhao": [47, 101], "tianjian": [47, 101], "tianjun": [47, 101], "tianyi": [47, 101], "tianyu": [47, 101], "tier": 41, "tild": [62, 76, 77], "tillet": [47, 101], "time": [2, 4, 8, 11, 18, 25, 33, 45, 49, 54, 57, 62, 63, 68, 71, 72, 84, 91, 95, 99, 100, 109, 112, 113, 120], "timeout": [25, 67], "tingyu": [47, 101], "tini": 14, "tip": 66, "titl": [74, 118], "titlecas": 19, "tk": 25, "tl": 13, "to_remov": 87, "todai": 52, "togeth": [1, 11, 30, 42, 54, 55, 63, 83, 84], "tok": 64, "tok_embed": [64, 65], "token": [7, 11, 12, 13, 15, 25, 31, 34, 35, 49, 54, 57, 58, 59, 61, 62, 63, 65, 67, 68, 71, 75, 77, 78, 79, 84, 98, 99, 100, 103, 108, 110, 111, 112, 113, 114, 115, 117], "token1": 109, "token2": 109, "token3": 109, "token_logprob": 64, "tokenization\u4e4b\u540e": 108, "tokenization\u7b97\u6cd5\u4e4b\u4e00": 108, "tokenize\u7684\u610f\u601d\u662f\u628a\u4e00\u4e2a\u53e5\u5b50\u6216\u957f\u8bed\u6599\u5206\u6210token": 108, "token\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u7b26\u53f7": 108, "token\u6570": 108, "token\u66ff\u6362\u5b83\u4eec": 108, "toler": 100, "tolist": 64, "tom": [47, 101], "tomli": 25, "tomlkit": 25, "tone": 63, "tong": [47, 101], "tongliang": [47, 101], "tongzheng": [47, 101], "too": [52, 67, 72, 82, 111], "took": 98, "tool": [1, 2, 7, 18, 27, 47, 54, 63, 117], "toolbelt": 25, "top": [1, 5, 13, 26, 40, 41, 48, 50, 54, 60, 62, 63, 64, 65, 71, 73, 88, 91, 103, 109], "top_p": 64, "topic": [32, 43, 59, 63], "topk": [60, 109], "topp": [25, 72], "torch": [25, 64, 65, 109, 111, 113], "toreproduc": 18, "total": [2, 24, 26, 30, 31, 38, 40, 42, 51, 55, 58, 59, 60, 62, 68, 77, 98, 109, 112], "total_len": 64, "toutanova": [47, 101], "toward": [30, 42, 47, 50, 85, 91, 99, 101, 109], "toxic": [15, 83], "tqdm": 25, "trace": [4, 98, 99], "traceback": 64, "track": 87, "tractabl": 52, "trade": 72, "tradeoff": 79, "tradit": [14, 23], "train": [2, 3, 7, 9, 11, 15, 20, 26, 27, 30, 31, 32, 37, 38, 39, 40, 42, 43, 47, 49, 50, 52, 54, 55, 57, 58, 62, 64, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 98, 100, 101, 109, 110, 111, 112, 113, 117], "train_bash": 119, "train_batch_s": 80, "train_ppo": 80, "train_ppo_llama": 80, "trainabl": 120, "trainer": 80, "trainin": 58, "training_step_actor": 80, "training_step_crit": 80, "trajectori": [5, 49, 73, 82, 95], "transduct": 11, "transfer": [114, 115], "transform": [9, 11, 13, 14, 47, 54, 57, 59, 60, 61, 62, 63, 66, 72, 101, 110, 111, 112, 113, 114, 115, 116, 120], "transformerblock": [12, 64, 65], "transit": [49, 99], "translat": [11, 13, 47, 63, 95, 101], "transmit": 76, "transpos": [64, 65], "trap": 99, "treat": [48, 64, 66, 88, 111], "tree": [1, 7, 9], "tremend": 59, "trend": 51, "tri": [89, 98], "trick": [56, 80, 110], "trigger": 8, "trigonometr": [64, 65, 110, 111], "trigonometri": 63, "trillion": [58, 60, 66, 67], "trim": [55, 103], "triplet": [12, 57, 79, 87], "triton": 25, "triu": [64, 65], "trivial": 72, "trl": 80, "troubl": 83, "trough": 57, "trove": 25, "true": [19, 62, 64, 65, 80, 113, 119], "truncat": 72, "trust": 82, "truth": [3, 19, 27, 28, 38, 52, 58, 59, 60, 63, 66, 71, 72, 73, 74, 87, 90], "try": [8, 18, 20, 39, 56, 64, 67, 75, 89, 106], "trylimit": 56, "tu": [47, 101], "tune": [14, 15, 18, 19, 20, 30, 33, 39, 42, 45, 47, 63, 67, 68, 74, 75, 77, 79, 80, 85, 86, 87, 89, 99, 100, 101, 103, 106, 110, 111], "tupl": [64, 65, 111], "turbo": [18, 26, 40, 58, 64], "turn": [1, 57, 63, 64, 68, 100, 111], "tutori": 67, "two": [2, 7, 9, 11, 12, 19, 21, 30, 31, 33, 42, 45, 47, 48, 49, 50, 52, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 68, 71, 72, 73, 74, 75, 76, 79, 83, 84, 85, 87, 88, 89, 90, 91, 95, 98, 99, 100, 103, 109, 110, 111, 112, 116], "tworek": [47, 101], "tx": 76, "txt": [20, 39], "type": [7, 18, 20, 25, 30, 33, 39, 41, 42, 45, 52, 54, 57, 60, 61, 64, 65, 68, 73, 79, 83, 84, 87, 88, 95, 111], "type_a": [64, 65, 111, 113], "typeddict": 64, "typescript": 63, "typic": [3, 13, 14, 31, 50, 52, 61, 63, 72, 75, 76, 77, 79, 83, 85, 91, 109, 110, 111, 114, 115], "tzdata": 25, "u": [12, 13, 14, 21, 31, 44, 54, 55, 60, 74, 79, 87, 88, 90, 100, 109, 112], "u_": [12, 109], "u_1": 12, "u_i": 12, "u_n": 12, "uation": 21, "ui": 7, "uiuc": 22, "uk": 112, "ultim": [33, 45, 52, 63, 68, 109], "ultrafeedback": 71, "uml": 7, "unambigu": 28, "unansw": 2, "unawar": 2, "unbalanc": 109, "unbias": [24, 64, 77, 113], "uncertainti": 76, "unchang": 99, "unclear": [52, 99], "uncur": 90, "under": [23, 26, 40, 49, 50, 59, 74, 75, 82], "underli": 111, "underload": 60, "underset": [62, 71, 76, 77, 91, 99], "understand": [7, 8, 12, 23, 44, 47, 48, 52, 56, 57, 63, 67, 101, 106], "undesir": [49, 72], "undo": 9, "unembed": [15, 59, 78], "uneth": 83, "unexpect": [72, 95], "unhealthi": 72, "unicod": [47, 67, 101], "unicode\u548cutf": 118, "unicode\u5f53\u524d\u9ed8\u8ba4\u7684\u7248\u672c\u662fuc": 118, "unicode\u662fascii": 118, "unicode\u7684\u5b57\u7b26\u96c6\u8303\u56f4": 118, "unicode\u76f4\u63a5\u517c\u5bb9\u4e86\u521d\u671fascii": 118, "unifi": [3, 33, 45, 68], "uniform": [57, 87, 100, 110, 113], "uniformli": [13, 76, 98, 100], "union": 64, "uniqu": [56, 57, 59], "unit": [24, 27, 41, 57, 62, 63, 66, 67, 110, 111], "univers": [44, 47, 101, 111], "unk": 87, "unknown": [2, 74, 87], "unlabel": [12, 91], "unleash": [44, 67], "unlik": [27, 41, 68, 72, 110], "unlikelihood": 79, "unlimit": 13, "unlock": [57, 59], "unmerg": 80, "unnecessari": 8, "unpack": [34, 35], "unsatisfactori": 79, "unsupervis": [13, 47, 52, 67, 101], "unsur": 62, "until": [8, 30, 42, 55, 56, 63, 76, 87, 109], "untruth": 15, "unveil": [33, 45], "up": [12, 14, 15, 19, 20, 30, 32, 39, 41, 42, 43, 55, 62, 63, 72, 76, 78, 79, 83, 98, 100, 103, 110, 111], "up_proj": 59, "updat": [7, 31, 51, 55, 60, 67, 68, 72, 80, 110], "upgrad": [22, 33, 45], "uplift": 72, "upon": [5, 50, 60, 66, 67], "upper": [50, 72, 111], "upweight": 49, "uq": 112, "uritempl": 25, "url": [47, 101], "urllib3": 25, "us": [1, 2, 4, 5, 7, 8, 9, 11, 12, 13, 14, 15, 19, 20, 21, 24, 25, 26, 27, 30, 31, 33, 39, 40, 41, 42, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 98, 100, 103, 106, 110, 111, 112, 113, 114, 115, 116], "usag": [3, 19, 33, 41, 45, 63], "use_fast_token": 119, "user": [2, 3, 8, 15, 18, 20, 39, 41, 52, 57, 62, 63, 64, 68, 78, 88, 89, 90, 103], "usual": [3, 7, 11, 30, 31, 42, 63, 72, 74, 77, 87, 90, 98, 109, 112, 114, 115], "uszkoreit": [47, 101], "ut": 79, "util": [2, 5, 7, 23, 33, 45, 56, 57, 60, 62, 63, 66, 67, 68, 72, 74, 83, 88, 95], "uv": 112, "uw_": 12, "v": [11, 49, 64, 65, 71, 79, 82, 85, 112, 114, 115, 116], "v0": [18, 22, 80], "v1": [26, 40, 62], "v2": [34, 35, 47, 60, 62, 101, 109, 112], "v3": [35, 62, 95], "v5": [57, 62], "v_": [71, 77], "v_head_dim": 59, "valid": [1, 8, 9, 14, 15, 27, 30, 32, 37, 41, 42, 54, 56, 60, 66, 67, 68, 72, 74, 78, 88, 91, 98], "valu": [11, 15, 27, 41, 51, 54, 60, 64, 65, 67, 75, 77, 78, 79, 82, 84, 87, 91, 109, 110, 111, 115], "valuabl": [114, 115], "valueerror": 64, "vanish": 76, "var": [64, 113], "vare": 51, "vari": [13, 23, 33, 45, 51, 55, 59, 61, 109, 110], "variabl": [67, 113, 114, 115], "varianc": [24, 49, 62, 66, 76, 77, 82, 113], "variant": [12, 57, 64, 65, 82, 89], "variat": [23, 47, 54, 64, 65, 85, 116], "varieti": [51, 63], "variou": [5, 7, 19, 21, 26, 30, 33, 40, 42, 45, 51, 58, 61, 63, 66, 67, 83, 89, 110, 111], "vast": 67, "vaswani": [47, 101], "vdot": [114, 115], "ve": 64, "vector": [7, 11, 12, 27, 57, 64, 65, 71, 75, 76, 110, 111, 112, 113, 115, 116], "vedant": [47, 101], "verb": [20, 39], "verbos": 71, "verdict": 90, "veri": [15, 24, 51, 52, 54, 67, 78, 83, 85, 110, 111], "verif": [19, 63, 67, 95], "verifi": [3, 9, 18, 19, 27, 28, 47, 60, 68, 72, 95, 99, 101], "versatil": [47, 101], "version": [9, 11, 15, 23, 26, 40, 41, 55, 57, 59, 62, 63, 64, 65, 74, 90, 95, 106, 116, 119], "versu": [82, 106], "veryeasyhack": 83, "via": [15, 19, 41, 47, 50, 56, 57, 63, 68, 71, 72, 74, 82, 86, 90, 93, 95, 101], "view": [8, 64, 65, 111], "view_as_complex": [64, 65, 111], "view_as_r": [64, 65, 111], "viewer": 8, "vineet": [47, 101], "violat": 85, "virtualenv": 25, "visual": [20, 39], "vllm": 22, "vocab": 75, "vocab_s": [59, 64, 65], "vocabulari": [59, 66, 68, 75], "voss": [47, 101], "vote": [73, 98, 100], "vsp": [11, 12, 47, 66, 101, 112], "vw_": 11, "w": [11, 15, 47, 64, 65, 71, 74, 75, 78, 87, 89, 90, 101, 108, 112, 114, 115, 116], "w1": [64, 65], "w2": [64, 65, 116], "w3": [64, 65], "w_": [11, 12, 49, 64, 65, 115, 116, 120], "w_1": 67, "w_1s_1": 67, "w_2": 11, "w_e": 12, "w_n": 67, "w_ns_n": 67, "w_p": 12, "w_y": 12, "wa": [12, 13, 21, 28, 33, 41, 45, 54, 55, 57, 58, 60, 62, 67, 89, 99], "wai": [5, 7, 9, 24, 27, 30, 42, 49, 50, 52, 56, 67, 72, 83, 87, 106, 109, 110, 111], "wainwright": [47, 101], "wait": 98, "waitlist": 15, "wake": [20, 39], "wan": [47, 101], "wang": [47, 101], "wangd": [47, 101], "want": [8, 15, 30, 42, 49, 78, 87, 106, 110, 111], "warm": 72, "warmup": [41, 61, 103], "wast": 54, "wastag": 109, "wavecod": [47, 67, 101], "wavelength": [11, 110], "wcg19": [47, 66, 101], "we": [1, 2, 3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 27, 28, 30, 31, 33, 37, 39, 40, 41, 42, 44, 45, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 98, 99, 100, 103, 106, 109, 110, 111, 112, 114, 115, 116, 120], "weak": [34, 79, 111], "weaker": [26, 40], "weakli": [51, 52], "weather": 2, "web": [7, 13, 58, 72, 87], "webpag": [13, 78], "websit": [41, 61, 66, 67, 72], "webtext": 13, "webtext2": 51, "wei": [47, 101], "weigh": 74, "weight": [11, 12, 41, 49, 54, 59, 61, 62, 64, 65, 67, 72, 74, 79, 84, 103, 109, 111, 113, 115, 116, 120], "welind": [47, 101], "well": [8, 11, 12, 18, 49, 66, 75, 79, 83, 110, 111], "wellcalibr": 83, "wen": [47, 101], "wenbin": [47, 101], "wenfeng": [47, 101], "wenji": [47, 101], "wenjun": [47, 101], "wentao": [47, 101], "wenxiang": [47, 101], "were": [24, 60, 62, 68, 100], "west": [34, 35], "what": [2, 20, 39, 52, 58, 61, 76, 111], "wheel": 25, "when": [2, 3, 8, 11, 13, 15, 20, 27, 30, 39, 41, 42, 47, 48, 49, 51, 52, 55, 56, 63, 64, 65, 68, 71, 72, 75, 76, 77, 79, 82, 85, 88, 90, 98, 99, 100, 106, 109, 113, 115, 116], "where": [1, 11, 12, 15, 19, 24, 27, 30, 31, 33, 38, 42, 44, 45, 49, 50, 51, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 87, 88, 89, 90, 93, 98, 106, 109, 110, 111, 112, 113, 114, 115, 116, 120], "wherea": [47, 49, 54], "wherebi": 62, "wherein": 79, "wherev": 60, "whether": [30, 42, 47, 52, 54, 58, 60, 64, 67, 79, 82, 84, 90, 95, 99, 100, 109], "which": [2, 3, 7, 8, 11, 12, 13, 14, 15, 20, 21, 23, 24, 26, 27, 28, 30, 33, 39, 40, 42, 45, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 84, 85, 87, 88, 89, 90, 91, 95, 100, 106, 109, 110, 111, 113, 114, 115, 116, 120], "while": [3, 4, 5, 7, 8, 11, 13, 14, 15, 26, 27, 31, 40, 49, 51, 55, 56, 57, 59, 60, 63, 66, 67, 75, 76, 77, 82, 83, 87, 88, 89, 99, 103, 106, 109, 110, 111, 115, 117], "white": 24, "whiten": 62, "who": 27, "whole": 79, "whose": [15, 64, 67], "why": [52, 56], "wide": [12, 15, 23, 31, 51, 52, 55, 63, 68, 71, 77, 88], "widespread": [47, 101], "width": 64, "wifi": 83, "wiki": 61, "wikihow": 103, "wikipedia": [4, 13, 61], "wildchat": 41, "william": [47, 101], "win": [76, 84, 87, 89, 90], "window": [8, 12, 31, 60, 63], "winner": 90, "winter": [47, 101], "wise": [12, 59, 60, 64, 65, 83, 98, 111, 113, 116], "within": [3, 4, 60, 63, 67, 72, 82, 83, 90, 91, 95, 110, 111, 113], "without": [1, 3, 13, 19, 21, 31, 49, 52, 67, 68, 71, 72, 74, 75, 76, 78, 83, 90, 95, 100, 103, 115], "wizard": [34, 35], "wk": [64, 65], "wo": [64, 65], "wojciech": [47, 101], "word": [12, 13, 15, 18, 20, 27, 31, 39, 47, 67, 72, 85, 101, 108, 114, 115, 117], "wordpiece\u6bcf\u6b21\u9009\u62e9\u5408\u5e76\u7684\u4e24\u4e2a\u5b50\u8bcd": 117, "wordpiece\u7b97\u6cd5\u4e5f\u662f\u6bcf\u6b21\u4ece\u8bcd\u8868\u4e2d\u9009\u51fa\u4e24\u4e2a\u5b50\u8bcd\u5408\u5e76\u6210\u65b0\u7684\u5b50\u8bcd": 117, "work": [3, 5, 7, 8, 9, 11, 13, 14, 19, 26, 27, 30, 40, 42, 44, 49, 52, 59, 61, 63, 64, 65, 73, 74, 75, 83, 90, 111, 116], "world": [3, 7, 20, 23, 31, 39], "world_siz": 80, "wors": [87, 106], "worst": [50, 91], "would": [8, 11, 49, 52, 62, 71, 83, 90, 100], "wq": [64, 65], "write": [15, 18, 20, 28, 39, 47, 48, 57, 59, 60, 62, 78, 95, 103, 110, 115], "writer": 27, "written": [7, 15, 24, 27, 30, 38, 42, 47, 48, 83], "wrong": [56, 75, 100, 106], "wrote": [20, 39, 83], "wu": [47, 101], "wv": [64, 65], "wwl": [41, 47, 63, 67, 101], "wx": 120, "x": [11, 12, 15, 21, 47, 49, 57, 62, 64, 65, 71, 73, 74, 75, 76, 77, 78, 79, 82, 84, 86, 87, 88, 90, 91, 99, 101, 108, 110, 111, 113, 114, 115, 116, 117, 120], "x_": [30, 42, 64, 65, 90, 99, 110, 111, 115], "x_0": [64, 65, 110, 111], "x_1": [11, 64, 65, 79, 86, 99, 110, 111], "x_2": [64, 65, 99], "x_i": [89, 90, 99], "x_m": 79, "x_n": [11, 86], "xdxac": 108, "xia": [47, 101], "xiangyu": [47, 101], "xianji": [47, 101], "xianzu": [47, 101], "xiao": [47, 101], "xiaodong": [47, 101], "xiaohan": [47, 101], "xiaohuan": [47, 101], "xiaojin": [47, 101], "xiaokang": [47, 101], "xiaosha": [47, 101], "xiaotao": [47, 101], "xiaowen": [47, 101], "xiaoxiang": [47, 101], "xie": [47, 101], "xin": [47, 101], "xingkai": [47, 101], "xingxuan": [47, 101], "xingzhang": [47, 101], "xinnan": [47, 101], "xinyi": [47, 101], "xinyu": [47, 101], "xiong": [47, 101], "xk": [64, 65, 111], "xk_": [64, 65, 111], "xk_out": [64, 65, 111], "xp": 116, "xq": [64, 65, 111], "xq_": [64, 65, 111], "xq_out": [64, 65, 111], "xu": [47, 101], "xuan": [47, 101], "xuancheng": [47, 101], "xue": [47, 101], "xuecheng": [47, 101], "xv": [64, 65, 116], "xw": [64, 65, 116], "xw_": [64, 65, 116], "xw_1": 11, "xx": [22, 35], "xxhash": 25, "xxx": 25, "xz": 25, "x\u4e3a\u5b57\u7b26\u7684unicode\u4e8c\u8fdb\u5236": 118, "y": [12, 15, 47, 49, 62, 64, 65, 71, 72, 74, 75, 76, 78, 79, 82, 84, 86, 87, 88, 90, 99, 101, 108, 110, 113, 117], "y1": 74, "y2": 74, "y3": 74, "y_": [15, 30, 42, 49, 62, 71, 73, 74, 75, 78, 79, 86, 87, 88, 89, 90, 91, 99], "y_1": [11, 15, 74, 79, 84, 88, 91, 99], "y_2": [15, 74, 84, 88, 91, 99], "y_c": 88, "y_i": [73, 99], "y_l": 75, "y_m": 11, "y_n": 79, "y_r": 88, "y_t": 79, "y_w": 75, "yaml": [25, 56], "yan": [47, 101], "yang": [47, 101], "yangyu": [47, 101], "yanhong": [47, 101], "yann": [47, 101], "yanp": [47, 101], "yao": [47, 101], "yaofeng": [47, 101], "yaohui": [47, 101], "yarl": 25, "yarn": 60, "ye": [47, 101], "yellow": 24, "yet": 19, "yi": [47, 101], "yibo": [47, 101], "yichang": [47, 101], "yichao": [47, 101], "yield": [11, 15, 28, 63, 76, 77, 88, 120], "yifeng": [47, 101], "yiliang": [47, 101], "yilong": [47, 101], "yin": [47, 101], "ying": [47, 101], "yishi": [47, 101], "yishuji": [47, 101], "yixin": [47, 101], "yixuan": [47, 101], "yiyuan": [47, 101], "yml": 25, "yongji": [47, 101], "yongqiang": [47, 101], "you": [18, 20, 25, 39, 47, 48, 57, 62, 82, 83, 88, 101, 106], "young": 27, "your": [18, 25, 47, 48, 57, 83, 101], "yu": [47, 101], "yuan": [47, 101], "yuchen": [47, 101], "yuduan": [47, 101], "yuheng": [47, 101], "yukun": [47, 101], "yuliang": 35, "yunfei": [47, 101], "yunfeng": [47, 101], "yunlong": [47, 101], "yunxian": [47, 101], "yuqiong": [47, 101], "yura": [47, 101], "yuri": [47, 101], "yute": [47, 101], "yuwei": [47, 101], "yuxiang": [47, 101], "yuxuan": [47, 101], "yuyao": [47, 101], "yyl": [47, 101, 106], "yz": [47, 67, 101], "yzh": [47, 67, 101], "z": [11, 47, 74, 76, 82, 87, 101, 108, 117], "z_": 87, "z_1": 11, "z_n": 11, "zabdzabac": 108, "zan": 7, "zaremba": [47, 101], "zehui": [47, 101], "zekun": [47, 101], "zemlyanskii": [47, 101], "zeng": [47, 101], "zero": [14, 23, 49, 62, 64, 65, 106, 115], "zero_stag": 80, "zeros_lik": 64, "zeyu": [47, 101], "zh": 58, "zha": [47, 101], "zhang": [47, 101], "zhangli": [47, 101], "zhao": [47, 101], "zhaojian": [47, 101], "zhe": [47, 101], "zhen": [47, 101], "zhenda": [47, 101], "zheng": [47, 101], "zhenru": [47, 101], "zhewen": [47, 101], "zhihong": [47, 101], "zhiniu": [47, 101], "zhipeng": [47, 101], "zhongyu": [47, 101], "zhou": [47, 101], "zhoujun": [47, 101], "zhu": [47, 101], "zhuoshu": [47, 101], "ziegler": [47, 101], "zihan": [47, 101], "zihui": [47, 101], "zilin": [47, 101], "zip": [64, 87], "zipp": 25, "ziwei": [47, 101], "zixuan": [47, 101], "zlib": 25, "zlm": [18, 47, 101], "zou": [47, 101], "zy": 108, "zydzyac": 108, "\u4e00": 118, "\u4e00\u4e2a\u5728\u5f00\u5934": 108, "\u4e00\u822c\u4e0d\u76f4\u63a5\u4f7f\u7528unicod": 118, "\u4e00\u90e8\u5206\u6b63\u8d1f\u62b5\u6d88\u4e00\u90e8\u5206\u632f\u8361": 110, "\u4e00\u95e8\u8bed\u8a00\u4e2d": 108, "\u4e0a\u9762\u4ecb\u7ecd\u4e86\u6587\u5b57\u5b57\u7b26\u6620\u5c04\u4e3aunicode\u5b57\u7b26\u96c6": 118, "\u4e0b\u4e00\u4e2a\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u662f": 108, "\u4e0b\u8f7d": 22, "\u4e0b\u8f7d\u8bc4\u4f30\u6587\u4ef6": 25, "\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50": 108, "\u4e0b\u9762\u7684\u793a\u4f8b\u5c06\u89e3\u91ca": 108, "\u4e0d\u4f1a\u51fa\u73b0\u53ea\u5b66\u90a3\u4e9b\u7b80\u5355\u4e14": 77, "\u4e0d\u4f1a\u5355\u72ec\u51fa\u73b0": 108, "\u4e0d\u8868\u793a\u5176\u4ed6\u8bed\u8a00": 118, "\u4e0d\u8db3\u7684\u5728\u9ad8\u4f4d\u75280\u8865\u5145": 118, "\u4e0ebpe\u7684\u6700\u5927\u533a\u522b\u5728\u4e8e": 117, "\u4e0ebpe\u7b97\u6cd5\u7c7b\u4f3c": 117, "\u4e14\u5047\u8bbe\u5404\u4e2a\u5b50\u8bcd\u4e4b\u95f4\u662f\u72ec\u7acb\u5b58\u5728\u7684": 117, "\u4e24\u4e2a\u5b57\u6bb5": 22, "\u4e2a": 108, "\u4e2a\u4e0d\u540c\u7684token": 108, "\u4e2a\u5355\u8bcd": 108, "\u4e2a\u5b50\u8bcd\u7ec4\u6210": 117, "\u4e2d": 22, "\u4e2d\u4f7f\u7528\u4e86\u4e0a\u8ff0\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53": 108, "\u4e2d\u51cf\u5c11\u8ba1\u6570": 108, "\u4e2d\u5b58\u5728": 108, "\u4e2d\u62bd\u53d6\u51fa\u6765": 25, "\u4e2d\u6587": 118, "\u4e2d\u7684": 22, "\u4e2d\u76f8\u5bf9\u597d\u7684": 77, "\u4e2d\u88ab\u9996\u6b21\u63d0\u51fa": 108, "\u4e3a\u4e86\u4ee5\u6700\u6709\u6548\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u6599\u5e93": 108, "\u4e3a\u4e86\u5408\u5e76": 108, "\u4e3a\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3": 108, "\u4e3a\u4e86\u672c\u6587\u7684\u7b80\u5355\u8d77\u89c1": 108, "\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4": 118, "\u4e3a\u4e86\u89e3\u51b3": 118, "\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u8c03\u7528": 22, "\u4e3a\u53e5\u5b50\u7684\u4e00\u4e2a\u5206\u8bcd\u7ed3\u679c": 117, "\u4e3a\u8865\u5145": 118, "\u4e3e\u4f8b1": 118, "\u4e3e\u4f8b2": 118, "\u4e4b\u524d": 118, "\u4e5f\u53eb\u5b57\u7b26\u96c6": 118, "\u4e5f\u5c31\u662f\u4e24\u5b50\u8bcd\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u5173\u8054\u6027": 117, "\u4e5f\u5c31\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u770b\u6210\u4e00\u4e2atoken": 108, "\u4e5f\u5c31\u662f\u7528\u5b9a\u957f2\u4e2a\u5b57\u8282\u6765\u8868\u793a\u5b57\u7b26": 118, "\u4e5f\u662fnlp\u4e2d\u6700\u91cd\u8981\u7684\u7f16\u7801\u65b9\u5f0f\u4e4b\u4e00": 108, "\u4e5f\u80fd\u88ab\u7b97\u4f5c\u5b57\u7b26\u5bf9\u7684\u4e00\u90e8\u5206": 108, "\u4e8c\u8fdb\u5236\u5c31\u662f01000001": 118, "\u4e8c\u8fdb\u5236\u5c31\u662f110000": 118, "\u4eca\u5929\u5c31\u6765\u4e86\u89e3\u4e0b\u5b57\u7b26\u5728\u8ba1\u7b97\u673a\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f": 118, "\u4ece": 25, "\u4ece\u6700\u957f\u5230\u6700\u77ed": 108, "\u4ece\u800c\u6211\u4eec\u77e5\u9053\u5269\u4f59\u7684": 108, "\u4ed6\u4eec\u5177\u6709\u6700\u5927\u7684\u4e92\u4fe1\u606f\u503c": 117, "\u4ee5\u4e2d\u6587": 118, "\u4f1a\u4e0d\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5f88\u6162": 77, "\u4f1a\u4e0d\u4f1a\u66f4\u597d": 77, "\u4f20\u5165\u89e3\u6790\u540e\u7684\u53c2\u6570": 22, "\u4f3c\u7136\u503c\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a": 117, "\u4f46\u4e00\u4e2a\u8bcd\u5728\u7ed3\u5c3e\u6709\u4e00\u4e2a": 108, "\u4f46\u4ecd\u6709\u53ef\u80fd\u51fa\u73b0\u4e0d\u5728\u91cc\u9762\u7684\u5355\u8bcd": 108, "\u4f46\u5b83\u5177\u6709\u826f\u597d\u7684\u6027\u80fd": 108, "\u4f46\u6211\u4eec\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u5305\u542b\u8fd9\u4e9b\u5b57\u7b26": 108, "\u4f46\u662funicode\u8fd8\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6269\u5c55\u673a\u5236": 118, "\u4f46\u662f\u5176\u4ed6\u6b27\u6d32\u56fd\u5bb6\u7684\u8bed\u8a00\u6bd4\u5982\u6cd5\u8bed": 118, "\u4f46\u662f\u5b83\u548c\u6c49\u5b57\u7684\u6620\u5c04\u4e0eunicode\u548c\u6c49\u5b57\u7684\u6620\u5c04\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb": 118, "\u4f46\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u5408\u7406\u7684\u7f16\u7801\u65b9\u5f0f": 108, "\u4f4e\u7ef4": 110, "\u4f4e\u9891\u5185\u63d2\u7684\u65b9\u5f0f": 110, "\u4f60\u53ef\u80fd\u4e0d\u6e05\u695awordpiece\u662f\u5982\u4f55\u9009\u53d6\u5b50\u8bcd\u7684": 117, "\u4f7f\u7528\u4e0b\u8ff0\u547d\u4ee4\u8fdb\u884c\u8bc4\u4f30": 25, "\u4f8b\u5982\u5b57\u7b26\u4e32": 22, "\u4f8b\u5982\u7f16\u7801\u5e8f\u5217": 108, "\u4fee\u6539\u540e\u663e\u793a\u7ed3\u679c\u5982\u4e0b": 118, "\u5047\u8bbe\u5355\u8bcd\u7684\u5e8f\u5217\u662f": 108, "\u5047\u8bbe\u53e5\u5b50": 117, "\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8bed\u6599\u5e93": 108, "\u5047\u8bbe\u6211\u4eec\u6709\u9700\u8981\u7f16\u7801": 108, "\u5047\u8bbe\u628a\u76f8\u90bb\u4f4d\u7f6e\u7684x\u548cy\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 117, "\u5047\u8bbe\u8fd9\u4e9b\u8bcd\u51fa\u73b0\u7684\u9891\u7387\u5982\u4e0b": 108, "\u50cf": 108, "\u5141\u8bb8\u8868\u793a\u4e00\u767e\u591a\u4e07\u4e2a\u5b57\u7b26": 118, "\u5168\u7403\u7edd\u5927\u90e8\u5206\u5b57\u7b26\u7684\u5b57\u7b26\u96c6": 118, "\u5176\u4e2d": [25, 108], "\u5176\u4e2d\u4e0d\u6b62utf": 118, "\u5176\u4e2d\u4f1a\u6d89\u53ca\u5230ascii": 118, "\u5176\u4e2d\u5305\u542b\u5355\u8bcd": 108, "\u5176\u4ed6\u5b57\u8282": 118, "\u5176\u4ed6\u8bed\u8a00": 118, "\u5176\u4ed6\u8bed\u8a00\u53ef\u80fd\u6709\u6240\u4e0d\u540c": 108, "\u51fa\u73b0\u4e86": 108, "\u51fd\u6570": 22, "\u51fd\u6570\u5462": 22, "\u51fd\u6570\u5feb\u901f\u8f6c\u6362\u4e3a\u547d\u4ee4\u884c\u63a5\u53e3": 22, "\u51fd\u6570\u7684\u53c2\u6570\u5217\u8868": 22, "\u5206\u522b\u6765\u81ea": 22, "\u5219\u53e5\u5b50": 117, "\u521d\u59cbtoken\u5c06\u662f\u6240\u6709\u5b57\u7b26\u548c": 108, "\u524d\u9762\u5168\u90e8\u586b\u51450": 118, "\u5269\u4e0b\u7684\u552f\u4e00\u5b57\u8282\u5bf9\u662f": 108, "\u52a0\u4e0a\u63a7\u5236\u7801\u540e\u5bf9\u5e94\u7684utf": 118, "\u5339\u914d": 22, "\u5341\u516d\u8fdb\u5236": 118, "\u5355\u5b57\u8282256\u4e2a\u5b57\u7b26\u80af\u5b9a\u6ca1\u6cd5\u5b8c\u5168\u8868\u793a": 118, "\u5373": [22, 108], "\u538b\u7f29": 108, "\u539f\u672c\u5728\u4f4e\u7ef4\u5ea6\u4e0a": 110, "\u53c2\u6570\u4e3a": 25, "\u53cd\u5411\u6267\u884c\u4ee5\u4e0a\u8fc7\u7a0b\u5c31\u884c\u4e86": 108, "\u53cd\u590d\u8fed\u4ee3\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6": 108, "\u53ea\u9700\u8981\u4e00\u4e2a\u5b57\u8282\u8868\u793a": 118, "\u53ea\u9700\u8981\u4f7f\u7528\u540e\u97627\u4f4d\u5c31\u8db3\u591f\u4e86": 118, "\u53ef\u4ee5\u4f7f\u75281": 118, "\u5404\u4e2a\u56fd\u5bb6\u4fbf\u7740\u624b\u81ea\u5df1\u56fd\u5bb6\u8bed\u8a00\u7684\u7f16\u7801": 118, "\u5408\u5e76\u505c\u6b62token": 108, "\u5408\u5e76\u540e\u4ea7\u751f\u7684\u5b50\u8bcd\u8bb0\u4e3az": 117, "\u5408\u5e76\u5b57\u7b26\u53ef\u4ee5\u8ba9\u4f60": 108, "\u5408\u5e76\u5b83\u4eec": 108, "\u540c\u7406\u8fd8\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u7279\u6709\u5b57\u7b26\u96c6": 118, "\u548c": [22, 108, 110], "\u548cascii\u7684\u76ee\u7684\u4e00\u6837": 118, "\u548cascii\u7801\u4e00\u81f4": 118, "\u56de\u8f6613\u7b49\u7b49\u4e00\u4e9b\u952e\u76d8\u4e0a\u6240\u89c1\u7684\u7b26\u53f7": 118, "\u56e0\u4e3a": 108, "\u56e0\u4e3a\u4eba\u7c7b\u8bed\u8a00\u4e5f\u7ecf\u5e38\u4ee5\u5355\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u4ea4\u6d41": 108, "\u56e0\u4e3a\u5b83\u4eec\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 108, "\u56e0\u4e3a\u6211\u4eec\u7edf\u8ba1\u76f8\u90bb\u5b57\u7b26\u5bf9\u65f6\u4e0d\u80fd\u628a\u5206\u522b\u4f4d\u4e8e\u4e24\u4e2a\u5355\u8bcd\u4e2d\u7684\u5b57\u7b26\u5bf9\u7b97\u8fdb\u53bb": 108, "\u56e0\u4e3a\u6ca1\u6709\u51fa\u73b0\u591a\u6b21\u7684\u5b57\u8282\u5bf9": 108, "\u56e0\u6b64": 108, "\u56e0\u6b64bpe\u4e5f\u662f\u5178\u578b\u7684\u57fa\u4e8esubword\u7684tokenization\u7b97\u6cd5": 108, "\u56e0\u6b64\u6211\u4eec\u53ef\u91c7\u7528\u9ad8\u9891\u5916\u63a8": 110, "\u56e0\u6b64\u6211\u4eec\u5c06\u7528\u4e00\u4e2a\u65b0\u5b57\u8282": 108, "\u56e0\u6b64\u6211\u4eec\u6ca1\u6709\u5c06\u5b83\u4eec\u5408\u5e76": 108, "\u5728": 22, "\u5728finest\u548clowest\u4e24\u4e2a\u8bcd\u4e2d": 108, "\u5728unicode\u8bde\u751f": 118, "\u5728\u5b9e\u8df5\u4e2d": 108, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d": 108, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 108, "\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0": 108, "\u5728\u8ba1\u7b97\u673a\u4e2d\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u4f4d0\u548c1\u6765\u5b58\u50a8\u7684": 118, "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u65f6\u5019\u9700\u8981\u5728\u8fd9\u4e2a\u62e5\u6709\u51e0\u4e07\u4e2a\u5355\u8bcd\u7684\u5217\u8868\u4e0a\u8ba1\u7b97\u4e00\u4e2a\u6982\u7387\u5206\u5e03": 108, "\u5728\u8fd9\u91cc": 108, "\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u6bd4\u8f83token\u7684\u9891\u7387\u5927\u5c0f\u6765\u7a77\u5c3d\u6bcf\u4e00\u79cd\u53ef\u80fd": 108, "\u5927\u5199\u5b57\u6bcda\u5bf9\u5e94\u7684ascii\u7801\u662f65": 118, "\u5927\u5bb6\u90fd\u77e5\u9053\u7535\u8111\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u548c\u5b58\u50a8\u7684": 118, "\u5927\u6982\u5c31\u662f\u8bf4ascii\u662f\u7f8e\u56fd\u4fe1\u606f\u4ea4\u6362\u6807\u51c6\u4ee3\u7801": 118, "\u5927\u90e8\u5206\u662f2\u5b57\u8282": 118, "\u5982\u4f55\u6765\u8868\u793aunicod": 118, "\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u5c31\u662f\u8981\u8868\u793a\u4e00\u4e2a\u5b57\u7b26\u8fd8\u662f\u8fde\u7eed\u7684\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 118, "\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u8bfb\u61c2unicod": 118, "\u5982\u4f55\u8bfb\u53d6unicode\u5b57\u7b26\u96c6": 118, "\u5982\u4f55\u9009\u62e9\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 117, "\u5982\u679c\u4f1a\u7559\u4e0b\u51e0\u4e2a\u5b50\u4e32": 108, "\u5982\u679c\u5728\u4f4e\u7ef4\u5ea6\u8fdb\u884c\u5185\u63d2": 110, "\u5982\u679c\u6309\u7167unicode\u7684\u65b9\u5f0f\u7edf\u4e00\u7528\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 118, "\u5982\u679c\u7b97\u6cd5\u770b\u5230token": 108, "\u5b57\u6bcd": 118, "\u5b57\u7b26\u7801\u5c31\u662f\u5bf9\u5e94\u7684unicod": 118, "\u5b57\u7b26\u7801\u7ec4\u6210": 118, "\u5b57\u7b26\u7b49": 108, "\u5b57\u7b26\u96c6\u5373\u662f\u6587\u5b57\u7b26\u53f7\u548c\u4e8c\u8fdb\u5236\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 118, "\u5b57\u8282\u957f\u5ea6": 118, "\u5b66\u540c\u4e00\u4e2a": 77, "\u5b83\u4e0d\u80fd\u88ab\u8fdb\u4e00\u6b65\u538b\u7f29": 108, "\u5b83\u4eec\u51fa\u73b0\u4e86": 108, "\u5b83\u4eec\u7ecf\u5e38\u5728\u8bed\u6599\u4e2d\u4ee5\u76f8\u90bb\u65b9\u5f0f\u540c\u65f6\u51fa\u73b0": 117, "\u5b83\u53ea\u6709\u4e00\u4e2a": 108, "\u5b83\u5728": 108, "\u5b83\u5c31\u4f1a\u77e5\u9053\u5b83\u662f": 108, "\u5b83\u7684\u4f5c\u7528\u662f\u628a\u5404\u4e2a\u8bed\u8a00\u7684\u5b57\u7b26\u6620\u5c04\u4e3a\u4e8c\u8fdb\u5236": 118, "\u5b83\u7684\u7279\u70b9\u662f\u53d8\u957f\u7f16\u7801": 118, "\u5b83\u9075\u5faa\u4e00\u79cd\u8d2a\u5a6a\u7684\u7b56\u7565\u6765\u5c3d\u53ef\u80fd\u53d6\u5f97\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848": 108, "\u5b8c\u5168\u517c\u5bb9ascii": 118, "\u5bf9\u4e0eascii\u7a7a\u95f4\u6d6a\u8d39": 118, "\u5bf9\u4e8e\u5355\u5b57\u8282\u7684\u5b57\u7b26": 118, "\u5bf9\u4e8e\u53e5\u5b50": 117, "\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u662f\u6781\u5927\u7684\u6d6a\u8d39": 118, "\u5bf9\u4e8e\u672a\u77e5": 108, "\u5bf9\u4e8e\u82f1\u6587\u56fd\u5bb6\u6765\u8bf4\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528": 118, "\u5bf9\u4e8e\u9700\u8981n\u4e2a\u5b57\u8282\u7684\u5b57\u7b26": 118, "\u5bf9\u5e94\u7684unicode\u5b57\u7b26\u96c6\u662f4e00": 118, "\u5bf9\u5e94\u7684unicode\u662fu": 118, "\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a01000001": 118, "\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u7f16\u7801\u7684\u8fc7\u7a0b\u8fd8\u662f\u6bd4\u8f83\u7b80\u5355\u7684": 108, "\u5bf9\u7528\u4f4e\u7ef4\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u95f4\u7684\u80fd\u529b\u5f71\u54cd\u66f4\u5927": 110, "\u5bfb\u627e\u6700\u5e38\u51fa\u73b0\u7684\u5b57\u8282\u5bf9": 108, "\u5c06": 22, "\u5c06\u53c2\u6570\u503c\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u7c7b\u578b": 22, "\u5c31\u4ee3\u8868\u4e00\u4e2a\u8bed\u8a00\u5355\u4f4d": 108, "\u5c31\u50cf\u5355\u8bcd": 108, "\u5c31\u662f\u4f7f\u7528\u63a7\u5236\u7801": 118, "\u5c31\u80fd\u4ee3\u8868\u4e86\u6240\u6709\u952e\u76d8\u4e0a\u7684\u666e\u901a\u7b26\u53f7": 118, "\u5c31\u8bde\u751f\u4e86utf": 118, "\u5c3d\u7ba1\u8d2a\u5a6a": 108, "\u5e03\u5c14\u503c\u7b49": 22, "\u5e74\u53d1\u8868\u7684\u6587\u7ae0": 108, "\u5e76\u4e00\u6b21\u53c8\u4e00\u6b21\u5730\u6267\u884c\u76f8\u540c\u7684\u8fed\u4ee3": 108, "\u5e76\u4e14\u6211\u4eec\u7684\u5b50\u5b57\u7b26\u4e32\u5c06\u88ab\u66ff\u6362\u4e3a\u6211\u4eectoken\u5217\u8868\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684token\u7ec4\u5408": 108, "\u5e76\u4e14\u7531utf": 118, "\u5e76\u5c06\u5176\u91cd\u547d\u540d\u4e3a": 22, "\u5e76\u5c06\u5176\u9891\u7387\u8bb0\u4e3a": 108, "\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230token\u5217\u8868\u4e2d": 108, "\u5e76\u5c06\u65b0\u8bcd\u7684token\u6dfb\u52a0\u5230\u6211\u4eec\u7684token\u5b57\u5178\u4e2d\u4ee5\u5907\u5c06\u6765\u7528\u5230": 108, "\u5e76\u5c1d\u8bd5\u4f7f\u7528\u8fd9\u4e9btoken\u66ff\u6362\u7ed9\u5b9a\u5355\u8bcd\u5e8f\u5217\u4e2d\u7684\u5b50\u5b57\u7b26\u4e32": 108, "\u5e76\u88ab\u4f5c\u4e3a\u673a\u5668\u7ffb\u8bd1\u7b49\u4e3b\u6d41nlp\u4efb\u52a1\u7684\u9996\u9009tokenize\u65b9\u6cd5\u4e4b\u4e00": 108, "\u5e76\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2atoken\u51fa\u73b0\u7684\u9891\u7387": 108, "\u5e93": 22, "\u5f00\u5934": 118, "\u5f00\u59cb": 108, "\u5f53\u524d\u5206\u8bcd\u4e0b\u53e5\u5b50s\u7684\u4f3c\u7136\u503c\u53ef\u4ee5\u8868\u793a\u4e3a": 117, "\u5f53\u7136": 108, "\u5f53\u8fd0\u884c\u811a\u672c\u65f6": 22, "\u610f\u5473\u7740\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u53f7\u53d8\u5316\u975e\u5e38\u8fc5\u901f": 110, "\u6211\u4eec\u4f1a\u5c06": 108, "\u6211\u4eec\u5148\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5b83\u7684\u6838\u5fc3\u601d\u60f3": 108, "\u6211\u4eec\u53ef\u4ee5\u770b\u5230": 108, "\u6211\u4eec\u53ef\u4ee5\u9012\u5f52\u5730\u4f7f\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u5c06": 108, "\u6211\u4eec\u5c06tokenized\u597d\u7684\u5355\u8bcd\u4fdd\u5b58\u5728\u5b57\u5178\u4e2d": 108, "\u6211\u4eec\u5c06\u4ece\u7b2c\u4e8c\u5e38\u89c1\u7684\u6807\u8bb0": 108, "\u6211\u4eec\u5c06\u5b57\u7b26\u89c6\u4e3a\u4e0e\u5b57\u8282\u7b49\u4ef7": 108, "\u6211\u4eec\u5c06\u5b83\u4eec\u5408\u5e76\u4ee5\u5f62\u6210\u4e00\u4e2a\u65b0\u7684token": 108, "\u6211\u4eec\u5c06\u6bcf\u4e2a\u5355\u8bcd\u62c6\u5206\u4e3a\u5b57\u7b26\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684\u51fa\u73b0\u6b21\u6570": 108, "\u6211\u4eec\u5c06\u7528unknown": 108, "\u6211\u4eec\u5c06\u7ee7\u7eed\u6267\u884c\u6b64\u5408\u5e76\u6b65\u9aa4": 108, "\u6211\u4eec\u5c06\u88ab\u89e3\u7801\u4e3a": 108, "\u6211\u4eec\u5c06\u904d\u5386\u6211\u4eec\u5728\u8bed\u6599\u5e93\u4e2d\u627e\u5230\u7684\u6240\u6709token": 108, "\u6211\u4eec\u5c06\u904d\u5386\u6240\u6709token": 108, "\u6211\u4eec\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8bcd\u6c47\u5217\u8868\u662f\u5f88\u5927\u7684": 108, "\u6211\u4eec\u5e94\u7528\u4e0a\u8ff0\u7f16\u7801\u65b9\u6cd5\u5bf9\u65b0\u8bcd\u8fdb\u884ctoken": 108, "\u6211\u4eec\u5fc5\u987b\u7b80\u5355\u5730\u5c06\u6240\u6709token\u8fde\u63a5\u5728\u4e00\u8d77\u4ee5\u83b7\u5f97\u6574\u4e2a\u5355\u8bcd": 108, "\u6211\u4eec\u603b\u5171\u6709": 108, "\u6211\u4eec\u6709\u4e00\u4e2a\u9891\u7387\u4e3a": 108, "\u6211\u4eec\u6765\u67e5\u51fa\u8fd9\u51e0\u4e2a\u5b57\u5bf9\u5e94\u7684utf": 118, "\u6211\u4eec\u73b0\u5728\u5c06\u5408\u5e76token": 108, "\u6211\u4eec\u73b0\u5728\u6709": 108, "\u6211\u4eec\u73b0\u5728\u6709\u4e86": 108, "\u6211\u4eec\u73b0\u5728\u770b\u5230\u5b57\u8282\u5bf9": 108, "\u6211\u4eec\u7684\u6570\u636e\u73b0\u5728\u5df2\u8f6c\u6362\u4e3a": 108, "\u6211\u4eec\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6ca1\u6709\u770b\u5230\u7684\u8bcd": 108, "\u6211\u4eec\u770b\u5230\u5b57\u8282\u5bf9": 108, "\u6211\u4eec\u77e5\u9053": 108, "\u6211\u4eec\u8ba1\u7b97\u8fd9\u4e9b\u8bcd\u5728\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387": 108, "\u6211\u4eec\u8fd8\u5c06\u4ece\u5355\u4e2atoken": 108, "\u6211\u4eec\u90fd\u4e86\u89e3\u4e00\u79cd\u6700\u57fa\u672c\u7684token": 108, "\u6216": 108, "\u6216\u8005\u53eb": 118, "\u6240\u4ee5": [108, 117], "\u6240\u4ee5ascii\u7684\u5b57\u7b26": 118, "\u6240\u4ee5\u4ed6\u4eec\u5c31\u628a\u7b2c\u4e00\u4e2a\u7a7a\u95f20\u4f7f\u7528\u4e86\u8d77\u6765": 118, "\u6240\u4ee5\u4ed6\u4eec\u628a\u6bcf\u4e2a\u5b57\u8282\u7684\u7b2c\u4e00\u4f4d\u7f6e\u7f6e0": 118, "\u6240\u4ee5\u4f7f\u7528\u4e24\u4e2a\u5b57\u8282\u5df2\u7ecf\u8db3\u591f": 118, "\u6240\u4ee5\u5165\u53e3\u662f": 22, "\u6240\u4ee5\u5bf9\u5e94\u7684utf": 118, "\u6240\u4ee5\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u5168\u7403\u7edf\u4e00\u7684\u7f16\u7801\u89c4\u5219\u53ebunicod": 118, "\u6240\u4ee5\u6211\u4eec\u4e0d\u5bf9\u5b83\u8fdb\u884c\u7f16\u7801": 108, "\u6240\u4ee5\u6211\u4eec\u6709": 108, "\u6240\u4ee5\u8fd9\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898": 118, "\u628a": 22, "\u628a\u5b83\u653e\u5728\u672c\u5730": 25, "\u63a5\u4e0b\u6765": 108, "\u63a7\u5236\u7801\u5c31\u662f\u544a\u8bc9\u8ba1\u7b97\u673a\u5f53\u524d\u662f\u5355\u5b57\u8282\u8fd8\u662f\u591a\u5b57\u8282": 118, "\u653e\u5165\u7528\u6237\u4e3b\u76ee\u5f55\u4e0b\u7684": 22, "\u6563\u5ea6\u76f4\u63a5\u653e\u5728": 77, "\u6570\u5b57\u548c\u5b57\u6bcd\u90fd\u672a\u4e71\u7801": 118, "\u6570\u636e\u7684\u538b\u7f29": 108, "\u6587\u4ef6": 22, "\u6587\u4ef6\u4e2d\u6709\u5982\u4e0b\u914d\u7f6e": 22, "\u6587\u4ef6\u653e\u5165\u6b64\u76ee\u5f55\u5e76\u91cd\u547d\u540d\u4e3a": 22, "\u659c\u4f53": 118, "\u65b0": 108, "\u65b0\u5efa\u4e00\u4e2ahtml\u8f93\u5165": 118, "\u65cb\u8f6c\u5f97\u8d8a\u591a": 110, "\u65cb\u8f6c\u5f97\u8d8a\u5c11": 110, "\u65cb\u8f6c\u89d2\u5ea6\u8f83\u5927": 110, "\u65e0\u8bba\u5982\u4f55": 108, "\u65e0\u8bba\u662fascii\u7f16\u7801\u8fd8\u662futf": 118, "\u65e5\u6587": 118, "\u65f6": 110, "\u662f\u4e00\u79cd\u7b80\u5355\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5": 108, "\u662f\u4ee3\u7801\u7247\u6bb5": 25, "\u662f\u4f7f\u7528": 22, "\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684sub": 108, "\u662f\u7684": 108, "\u666e\u901a\u7b26\u53f7\u7684\u5b57\u7b26\u96c6": 118, "\u66ff\u6362\u5b83": 108, "\u6700\u5e38\u51fa\u73b0": 108, "\u6700\u5e38\u89c1\u7684\u5e26\u6709": 108, "\u6700\u7ec8": 108, "\u6700\u7ec8\u5bfc\u81f4": 110, "\u6709\u4e00\u79cd\u7f16\u7801\u65b9\u5f0f\u80fd\u5927\u5927\u51cf\u5c0ftoken": 108, "\u6709\u4ec0\u4e48\u7528": 22, "\u6709\u5f88\u591a\u9ad8\u9891\u7ef4\u5ea6\u8f6c\u4e86\u5f88\u591a\u5708": 110, "\u672a\u63d0\u53ca\u7684\u4f4d\u4f7f\u7528\u5bf9\u5e94\u7684unicode\u8865\u5145": 118, "\u6765\u505a\u4e00\u4e2a\u5c0f\u5b9e\u9a8c\u5e76\u4e14\u9a8c\u8bc1\u4e0b": 118, "\u6765\u8bf4": 118, "\u67e5\u770b\u5176\u4ed6token": 108, "\u6807\u8bb0\u4ee5\u6807\u8bc6\u5355\u8bcd\u8fb9\u754c\u80fd\u591f\u8ba9\u7b97\u6cd5\u77e5\u9053\u6bcf\u4e2a\u5355\u8bcd\u7684\u7ed3\u675f\u4f4d\u7f6e": 108, "\u6807\u8bb0\u7684\u96c6\u5408": 108, "\u6a21\u4eff\u663e\u8457\u6027": 52, "\u6b21": 108, "\u6b27\u6d32\u90e8\u5206\u8bed\u8a00\u5b57\u6bcd\u7684\u5b57\u7b26\u96c6": 118, "\u6b64\u65f6\u53e5\u5b50": 117, "\u6bd4\u5982utf": 118, "\u6bd4\u5982\u4e2d\u56fd1980\u5e74\u53d1\u884c\u4e86gb2312\u4ee5\u53ca\u540e\u9762\u51fa\u73b0\u5b83\u7684\u6269\u5c55\u7248\u672cgbk": 118, "\u6bd4\u5982\u5728ascii\u4e2d": 118, "\u6bd4\u5982\u5927\u5199\u5b57\u6bcda": 118, "\u6bd4\u5982\u6c49\u5b57": 118, "\u6bd4\u5982\u6c49\u5b57\u4e00\u5728unicode\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662f4e00": 118, "\u6bd4\u5982\u82f1\u6587\u5b57\u6bcda\u5bf9\u5e94\u7684unicode\u662fu": 118, "\u6bd4\u5982\u8bf4\u4e2d\u6587": 118, "\u6c49\u5b57": 118, "\u6c49\u5b57\u7684\u5b57\u7b26\u96c6": 118, "\u6ca1\u6709": 77, "\u6d4f\u89c8\u5668\u6253\u5f00\u540e\u663e\u793a\u6b63\u5e38": 118, "\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7": 108, "\u7136\u540e\u6211\u4eec\u4f7f\u7528chrome\u7684charset\u63d2\u4ef6\u6765\u4fee\u6539\u5f53\u524d\u9875\u9762\u89e3\u7801\u7684\u5b57\u7b26\u96c6": 118, "\u7136\u800c": 108, "\u73b0\u5728\u6211\u4eec\u53d1\u73b0": 108, "\u73b0\u5728\u6211\u4eec\u5c06\u6700\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u5408\u5e76\u6210\u4e00\u4e2atoken": 108, "\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u89e3\u7801\u6211\u4eec\u7684\u793a\u4f8b": 108, "\u751f\u6210\u5f85\u8bc4\u4f30\u7684\u6587\u4ef6": 25, "\u7528\u6700\u5c11\u7684token\u6765\u8868\u793a\u8bed\u6599\u5e93": 108, "\u7528\u6765\u8868\u793a\u7535\u8111\u548c\u5176\u4ed6\u7535\u4fe1\u8bbe\u5907\u7684\u6587\u672c": 118, "\u7531": 117, "\u7531m\u4e2a\u5b50\u8bcd\u7ec4\u6210": 117, "\u7531\u4e8eascii\u8868\u793a\u7684\u8303\u56f4\u6709\u9650": 118, "\u7531\u4e8e\u6211\u4eec\u603b\u5171\u6709": 108, "\u7684": [22, 108], "\u7684\u4f18\u52bf": 77, "\u7684\u5b57\u7b26\u91cf\u5df2\u7ecf\u8db3\u4ee5\u7528\u4e8e\u5168\u7403\u4e3b\u8981\u8bed\u8a00\u7684\u5927\u591a\u6570\u5b57\u7b26": 118, "\u7684\u5b57\u8282\u5bf9\u662f": 108, "\u7684\u60c5\u51b5": 77, "\u7684\u6548\u679c": 77, "\u7684\u6570\u636e": 108, "\u7684\u65b0token": 108, "\u7684\u6838\u5fc3\u673a\u5236": 22, "\u7684\u7b2c\u4e00\u5b57\u8282\u5168\u662f0": 118, "\u7684\u8bed\u8a00\u6a21\u578b\u4f3c\u7136\u503c\u7b49\u4ef7\u4e8e\u6240\u6709\u5b50\u8bcd\u6982\u7387\u7684\u4e58\u79ef": 117, "\u7684\u9891\u7387\u4e3a": 108, "\u7684\u9891\u7387\u51cf\u5c11": 108, "\u76ee\u5f55\u4e0b": 25, "\u76f4\u5230\u8fbe\u5230\u6211\u4eec\u9884\u5148\u8bbe\u7f6e\u7684token\u6570\u9650\u5236\u6216\u8fed\u4ee3\u9650\u5236": 108, "\u76f8\u6bd4": 77, "\u76f8\u90bb\u5b57\u8282\u5bf9": 108, "\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u5728bpe\u4e2d\u770b\u4f5c\u76f8\u90bb\u5b57\u8282\u5bf9": 108, "\u7701\u8d44\u6e90": 77, "\u770b\u5230\u8fd9\u91cc": 117, "\u770b\u5b8c\u4e0b\u9762\u5b8c\u6574\u7684\u8fed\u4ee3\u8fc7\u7a0b": 108, "\u770b\u770b\u6211\u4eec\u6700\u7ec8\u7684token\u5217\u8868": 108, "\u771f\u5b9e\u7684": 79, "\u77e5\u9053\u4e86\u7f16\u7801\u7684\u539f\u7406\u540e\u81ea\u7136\u80fd\u60f3\u5230\u7684\u5c31\u662f\u6587\u672c\u7f16\u7801\u548c\u89e3\u7801\u6240\u4f7f\u7528\u7684\u5b57\u7b26\u96c6\u4e0d\u540c": 118, "\u786e\u4fdd\u6700\u5e38\u89c1\u7684\u8bcd\u5728token\u5217\u8868\u4e2d\u8868\u793a\u4e3a\u5355\u4e2atoken": 108, "\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230": 108, "\u7a76\u7adf\u8c03\u7528\u7684\u662f\u4ec0\u4e48\u51fd\u6570": 22, "\u7a7a\u95f4\u6781\u5927\u6d6a\u8d39": 118, "\u7b2cn": 118, "\u7b2c\u4e00\u4e2a\u5b57\u8282": 118, "\u7b2c\u4e00\u4e2a\u5b57\u8282\u7684\u7b2c\u4e8c\u4e2a0": 118, "\u7b2c\u4e8c\u9ad8\u9891\u7387\u6807\u8bb0\u662f": 108, "\u7b49\u8bcd\u4e4b\u95f4\u7684\u533a\u522b": 108, "\u7b97\u6cd5\u7684\u4e0b\u4e00\u6b65\u662f\u5bfb\u627e\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9": 108, "\u7b97\u6cd5\u7684\u4e3b\u8981\u76ee\u6807": 108, "\u7c7b\u4f3c\u5730": 22, "\u7f16\u7801\u4e3a": 108, "\u7f16\u7801\u672c\u8eab\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u8f83\u9ad8": 108, "\u7f16\u7801\u7c7b\u578b": 118, "\u8001\u89c4\u77e9": 108, "\u800cwordpiece\u9009\u62e9\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6700\u5927\u7684\u76f8\u90bb\u5b50\u8bcd\u52a0\u5165\u8bcd\u8868": 117, "\u800c\u4e0d\u662f": 108, "\u800c\u4e14\u8fc7\u5927\u7684token\u5217\u8868\u5341\u5206\u5f71\u54cd\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6": 108, "\u800c\u5728gb2312\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662fd2bb": 118, "\u800c\u662f\u5c06\u5b83\u4ee5utf": 118, "\u800c\u6c49\u5b57\u4e00\u4e8c\u4e09\u4e71\u7801\u4e86": 118, "\u800c\u7f55\u89c1\u7684\u8bcd\u88ab\u5206\u89e3\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2asubword": 108, "\u80fd\u591f\u6e05\u695a\u5730\u7406\u89e3wordpiece\u5728\u5408\u5e76\u8fd9\u4e00\u6b65\u662f\u5982\u4f55\u4f5c\u51fa\u9009\u62e9\u7684": 117, "\u80fd\u591f\u7cbe\u7ec6\u5730\u533a\u5206\u76f8\u90bb\u4f4d\u7f6e": 110, "\u82e5\u4f7f\u7528\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f": 108, "\u82f1\u6587\u5b57\u6bcd": 118, "\u83b7\u53d6\u6a21\u578b\u7684": 22, "\u8461\u8404\u7259\u8bed\u7b49\u65e0\u6cd5\u7528127\u4e2a\u5b57\u7b26\u8868\u793a\u5b8c\u5168": 118, "\u8868\u793a\u5b50\u8bcd": 117, "\u8981\u89e3\u7801": 108, "\u89c4\u52191": 118, "\u89c4\u52192": 118, "\u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570": 22, "\u8ba1\u7b97": 110, "\u8ba1\u7b97\u673a\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u662f\u6309\u7167\u4e00\u4e2a\u5b57\u8282\u7684\u5927\u5c0f\u6765\u8bfb\u53d6\u8bc6\u522b\u7684": 118, "\u8ba1\u7b97\u673a\u6309\u7167\u5b57\u8282\u6765\u8bfb\u53d6\u6570\u636e\u65f6": 118, "\u8ba1\u7b97\u673a\u662f\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u8868\u793a\u7684\u662f\u4ec0\u4e48\u610f\u601d\u5462": 118, "\u8ba9\u6211\u4eec\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0\u4e00\u4e2a\u7279\u6b8a\u7684\u7ed3\u675f\u6807\u8bb0": 108, "\u8ba9\u6211\u4eec\u73b0\u5728\u505c\u6b62\u8fed\u4ee3\u5e76": 108, "\u8ba9\u6211\u4eec\u73b0\u5728\u8003\u8651": 108, "\u8ba9\u6211\u4eec\u7528": 108, "\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\u6765\u4e86\u89e3\u4e00\u4e0b\u5b83\u7684nlp\u7248\u672c": 108, "\u8bcd": 108, "\u8bf4\u660e": 118, "\u8bf4\u660eunicode\u548cgbk\u90fd\u5411\u4e0b\u517c\u5bb9\u4e86ascii": 118, "\u8c03\u7528": 22, "\u8d8a\u8fd1": 110, "\u8d8a\u8fdc": 110, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f0100": 118, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f100": 118, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f19968": 118, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f65": 118, "\u8f93\u51fa\u6587\u4ef6": 22, "\u8fd8\u6709\u5176\u4ed6\u7f16\u7801\u65b9\u5f0f": 118, "\u8fd8\u6709\u7a7a\u683c32": 118, "\u8fd9\u4e00\u95ee\u9898": 118, "\u8fd9\u4e24\u4e2a\u8bcd\u90fd\u6709\u4e00\u4e2a\u5171\u540c\u7684": 108, "\u8fd9\u4e2a\u4e8c\u8fdb\u5236\u670915\u4f4d": 118, "\u8fd9\u4e2a\u8bcd\u7684token": 108, "\u8fd9\u4e5f\u662f": 108, "\u8fd9\u53ea\u662f\u82f1\u8bed\u7684\u7528\u6cd5": 108, "\u8fd9\u5b8c\u5168\u7b49\u540c\u4e8e127\u4f4d\u6700\u521d\u7684ascii\u7801": 118, "\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u9891\u7387\u8ba1\u6570\u5c06\u5728\u6bcf\u4e2a\u5408\u5e76\u6b65\u9aa4\u540e\u53d1\u751f\u53d8\u5316": 108, "\u8fd9\u662f\u66f4\u65b0\u540e\u7684\u8868\u683c": 108, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u67e5\u770b\u6bcf\u4e2a\u5b57\u7b26\u5e76\u627e\u5230\u9891\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u914d\u5bf9": 108, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u7406\u89e3": 108, "\u8fd9\u6837\u7684token\u5c06\u88ab\u4e0d\u540c\u5730\u5904\u7406": 108, "\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e4b\u4e3a": 110, "\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f\u5341\u5206\u7b26\u5408\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef": 108, "\u8fd9\u91cc": [22, 117], "\u8fd9\u91cc\u4fee\u6539\u4e3agbk": 118, "\u8fd9\u91cc\u7b80\u5355\u4ecb\u7ecd\u4e0b\u8fd9\u51e0\u79cd\u7f16\u7801\u65b9\u5f0f\u7684\u533a\u522b": 118, "\u8fdc\u7a0b\u8870\u51cf\u66f2\u7ebf\u5982\u4e0b": 110, "\u8fed\u4ee3": 108, "\u901a\u5e38\u6709\u51e0\u4e07\u5230\u51e0\u5341\u4e07\u91cf\u7ea7\u7684\u5355\u8bcd\u6570": 108, "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5": 117, "\u90a3\u4e48\u4eba\u4eec\u80fd\u8bc6\u522b\u7684\u6587\u5b57\u548c\u8ba1\u7b97\u673a\u4e2d\u7684\u4e8c\u8fdb\u5236\u5fc5\u7136\u5b58\u5728\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 118, "\u90a3\u4e48\u9762\u5bf9\u5168\u4e16\u754c\u8fd9\u4e48\u591a\u8bed\u8a00": 118, "\u90a3\u5982\u4f55\u628a\u538b\u7f29\u7684\u7f16\u7801\u590d\u539f\u5462": 108, "\u90a3\u5c31\u662f\u672c\u6587\u5373\u5c06\u4ecb\u7ecd\u7684byte": 108, "\u90a3\u6837\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u6050\u6016\u7684": 108, "\u90a3\u82f1\u6587\u5b57\u7b26": 118, "\u90e8\u5206\u9891\u7387\u4f4e": 110, "\u90e8\u5206\u9891\u7387\u9ad8": 110, "\u90fd\u4e00\u6837": 118, "\u91cc\u548c\u653e\u5728": 77, "\u91cc\u7684\u533a\u522b": 77, "\u95f4\u76f8\u4e92\u9694\u5f00": 77, "\u963f\u62c9\u4f2f\u6570\u5b570\u5bf9\u5e94\u7684ascii\u7801\u662f48": 118, "\u963f\u62c9\u4f2f\u6570\u5b57\u548c\u82f1\u6587\u5b57\u6bcd": 118, "\u968f\u673a\u6027\u5f88\u5927": 110, "\u968f\u7740\u8ba1\u7b97\u673a\u5728\u5168\u7403\u7684\u53d1\u5c55\u548c\u666e\u53ca": 118, "\u9700": 22, "\u9700\u52a0\u4e0a": 22, "\u9700\u8981\u4ece": 25, "\u9700\u8981\u81f3\u5c112\u4e2a\u5b57\u8282\u8868\u793a": 118, "\u975e\u5e38\u91cd\u8981": 108, "\u9996\u5148\u6765\u660e\u786e\u4e00\u4e0b\u57fa\u7840\u6982\u5ff5": 108, "\u9996\u5148\u770b\u4e0bwiki\u5bf9\u5b83\u7684\u5b9a\u4e49": 118, "\u9ad8\u4f4d\u4ee5": 118, "\u9ad8\u4f4d\u524dn\u4f4d\u4e3a": 118, "\u9ad8\u7684": 77, "\u9ad8\u7ef4": 110, "\u9ad8\u9891\u4fe1\u606f\u7684\u635f\u5931": 110, "\u9ad8\u9891\u7ef4\u5ea6\u5c11\u4f4e\u9891\u7ef4\u5ea6\u591a": 110, "\ud835\udc41": 76}, "titles": ["Agent", "AGENTLESS", "API-Bank", "CodeAct", "REACT", "Reflexion", "Search-R1", "Agents in Software Engineering", "SWE-agent", "SWE-smith", "Base", "Attention Is All You Need", "GPT", "GPT2", "GPT3", "InstructGPT", "Benchmarks", "Aider Polyglot", "Alignment Benchmarks", "BigCodeBench", "Code Alpaca", "CRUXEval", "EvalPlus", "General Benchmarks", "HumanEval", "LiveCodeBench", "Magicoder", "Math &amp; Science Benchmarks", "MBPP", "RewardBench", "SELF-INSTRUCT", "SWE-bench", "TACO", "WizardCoder", "Contents", "Contents", "Data", "AlphaCode", "APPS", "Code Alpaca", "Magicoder", "OpenCoder", "SELF-INSTRUCT", "TACO", "UNICODER", "WizardCoder", "Introduction", "Markdown Files", "Notebooks with MyST Markdown", "GOLD", "Evaluation of LLMs Should Not Ignore Non-Determinism", "Scaling Laws for Neural Language Models", "Weak to Strong Generalization", "Models", "AlphaCode", "AlphaCode 2", "AlphaCodium", "Code Llama", "DeepSeek-Coder-V2", "DeepSeek-V2", "DeepSeek V3", "Llama", "Llama 2", "Llama 3", "Llama3", "Llama 3 Source Code", "Qwen 2.5", "Qwen2.5-Coder", "Qwen3", "Seed-Coder", "Preference Optimization", "ArmoRM-MoE", "DAPO", "DeepSeek-GRM", "DPO", "DPOP", "Efficient Exploration for LLMs", "Group Relative Policy Optimization", "Instruct GPT", "Aligning Language Models with Judgments", "OpenRLHF", "PPO", "REINFORCE++", "Constitutional AI: Harmlessness from AI Feedback", "RLAIF vs. RLHF", "RLCD", "RS-DPO", "RSO", "Secrets of RLHF in Large Language Models: Reward Modeling", "Self-Rewarding Language Models", "Self-Taught Evaluators", "West-of-N", "Reasoning", "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "DeepCoder", "DeepSeek-R1", "Logic-RL", "OpenCodeReasoning", "s1: Simple test-time scaling", "Training Language Models to Self-Correct via Reinforcement Learning", "Let\u2019s Verify Step by Step", "References", "SFT", "LIMA: Less Is More for Alignment", "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED", "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold", "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "Techniques", "Byte Pair Encoding (BPE)", "DeepSeekMoE", "Extending context window of LLMs", "Extending context window of large language models via position interpolation", "Multi-Head Latent Attention", "Normalization", "RoPE", "Rotary Positional Embeddings (RoPE)", "SwiGLU", "WordPiece, ULM and SentencePiece", "ASCII,UNICODE,UTF8", "Llama Factory", "LORA", "OpenRLHF"], "titleterms": {"": 100, "1": 71, "16": 118, "2": [55, 57, 62, 66, 71], "2d": [114, 115], "3": [63, 65], "32\u7b49": 118, "5": [66, 67], "500": 27, "8": 118, "A": 67, "AT": 104, "Not": 50, "The": [8, 49, 56, 71, 82, 106], "abil": [89, 106], "ablat": [103, 112], "absolut": 115, "accuraci": 106, "aci": 8, "action": 7, "activ": [64, 65, 76, 100], "adapt": 88, "add": 48, "addit": 56, "advantag": 82, "agent": [0, 3, 7, 8], "agentless": 1, "aggreg": 71, "aha": 95, "ai": [83, 84], "aider": 17, "algorithm": [49, 76, 82, 87, 89, 95], "align": [18, 50, 58, 59, 79, 89, 103], "all": [11, 95, 104], "almost": 104, "alpaca": [20, 39], "alphacod": [37, 54, 55], "alphacodium": 56, "an": [8, 48, 76], "analyz": 88, "annot": 90, "api": 2, "app": 38, "appendix": 74, "approach": [1, 13, 14, 31, 54, 61, 73, 87, 115], "architectur": [11, 14, 59, 60, 61, 66, 68, 76], "arena": 18, "armorm": 71, "ascii": 118, "assess": 76, "attent": [11, 64, 65, 112], "auditori": 7, "augment": 106, "automat": 19, "averag": 63, "awar": 110, "background": [82, 110, 111, 115], "balanc": 109, "bank": 2, "base": [10, 31, 66, 67, 72, 73, 95, 100], "basic": [51, 60], "batch": [82, 113], "batchnorm": 64, "bench": 31, "benchmark": [16, 18, 19, 23, 27, 31, 73], "benefit": 3, "better": [3, 88], "between": 112, "bigcodebench": 19, "boost": 73, "bpe": 108, "byte": 108, "cach": 112, "capabl": 63, "case": [19, 114, 115], "cell": 48, "chain": 93, "chart": 51, "chat": 63, "chatformat": 64, "citat": 47, "classif": [30, 42], "clip": [72, 82], "cluster": [54, 55], "code": [19, 20, 22, 33, 39, 45, 56, 57, 63, 65], "codeact": 3, "codecontest": 37, "codellama": 31, "coder": [58, 67, 69], "cold": [68, 73, 95], "collaps": 99, "collect": [9, 58, 62, 100], "commun": 109, "comparison": [73, 112], "composit": [41, 67], "compress": 112, "comput": [8, 51], "concept": 56, "consider": 109, "constitut": 83, "construct": [19, 31, 59, 60, 90], "content": [34, 35], "context": [57, 60, 110, 111], "contextwindow": 110, "contrast": 79, "control": 63, "correct": [22, 24, 99], "cot": 68, "count": [51, 106], "creat": [48, 98], "creation": 89, "critiqu": [73, 83], "cruxev": 21, "curat": [19, 98], "dapo": 72, "data": [19, 20, 30, 36, 39, 41, 42, 51, 58, 59, 60, 61, 62, 63, 67, 88, 98, 100, 103, 104, 105, 106], "dataset": [13, 14, 15, 37, 51, 54, 57, 72, 78], "decod": [11, 12], "decontamin": [41, 67], "decoupl": 112, "deepcod": 94, "deepseek": [58, 59, 60, 73, 95], "deepseekmo": 109, "deriv": 74, "design": [2, 8, 56], "detail": [15, 26, 40, 41, 72, 80], "determin": 50, "devic": 109, "dialog": 63, "differ": [73, 88], "direct": [47, 63, 74, 111], "discuss": 59, "distanc": 110, "distil": 68, "diverg": 72, "divers": [88, 103], "done": 3, "dot": 11, "dpo": [74, 75, 86], "dpop": 75, "drop": 109, "dynam": [72, 110], "effect": 50, "effici": [76, 105, 110], "eight": 105, "elicit": 93, "embed": [11, 51, 110, 111, 112, 115], "empir": [51, 76], "encod": [11, 108], "engin": [7, 8], "enhanc": 82, "enn": 76, "episod": 7, "epistem": 76, "estim": 76, "evalplu": 22, "evalu": [2, 14, 19, 22, 25, 26, 33, 40, 45, 50, 54, 55, 59, 60, 66, 67, 84, 90, 103], "evol": [33, 45], "evolut": 95, "exampl": 48, "exist": 3, "experi": [13, 72, 89, 111], "experiment": [15, 31, 50, 58, 76, 82, 89], "expert": [71, 109], "explor": 76, "extend": [110, 111], "extens": [60, 110], "extern": 7, "extrapol": 111, "factor": [50, 106], "factori": 119, "failur": 75, "featur": 31, "feed": 11, "feedback": [83, 84], "feedforward": [64, 65], "fewer": 3, "ffn": 116, "file": 47, "filter": [30, 42, 54, 55], "fine": [12, 31, 37, 54, 55, 57, 58, 59, 60, 62, 66, 73, 78, 90, 95, 109], "finetun": [30, 42, 63], "flip": 88, "flow": 56, "fold": 105, "follow": [30, 42, 89], "form": [114, 115], "format": [31, 63], "formul": [114, 115], "forward": 11, "framework": [3, 12, 49], "frequenc": 110, "from": [3, 26, 40, 49, 73, 79, 83, 84], "full": 50, "fullest": 88, "function": [24, 64, 65], "fusion": 68, "gate": 116, "gb2312": 118, "gbk\u7b49\u5176\u4ed6\u7f16\u7801": 118, "gener": [9, 19, 23, 30, 42, 50, 52, 64, 68, 73, 100, 114, 115], "get": 3, "glu": 116, "gold": 49, "gpqa": 27, "gpt": [12, 78], "gpt2": 13, "gpt3": 14, "gqa": 112, "gradient": [49, 72, 74], "grain": 109, "grm": 73, "group": 77, "grpo": 77, "gsm8k": 27, "hard": 18, "harmless": 83, "head": [11, 112], "high": [15, 110], "higher": 72, "how": [50, 88], "human": [19, 62, 88, 103], "humanev": [22, 24], "hyper": 59, "i": [3, 11, 47, 50, 99, 103, 104], "identif": [30, 42], "ifev": 18, "ignor": 50, "ii": 99, "impact": 88, "implement": [26, 40, 80, 111], "incorpor": 79, "incorrect": 105, "infer": 73, "infil": 57, "infinit": 51, "influenc": 50, "inform": 110, "initi": [89, 90, 99], "input": [7, 12, 13, 31], "insight": 56, "instal": 25, "instanc": [30, 42], "instruct": [19, 26, 30, 33, 40, 41, 42, 44, 45, 57, 66, 67, 78, 89, 90], "instructgpt": 15, "integr": 82, "interact": 3, "interfac": 8, "intern": 7, "interpol": [110, 111], "interpret": 71, "introduct": [9, 26, 40, 46, 52, 57, 61, 79, 85, 111], "isol": 109, "iter": [62, 63, 77, 90], "its": 88, "joint": 112, "judgment": [79, 90], "kei": 112, "kl": [72, 82], "kv": 112, "label": [84, 88], "languag": [51, 63, 79, 88, 89, 93, 99, 106, 110, 111, 117], "larg": [54, 88, 93, 100, 106, 110, 111], "latent": 112, "law": 51, "layer": 113, "layernorm": 64, "learn": [47, 58, 59, 60, 66, 76, 78, 79, 83, 84, 95, 99, 100, 106], "less": 103, "let": 100, "level": [15, 72, 82, 109], "leverag": 88, "lima": 103, "limit": 51, "linear": 116, "lite": 31, "livecodebench": 25, "llama": [31, 57, 61, 62, 63, 65, 111, 119], "llama3": 64, "llm": [3, 50, 76, 84, 105, 106, 110], "lm": [30, 42], "load": 109, "local": 110, "logic": 96, "long": [57, 60, 68], "lora": 120, "loss": [72, 74, 106, 109, 110], "low": 112, "magicod": [26, 40], "main": [72, 83], "make": 3, "margin": 88, "markdown": [47, 48], "math": [27, 105, 106], "mathemat": 106, "mbpp": [22, 28], "measur": 88, "mechan": 112, "memori": 7, "metadata": 48, "method": [15, 83, 90, 100], "methodologi": [15, 52, 78, 84], "mha": 112, "mini": 82, "mixtur": [67, 71, 109], "mla": 112, "mle": 49, "mmlu": 23, "mode": [68, 75], "model": [11, 13, 14, 15, 51, 53, 55, 62, 63, 64, 65, 66, 67, 71, 72, 73, 76, 78, 79, 88, 89, 90, 91, 93, 95, 99, 100, 106, 110, 111, 117], "moe": 71, "moment": 95, "more": [3, 47, 103], "mqa": 112, "multi": [3, 11, 60, 71, 99, 112], "myst": [47, 48], "n": [51, 91], "need": [11, 71, 104], "network": [11, 76], "neural": [51, 76], "nl": 19, "nlp\u5b9e\u4f8b": 108, "non": [50, 51], "normal": [64, 82, 113], "notebook": 48, "ntk": 110, "object": 71, "off": 49, "offlin": 66, "onli": 12, "onlin": 66, "ood": 100, "open": [26, 40], "opencod": 41, "opencodereason": 97, "openrlhf": [80, 121], "optim": [61, 63, 70, 74, 77], "orient": [19, 56, 95], "orm": 100, "oss": [26, 40], "outcom": [77, 100], "overal": [55, 89], "overfit": 51, "overlong": 72, "overview": 56, "packag": 3, "pair": [90, 108], "paramet": [51, 59], "part": 110, "passiv": 76, "pattern": 50, "penalti": 82, "percept": 7, "perform": [51, 88, 95], "pi_": 74, "pipelin": 76, "point": 76, "polici": [49, 55, 67, 72, 77], "polyglot": 17, "posit": [11, 110, 111, 112, 115], "post": [41, 60, 63, 66, 67, 68], "postprocess": [30, 42], "potenti": [50, 88], "power": 51, "ppo": [77, 80, 81, 82], "pre": [12, 59, 60, 61, 63, 66, 67, 68, 106], "predict": 60, "prefer": [62, 63, 70, 74, 84, 88, 91], "preliminari": [72, 74, 87, 88, 99, 109, 112, 115], "pretrain": [41, 62], "prevent": 99, "principl": [2, 73], "prm": 100, "pro": 23, "problem": [79, 99], "procedur": 7, "process": [63, 77, 95, 100], "product": 11, "program": 19, "promis": 3, "prompt": [33, 45, 84, 93], "properti": 115, "propos": [56, 115], "qualiti": [63, 73, 103], "quantiti": 103, "queri": 112, "quick": 22, "quickli": 48, "qwen": 66, "qwen2": 67, "qwen3": 68, "r": [74, 86], "r1": [6, 95], "random": 104, "rank": 112, "react": 4, "reason": [68, 92, 93, 95, 98, 105, 106], "recip": 67, "redux": 23, "refactor": 19, "refer": 101, "reflect": 5, "reflexion": 5, "reinforc": [5, 58, 59, 60, 66, 78, 82, 83, 84, 95, 99], "reject": [73, 87, 95], "rel": [77, 110], "relat": 91, "relationship": 106, "remov": 72, "represent": 13, "respons": 90, "result": [8, 15, 31, 50, 51, 58, 59, 60, 63, 72, 73, 76, 83, 84, 89, 98], "rethink": 104, "retriev": 31, "review": 77, "revis": 83, "reward": [49, 62, 63, 71, 72, 73, 76, 78, 82, 88, 89, 95, 99, 100], "rewardbench": 29, "rl": [49, 68, 73, 77, 78, 96, 99, 105], "rlaif": 84, "rlcd": 85, "rlhf": [62, 84, 88], "rm": [73, 78, 88], "rmsnorm": [64, 65, 113], "role": 47, "rope": [64, 65, 110, 111, 114, 115], "rotari": [110, 111, 112, 115], "round": 63, "rso": 87, "rule": [72, 73], "s1": 98, "s1k": 98, "sampl": [47, 54, 55, 72, 87, 95], "scale": [9, 11, 50, 51, 54, 73, 98, 100, 104, 105, 106, 110], "scenario": 95, "scienc": 27, "score": [55, 99], "search": 6, "secret": 88, "seed": 69, "segment": 109, "select": [90, 104], "self": [30, 42, 73, 89, 90, 91, 95, 99], "semant": 7, "semi": 19, "sentencepiec": 117, "set": 79, "setup": [31, 82, 89, 99], "sft": [62, 63, 78, 102, 119, 121], "shape": [72, 99], "share": 109, "should": 50, "show": 3, "simpl": 98, "size": 51, "small": 100, "smith": 9, "smooth": 88, "softmax": 11, "softwar": [3, 7, 8, 9], "sourc": [26, 40, 65], "spct": 73, "special": 57, "specif": 12, "stack": 11, "stage": [41, 56, 71, 99], "standard": 112, "stanford": [20, 39], "start": [22, 68, 73, 95], "statist": [19, 87], "step": 100, "strategi": 109, "strength": 88, "strong": [3, 52, 68], "summar": 13, "supervis": [12, 58, 59, 60, 63, 66, 77, 78, 83, 95, 100, 106], "surfac": 50, "swe": [8, 9, 31], "swiglu": [64, 65, 116], "swish": 116, "synthesi": 19, "synthet": [100, 105], "system": [2, 55], "taco": [32, 43], "takeawai": [58, 59, 60, 63, 66, 67, 88, 100, 114], "task": [9, 12, 30, 42], "taught": 90, "techniqu": [84, 107], "temperatur": 50, "templat": 95, "test": [19, 98], "textual": 7, "think": 68, "thought": 93, "tiktoken": 64, "time": [51, 73, 98], "token": [60, 64, 66, 72, 82, 109], "tool": 3, "train": [12, 13, 14, 33, 41, 45, 51, 59, 60, 61, 63, 66, 67, 68, 72, 76, 89, 90, 91, 95, 99, 103, 106], "transform": [12, 51, 64, 65, 109], "tune": [12, 26, 31, 37, 40, 41, 54, 55, 57, 58, 59, 60, 62, 66, 73, 78, 90, 95], "turn": [3, 99], "two": 41, "ulm": 117, "understand": 73, "unicod": [44, 118], "unigram": 117, "unit": 116, "unpin": 73, "unsupervis": 12, "updat": 82, "us": 3, "utf": 118, "utf8": 118, "v": [84, 100, 106], "v2": [58, 59], "v3": 60, "valu": 112, "variant": 116, "variou": 50, "verbal": 5, "verifi": 100, "via": [5, 99, 111], "visual": 7, "weak": [52, 68], "west": 91, "what": [3, 47, 50], "why": [12, 112, 113], "window": [110, 111], "wise": 11, "wizardcod": [33, 45], "wizardlm": [33, 45], "wordpiec": 117, "work": 91, "yaml": 48, "yarn": 110, "you": [11, 104], "zero": 95, "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": 118, "\u521d\u8bc6bpe": 108, "\u603b\u7ed3": 118, "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5": 108, "\u672c\u5730": [22, 25], "\u7684\u8fdc\u7a0b\u8870\u51cf": 110, "\u7f16\u7801\u548c\u89e3\u7801": 108, "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": 110}})