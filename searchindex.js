Search.setIndex({"alltitles": {"2D case": [[3, "d-case"], [4, "d-case"]], "A General Language Assistant as a Laboratory for Alignment": [[65, "a-general-language-assistant-as-a-laboratory-for-alignment"]], "ASCII": [[7, "ascii"]], "ASCII,UNICODE,UTF8": [[7, "ascii-unicode-utf8"]], "Ablation of Attention Mechanisms": [[37, "ablation-of-attention-mechanisms"]], "Ablation of MHA, GQA, and MQA": [[37, "ablation-of-mha-gqa-and-mqa"]], "Absolute position embedding": [[4, "absolute-position-embedding"]], "Active Exploration with a Point Estimate": [[56, "active-exploration-with-a-point-estimate"]], "Active Exploration with an ENN": [[56, "active-exploration-with-an-enn"]], "Active Learning": [[41, "active-learning"]], "Adaptive Margin": [[61, "adaptive-margin"]], "Additional insights": [[28, "additional-insights"]], "Aligning Language Models with Judgments": [[57, "aligning-language-models-with-judgments"]], "Alignment Effect on Non-Determinism": [[22, "alignment-effect-on-non-determinism"]], "AlphaCode": [[26, "alphacode"]], "AlphaCode 2": [[27, "alphacode-2"]], "AlphaCodium": [[28, "alphacodium"]], "An example cell": [[20, "an-example-cell"]], "Analyze and Leverage Diverse Data to its Fullest Potential": [[61, "analyze-and-leverage-diverse-data-to-its-fullest-potential"]], "Appendix": [[46, "appendix"]], "Approach": [[26, "approach"], [34, "approach"]], "Architecture": [[32, "architecture"], [34, "architecture"]], "ArmoRM-MoE": [[55, "armorm-moe"]], "Assessment Pipeline": [[56, "assessment-pipeline"]], "Attention": [[36, "attention"], [36, "id1"]], "Background": [[4, "background"]], "Background: Rotary Position Embedding (RoPE)": [[1, "background-rotary-position-embedding-rope"], [2, "background-rotary-position-embedding-rope"]], "Base Models": [[41, "base-models"]], "BatchNorm": [[36, "batchnorm"]], "Byte Pair Encoding (BPE)": [[0, "byte-pair-encoding-bpe"]], "CRUXEval": [[10, "cruxeval"]], "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [[39, "chain-of-thought-prompting-elicits-reasoning-in-large-language-models"]], "Charting the Infinite Data Limit and Overfitting": [[23, "charting-the-infinite-data-limit-and-overfitting"]], "ChatFormat": [[36, "chatformat"]], "Citations": [[19, "citations"]], "Classification Task Identification": [[15, "classification-task-identification"]], "Clustering": [[26, "clustering"], [27, "clustering"]], "Code Alpaca": [[9, "code-alpaca"], [9, "id1"]], "Code Llama": [[29, "code-llama"]], "Code Llama: Specializing Llama 2 for code": [[29, "code-llama-specializing-llama-2-for-code"]], "Code-Oriented Design Concepts": [[28, "code-oriented-design-concepts"]], "Comparison Between MLA and MHA": [[37, "comparison-between-mla-and-mha"]], "Comparison of Key-Value Cache": [[37, "comparison-of-key-value-cache"]], "Conditioning on Aligned Behavior": [[65, "conditioning-on-aligned-behavior"]], "Constitutional AI: Harmlessness from AI Feedback": [[58, "constitutional-ai-harmlessness-from-ai-feedback"]], "Contents": [[8, "contents"]], "Create a notebook with MyST Markdown": [[20, "create-a-notebook-with-myst-markdown"]], "Critiques, Revisions, and Supervised Learning": [[58, "critiques-revisions-and-supervised-learning"]], "DPO": [[46, "dpo"]], "DPOP": [[47, "dpop"], [47, "id1"]], "Data": [[9, "data"]], "Data Collection": [[30, "data-collection"], [41, "data-collection"]], "Data Generation": [[15, "data-generation"]], "Dataset": [[29, "dataset"], [49, "dataset"]], "Datasets": [[26, "datasets"]], "Decoupled Rotary Position Embedding": [[37, "decoupled-rotary-position-embedding"]], "DeepSeek V3": [[33, "deepseek-v3"]], "DeepSeek-Coder-V2": [[30, "deepseek-coder-v2"]], "DeepSeek-V2": [[32, "deepseek-v2"]], "DeepSeekMoE": [[31, "deepseekmoe"], [32, "deepseekmoe"]], "Derivation of \\pi_{r}": [[46, "derivation-of-pi-r"]], "Direct Preference Optimization": [[46, "direct-preference-optimization"]], "Direct extrapolation": [[2, "direct-extrapolation"]], "Efficient Exploration for LLMs": [[56, "efficient-exploration-for-llms"]], "Empirical Results": [[56, "empirical-results"]], "Empirical Results and Basic Power Laws": [[23, "empirical-results-and-basic-power-laws"]], "Epistemic Neural Network": [[56, "epistemic-neural-network"]], "Evaluation": [[10, "evaluation"], [12, "evaluation"], [17, "evaluation"], [26, "evaluation"], [27, "evaluation"], [59, "evaluation"]], "Evaluation of LLMs Should Not Ignore Non-Determinism": [[22, "evaluation-of-llms-should-not-ignore-non-determinism"]], "Evol-Instruct": [[17, "evol-instruct"]], "Evol-Instruct Prompts for Code": [[17, "evol-instruct-prompts-for-code"]], "Experimental Results": [[22, "experimental-results"]], "Experimental Setup": [[62, "experimental-setup"]], "Experimentation Pipeline": [[56, "experimentation-pipeline"]], "Experiments": [[2, "experiments"], [62, "experiments"]], "Exploration Algorithms": [[56, "exploration-algorithms"]], "Extending context window of LLMs": [[1, "extending-context-window-of-llms"]], "Extending context window of large language models via position interpolation": [[2, "extending-context-window-of-large-language-models-via-position-interpolation"]], "FFN": [[5, "ffn"]], "Failure Mode of DPO": [[47, "failure-mode-of-dpo"]], "FeedForward": [[36, "feedforward"]], "Filtering": [[26, "filtering"], [27, "filtering"]], "Filtering and Postprocessing": [[15, "filtering-and-postprocessing"]], "Fine-Grained Expert Segmentation": [[31, "fine-grained-expert-segmentation"], [32, "fine-grained-expert-segmentation"]], "Fine-tuning": [[26, "fine-tuning"]], "Finetuning the LM to Follow Instructions": [[15, "finetuning-the-lm-to-follow-instructions"]], "Flipping the Labels": [[61, "flipping-the-labels"]], "Flow stages": [[28, "flow-stages"]], "Formulation": [[3, "formulation"], [4, "formulation"]], "From MLE to RL framework": [[21, "from-mle-to-rl-framework"]], "GB2312\u3001GBK\u7b49\u5176\u4ed6\u7f16\u7801": [[7, "gb2312gbk"]], "GOLD": [[21, "gold"]], "GRPO": [[48, "grpo"]], "Gated Linear Units (GLU) and Variants": [[5, "gated-linear-units-glu-and-variants"]], "General form": [[3, "general-form"], [4, "general-form"]], "Generation": [[36, "generation"]], "Generator": [[41, "generator"]], "Gradient of DPO Loss": [[46, "gradient-of-dpo-loss"]], "Group Relative Policy Optimization (GRPO)": [[48, "group-relative-policy-optimization-grpo"]], "How Various Factors Influence Non-Determinism?": [[22, "how-various-factors-influence-non-determinism"]], "How to Better Model Human Preference?": [[61, "how-to-better-model-human-preference"]], "Human Preference Data Collection": [[35, "human-preference-data-collection"]], "Impacts of Different Data on RM Performance": [[61, "impacts-of-different-data-on-rm-performance"]], "Implementation Details": [[12, "implementation-details"]], "Incorporating Judgments for Alignment": [[57, "incorporating-judgments-for-alignment"]], "Infilling": [[29, "infilling"]], "Initialization": [[62, "initialization"], [63, "initialization"]], "Instance Generation": [[15, "instance-generation"]], "Instruct GPT": [[49, "instruct-gpt"]], "Instruction Following Ability Results": [[62, "instruction-following-ability-results"]], "Instruction Following Training": [[62, "instruction-following-training"]], "Instruction Generation": [[15, "instruction-generation"]], "Instruction Selection": [[63, "instruction-selection"]], "Instruction fine-tuning": [[29, "instruction-fine-tuning"]], "Introduction": [[2, "introduction"], [12, "introduction"], [18, "introduction"], [24, "introduction"], [29, "introduction"], [30, "introduction"], [34, "introduction"], [57, "introduction"], [60, "introduction"]], "Iterative Fine-Tuning": [[35, "iterative-fine-tuning"]], "Iterative RL with GRPO": [[48, "iterative-rl-with-grpo"]], "Iterative Training": [[63, "iterative-training"]], "Judgment Annotation": [[63, "judgment-annotation"]], "LORA": [[43, "lora"]], "Label Smoothing": [[61, "label-smoothing"]], "Large scale sampling": [[26, "large-scale-sampling"]], "Large-scale Supervision": [[41, "large-scale-supervision"]], "LayerNorm": [[36, "layernorm"]], "Learn more": [[19, "learn-more"]], "Learning Pipeline": [[56, "learning-pipeline"]], "Learning from Contrasting": [[57, "learning-from-contrasting"]], "Let\u2019s Verify Step by Step": [[41, "lets-verify-step-by-step"]], "LiveCodeBench": [[11, "livecodebench"]], "Llama": [[34, "llama"]], "Llama 2": [[35, "llama-2"]], "Llama Factory": [[42, "llama-factory"]], "Llama implementation": [[2, "llama-implementation"]], "Llama3": [[36, "llama3"]], "Load Balance Consideration": [[31, "load-balance-consideration"], [32, "load-balance-consideration"]], "Long context fine-tuning": [[29, "long-context-fine-tuning"]], "Loss": [[46, "loss"]], "Low-Rank Compression for Queries": [[37, "low-rank-compression-for-queries"]], "Low-Rank Key-Value Joint Compression": [[37, "low-rank-key-value-joint-compression"]], "MBPP": [[13, "mbpp"]], "Magicoder": [[12, "magicoder"]], "Main Result": [[58, "main-result"]], "Main Results": [[58, "main-results"]], "Markdown Files": [[19, "markdown-files"]], "Measuring the Strength of Preferences": [[61, "measuring-the-strength-of-preferences"]], "Method": [[58, "method"], [58, "id1"], [63, "method"]], "Methodology": [[24, "methodology"], [59, "methodology"]], "Methods": [[41, "methods"]], "Model": [[36, "model"]], "Model Fine-tuning (Iterative Training)": [[63, "model-fine-tuning-iterative-training"]], "Model-oriented Data Selection for Instruction Tuning": [[66, "model-oriented-data-selection-for-instruction-tuning"]], "Models": [[25, "models"]], "Multi-Head Latent Attention": [[37, "multi-head-latent-attention"]], "Multi-head Latent Attention": [[32, "multi-head-latent-attention"]], "NLP\u5b9e\u4f8b": [[0, "nlp"]], "Normalization": [[36, "normalization"]], "Notebooks with MyST Markdown": [[20, "notebooks-with-myst-markdown"]], "OOD Generalization": [[41, "ood-generalization"]], "OSS-INSTRUCT: Instruction Tuning from Open Source": [[12, "oss-instruct-instruction-tuning-from-open-source"]], "Off-policy policy gradient": [[21, "off-policy-policy-gradient"]], "OpenRLHF": [[44, "openrlhf"], [50, "openrlhf"]], "Optimizer": [[34, "optimizer"]], "Outcome Supervision RL with GRPO": [[48, "outcome-supervision-rl-with-grpo"]], "Outcome-supervised Reward Models (ORMs)": [[41, "outcome-supervised-reward-models-orms"]], "Overall Self-Alignment Algorithm": [[62, "overall-self-alignment-algorithm"]], "Overall System": [[27, "overall-system"]], "Overview": [[28, "overview"]], "PPO Review": [[48, "ppo-review"]], "PPO implementation detail": [[50, "ppo-implementation-detail"]], "Parameter and Compute Scaling of Transformers": [[23, "parameter-and-compute-scaling-of-transformers"]], "Passive Exploration": [[56, "passive-exploration"]], "Path to o1": [[38, "path-to-o1"]], "Performance with Dataset Size and Compute": [[23, "performance-with-dataset-size-and-compute"]], "Performance with Non-Embedding Parameter Count N": [[23, "performance-with-non-embedding-parameter-count-n"]], "Point Estimate": [[56, "point-estimate"]], "Policy and Fine-Tuning": [[27, "policy-and-fine-tuning"]], "Position extrapolation": [[1, "position-extrapolation"]], "Position interpolation": [[1, "position-interpolation"]], "Positional Interpolation": [[2, "positional-interpolation"]], "Pre-Training": [[32, "pre-training"]], "Pre-training data": [[34, "pre-training-data"]], "Preference Labeling with LLMs": [[59, "preference-labeling-with-llms"]], "Preference Optimization": [[45, "preference-optimization"]], "Preliminaries": [[46, "preliminaries"], [53, "preliminaries"], [61, "preliminaries"]], "Preliminaries and Problem Setup": [[40, "preliminaries-and-problem-setup"]], "Preliminaries: Mixture-of-Experts for Transformers": [[31, "preliminaries-mixture-of-experts-for-transformers"]], "Preliminaries: Standard Multi-Head Attention": [[37, "preliminaries-standard-multi-head-attention"]], "Preliminary": [[4, "preliminary"]], "Pretrain": [[35, "pretrain"]], "Problem Setting": [[57, "problem-setting"]], "Process Supervision RL with GRPO": [[48, "process-supervision-rl-with-grpo"]], "Process vs Outcome Supervision": [[41, "process-vs-outcome-supervision"]], "Process-supervised Reward Models (PRMs)": [[41, "process-supervised-reward-models-prms"]], "Prompting Techniques": [[59, "prompting-techniques"]], "Prompts": [[10, "prompts"]], "Properties of RoPE": [[4, "properties-of-rope"]], "Proposed approach": [[4, "proposed-approach"]], "Quickly add YAML metadata for MyST Notebooks": [[20, "quickly-add-yaml-metadata-for-myst-notebooks"]], "RFT": [[51, "rft"]], "RLAIF vs. RLHF": [[59, "rlaif-vs-rlhf"], [59, "id1"]], "RLCD": [[60, "rlcd"], [60, "id1"]], "RLHF": [[35, "rlhf"]], "RMSNorm": [[36, "rmsnorm"]], "RS-DPO": [[52, "rs-dpo"]], "RSO": [[53, "rso"]], "RSO APPROACH": [[53, "rso-approach"]], "References": [[37, "references"]], "Reinforcement Learning from AI Feedback": [[58, "reinforcement-learning-from-ai-feedback"], [59, "reinforcement-learning-from-ai-feedback"]], "Reinforcement learning (RL)": [[49, "reinforcement-learning-rl"]], "Related Work": [[64, "related-work"]], "Response Pair Construction": [[63, "response-pair-construction"]], "Results": [[59, "results"]], "Reward": [[21, "reward"]], "Reward Model": [[54, "reward-model"]], "Reward Model Architectures and Training": [[56, "reward-model-architectures-and-training"]], "Reward Modeling": [[35, "reward-modeling"]], "Reward Modeling Ability Results": [[62, "reward-modeling-ability-results"]], "Reward modeling (RM)": [[49, "reward-modeling-rm"]], "RewardBench": [[14, "rewardbench"]], "RoPE": [[3, "rope"], [36, "rope"]], "RoPE \u7684\u8fdc\u7a0b\u8870\u51cf": [[1, "rope"]], "Rotary Positional Embeddings (RoPE)": [[4, "rotary-positional-embeddings-rope"]], "SCoRe: Self-Correction via Multi-Turn Reinforcement Learning": [[40, "score-self-correction-via-multi-turn-reinforcement-learning"]], "SELF-INSTRUCT": [[15, "self-instruct"]], "SFT": [[35, "sft"], [42, "sft"], [44, "sft"]], "STATISTICAL REJECTION SAMPLING ALGORITHM": [[53, "statistical-rejection-sampling-algorithm"]], "Sample Roles and Directives": [[19, "sample-roles-and-directives"]], "Sampling": [[27, "sampling"]], "Scaling Effect on Non-Determinism": [[22, "scaling-effect-on-non-determinism"]], "Scaling Laws for Neural Language Models": [[23, "scaling-laws-for-neural-language-models"]], "Scaling Laws with Model Size and Training Time": [[23, "scaling-laws-with-model-size-and-training-time"]], "Scoring Model": [[27, "scoring-model"]], "Secrets of RLHF in Large Language Models: Reward Modeling": [[61, "secrets-of-rlhf-in-large-language-models-reward-modeling"]], "Self-Instruction Creation": [[62, "self-instruction-creation"]], "Self-Rewarding Language Models": [[62, "self-rewarding-language-models"]], "Self-Taught Evaluators": [[63, "self-taught-evaluators"]], "Self-Training for Preference Modeling": [[64, "self-training-for-preference-modeling"]], "SentencePiece": [[6, "sentencepiece"]], "Shared Expert Isolation": [[31, "shared-expert-isolation"], [32, "shared-expert-isolation"]], "Small-scale Synthetic Supervision": [[41, "small-scale-synthetic-supervision"]], "Stage I: Training a Model Initialization to Prevent Collapse": [[40, "stage-i-training-a-model-initialization-to-prevent-collapse"]], "Stage II: Multi-Turn RL with Reward Shaping": [[40, "stage-ii-multi-turn-rl-with-reward-shaping"]], "Stage-1: Multi-Objective Reward Modeling": [[55, "stage-1-multi-objective-reward-modeling"]], "Stage-2: Mixture-of-Experts Aggregation of Reward Objectives": [[55, "stage-2-mixture-of-experts-aggregation-of-reward-objectives"]], "Stanford Alpaca": [[9, "stanford-alpaca"]], "Supervised fine-tuning (SFT)": [[49, "supervised-fine-tuning-sft"]], "Surface Patterns in Non-Determinism Generation?": [[22, "surface-patterns-in-non-determinism-generation"]], "SwiGLU": [[5, "swiglu"]], "SwiGLU activation function": [[36, "swiglu-activation-function"]], "Swish": [[5, "swish"]], "TACO": [[16, "taco"]], "Takeaways": [[41, "takeaways"], [61, "takeaways"]], "Temperature Effect on Non-Determinism": [[22, "temperature-effect-on-non-determinism"]], "The GOLD algorithm": [[21, "the-gold-algorithm"]], "The Need for Interpretable Reward Models": [[55, "the-need-for-interpretable-reward-models"]], "The Proposed Flow": [[28, "the-proposed-flow"]], "Tiktoken": [[36, "tiktoken"]], "Tokenizer": [[36, "tokenizer"], [36, "id2"]], "Training Language Models to Self-Correct via Reinforcement Learning": [[40, "training-language-models-to-self-correct-via-reinforcement-learning"]], "Training WizardCoder": [[17, "training-wizardcoder"]], "Transformer": [[36, "transformer"]], "UTF-16\u3001UTF-32\u7b49": [[7, "utf-16utf-32"]], "UTF-8": [[7, "utf-8"]], "Unigram Language Model (ULM)": [[6, "unigram-language-model-ulm"]], "Weak to Strong Generalization": [[24, "weak-to-strong-generalization"]], "West-of-N": [[64, "west-of-n"]], "West-of-N Self-Training": [[64, "west-of-n-self-training"]], "What is MyST?": [[19, "what-is-myst"]], "What is the Full Potential of Non-Determinism?": [[22, "what-is-the-full-potential-of-non-determinism"]], "Why KV cache": [[37, "why-kv-cache"]], "WizardCoder": [[17, "wizardcoder"]], "WizardLM": [[17, "wizardlm"]], "WordPiece": [[6, "wordpiece"]], "WordPiece, ULM and SentencePiece": [[6, "wordpiece-ulm-and-sentencepiece"]], "methodology": [[49, "methodology"]], "unicode": [[7, "unicode"]], "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": [[7, "id1"]], "\u521d\u8bc6BPE": [[0, "bpe"]], "\u603b\u7ed3": [[7, "id2"]], "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff1f": [[0, "id2"]], "\u7f16\u7801\u548c\u89e3\u7801": [[0, "id1"]]}, "docnames": ["basic/bpe", "basic/extending", "basic/extending-old", "basic/rope", "basic/rope-old", "basic/swiglu", "basic/tokenize", "basic/unicode-utf8", "content", "eval-dataset/code-alpaca", "eval-dataset/cruxeval", "eval-dataset/livecodebench", "eval-dataset/magic", "eval-dataset/mbpp", "eval-dataset/reward-bench", "eval-dataset/self-instruct", "eval-dataset/taco", "eval-dataset/wizard", "intro", "markdown", "markdown-notebooks", "methodology/gold", "methodology/non-determin", "methodology/scaling-law", "methodology/weak-to-strong", "models/0", "models/alphacode", "models/alphacode2", "models/alphacodium", "models/codellama", "models/deepseek-coder-v2", "models/deepseek-moe", "models/deepseek-v2", "models/deepseek-v3", "models/llama", "models/llama2", "models/llama3", "models/mla", "o1/0", "o1/cot", "o1/self-correct-rl", "o1/verify", "others/llama-factory", "others/lora", "others/openrlhf", "preference-optimization/0", "preference-optimization/dpo", "preference-optimization/dpop", "preference-optimization/grpo", "preference-optimization/instruct-gpt", "preference-optimization/openrlhf", "preference-optimization/rft", "preference-optimization/rs-dpo", "preference-optimization/rso", "rm/0", "rm/armo", "rm/ee", "rm/judge", "rm/rlaif-1", "rm/rlaif-2", "rm/rlcd", "rm/secret-rm", "rm/self-reward", "rm/self-taught", "rm/west-of-n", "sft/lab-for-align", "sft/mods"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["basic/bpe.ipynb", "basic/extending.ipynb", "basic/extending-old.ipynb", "basic/rope.ipynb", "basic/rope-old.ipynb", "basic/swiglu.ipynb", "basic/tokenize.ipynb", "basic/unicode-utf8.ipynb", "content.ipynb", "eval-dataset/code-alpaca.ipynb", "eval-dataset/cruxeval.ipynb", "eval-dataset/livecodebench.ipynb", "eval-dataset/magic.ipynb", "eval-dataset/mbpp.ipynb", "eval-dataset/reward-bench.ipynb", "eval-dataset/self-instruct.ipynb", "eval-dataset/taco.ipynb", "eval-dataset/wizard.ipynb", "intro.md", "markdown.md", "markdown-notebooks.md", "methodology/gold.ipynb", "methodology/non-determin.ipynb", "methodology/scaling-law.ipynb", "methodology/weak-to-strong.ipynb", "models/0.ipynb", "models/alphacode.ipynb", "models/alphacode2.ipynb", "models/alphacodium.ipynb", "models/codellama.ipynb", "models/deepseek-coder-v2.ipynb", "models/deepseek-moe.ipynb", "models/deepseek-v2.ipynb", "models/deepseek-v3.ipynb", "models/llama.ipynb", "models/llama2.ipynb", "models/llama3.ipynb", "models/mla.ipynb", "o1/0.ipynb", "o1/cot.ipynb", "o1/self-correct-rl.ipynb", "o1/verify.ipynb", "others/llama-factory.ipynb", "others/lora.ipynb", "others/openrlhf.ipynb", "preference-optimization/0.ipynb", "preference-optimization/dpo.ipynb", "preference-optimization/dpop.ipynb", "preference-optimization/grpo.ipynb", "preference-optimization/instruct-gpt.ipynb", "preference-optimization/openrlhf.ipynb", "preference-optimization/rft.ipynb", "preference-optimization/rs-dpo.ipynb", "preference-optimization/rso.ipynb", "rm/0.ipynb", "rm/armo.ipynb", "rm/ee.ipynb", "rm/judge.ipynb", "rm/rlaif-1.ipynb", "rm/rlaif-2.ipynb", "rm/rlcd.ipynb", "rm/secret-rm.ipynb", "rm/self-reward.ipynb", "rm/self-taught.ipynb", "rm/west-of-n.ipynb", "sft/lab-for-align.ipynb", "sft/mods.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 2, 6, 10, 19, 20, 21, 23, 24, 28, 29, 31, 32, 35, 36, 37, 40, 46, 47, 48, 49, 53, 55, 56, 58, 59, 60, 61, 63], "0": [1, 2, 3, 4, 5, 7, 10, 15, 17, 21, 22, 23, 26, 27, 31, 32, 34, 35, 36, 42, 43, 46, 47, 48, 50, 53, 55, 57, 58, 59, 61, 62, 64], "000": [16, 26, 29], "0000": [2, 7], "0000j": 2, "0001": 7, "0010": 7, "003": 9, "0041": 7, "007f": 7, "0080": 7, "01": 50, "0100j": 2, "02120": 12, "02150": [19, 37], "03": 34, "03300": 48, "03762": [19, 37], "04434": [19, 37], "0461": 2, "0596": 2, "0596j": 2, "06": 34, "0674": 2, "0674j": 2, "076": 23, "07ff": 7, "0800": 7, "08568": 17, "096": 29, "09864": [19, 37], "0xxxxxxx": 7, "1": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 15, 16, 17, 21, 22, 23, 26, 27, 29, 31, 32, 34, 36, 37, 40, 41, 42, 46, 47, 48, 49, 50, 53, 56, 57, 58, 59, 61, 62, 63, 64], "10": [0, 7, 10, 22, 23, 27, 29, 30, 34, 42, 48, 59, 61], "100": [9, 10, 27, 29, 41, 55, 56], "1000": [2, 17, 41], "10000": [1, 2, 3, 4, 27, 36], "100000": 50, "10000000": 7, "10111000": 7, "1024": 50, "10560": 15, "10xxxxxx": 7, "11": 4, "1106": 12, "110k": 12, "110xxxxx": 7, "110\u8868\u793a\u9700\u8981\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u5f53\u524d\u5b57\u7b26": 7, "1110": 7, "1110xxxx": 7, "1110\u8868\u793a\u9700\u8981\u4e09\u4e2a\u5b57\u8282": 7, "11110xxx": 7, "11110\u8868\u793a\u9700\u8981\u56db\u4e2a\u5b57\u8282": 7, "1139": 36, "1160": 36, "12": [0, 4, 23, 27], "12000": 42, "123abc\u4e00\u4e8c\u4e09": 7, "128": 50, "128k": [30, 32], "128\u4f4dascii\u7801\u662f\u6570\u5b57": 7, "12k": 41, "12n_": 23, "13": [0, 23, 36], "13245": [19, 37], "13b": 29, "14": [29, 37], "15": [12, 34, 35], "15b": 17, "16": [10, 34, 49, 50, 58], "1609": 36, "16k": 30, "17": 10, "1706": [19, 37], "175": 15, "1911": [19, 37], "1990\u5e74\u5f00\u59cb\u7814\u53d1": 7, "1994": 0, "1e": [36, 42], "1l": 52, "1w": 52, "1\u4f4d\u4e3a": 7, "2": [0, 1, 2, 3, 4, 5, 7, 9, 10, 15, 20, 23, 24, 26, 28, 31, 32, 34, 36, 37, 40, 41, 46, 47, 48, 49, 50, 53, 56, 57, 58, 59, 61, 62, 64], "20": [9, 41, 61], "200": [9, 41], "2000": 34, "2019": [19, 37], "2023": [19, 37], "2024": [19, 37], "2048": [1, 2, 36], "20k": [9, 12, 17], "21": [4, 12], "2104": [19, 37], "21b": 32, "22": 4, "2212": 15, "2294": 36, "23": [0, 19, 34, 37], "2305": [19, 37], "2306": 17, "2312": 12, "236b": 32, "24": [19, 37], "2402": 48, "2405": [19, 37], "25": [16, 37, 61], "256": [36, 62], "256\u4f4dascii\u6269\u5c55\u7801\u662fascii": 7, "2601": 36, "264": 36, "27": 35, "2900": 2, "29460": 36, "2d_": 23, "2i": [4, 29], "2j": [1, 2, 36], "2n": 23, "2n_": [23, 37], "2t": 4, "2\u62164\u5b57\u8282\u53d8\u957f": 7, "3": [0, 1, 2, 5, 10, 12, 22, 23, 26, 28, 29, 36, 49, 50, 58, 62], "30": 30, "3000": 2, "315": 36, "32": [7, 36, 56], "3200": 56, "32768": 2, "33t": 37, "34b": [10, 29, 50], "374": 36, "4": [0, 2, 7, 10, 12, 23, 24, 29, 34, 36, 37, 41, 42, 47, 49, 50, 56, 59, 62], "40": [55, 58, 61], "4037": 36, "4096": [36, 42], "426": 13, "443": 16, "45": 34, "4d": 36, "4e00": 7, "4e00\u57280800": 7, "4e00\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a100": 7, "4t": 34, "4\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 7, "4\u5b57\u8282\u53d8\u957f": 7, "4\u5b57\u8282\u8868\u793a": 7, "5": [0, 2, 8, 10, 12, 26, 29, 34, 36, 42, 46, 47, 55, 56, 61, 62, 64], "50": [27, 29], "500000": 36, "5005": 36, "500b": 29, "52": 29, "52k": [9, 15], "54": 26, "540": 35, "5403": 2, "55m": 16, "5963": 36, "5b": 41, "5e": 50, "5pm": 9, "6": [2, 12, 15, 23, 28, 29, 36, 41, 42, 50, 59], "60": [30, 55, 58], "62": 29, "64": 34, "65b": 34, "67": 34, "6n": 23, "6nb": 23, "6t": 30, "6w": 7, "7": [0, 2, 15, 24, 27, 35, 50], "70b": [29, 35, 50, 62], "75k": [12, 41], "77": 27, "7b": [9, 12, 29, 34, 35, 37, 42, 50], "8": [2, 10, 15, 23, 28, 29, 37, 50, 58], "80": [24, 41], "800": 10, "8000": 27, "800k": 41, "80gb": 50, "80k": 12, "82k": 15, "83": 36, "8415j": 2, "85": 27, "8b": [22, 50], "8binstruct": 22, "8\u4e2abit\u4f4d\u4e2d\u9ad8\u4f4d\u5fc5\u987b\u7b49\u4e8e0": 7, "8\u4e2abit\u4f4d\u662f\u4e00\u4e2a\u5b57\u8282": 7, "8\u4e3a11100100": 7, "8\u4e3a\u4e09\u5b57\u8282": 7, "8\u4f4d\u53ef\u8868\u793a256\u4e2a\u5b57\u7b26": 7, "8\u548cgbk\u7f16\u7801": 7, "8\u6765\u5b9e\u73b0\u7f16\u7801": 7, "8\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u89e3\u7801\u4f7f\u7528": 7, "8\u7684\u6620\u5c04\u5173\u7cfb\u5982\u4e0b": 7, "8\u7684\u7f16\u7801\u65b9\u5f0f": 7, "8\u7684\u89c4\u5219\u5f88\u7b80\u5355": 7, "8\u7b49": 7, "8\u7f16\u7801": 7, "9": [0, 34, 36, 37, 49, 60], "925": 36, "9297": 2, "95": 34, "974": 13, "9901": 42, "9999": 2, "9e": 50, "A": [0, 4, 5, 9, 15, 21, 22, 27, 31, 32, 35, 36, 43, 48, 53, 55, 56, 58, 59, 63, 64], "And": 48, "As": [21, 24, 27, 28, 31, 32, 35, 37, 41, 47, 48, 56, 64], "At": [1, 2, 15, 21, 26, 35, 41, 63], "By": [36, 56, 61], "FOR": 58, "For": [1, 2, 9, 12, 13, 15, 19, 22, 23, 24, 27, 28, 29, 32, 35, 37, 41, 43, 47, 48, 52, 53, 55, 56, 57, 58, 60, 61], "If": [2, 5, 20, 21, 24, 28, 31, 32, 36, 48, 53, 56, 58, 63], "In": [2, 3, 4, 9, 10, 12, 15, 17, 21, 22, 26, 28, 29, 30, 31, 32, 35, 37, 39, 46, 47, 48, 49, 53, 56, 57, 58, 59, 61, 62, 63, 64], "It": [2, 9, 17, 19, 23, 24, 28, 29, 32, 35, 36, 40, 46, 48, 58], "Its": 27, "NOT": 10, "No": 22, "Not": 9, "OF": 58, "Of": 15, "On": [24, 56], "One": [1, 2, 4, 21, 26, 53, 56, 57, 58, 59], "Such": 63, "That": 20, "The": [1, 2, 4, 5, 9, 10, 12, 13, 15, 17, 19, 20, 22, 23, 26, 27, 29, 31, 32, 34, 35, 36, 37, 41, 46, 47, 48, 49, 50, 53, 56, 57, 58, 59, 60, 61, 62, 63], "Their": 41, "Then": [3, 12, 30, 31, 32, 37, 47, 48, 53, 56, 58, 59], "There": 10, "These": [9, 16, 17, 53, 58, 62, 63], "To": [5, 10, 12, 15, 17, 21, 22, 23, 26, 27, 29, 30, 31, 32, 34, 35, 36, 41, 48, 49, 53, 55, 57, 59, 62, 64], "With": [20, 28], "_": [1, 3, 4, 5, 15, 17, 21, 29, 31, 32, 35, 36, 37, 40, 41, 46, 47, 48, 49, 52, 53, 55, 56, 57, 61, 64], "_1": 40, "__init__": 36, "_bsz": 36, "_mergeable_rank": 36, "_norm": 36, "_t": 37, "a100": 50, "a_": [2, 4, 21, 48], "aa": 0, "aaabdaaabac": 0, "ab": [0, 2, 19, 37], "abbrevi": 7, "abil": [12, 24, 39, 41, 47, 48, 53, 65], "abl": [9, 10, 24, 35], "ablat": 41, "about": [2, 9, 12, 19, 20, 24, 27, 28, 29, 56, 61], "abov": [24, 27, 29, 31, 32, 40, 53, 61, 63, 64], "absolut": [3, 34, 55], "absorb": 37, "abstractset": 36, "ac": 0, "acceler": 37, "accept": [19, 53], "access": [24, 35, 40, 53, 56, 62, 63, 64], "accommod": [30, 41], "accompani": 57, "accomplish": 22, "accord": [2, 27, 41, 56, 61, 64], "account": [23, 29], "accumul": 28, "accur": [13, 16, 35, 48, 61], "accuraci": [59, 61], "achiev": [26, 30, 34, 35, 37, 46, 47, 53, 57, 59, 61, 64], "acquir": [31, 32, 35], "across": [24, 27, 31, 32, 37, 41, 56], "action": [9, 21], "activ": [5, 31, 32, 34, 37], "actor": [48, 50], "actor_learning_r": 50, "actual": [40, 48], "ad": [4, 15, 17, 26, 40, 48, 61], "adam_offload": 50, "adamw": 34, "adapt": [1, 2, 17, 31, 32, 43, 57], "add": [17, 28, 29, 34, 35, 36, 49, 55, 61, 62], "addit": [5, 7, 21, 24, 26, 27, 29, 30, 31, 32, 36, 37, 40, 41, 49, 56, 57, 60, 62], "addition": [15, 31, 32, 56], "additionali": 48, "address": [17, 28, 48, 53, 59], "adher": 24, "adjust": [37, 53, 55], "adopt": [9, 12, 22, 26, 32, 37], "advanc": 27, "advantag": [24, 37, 48, 50, 57, 65], "advis": 58, "affect": [8, 22], "affin": [31, 32, 36], "aforement": 59, "after": [2, 15, 17, 22, 26, 27, 31, 32, 34, 35, 36, 41, 47, 48, 49, 53, 56, 59, 61, 62], "again": [5, 59], "against": [28, 58, 60], "agent": [53, 56], "aggreg": 27, "aggress": 9, "agnost": 57, "ahm": [19, 37], "ai": [19, 28, 37, 62, 64], "aidan": [19, 37], "aif": 62, "aift": 62, "aim": [21, 22, 40, 48, 53, 62, 63], "ainsli": [19, 37], "aixin": [19, 37], "algorithm": [0, 15, 16, 26, 27, 28, 30, 34, 35, 46, 48], "alibi": 2, "align": [1, 2, 3, 4, 5, 8, 23, 24, 30, 31, 32, 35, 36, 37, 46, 47, 48, 49, 53, 55, 56, 59], "align_n": 57, "alignmentrelev": 24, "alik": 29, "all": [2, 5, 9, 10, 13, 17, 19, 20, 21, 23, 26, 27, 31, 32, 35, 36, 37, 40, 41, 46, 47, 48, 49, 52, 53, 56, 58, 59, 61], "allclos": 36, "allevi": [31, 32], "allow": [2, 4, 19, 21, 26, 27, 36, 58, 63], "allowed_speci": 36, "allowed_token": 36, "almost": 61, "alon": [59, 61, 62], "along": [26, 28, 29], "alongsid": 48, "alpaca": [8, 12, 17], "alpacaev": [22, 62], "alpha": [40, 57, 61], "alpha_": [23, 31, 32], "alphacod": 29, "alreadi": [24, 26, 36, 56, 62], "also": [5, 9, 13, 15, 19, 20, 22, 23, 24, 26, 27, 28, 29, 31, 32, 35, 36, 37, 46, 47, 48, 49, 55, 58, 62, 63, 64], "altdj": [19, 37], "alter": 28, "altern": [35, 46, 56, 57, 59], "although": [7, 21], "alwai": [2, 26, 57, 61], "ambigu": 61, "american": 7, "among": [10, 29, 31, 32, 37, 53, 56], "amount": [5, 23, 27, 37, 41, 62], "an": [1, 2, 9, 10, 12, 15, 17, 19, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 40, 41, 46, 47, 48, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64], "analogi": 24, "analysi": [28, 57, 59], "anchor": 28, "angl": [2, 3], "ani": [2, 3, 4, 9, 10, 12, 15, 20, 21, 24, 28, 36, 37, 41, 49, 58, 64], "annot": [29, 35, 59, 62], "anoth": [2, 9, 21, 26, 28, 35, 48, 57, 59, 61], "answer": [2, 10, 16, 22, 29, 35, 40, 41, 58, 63], "anthrop": 56, "anywher": 49, "api": 49, "app": 58, "appear": [2, 23, 28], "append": [15, 36, 50, 53, 58], "appli": [1, 2, 5, 12, 17, 22, 27, 28, 29, 36, 40, 46, 48, 49, 55, 56, 57, 61, 63, 64], "applic": [1, 2, 29, 35], "apply_chat_templ": 50, "apply_rotary_emb": [2, 36], "approach": [1, 2, 12, 15, 21, 23, 27, 29, 35, 40, 46, 55, 57, 59, 60, 62, 63, 64], "appropri": [9, 29], "approx": [3, 23], "approxim": [2, 21, 41, 56, 61, 64], "ar": [1, 2, 4, 7, 9, 10, 12, 15, 17, 19, 20, 21, 22, 23, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 39, 41, 46, 47, 48, 49, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63], "arang": [2, 36, 46], "arbitrari": 2, "architectur": [2, 4, 23, 26, 29, 37, 43], "arg": [2, 35, 36, 50, 53], "argmax": 36, "argu": 53, "argument": 10, "aris": [58, 59], "armorm": 22, "around": 37, "arriv": 10, "art": [24, 34], "arxiv": [12, 15, 17, 19, 34, 37, 48], "ascertain": 56, "ascii\u5c31\u662f\u6700\u521d\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 7, "ascii\u8d77\u521d\u53ea\u89c4\u5b9a\u4e86127\u4e2a\u5b57\u7b26": 7, "ashish": [19, 37], "ask": [9, 13, 15, 28, 35, 49, 59, 63], "aspect": [28, 57, 62], "assert": [2, 10, 29, 36], "assertionerror": [2, 36], "assess": [17, 52], "assign": [21, 26, 31, 32, 35, 40, 41, 48, 53, 55, 56, 57, 61, 64], "assist": [9, 24, 29, 36, 58, 60, 62, 63], "associ": [29, 53], "assum": [6, 21, 40, 47, 53, 57, 62, 63, 64], "ast": [4, 40, 46, 53], "atol": 36, "att": [31, 32], "attach": 55, "attain": 56, "attempt": [24, 40, 41], "attent": [1, 2, 3, 4, 8, 19, 23, 31, 47], "attention_norm": 36, "attn": 23, "attract": 2, "attribut": [27, 60], "audio": 9, "augment": 62, "authent": 57, "author": [46, 62], "autom": 15, "automat": [12, 15, 17, 31, 32, 55, 60], "autoregress": [21, 29, 35], "auxiliari": [24, 26, 40], "avail": [16, 29, 34], "averag": [26, 27, 36, 48, 59], "avoid": [21, 24, 26, 27, 28, 47, 48, 53, 61], "await": 17, "axi": 36, "b": [5, 10, 21, 23, 36, 40, 43, 56, 58, 63], "b_": [5, 36], "ba": 10, "backbon": 55, "backpropag": 35, "backward": [10, 23], "bad": [21, 24], "bag": 35, "balanc": 63, "banana": 10, "base": [2, 3, 4, 7, 9, 12, 15, 17, 20, 21, 24, 26, 27, 28, 29, 30, 34, 35, 36, 40, 42, 46, 48, 49, 53, 55, 56, 57, 58, 61, 62, 63, 64], "baselin": [22, 41, 62, 63, 65], "basi": [2, 36], "basic": [8, 13, 28], "batch": [9, 23, 29, 34, 35, 36, 37, 49, 56], "batchnorm1d": 36, "batchnorm2d": 36, "bax": 43, "becaus": [9, 15, 28, 55, 58], "becom": [2, 10, 31, 32, 37, 40, 47, 59], "been": [21, 27, 28, 36, 48, 56, 61, 64], "befor": [2, 10, 15, 24, 26, 35, 60], "begin": [1, 2, 3, 4, 5, 23, 29, 31, 32, 35, 36, 37, 46, 47, 48, 49, 53, 56, 58, 64], "begin_of_text": 36, "behav": [2, 24, 27], "behavior": [2, 21, 24, 27, 28, 30, 58], "behaviour": 26, "behind": 2, "bei": [19, 37], "being": [12, 19, 26, 64], "believ": 55, "below": [9, 12, 24, 29, 47, 61], "bench": 8, "benchmark": [10, 16, 17, 24, 30, 37], "benefici": [28, 61], "benefit": [35, 61], "best": [22, 23, 26, 27, 28, 34, 35, 40, 41, 49, 56, 61, 62, 64], "bestof": 22, "beta": [5, 35, 36, 46, 47, 48, 49, 53], "beta_": [34, 40], "better": [24, 27, 28, 34, 35, 37, 41, 47, 53, 58, 59, 63], "between": [3, 4, 5, 9, 12, 21, 22, 24, 26, 27, 29, 35, 36, 40, 41, 46, 47, 48, 49, 53, 58, 59, 61, 62], "beyond": [2, 24, 59], "bf16": [42, 50], "bhihia": 10, "bi": [19, 37], "bia": [5, 36, 40, 55, 59, 63], "bias": [15, 21], "bib": 19, "bibliographi": 19, "bibtex": 19, "biggest": 27, "bilinear": 5, "bin": [19, 37], "binari": [35, 59, 61], "bingxuan": [19, 37], "binom": 49, "bit": 56, "black": 23, "bleu": 21, "block": [20, 29, 31, 32], "blue": 17, "bn": 36, "bo": [19, 36, 37], "bodi": 7, "boltzmann": 56, "bonu": 40, "book": [19, 20, 34], "bool": 36, "bootstrap": [12, 15, 24], "bos_id": 36, "both": [1, 2, 10, 12, 19, 22, 26, 29, 35, 37, 40, 41, 48, 49, 57, 58, 59, 60, 62, 64], "bottleneck": 37, "bottom": 61, "bound": [2, 22], "boundari": [12, 15], "box": 19, "bpe": [29, 34], "bpe\u6bcf\u4e00\u6b65\u90fd\u5c06\u6700\u5e38\u89c1\u7684\u4e00\u5bf9\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u66ff\u6362\u4e3a\u8be5\u6570\u636e\u4e2d\u6ca1\u6709\u51fa\u73b0\u8fc7\u7684\u4e00\u4e2a\u65b0\u5355\u4f4d": 0, "bpe\u9009\u62e9\u9891\u6570\u6700\u9ad8\u7684\u76f8\u90bb\u5b50\u8bcd\u5408\u5e76": 6, "bradlei": [46, 53, 55, 61], "brainstorm": 63, "breadth": 17, "break": [15, 36, 53], "breviti": [31, 32, 37], "bridg": 21, "bring": 48, "broad": 15, "broadcast": 2, "brute": 28, "bsz": 36, "bt": 53, "budget": [26, 27, 29, 34], "buffer": [50, 56], "bug": [28, 50], "build": [19, 22, 36, 55, 60, 62, 63], "built": [20, 35], "bullet": 28, "burden": 48, "byte": [29, 34], "c": [1, 2, 5, 10, 23, 26, 27, 35, 36, 37, 56, 61], "c4": 34, "c_": 23, "cach": 36, "cache_k": 36, "cache_len": 36, "cache_v": 36, "cai": [19, 37, 58], "caichat": 50, "calcul": [2, 31, 32, 36, 48, 56, 58, 59, 61], "calibr": [22, 58], "call": [2, 5, 10, 17, 19, 21, 24, 28, 35, 37, 39, 41, 49, 53, 57, 58], "can": [1, 2, 4, 5, 6, 10, 12, 15, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 35, 37, 41, 46, 47, 48, 49, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65], "cancel": 46, "candid": [26, 27, 53, 56, 59, 62, 64], "cannot": [2, 9, 21, 24, 37], "canon": 59, "capabl": [2, 12, 17, 22, 24, 29, 35, 57, 62], "capac": 56, "captur": [31, 32, 61], "cardin": [27, 56], "care": 24, "carlo": [21, 48], "carri": 37, "cascad": 29, "case": [9, 12, 13, 15, 21, 26, 27, 28, 29, 30, 31, 32, 35, 47, 57, 58, 64], "cast": 36, "catastroph": 2, "categor": [27, 61, 63], "categori": 63, "caus": [36, 46, 47, 60], "causal": 29, "cdot": [4, 5, 31, 32, 40, 46, 47, 53, 57], "ce": 56, "ceas": 23, "ceil": 24, "central": 61, "centroid": [31, 32], "certain": [1, 2, 21, 63, 64], "chain": [58, 59, 63], "challeng": [9, 16, 24, 28, 41, 46, 61, 63], "chanc": 28, "chang": [9, 40, 60], "channel": 36, "charact": [7, 28, 29], "character": [23, 32], "characterist": 17, "charset": 7, "chat": [35, 36], "chat_complet": 36, "chatgpt": [12, 24], "check": [13, 29, 40, 41], "checkpoint": [19, 30, 35, 36, 37, 50], "chen": [19, 37], "chenggang": [19, 37], "chengqi": [19, 37], "chess": 24, "choic": [4, 21, 35, 41, 47, 53, 56, 58], "chong": [19, 37], "choos": [17, 26, 28, 35, 41, 58, 61, 63], "chosen": [23, 35, 55, 61], "ci": 2, "cite": 19, "ckpt_dir": 36, "ckpt_path": 36, "cl": 12, "clamp": 58, "clarifi": 23, "class": [15, 36, 47], "classif": [9, 24, 41, 61], "classifi": [26, 57, 63], "clean": 35, "clear": [2, 50, 61], "clearli": 28, "clever": 46, "cli": 50, "clip": [34, 48], "close": [12, 21, 27, 28, 30, 36, 58], "closer": 53, "closest": 28, "co": [1, 2, 3, 4, 29, 36], "code": [7, 8, 10, 12, 16, 20, 22, 24, 26, 27, 30, 34, 63], "code_alpaca_20k": 9, "codealpaca": [8, 9, 12], "codecontest": [26, 27], "codeforc": [26, 27], "codellama": 12, "coder": [8, 12, 42], "codex": [8, 29], "coeffici": [2, 46, 49, 55], "coher": 59, "collect": [12, 15, 29, 34, 36, 49, 50, 57, 58, 63, 64], "colon": 60, "combin": [9, 12, 27, 28, 29, 31, 32, 35, 49, 52, 53, 57, 59], "come": [1, 2, 9, 15], "command": 20, "comment": 29, "common": [21, 28, 31, 32, 55, 56], "commoncrawl": 34, "commonli": 12, "commonmark": 19, "commun": 7, "commut": 37, "compar": [5, 21, 22, 30, 40, 41, 47, 48, 56, 57, 62, 64], "comparison": [22, 29, 49, 53, 57, 58, 61], "compat": [2, 29], "competit": [26, 27], "compil": 30, "complet": [9, 10, 17, 22, 28, 29, 35, 36, 46, 47, 49], "complex": [1, 2, 4, 12, 17, 24, 29, 36, 39, 48], "complex64": [2, 36], "compli": 27, "complic": [17, 24, 48], "compon": [5, 27, 35, 36, 61, 62], "compos": [31, 32], "composit": 30, "comprehens": [17, 57], "compress": 0, "compris": [31, 32, 56], "comput": [1, 2, 4, 5, 7, 10, 24, 27, 29, 31, 32, 34, 35, 36, 37, 41, 48, 52, 56, 58, 59], "concaten": [10, 15, 35, 40, 59], "concept": 29, "concis": 56, "conclus": 37, "concret": [17, 40], "concurr": 28, "condit": [15, 21, 26, 57], "conduct": [2, 27, 41, 53, 57, 59], "conduct_rejection_sampl": 53, "confer": 57, "confid": [24, 58, 64], "configur": 22, "confin": 35, "conjug": 4, "consecut": [12, 27], "consequ": 57, "consid": [1, 2, 21, 24, 47, 53, 55, 56, 57, 58, 59, 61, 63], "consider": 57, "consist": [10, 12, 24, 29, 31, 32, 46, 49, 55, 64], "consolid": [31, 32], "constant": [4, 5, 21, 31, 32], "constrain": [46, 53], "constraint": [17, 28, 35], "construct": [10, 17, 29, 30, 31, 32, 53, 57, 60, 62], "consum": 64, "contain": [2, 9, 10, 12, 13, 15, 24, 26, 27, 28, 29, 34, 35, 36, 37, 41, 60], "content": [9, 19, 20, 36, 57, 58], "contest": 27, "context": [4, 9, 15, 21, 23, 30, 31, 32, 48, 55, 57, 58, 59, 60, 65], "context_messag": 50, "contigu": 36, "continu": [12, 28, 48, 49, 53, 55, 58, 61], "contrast": [2, 21, 28, 60, 64], "contribut": 61, "control": [24, 36, 46, 49, 59], "convei": 57, "convent": 37, "converg": [31, 32], "convers": [2, 23, 36, 58], "convert": [20, 53, 59], "convinc": 41, "core": [24, 37], "corpu": [2, 12, 30, 56], "corr": 55, "correct": [8, 10, 13, 21, 26, 27, 28, 29, 41, 47, 55, 57, 63], "correctli": [2, 28, 40, 64], "correl": [55, 57, 62], "correspond": [2, 3, 4, 15, 17, 21, 27, 28, 29, 36, 46, 48, 53, 55, 57], "correspondingli": 48, "cosin": [34, 42], "cost": [9, 31, 32], "cot": [8, 58, 59], "could": [2, 22, 24, 26, 27, 55, 61, 64], "count": 10, "counterclockwis": 3, "counterpart": 35, "coupl": 40, "cover": [28, 62], "coverag": [15, 59, 64], "cpu": 36, "cr": 56, "craft": 56, "creat": [9, 15, 17, 24, 29, 30, 60, 62], "creation": 28, "creativ": 24, "credit": 21, "criteria": [35, 60], "critic": [26, 40, 48, 50], "critic_learning_r": 50, "critiqu": [8, 57], "cross": [23, 26, 56, 59], "cross_entropi": 36, "crowd": 13, "crowdwork": 58, "ctx": 23, "cuda": 36, "cumbersom": 56, "cumsum": 36, "cumul": 36, "cur_po": 36, "curat": [26, 55], "curiou": 61, "current": [9, 16, 17, 21, 37, 41, 48, 49, 53, 56, 63], "curv": [23, 35], "cut": [36, 57], "cutoff_len": 42, "d": [0, 1, 2, 3, 4, 17, 20, 21, 23, 29, 31, 32, 35, 36, 37, 40, 43, 46, 47, 48, 49, 52, 53, 55, 56, 59, 60, 61, 64], "d_": [5, 23, 35, 37, 49, 53, 61], "d_c": 37, "d_h": 37, "dai": [19, 37], "dalf": [19, 37], "damai": [19, 37], "danger": 58, "data": [0, 2, 8, 12, 17, 21, 22, 24, 29, 40, 46, 48, 49, 52, 53, 55, 56, 57, 58, 60, 62, 63, 64], "dataclass": 36, "datalabel": 41, "dataset": [9, 12, 13, 16, 17, 24, 27, 30, 34, 35, 40, 41, 42, 48, 52, 53, 55, 56, 57, 61, 62, 64], "davinci": 9, "daya": [19, 37], "ddot": [3, 4], "de": [19, 29, 37], "deal": 63, "debug": 17, "debugg": 55, "decai": [2, 4, 34], "decid": [41, 62], "decis": [21, 28, 55], "declin": 17, "decod": [9, 12, 19, 22, 26, 36, 37, 55, 59], "decompos": 35, "decomposit": 43, "decreas": [22, 23, 31, 32, 46, 47, 53, 57], "dedic": [31, 32], "deduc": 40, "dedupl": 29, "deem": 63, "deepen": 17, "deepseek": [8, 12, 19, 37, 42, 48], "deepseekcod": 42, "deepspe": 42, "def": [2, 10, 36, 53], "default": [2, 20, 36], "defin": [1, 2, 3, 4, 5, 10, 15, 20, 21, 23, 24, 35, 36, 46, 62], "degener": 46, "degre": 35, "dejian": [19, 37], "deli": [19, 37], "deliber": 41, "delta": [21, 35, 43], "delta_": 48, "demonstr": [2, 21, 22, 37, 39, 49, 56, 57, 61], "dengr": [19, 37], "denomin": 21, "denot": [4, 21, 23, 26, 29, 31, 32, 37, 40, 47, 53, 55, 56, 61], "dens": 37, "densiti": 53, "depend": [1, 2, 3, 4, 19, 23, 36, 46, 56, 57, 64], "depict": 58, "deploi": [31, 32], "deploy": 37, "depth": 17, "deriv": [2, 21, 29, 53, 62], "descend": 36, "describ": [9, 28, 59, 62], "descript": [13, 26, 27, 28, 60], "design": [13, 16, 31, 32, 37, 41, 47, 58, 60], "desir": [21, 53, 57, 60, 65], "despit": [24, 49, 57], "detail": [20, 27, 28, 57], "detect": [15, 26, 57], "determin": [56, 64], "determinist": 22, "detoken": 6, "devbal": [31, 32], "develop": [24, 29, 30, 40, 53, 58, 63], "deviat": [22, 36, 46, 48, 61], "devic": [2, 7, 31, 32, 36], "devis": 12, "diagon": [29, 36], "dialog": 36, "dialogu": [29, 35], "dict": 36, "dictionari": [9, 53], "did": 59, "differ": [3, 4, 9, 10, 15, 19, 21, 22, 24, 26, 27, 28, 29, 31, 32, 34, 35, 37, 41, 46, 47, 48, 49, 50, 53, 56, 57, 58, 60], "differenti": 60, "difficult": [24, 28], "difficulti": [16, 17, 27], "dim": [2, 36], "dimens": [1, 2, 4, 5, 23, 29, 31, 32, 36, 37, 47, 55], "dimension": [3, 4, 55], "diminish": 57, "ding": [19, 37], "direct": [17, 20, 28, 52, 53, 57, 59, 60], "directli": [1, 2, 4, 6, 12, 22, 29, 40, 46, 48, 53, 59], "directori": 36, "disagre": 63, "disallowed_speci": 36, "disallowed_token": 36, "disanalogi": 24, "discard": [9, 63], "discontinu": 17, "discrep": [21, 26, 35, 61], "discret": 35, "discrimin": 26, "discuss": [4, 29, 41, 58], "displai": [20, 57], "dispref": [46, 47], "distanc": [2, 47], "distil": [12, 35, 60, 64], "distinct": [56, 57, 61], "distinguish": [53, 56], "distribut": [17, 21, 26, 29, 35, 36, 40, 41, 46, 48, 49, 53, 55, 56, 58, 59, 61, 63, 64], "div_": 36, "diverg": [35, 46, 48], "divers": [9, 15, 16, 17, 22, 26, 27, 28, 29, 62, 63], "divid": [3, 4, 26, 28, 48], "divis": 27, "dkv": 37, "do": [9, 10, 12, 15, 19, 21, 24, 27, 28, 35, 36, 37, 40, 41, 49, 63, 65], "do_train": 42, "docstr": 29, "doctyp": 7, "document": [2, 12, 19, 20, 29], "doe": [2, 15, 29, 36, 37, 46, 61], "doesn": 2, "domain": [17, 21, 30], "domin": 21, "done": 17, "dong": [19, 37], "dongji": [19, 37], "dot": [1, 2, 3, 4, 6, 21, 31, 32, 36, 37, 47, 48, 52, 57, 62, 63], "doubl": [28, 56], "down": [1, 2, 27], "downstream": 43, "dpo": [8, 22, 50, 53, 62, 63], "dpop": 8, "dq": 37, "draw": [12, 53], "drawn": 56, "drive": 26, "drop_last": 50, "dschat": 50, "dtype": 36, "du": [19, 37], "due": [2, 28, 55], "duplic": 29, "dure": [2, 9, 16, 21, 23, 26, 29, 35, 37, 41, 46, 58], "dynam": 57, "dz": 56, "e": [0, 1, 2, 9, 10, 12, 15, 21, 24, 31, 32, 35, 36, 40, 46, 47, 48, 49, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63], "e501": 36, "e_": 63, "each": [1, 2, 9, 12, 13, 15, 16, 17, 21, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 40, 41, 43, 47, 48, 49, 52, 53, 55, 56, 58, 59, 60, 61, 62, 63], "earli": 58, "earlier": [35, 58], "easi": [21, 24, 28, 29, 50, 53], "easier": [2, 24, 28, 53], "easili": [10, 12, 26], "eason": 10, "echo": 36, "econom": [19, 32, 37], "ecosystem": 19, "ecut": 10, "edit": [9, 13, 28, 40, 47], "editor": 29, "ee": 8, "effect": [2, 3, 4, 12, 16, 24, 28, 47, 48, 53, 59, 61, 62], "effici": [19, 27, 32, 37, 41, 48], "effort": 64, "eft": 62, "either": [9, 27, 35, 40, 41, 57], "electron": 7, "element": [2, 3, 4, 29, 37, 49], "elicit": [24, 56, 58, 59], "elimin": 17, "elment": 36, "elo": 58, "els": [2, 36, 58, 64], "embed": [3, 19, 29, 34, 36], "emerg": 39, "emit": 47, "emphas": 40, "empir": [1, 2, 21, 24], "emploi": [12, 17, 22, 29, 30, 32, 36, 48, 55, 61], "empow": 17, "empti": 9, "emptyset": 64, "enabl": [1, 2, 3, 4, 28, 29, 31, 32, 57], "encod": [1, 2, 3, 4, 7, 15, 26, 29, 34, 36], "encode_dialog_prompt": 36, "encode_head": 36, "encode_messag": 36, "encoding_for_model": 36, "encount": [31, 32], "encourag": [15, 21, 24, 27, 60], "end": [1, 2, 3, 4, 5, 9, 10, 12, 15, 23, 27, 29, 31, 32, 35, 36, 37, 40, 41, 46, 47, 48, 49, 53, 58, 59, 60, 64], "end_header_id": 36, "end_of_text": 36, "enforc": 2, "engin": 50, "english": 9, "enhanc": [12, 19, 22, 37, 61], "enlighten": 12, "enough": [10, 24, 35, 37, 47, 53], "ensembl": [22, 61], "ensur": [10, 13, 16, 17, 26, 31, 32, 35, 41, 47, 64], "entir": [34, 40, 41], "entri": [12, 13, 29, 36], "entropi": [23, 26, 56, 59], "enumer": [2, 36], "environ": [21, 49], "eo": 36, "eos_id": 36, "eos_idx": 36, "eos_reach": 36, "eot_id": 36, "ep": 36, "episod": [49, 50], "epoch": [17, 34, 35, 41, 49, 50, 56], "epsilon": [36, 48], "equal": [3, 10, 21, 34, 37], "equat": [4, 40, 53], "equip": [7, 37, 40], "equival": [26, 28, 53, 60], "erhang": [19, 37], "error": [5, 15, 24, 28, 36, 48], "especi": 15, "essenti": [26, 28, 57], "est": 0, "establish": 53, "estat": 0, "estim": [0, 21, 23, 27, 35, 46, 48, 53], "estrang": 0, "etc": [9, 15], "ethic": 58, "eval": [8, 10, 56], "eval_step": 50, "evalplu": 12, "evalu": [9, 16, 21, 23, 24, 30, 35, 37, 40, 41, 52, 58, 61, 62], "evas": 58, "even": [2, 3, 4, 10, 17, 21, 24, 37, 46, 47, 53], "evenli": 27, "event": [48, 56], "everi": [15, 59], "evid": [2, 24], "evol": 12, "evolut": 17, "evolutionari": 17, "evolv": 17, "exact": 29, "exactli": 21, "exampl": [1, 2, 9, 10, 12, 15, 19, 21, 24, 26, 28, 29, 35, 46, 47, 55, 57, 58, 59, 60, 61, 62, 63, 64], "exce": [9, 22, 36], "exceed": [1, 2], "except": [17, 22, 36, 37, 47], "exclus": [34, 41], "execut": [2, 10, 20, 26, 27, 29], "exemplar": [39, 59], "exemplifi": 60, "exhibit": [40, 57], "exist": [1, 2, 6, 12, 15, 26, 63], "exp": [4, 5, 36, 46, 53, 55], "expans": 2, "expbal": [31, 32], "expect": [2, 15, 21, 27, 48, 57, 58, 65], "expens": [24, 29, 46, 64], "experi": [17, 35, 41, 46, 49, 50, 56, 58, 59, 61], "experience_mak": 50, "expert": [19, 37], "explain": [28, 55, 59], "explan": 59, "explicit": [1, 2, 3, 4], "explicitli": [9, 35, 40, 58, 60], "explor": [28, 35, 39, 48, 57], "exponenti": 2, "express": [10, 46, 56], "extend": [29, 30, 36, 50, 64], "extens": [1, 2, 19, 28, 57], "extra": [2, 10, 28], "extract": [12, 55, 59], "extractor": 55, "extrem": [21, 24], "f": [0, 1, 2, 5, 10, 36], "f_": [3, 4, 31, 32, 55, 64], "face": 61, "facilit": [26, 57], "fact": 2, "factor": [2, 5, 23, 55], "fail": 28, "failur": 24, "fair": 37, "faithfulli": [24, 57], "fake": 57, "fals": 36, "famili": [2, 24, 27, 29], "fangyun": [19, 37], "far": 56, "fashion": [15, 40], "fast": [19, 36, 37], "favor": 55, "featur": [24, 29, 36, 50, 55], "federico": [19, 37], "feed": [5, 23, 31, 32, 36], "feed_forward": 36, "feedback": [24, 29, 30, 41, 46, 53, 56, 57, 62, 64], "feng": [19, 37], "few": [15, 26, 27, 29, 39, 41, 58, 59, 62, 64], "fewer": [1, 2, 28], "ff": [5, 23], "ffff": 7, "ffff\u7684\u8303\u56f4": 7, "ffn": [31, 32, 36], "ffn_norm": 36, "field": [9, 15, 16], "fifo": 56, "figur": [23, 35, 56, 57, 58], "file": [9, 20, 29, 36], "fill": [29, 35], "filter": [10, 12, 41, 63, 64], "final": [15, 17, 21, 27, 34, 35, 41, 46, 49, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64], "find": [9, 10, 22, 23, 24, 26, 27, 35, 37, 40, 41, 49, 53, 58, 59, 62], "fine": [1, 2, 9, 16, 17, 30, 40, 41, 46, 48, 52, 53, 57, 60, 62], "finer": [31, 32], "finest": 0, "finetun": [12, 17, 24, 41, 58, 64], "finetuning_typ": 42, "first": [4, 5, 10, 12, 15, 21, 27, 28, 29, 30, 35, 36, 37, 40, 41, 46, 47, 49, 50, 53, 56, 57, 59, 61, 62, 63], "firstli": 28, "fit": [2, 23, 50, 53, 56], "five": 17, "fix": [23, 28, 41, 49, 56], "flag": 36, "flagopen": 16, "flash": 8, "flash_attn": 50, "flatten": [2, 36], "flavor": 19, "flexibl": [31, 32], "flip": [40, 57], "float": [2, 36, 53], "float32": 36, "fluenci": 21, "focu": [9, 21, 34, 41, 56], "focus": [16, 57], "follow": [1, 2, 9, 10, 12, 17, 19, 20, 29, 31, 32, 34, 35, 36, 37, 46, 47, 48, 49, 53, 55, 57, 58, 59, 60, 61, 63], "fool": 41, "forc": [26, 28, 40], "forgo": 56, "form": [1, 2, 10, 17, 27, 29, 41, 46, 56, 60, 62], "formal": 48, "format": [15, 17, 29, 58], "formatt": 36, "formul": [21, 31, 32, 46, 61], "fortun": 46, "forward": [5, 23, 31, 32, 36, 43], "found": [1, 2, 15, 26, 27, 28, 35, 58], "foundat": [12, 17, 29, 34], "four": [17, 29, 35, 37, 61], "frac": [2, 3, 4, 5, 6, 21, 23, 31, 32, 36, 37, 46, 47, 48, 49, 53, 55, 57, 61], "framework": [15, 57], "free": 63, "freez": [43, 55], "freq": [2, 36], "freqs_ci": [2, 36], "frequenc": [2, 3, 4, 29], "frequent": [1, 2], "fresh": 41, "friendli": 58, "from": [1, 2, 4, 6, 7, 8, 9, 10, 15, 17, 19, 22, 24, 26, 27, 28, 29, 30, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 52, 53, 55, 56, 60, 61, 62, 63, 64], "fsfairx": 22, "fu": [19, 37], "fulfil": 57, "fuli": [19, 37], "full": [10, 24, 28, 29, 36, 42, 50], "fulli": [9, 24, 65], "function": [1, 2, 3, 4, 5, 10, 13, 19, 21, 24, 28, 29, 34, 35, 40, 46, 47, 48, 49, 53, 56, 57, 61], "fundament": 24, "further": [2, 4, 9, 12, 22, 27, 29, 30, 31, 32, 35, 48, 56, 64], "furthermor": 58, "futur": 24, "g": [3, 4, 12, 15, 35, 40, 48, 53, 55, 59, 60, 63], "g_": [31, 32, 55], "gae": 48, "gain": [12, 28, 35, 57, 59], "gamma": [21, 36, 48, 49, 57], "gao": [19, 37], "gap": [12, 21, 22, 24, 52], "gate": [31, 32, 55], "gather": [35, 36], "gaussian": 5, "gave": 9, "gb2312\u56e0\u4e3a\u53ea\u8868\u793a\u666e\u901a\u6570\u5b57": 7, "gbk\u662fascii": 7, "ge": [15, 19, 37, 47, 48, 53, 55], "geglu": 5, "gelu": 5, "gemini": [27, 56], "gen": 36, "gener": [9, 10, 12, 16, 17, 19, 21, 26, 27, 28, 29, 30, 35, 37, 39, 40, 46, 47, 48, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64], "generate_kwarg": 50, "generate_max_len": 50, "generation_logprob": 36, "generation_token": 36, "geometr": 4, "get": [19, 20, 21, 29, 53, 55], "get_unique_el": 29, "gg": 23, "gibb": 46, "gibberish": 21, "github": [9, 13, 16, 26, 34, 36], "give": [2, 62, 63], "given": [1, 2, 9, 10, 15, 17, 21, 23, 24, 26, 28, 29, 34, 35, 36, 40, 41, 46, 47, 48, 49, 53, 55, 56, 59, 60, 62, 63, 64], "glob": 36, "glu": 36, "go": 50, "goal": [28, 40, 46, 53, 63], "gold": [8, 26, 27], "gomez": [19, 37], "good": [8, 10, 21, 24, 26, 48, 53, 63], "googl": 13, "google\u7684bert\u6a21\u578b\u5728\u5206\u8bcd\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662fwordpiece\u7b97\u6cd5": 6, "gpt": [8, 9, 10, 12, 24, 36, 41, 62], "gpt2": 8, "gpt3": 8, "gpt4": 30, "gpu": 42, "gqa": 19, "gradient": [34, 47, 49, 56], "gradient_accumulation_step": 42, "gradient_checkpoint": 50, "gradual": 29, "grain": [16, 57], "grammar": 15, "grammat": 15, "granular": 32, "great": 36, "greatli": 43, "greedi": [12, 22, 36], "grid": 2, "ground": [13, 24, 46, 53, 63], "group": [26, 27, 30, 31, 32, 36, 37, 61], "grow": 56, "grpo": [8, 30], "gsm8k": [8, 22], "gu": [19, 37], "guan": [19, 37], "guangbo": [19, 37], "guant": [19, 37], "guarante": [47, 48], "guid": [15, 22, 30, 53, 61, 65], "guo": [19, 37], "guowei": [19, 37], "h": [19, 31, 32, 35, 36, 37, 43], "h_": 2, "h_j": 2, "ha": [5, 15, 21, 24, 32, 35, 36, 37, 40, 48, 56, 61, 64], "hack": [35, 55, 58], "had": [13, 26], "half": [24, 26, 29], "ham": 47, "hand": [13, 23, 24, 56], "hanwei": [19, 37], "hao": [19, 37], "haowei": [19, 37], "happen": 2, "hard": [27, 28, 37, 46, 60], "harder": 27, "harm": [58, 60], "harmless": [59, 60, 62], "hat": [21, 40, 46, 48, 61], "have": [2, 5, 12, 15, 20, 21, 23, 24, 27, 28, 35, 46, 47, 53, 55, 58, 61, 62, 63], "he": [19, 37], "head": [1, 2, 7, 19, 23, 36, 62], "head_dim": 36, "heart": 63, "heavi": [23, 37, 40], "height": 36, "help": [19, 28, 29, 35, 49, 55, 56, 58, 60, 62], "helpfulli": 49, "helpsteer2": 8, "henc": [46, 62], "here": [1, 2, 9, 17, 19, 21, 23, 34, 35], "heurist": [12, 15], "hf": 53, "hh": 58, "hi": 10, "hidden": [5, 31, 32, 36, 55], "hidden_dim": 36, "high": [0, 4, 12, 21, 22, 26, 35, 40, 47, 55, 56, 61, 62, 63, 64], "highconfid": 64, "higher": [16, 22, 27, 28, 31, 32, 56, 57, 61], "highest": [0, 3, 9, 17, 22, 31, 32, 56, 61, 62], "highli": [24, 41, 55, 63, 64], "hihi": 10, "hinder": 61, "hing": 46, "histor": 48, "histori": 21, "hoc": 59, "hold": [23, 41], "holdgraf_evidence_2014": 19, "honesti": 55, "honghui": [19, 37], "hood": 12, "how": [2, 20, 21, 24, 27, 39, 41, 46, 48, 55, 59, 60], "howev": [1, 2, 4, 15, 21, 22, 24, 31, 32, 35, 46, 49, 53, 55, 57, 60, 61], "hstack": 36, "html": 7, "http": [12, 15, 17, 19, 37, 48], "huajian": [19, 37], "huang": [19, 37], "huazuo": [19, 37], "huge": [2, 28], "huggingfac": 50, "hui": [19, 37], "human": [10, 13, 15, 17, 21, 24, 29, 30, 41, 46, 49, 52, 53, 56, 57, 58, 59, 60, 62, 63, 64], "humanev": [17, 22], "hundr": 2, "hybridengin": 50, "hyper": [34, 36, 48, 57], "hyperparamet": [23, 27, 47, 56, 57], "i": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 41, 46, 47, 48, 49, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64], "i_": 15, "i_t": 15, "id": 36, "idea": [1, 2, 32, 57, 64], "ideal": [2, 9], "ident": [31, 32, 41, 46, 56, 63], "identifi": [15, 22, 56, 57, 58, 60, 61, 64], "ift": 62, "ignor": [2, 21, 26, 36], "ignore_index": 36, "ik_": [1, 2, 36], "illeg": 58, "illia": [19, 37], "illustr": [24, 35, 36], "im": [1, 2, 36], "imag": 23, "imaginari": [1, 2], "imbal": [31, 32], "imit": 24, "impact": [22, 27, 41], "imper": 9, "imperfect": 64, "implement": [17, 34, 64], "implicit": 46, "implicitli": [24, 40, 46], "import": [2, 21, 24, 35, 36, 46, 53, 62, 63], "importantli": [37, 46], "improv": [12, 21, 24, 26, 28, 29, 34, 35, 36, 39, 40, 41, 47, 48, 59, 61, 62, 63, 64], "inappropri": 57, "incentiv": 40, "includ": [1, 2, 9, 16, 17, 20, 22, 23, 24, 26, 27, 29, 30, 32, 35, 36, 42, 46, 52, 53, 58], "incomplet": 10, "incorpor": [3, 4, 35, 48], "incorrect": [10, 26, 28, 40, 41, 61, 64], "incorrectli": 46, "increas": [2, 4, 12, 17, 27, 29, 31, 32, 46, 47, 57], "inde": 57, "independ": [6, 15, 29], "index": [1, 2, 36, 37, 48, 56], "indic": [1, 2, 27, 36, 37, 55, 56, 57, 60], "individu": [3, 4, 23], "induc": 53, "inequ": 46, "inf": 36, "infer": [2, 9, 21, 29, 32, 34, 36, 37, 50, 53, 57, 59, 63], "inference_mod": 36, "infomax": 56, "inform": [1, 2, 3, 4, 7, 9, 10, 20, 26, 31, 32, 35, 48, 61], "infrastructur": 2, "infti": 23, "inherit": 55, "init": 20, "init_kl_coef": 50, "initi": [10, 12, 15, 17, 28, 29, 35, 36, 46, 49, 56, 58, 60, 64], "inject": [1, 2, 43], "inlin": [19, 46], "inner": [3, 4], "innov": [32, 37], "input": [1, 2, 3, 4, 5, 6, 9, 10, 12, 15, 17, 19, 26, 27, 28, 29, 30, 34, 35, 36, 37, 47, 49, 53, 56, 57, 59, 63], "input_kei": 50, "input_text_mask": 36, "inputoutput": 28, "insert": [19, 26, 36, 56], "insid": [10, 48], "insight": 46, "inspect": 13, "inspir": 12, "inst": 29, "instanc": [9, 36, 55, 58], "instead": [1, 2, 4, 9, 17, 24, 27, 29, 34, 36, 48, 56, 57, 58, 64], "instruciton": 9, "instruct": [8, 9, 20, 22, 24, 30, 35, 40, 55, 57, 58, 59, 61], "instructgpt": 49, "instructionfollow": 62, "int": [2, 36, 53], "int_": 56, "integ": 36, "intent": 61, "intention": 57, "interact": [21, 36, 56, 57], "interc": [1, 2, 3, 31, 32, 37, 55], "interchang": 7, "interest": [24, 53], "interesting": 21, "interleav": 40, "interlm2": 8, "intermedi": [23, 24, 30, 31, 32, 39, 41], "intern": 24, "internet": 49, "interpol": 29, "interpret": [35, 48], "interview": 29, "introduc": [1, 2, 12, 15, 21, 27, 36, 48, 53, 59], "introduct": 59, "intuit": [4, 21, 24, 46], "invas": 58, "invest": [1, 2, 56], "investig": [41, 57], "involv": [9, 23], "ip": 59, "ipo": 46, "ipynb": 19, "iq_": [1, 2, 36], "is_safeti": 35, "isin": 36, "issu": [2, 31, 32, 40, 55, 58, 59], "item": [50, 53], "iter": [15, 17, 28, 36, 40, 49, 53, 56, 57, 61, 62], "its": [2, 4, 5, 12, 13, 15, 24, 26, 27, 29, 30, 31, 32, 36, 37, 40, 41, 46, 53, 55, 56, 57, 58, 62], "itself": [10, 15, 40, 62], "ix_": [1, 2, 36], "j": [1, 2, 4, 19, 21, 31, 32, 36, 37, 47, 48, 57, 63], "j_": [48, 63], "j_1": 57, "j_q": 57, "jakob": [19, 37], "jame": [19, 37], "ji": [19, 37], "jian": [19, 37], "jianlin": [19, 37], "jianzhong": [19, 37], "jiaqi": [19, 37], "jiashi": [19, 37], "jin": [19, 37], "jingyang": [19, 37], "jone": [19, 37], "jong": [19, 37], "joshua": [19, 37], "json": [9, 36, 42], "judg": [27, 28, 57, 62, 63], "judgement": 57, "judgment": 21, "junji": [19, 37], "junxiao": [19, 37], "jupyt": [19, 20], "jupyterbook": 19, "jupytext": 20, "just": 19, "k": [1, 2, 3, 4, 17, 19, 26, 31, 32, 35, 36, 37, 43, 47, 49, 52, 55, 56], "k_": [1, 2, 31, 32, 36, 48], "k_1": 48, "k_i": 48, "kai": [19, 37], "kaig": [19, 37], "kaiser": [19, 37], "kang": [19, 37], "keep": [5, 27, 31, 32, 35, 40], "keepdim": 36, "kei": [1, 2, 3, 4, 24, 27, 28, 29, 32, 36, 53, 57], "kernel": 20, "kind": [19, 57], "kl": [35, 46, 48, 49, 53], "knew": 21, "know": [10, 21, 24], "knowledg": [3, 4, 12, 28, 31, 32, 35], "known": [2, 21, 36, 61], "kr": 37, "kto": [8, 22], "l": [0, 2, 15, 19, 21, 23, 31, 32, 35, 36, 37, 40, 46, 47, 48, 49, 53, 56, 61, 62, 63, 64], "l_": [46, 57, 61], "l_1": 57, "l_2": 57, "label": [15, 16, 24, 35, 41, 49, 53, 58, 60, 63, 64], "lack": 53, "lambda": [2, 47, 48, 56, 57], "lambda_": 55, "land": 58, "langl": [1, 2, 4, 36], "languag": [1, 3, 4, 9, 15, 18, 19, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 41, 46, 49, 56, 64], "larg": [1, 4, 10, 15, 18, 21, 24, 27, 35, 36, 37, 46, 47, 49, 56, 64, 65], "larger": [2, 4, 16, 35, 41], "largest": [16, 26, 27, 34, 35], "last": [26, 36, 41, 48, 55, 58], "later": 15, "latest": 35, "law": [24, 37], "layer": [1, 2, 5, 23, 26, 31, 32, 34, 36, 37, 43, 49, 50, 55], "layer_id": 36, "le": [2, 5, 17, 31, 32, 47], "lead": [1, 2, 10, 21, 24, 28, 29, 34, 41, 47, 58], "leakag": 24, "lean": [19, 37], "learn": [5, 21, 22, 23, 24, 26, 29, 30, 31, 32, 34, 36, 46, 48, 53, 60, 61, 62, 65], "learnabl": 36, "learning_r": 42, "least": [27, 58], "leav": [26, 28], "lebr\u00f3n": [19, 37], "lecong": [19, 37], "led": [35, 58], "lee": [19, 37], "leed": [31, 32], "left": [1, 2, 4, 6, 21, 23, 27, 29, 36, 37, 40, 46, 47, 48, 49, 53, 55, 57, 59], "leftarrow": 37, "legal": 58, "lei": [19, 37], "len": [10, 36, 50, 53], "length": [2, 23, 29, 30, 31, 32, 35, 36, 37, 47, 55, 57, 59], "lengthi": 28, "less": [8, 9, 15, 22, 41, 48, 56, 58, 61], "let": [3, 4, 10, 20, 21, 37, 47, 53, 55, 58, 64], "level": [13, 16, 17, 21, 24, 27, 29, 31, 32, 35, 41, 56], "leverag": [2, 3, 4, 12, 15, 28, 35], "lex": 2, "leyi": [19, 37], "li": [19, 37], "liang": [19, 37], "librari": 29, "lie": [37, 58], "like": [9, 19, 20, 21, 24, 28, 41, 47, 56, 58, 60, 63], "likelihood": [21, 22, 26, 41, 46, 47, 53, 59, 61, 64], "limit": [1, 2, 15, 24, 26, 27, 35, 37, 53, 56, 59], "lin": [19, 37], "line": [12, 15, 17, 19, 20, 23, 24, 29], "linear": [2, 4, 29, 34, 35, 36, 55], "linearli": 27, "list": [0, 9, 17, 27, 28, 29, 36, 50, 53], "liter": [10, 36], "liu": [19, 37], "livecodebench": 8, "liyu": [19, 37], "ll": [19, 36, 37, 43], "llama": [1, 8, 9, 10, 22, 36, 50, 62], "llama2": [8, 35], "llama3": 8, "llion": [19, 37], "llm": [2, 12, 17, 18, 28, 29, 35, 40, 46, 47, 48, 55, 57, 60, 62, 63], "lm": 49, "ln": [2, 36, 56], "load": 36, "load_checkpoint": 50, "load_state_dict": 36, "load_tiktoken_bp": 36, "local": 40, "localhost": 42, "locat": [2, 29], "log": [6, 21, 27, 35, 36, 40, 41, 46, 47, 48, 49, 53, 57, 58, 59, 61], "logging_step": [42, 50], "logic": 28, "logist": 61, "logit": [26, 35, 36, 46, 47], "logprob": 36, "logprobs_i": 36, "long": [1, 2, 4, 9, 36, 47], "longer": [1, 2, 29, 30, 47, 55, 59], "look": 28, "loos": 2, "lora": 8, "lose": 62, "loss": [21, 23, 24, 26, 31, 32, 35, 47, 48, 49, 55, 56, 57, 59, 61], "lot": 19, "low": [4, 10, 15, 21, 35, 43, 47, 48, 64], "lower": [9, 47], "lowest": [0, 61, 62], "lr_scheduler_typ": 42, "lu": [19, 37], "lukasz": [19, 37], "luo": [19, 37], "m": [1, 2, 3, 4, 15, 31, 32, 35, 36, 47, 53, 56, 57, 61], "m_": 53, "m_0": 62, "m_1": 62, "m_2": 62, "m_3": 62, "m_t": 62, "ma": [19, 37], "machin": 29, "made": [17, 56, 59, 61], "magic": 8, "magnitud": [2, 24, 26, 37], "mai": [2, 10, 22, 24, 28, 31, 32, 47, 48, 58, 59, 60, 61], "main": [22, 24, 27, 28, 29, 34, 35], "mainli": [24, 28, 61], "maintain": [31, 32, 35], "major": [41, 60], "make": [2, 3, 4, 9, 15, 16, 21, 24, 27, 29, 36, 40, 46, 50, 55, 56, 57, 58, 62], "make_cot_input_prompt": 10, "make_cot_output_prompt": 10, "make_direct_input_prompt": 10, "make_direct_output_prompt": 10, "make_experience_list": 50, "mani": [2, 7, 15, 19, 20, 29, 49], "manner": [62, 63], "manual": [13, 15], "map_loc": 36, "margin": [17, 22, 35], "mark": 29, "markdownfil": 20, "markedli": 19, "markup": 19, "mask": [26, 29, 36], "mass": [17, 21, 36], "master_port": 42, "match": [1, 2, 16, 36, 37, 40], "math": [30, 36, 41, 47, 48], "mathbb": [3, 4, 21, 31, 32, 35, 37, 40, 43, 46, 47, 48, 49, 53, 55, 57, 61], "mathbf": [1, 2, 3, 4, 21, 29, 31, 32, 36, 37, 48, 57], "mathcal": [5, 21, 31, 32, 35, 37, 40, 46, 47, 52, 53, 55, 56, 61, 63, 64], "mathemat": [46, 48], "mathmix": 41, "mathrm": 52, "matmul": 36, "matplotlib": 46, "matric": [5, 36, 37, 43], "matrix": [3, 4, 5, 29, 36, 37], "max": [5, 35, 36, 40, 47, 53, 64], "max_": [2, 46, 53], "max_batch_s": 36, "max_epoch": 50, "max_gen_len": 36, "max_prompt_len": 36, "max_reward": 53, "max_sampl": 50, "max_seq_len": 36, "maxim": [2, 9, 12, 17, 21, 27, 34, 40, 41, 46, 48, 49, 53, 56, 64], "maximum": [1, 2, 21, 26, 29, 35, 36, 37, 46, 53, 56], "mbox": 4, "mbpp": [8, 17], "md": [19, 20], "me": 58, "mean": [4, 35, 36, 47, 48, 56, 61, 62], "meaning": 28, "meansquar": 36, "meanwhil": [2, 3, 4], "measur": [21, 26, 48, 59, 64], "mechan": [3, 4, 27, 48], "median": 35, "medium": 29, "memori": [10, 37, 48], "meng": [19, 37], "merg": 17, "mergeable_rank": 36, "messag": [28, 36], "meta": [7, 36], "metadata": 27, "method": [2, 3, 4, 12, 17, 22, 35, 36, 39, 46, 56, 57, 60, 61], "metric": [17, 21, 24, 26, 55, 59], "miaojun": [19, 37], "michiel": [19, 37], "micro_rollout_batch_s": 50, "micro_train_batch_s": 50, "middl": [15, 29], "million": [24, 26, 27, 29], "min": [36, 43, 48, 53, 55], "min_": 46, "min_prompt_len": 36, "mine": 53, "mingchuan": [19, 37], "minghua": [19, 37], "minghui": [19, 37], "mingm": [19, 37], "mini": 36, "minim": [2, 46, 56], "minimis": [26, 47], "minimum": 46, "minor": 40, "minu": 36, "minut": 10, "misalign": 57, "mismatch": [40, 47], "miss": 29, "mistak": [28, 40, 57], "mitig": [2, 40, 48, 49, 55, 59, 61, 64], "mix": [26, 29, 49, 53], "mixtral": 50, "mixtur": [19, 32, 37, 50], "mk": [31, 32], "ml": 2, "mla": 32, "mle": [46, 53, 57], "mlp": 55, "mmlu": 22, "mn": [31, 32], "mode": [24, 46], "model": [1, 3, 4, 8, 9, 10, 12, 15, 16, 17, 18, 19, 21, 22, 24, 26, 28, 29, 30, 31, 32, 34, 37, 43, 46, 47, 48, 50, 52, 53, 58, 59, 60, 65], "model_arg": 36, "model_name_or_path": 42, "modelarg": 36, "modern": [7, 24], "modest": 41, "modif": [9, 17, 26], "modifi": [2, 9, 29, 35, 40, 43, 60, 62, 63], "modul": [31, 32, 36], "modular": 28, "modulelist": 36, "moe": [31, 32, 37], "monoton": 53, "mont": [21, 48], "month": 35, "more": [8, 9, 12, 15, 16, 17, 20, 24, 26, 27, 28, 29, 31, 32, 34, 35, 37, 41, 47, 48, 49, 53, 55, 56, 57, 58, 60, 61], "moreov": [19, 40], "most": [2, 7, 19, 22, 29, 35, 41, 55, 57, 62], "mostli": 13, "motiv": [46, 53, 64], "move": 29, "mq": 10, "much": [2, 4, 9, 24, 29, 41, 46, 58], "multi": [8, 19, 23, 29, 34, 36], "multinomi": 36, "multipl": [4, 10, 15, 22, 28, 31, 32, 36, 37, 40, 50, 56, 58, 62], "multiple_of": 36, "multipli": [4, 55], "multitask": 29, "murtadha": [19, 37], "must": [1, 2, 10, 19, 21, 23, 29, 41, 47], "my": 58, "my_list": 10, "n": [0, 1, 2, 3, 4, 5, 6, 8, 10, 17, 19, 21, 22, 26, 29, 31, 32, 36, 37, 40, 41, 53, 56, 57, 62, 63], "n_": [15, 23, 37], "n_h": 37, "n_head": 36, "n_layer": 36, "n_t": 15, "n_vocab": 36, "n_word": 36, "nabla_": [21, 46, 47], "naiv": [24, 46], "name": [5, 17, 26, 28, 36, 46], "nana": 10, "nano": 56, "narrow": 12, "natur": [1, 2, 15, 24, 26, 28, 29, 30, 36, 39, 59], "nderstand": 10, "ndim": [2, 36], "ne": 47, "nearli": [24, 56], "necessari": [55, 62], "necessit": [31, 32], "necssari": 9, "need": [2, 15, 19, 20, 24, 28, 35, 36, 37, 48, 61], "neg": [21, 40, 41, 47, 55, 57, 60, 61, 64], "negligibli": 35, "neighbor": 58, "network": [5, 31, 32, 34, 36, 55], "neural": [5, 6, 36], "neutral": 41, "new": [0, 5, 9, 10, 12, 15, 17, 24, 26, 27, 29, 35, 36, 47, 48, 49, 55, 56, 62], "newli": 17, "newlygener": 15, "next": [2, 4, 15, 21, 26, 28, 49, 56, 58, 62, 63], "next_token": 36, "ni": [19, 37], "nie": [19, 37], "niki": [19, 37], "ning": [19, 37], "nl": 52, "nlp": [0, 24, 49], "nn": [2, 36], "noam": [19, 37], "nois": 61, "noisi": [61, 63, 64], "non": [4, 9, 10, 15, 34, 53, 55, 58], "none": 36, "nonlinear": [5, 36], "noqa": 36, "norm": 36, "norm_ep": 36, "normal": [31, 32, 34, 48, 50, 58, 59, 61], "normalize_reward": 50, "normalized_shap": 36, "notabl": [2, 22, 55], "note": [18, 19, 23, 28, 36, 46, 47, 48, 56, 63], "notebook": 19, "notin": [53, 57], "novel": [3, 4, 12, 17, 53, 57, 63], "now": [2, 10, 28, 40, 46, 47, 55, 63], "np": [46, 53], "nucleu": 36, "num": 37, "num_base_token": 36, "num_channel": 36, "num_episod": 50, "num_featur": 36, "num_reserved_special_token": 36, "num_sampl": [36, 53], "num_train_epoch": 42, "number": [2, 4, 5, 15, 17, 22, 23, 24, 26, 29, 31, 32, 36, 37, 41, 43, 48, 53, 56], "numer": 47, "numpi": [46, 53], "nw": 52, "o": [0, 4, 10, 37, 48, 60], "o1": 8, "o_": 48, "o_1": [48, 60], "o_2": [48, 60], "o_g": 48, "obei": 37, "object": [21, 26, 27, 29, 31, 32, 35, 46, 48, 49, 53, 57, 64], "observ": [17, 22, 24, 28, 37, 55, 56, 59, 61], "obstacl": 21, "obtain": [9, 12, 17, 27, 40, 53, 55, 56, 59], "obviou": 21, "od": 10, "off": [15, 19, 20, 22, 57, 59], "offer": [56, 57, 59], "offlin": [8, 21, 26, 57], "often": [15, 21, 28, 57, 59, 60, 61, 64], "ofthought": 39, "ol": 0, "old": [0, 48], "older": 0, "omit": [5, 31, 32, 37], "onc": [9, 17, 23, 37], "one": [2, 5, 10, 15, 17, 19, 21, 22, 24, 26, 27, 29, 31, 32, 35, 36, 37, 41, 47, 48, 53, 55, 56, 57, 59, 60, 62], "ones": [2, 35, 36, 64], "ones_lik": [2, 36], "onli": [1, 2, 3, 4, 9, 10, 15, 24, 26, 27, 29, 35, 36, 37, 40, 41, 46, 47, 48, 55, 57, 58, 60, 62, 63, 64], "onlin": [8, 27, 57], "open": [9, 17, 36, 62], "openai": [36, 49], "oper": [2, 17, 56], "opportun": 56, "oppos": [5, 29], "opposit": [57, 60], "optim": [2, 8, 9, 21, 22, 23, 28, 30, 35, 40, 49, 52, 53, 56, 63], "optima": 40, "optimis": 47, "option": [2, 9, 21, 36, 58, 59], "oracl": [21, 22, 40], "order": [1, 2, 3, 4, 24, 26, 27, 28, 29, 31, 32, 35, 37, 46, 49, 58, 59, 61, 62, 63], "org": [12, 15, 17, 19, 37, 48], "organ": 46, "origin": [2, 4, 5, 15, 17, 27, 28, 31, 32, 34, 35, 55, 57, 59, 61, 62, 63], "orthogon": 12, "other": [5, 7, 17, 20, 21, 24, 28, 29, 31, 32, 36, 40, 53, 56, 57, 62, 64], "otherwis": [21, 31, 32, 35, 41, 53, 57], "otim": [5, 36], "our": [2, 3, 4, 9, 10, 12, 15, 17, 21, 24, 26, 27, 29, 34, 35, 40, 41, 43, 46, 47, 48, 49, 52, 56, 58, 59, 61, 62, 63], "ourselv": 27, "out": [2, 27, 35, 36, 37, 49, 56], "out_logprob": 36, "out_token": 36, "outer": [2, 36], "outermost": 50, "outlin": [17, 61], "outperform": [22, 24, 29, 41, 59], "output": [4, 9, 10, 12, 15, 20, 21, 22, 23, 26, 27, 28, 29, 31, 32, 34, 35, 36, 37, 48, 49, 55, 57, 60, 61, 63, 64], "output_dir": 42, "outsid": 61, "over": [4, 21, 23, 27, 29, 35, 36, 37, 40, 41, 48, 49, 50, 56, 57, 59, 61, 62, 64], "overal": [15, 23, 26, 48, 55, 57, 59], "overconfid": 61, "overfit": [16, 49, 61], "overview": [19, 36], "overwrite_cach": 42, "own": [40, 41, 57, 58, 62], "p": [4, 6, 21, 22, 35, 36, 46, 48, 53, 56, 57, 60], "p_": [21, 31, 32, 40, 56, 61, 64], "p_1": 40, "pack": 42, "pad_id": 36, "page": [19, 20], "pair": [9, 10, 21, 24, 28, 29, 34, 40, 49, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64], "pairwis": [35, 52, 53, 55, 60, 62, 63], "palm": 36, "pan": [19, 37], "panpan": [19, 37], "paper": [2, 12, 15, 17, 18, 21, 27, 28, 29, 48], "par": 59, "paradigm": 57, "parallel": [26, 36], "param": 36, "paramet": [2, 3, 4, 5, 12, 22, 27, 29, 31, 32, 34, 35, 36, 37, 43, 46, 47, 48, 49, 53, 55, 56, 57, 61], "parameter": [23, 64], "parametr": 46, "parenthes": 60, "parmar": [19, 37], "part": [4, 24, 29, 56], "partial": [21, 28], "particip": [13, 26, 27], "particular": [5, 36, 39, 46, 48, 56], "particularli": 57, "partit": [31, 32, 46, 61], "pass": [5, 10, 13, 17, 23, 26, 28, 29, 36, 43, 55], "past": 56, "pat_str": 36, "path": [20, 36], "pattern": 36, "pbar": 50, "pdf": [12, 15, 17, 48], "peak": 9, "pearson": 55, "pei": [19, 37], "peiyi": [19, 37], "penal": [24, 61], "penalti": [35, 40, 48, 49, 55], "peng": [19, 37], "per": [21, 23, 26, 27, 36, 37, 41, 48, 49, 52, 60, 62], "per_device_train_batch_s": 42, "percent": 58, "percentag": [26, 59], "perceptu": 21, "perfect": 62, "perform": [9, 10, 12, 22, 24, 26, 27, 28, 30, 34, 35, 36, 37, 39, 41, 49, 53, 56, 57, 59, 62, 64], "period": [4, 29], "permit": 9, "permut": 36, "person": 58, "perspect": 4, "pgr": 24, "phase": [15, 28, 29, 30, 35, 46, 58], "phenomenon": [24, 55], "phi": [5, 46, 48, 49, 55, 59, 63], "phi4": 8, "pi": [2, 21, 35, 40, 46, 49, 53, 56, 61, 64], "pi_": [21, 35, 40, 47, 48, 49, 53, 64], "piao": [19, 37], "pick": [22, 26], "piec": [34, 58, 59], "piecewis": 35, "pile": 2, "pipelin": [9, 41, 46, 60], "pivot": 22, "place": [5, 36, 60], "placehold": 9, "plai": 22, "plain": 28, "plan": 2, "plane": 4, "platform": [26, 27], "pleas": 58, "plot": [23, 46, 56], "plot_loss": 42, "plt": 46, "pm": 64, "pmatrix": [3, 4, 29], "point": [2, 22, 27, 28, 35, 62], "pointwis": 53, "polar": [2, 36], "polici": [30, 35, 40, 46, 49, 53, 56, 58, 59, 64], "polit": 58, "polosukhin": [19, 37], "pool": [15, 26, 53, 63, 64], "poor": [28, 56], "poorli": 24, "pop": 53, "popular": 24, "portion": 29, "posit": [3, 5, 19, 24, 29, 34, 36, 41, 47, 48, 57, 59, 60, 62, 63, 64], "possess": 62, "possibl": [15, 24, 27, 28, 34, 40, 41, 52, 56, 58, 60, 63], "possibli": 58, "post": 59, "postpon": 28, "potenti": [28, 35, 57, 59], "pow": 36, "power": [12, 19, 26, 27, 36], "ppo": [8, 35, 49, 60], "ppo_train": 50, "practic": [2, 21, 24, 28, 31, 32, 46, 55, 56, 61, 64], "practition": 12, "pre": [0, 1, 2, 3, 4, 6, 26, 28, 30, 36, 55, 58], "preambl": 59, "preced": 35, "precis": [21, 29, 57], "precomput": 2, "precompute_freqs_ci": [2, 36], "predefin": [12, 52], "predict": [2, 10, 24, 26, 27, 29, 36, 40, 41, 49, 55, 56, 61, 64], "predominantli": 29, "prefer": [2, 8, 21, 22, 30, 40, 41, 47, 49, 52, 53, 55, 56, 58, 60, 62, 63], "prefix": [15, 21, 29, 41], "prepend": [36, 58], "prescrib": 56, "presenc": 20, "present": [2, 28, 41, 49, 56, 57, 58, 59, 63], "preserv": 2, "pretrain": [2, 15, 24, 29, 41, 43, 49, 50, 58, 62], "pretrained_weight": 42, "prev_po": 36, "prevent": 29, "previou": [1, 2, 15, 17, 36, 40, 56, 57], "primarili": [49, 57], "principl": [58, 60], "print": [20, 36], "prior": [35, 46, 57, 58, 64], "privaci": 58, "prm800k": 41, "pro": [27, 56], "prob": 36, "probabl": [21, 22, 36, 41, 46, 47, 48, 53, 56, 57, 58, 59, 64], "problem": [10, 12, 13, 16, 24, 26, 27, 28, 29, 41, 46, 53, 61], "probs_idx": 36, "probs_sort": 36, "probs_sum": 36, "proce": 17, "procedur": [24, 27, 47, 49, 56, 59, 62], "process": [2, 4, 6, 15, 17, 21, 22, 24, 28, 36, 55, 56, 57], "produc": [9, 10, 12, 15, 17, 21, 22, 26, 27, 28, 36, 37, 40, 49, 55, 56, 57, 59, 60, 61, 64, 65], "product": [3, 4, 5, 21, 36], "profession": 29, "program": [10, 13, 26, 27, 28, 29], "programm": [10, 13], "progress": [28, 35, 48, 56], "project": [26, 37], "promin": 17, "promis": [22, 59], "promot": 15, "prompt": [9, 12, 15, 26, 27, 28, 29, 35, 36, 49, 50, 52, 53, 55, 56, 58, 60, 61, 62, 63, 64, 65], "prompt_data": 50, "prompt_max_len": 50, "prompt_token": 36, "prompts_dataload": 50, "prone": [16, 61], "prop": 34, "proper": 55, "properli": [19, 35], "properti": [2, 3], "proport": [29, 47], "propos": [5, 15, 21, 24, 29, 36, 37, 40, 43, 46, 48, 53, 55, 57, 63, 64], "proprietari": 29, "propto": 47, "prove": 4, "proven": 48, "provid": [2, 4, 9, 10, 13, 16, 24, 29, 35, 36, 39, 41, 46, 47, 48, 57, 61, 62, 65], "proxim": 48, "prune": 13, "pseudo": 64, "pseudolabel": 64, "psi": [46, 48, 53, 61], "psi_": 61, "psm": 29, "pth": 36, "ptx": 49, "public": [26, 27, 28, 49], "publicli": [29, 34], "purpos": [2, 19, 24, 29], "push": [12, 57], "put": [9, 15, 21, 26], "puzzl": 24, "px": 10, "py": 42, "pyplot": 46, "python": [10, 12, 13, 26, 27, 29], "q": [1, 2, 3, 4, 19, 21, 36, 37, 48, 57], "q_": [1, 2, 36], "q_0": 36, "q_1": 36, "q_2": 36, "q_3": 36, "qa": 34, "qihao": [19, 37], "qinyu": [19, 37], "qiu": [19, 37], "qiushi": [19, 37], "qlora": 50, "qr": 37, "qu": [19, 37], "quad": [2, 23, 31, 32, 35, 61, 64], "qualiti": [2, 8, 12, 15, 16, 21, 27, 35, 52, 55, 59, 60, 62, 63, 64], "quantifi": 61, "quantil": 64, "quantiti": 8, "queri": [1, 2, 3, 4, 19, 29, 36, 48, 56, 61, 64], "question": [1, 2, 9, 13, 17, 22, 28, 29, 41, 48, 59], "quit": 28, "qwen": 8, "qwen2": 8, "r": [1, 3, 4, 10, 17, 19, 21, 29, 31, 32, 35, 36, 37, 40, 43, 47, 48, 53, 55, 56, 61], "r_": [3, 4, 21, 35, 46, 48, 49, 53, 55, 56, 59, 61, 62], "r_1": 48, "r_h": 35, "r_i": 48, "racist": 58, "rais": [2, 36], "ran": 27, "rand_prompt": 50, "randn": 36, "random": [12, 26, 27, 36, 53, 56, 61, 63], "randomli": [10, 12, 17, 26, 29, 58, 60], "rang": [0, 2, 12, 24, 29, 34, 35, 36, 50, 58, 59], "rangl": [1, 2, 4, 36], "rank": [22, 26, 28, 35, 43, 46, 49, 53, 61, 62], "rapidli": 57, "rate": [24, 26, 27, 28, 34, 35, 41, 49, 55, 56, 59], "rater": 56, "rather": [46, 60], "ratio": 47, "rational": 59, "raw": 6, "re": [1, 2, 4, 28, 36, 46, 53], "reach": [15, 27, 28, 35, 41], "read": 36, "real": [2, 4, 29, 50], "realist": 9, "realiti": [2, 53], "realm": [12, 17], "rearrang": [46, 53], "reason": [2, 17, 21, 22, 28, 29, 41, 47, 48, 59, 63], "recal": [21, 56, 57], "receiv": [21, 35, 56], "recent": [26, 27, 34, 35, 49, 55], "recip": [29, 63], "recommend": 62, "recov": [24, 56], "rectifi": [5, 36], "red": [17, 37], "reduc": [2, 5, 9, 21, 22, 31, 32, 35, 37, 40, 43, 47], "reduct": [36, 47], "redund": [27, 31, 32], "ref": [40, 46, 47, 48], "refer": [13, 16, 19, 21, 29, 35, 41, 46, 47, 48, 55, 56, 58, 62], "refin": 56, "reflect": [13, 28, 57], "regardless": 55, "regex": 36, "regim": 41, "region": [2, 21], "reglu": [5, 36], "regress": [29, 35, 49, 55], "regular": [19, 48, 56], "rehears": 29, "reinforc": [24, 29, 30, 41, 46, 48, 60], "reject": [8, 29, 35, 52, 55, 61, 63, 64], "rel": [1, 2, 3, 4, 22, 26, 30, 36, 47, 58], "relat": [4, 9, 22, 29, 37, 48, 53], "releas": [9, 29], "relev": [24, 28, 41, 63, 64], "reli": [12, 21, 24, 27, 28, 64], "reliabl": [10, 24, 41], "relu": [5, 34, 36, 46], "remain": [15, 23, 24, 26, 27, 41, 47, 61, 64], "remind": 9, "remov": [17, 27, 29, 34, 49, 53, 58, 63], "ren": [19, 37], "render": 19, "renorm": 36, "reorder": 29, "reparameter": 46, "repeat": [9, 15, 28], "repeatedli": 26, "replac": [2, 5, 34, 36, 58, 59], "replai": [48, 50, 56], "replay_buff": 50, "report": [10, 61], "repositori": [26, 29], "repres": [1, 2, 4, 5, 7, 15, 17, 21, 29, 31, 32, 36, 47, 61], "represent": [4, 5, 24, 26, 36, 46, 59], "request": [9, 58, 62], "requir": [1, 2, 3, 4, 9, 10, 24, 27, 28, 29, 35, 36, 37, 53, 56], "rerank": 27, "resampl": 56, "rescal": 2, "research": [13, 35, 57], "reserved_special_token_": 36, "reserved_special_token_0": 36, "reserved_special_token_1": 36, "reserved_special_token_2": 36, "reserved_special_token_3": 36, "reserved_special_token_4": 36, "reshap": [2, 36], "reshape_for_broadcast": [2, 36], "residu": 23, "resolv": [26, 55], "resourc": [28, 35], "respect": [22, 31, 32, 37, 47, 48, 49, 57, 59, 60, 61], "respons": [9, 17, 22, 31, 32, 35, 36, 40, 48, 49, 52, 53, 55, 56, 57, 58, 59, 61, 62, 64], "response_candid": 53, "response_reward": 53, "rest": 20, "restrict": [21, 47], "result": [2, 3, 4, 12, 16, 21, 24, 27, 28, 29, 31, 32, 35, 37, 41, 48, 53, 57, 61], "retain": [29, 58, 64], "return": [2, 10, 21, 36, 53, 57], "reus": 2, "revers": 59, "review": 46, "revis": 40, "reward": [8, 22, 24, 28, 29, 30, 46, 48, 50, 52, 53, 57, 59, 63, 64], "reward_pretrain": 50, "rewrit": 58, "rft": 8, "rho_": 53, "right": [1, 2, 4, 6, 21, 23, 29, 36, 37, 40, 41, 46, 47, 48, 49, 53, 55, 57, 59], "rl": [8, 26, 35, 41, 46, 58, 59, 60, 64], "rlaif": [58, 60, 64], "rlcd": [8, 64], "rlhf": [24, 29, 46, 49, 50, 53, 55, 56, 58], "rm": [8, 24, 35, 50, 52, 55, 59], "rmboost": 8, "rmsnorm": 34, "robust": [15, 28, 58], "roform": [19, 37], "role": [22, 36], "rollout": 40, "rollout_batch_s": 50, "room": 28, "rope": [8, 29, 34, 37], "rope_theta": 36, "rotari": [3, 19, 29, 34], "rotat": [3, 4, 29], "roug": 15, "roughli": [23, 27, 34, 41, 61], "round": [17, 27], "rout": [31, 32], "row": [2, 36], "rso": 8, "rsqrt": 36, "rtol": 36, "rtx4090": 50, "ruan": [19, 37], "ruiqi": [19, 37], "ruizh": [19, 37], "rule": 28, "run": [10, 20, 28, 29, 40, 47, 58], "runtim": 27, "runxin": [19, 37], "ruyi": [19, 37], "rx": 56, "s1": 10, "s2": 10, "s_": [2, 21, 31, 32, 47], "s_1": 2, "s_2": 2, "safe": 49, "safeti": [24, 29, 35], "sahil280114": 9, "sai": 58, "salienc": 24, "salient": 24, "same": [2, 17, 19, 26, 27, 28, 29, 31, 32, 37, 46, 47, 53, 58, 60, 61, 62], "sampl": [8, 10, 12, 15, 17, 21, 22, 29, 34, 35, 36, 41, 46, 48, 52, 56, 58, 59, 60, 62, 63, 64], "sample_top_p": 36, "sanghai": [19, 37], "satisfactori": 57, "satisfi": 57, "save": [28, 37], "save_path": 50, "save_step": [42, 50], "scalabl": [57, 59], "scalar": [35, 49, 55, 57], "scale": [1, 2, 15, 16, 24, 35, 36, 37, 46, 57], "scan": 23, "schedul": 34, "scheme": [7, 35, 56], "scienc": 34, "score": [1, 2, 10, 31, 32, 35, 36, 41, 48, 49, 53, 55, 56, 58, 59, 60, 61, 62, 64], "scrape": 26, "scratch": [1, 2, 8, 61], "script": 42, "search": [27, 28, 41], "seattl": 0, "second": [5, 9, 10, 21, 27, 40, 56, 59], "secret": 8, "section": [2, 4, 58], "see": [2, 10, 19, 20, 21, 23, 32, 47, 59], "seed": [9, 12, 15, 62, 63], "seek": 35, "seen": 64, "segment": [6, 35], "select": [10, 17, 22, 26, 27, 28, 29, 31, 32, 35, 36, 41, 49, 55, 56], "selector": 41, "self": [1, 2, 3, 4, 8, 9, 12, 13, 29, 31, 32, 36, 48, 50], "selfattent": 4, "selfinstruct": 15, "semant": [13, 26, 27, 28, 63], "semi": 15, "send": [23, 56], "sensit": 37, "sentenc": [6, 9, 34, 59], "separ": [27, 29, 35, 41], "seq_len": 36, "seqlen": 36, "sequenc": [3, 4, 5, 6, 21, 29, 31, 32, 35, 36, 37, 53, 56, 57, 62], "sequenti": [21, 56], "seri": [12, 34, 39, 41, 62], "serv": [19, 22, 31, 32, 56, 61], "set": [1, 2, 4, 9, 10, 15, 16, 17, 21, 22, 24, 26, 29, 31, 32, 35, 36, 41, 48, 49, 53, 56, 58, 61, 62, 63], "setup": 24, "sever": [22, 26, 27, 29, 35, 56], "sexist": 58, "sft": [8, 40, 46, 47, 48, 50, 52, 53, 59, 61, 62], "sh": 50, "sha": [19, 37], "sha19": [19, 37], "shallow": 55, "shanghao": [19, 37], "shangyan": [19, 37], "shanhuang": [19, 37], "shao": [19, 37], "shaoq": [19, 37], "shape": [2, 23, 36], "share": 37, "shazeer": [19, 37], "shelf": [22, 57, 59], "shen": [19, 37], "shengfeng": [19, 37], "shift": 41, "shirong": [19, 37], "shiyu": [19, 37], "short": [2, 10, 13], "shorter": 22, "shot": [15, 41, 58, 59, 62, 64], "should": [9, 10, 20, 23, 24, 27, 37, 47, 53, 57, 58, 60], "show": [2, 4, 19, 20, 21, 29, 34, 37, 39, 41, 46, 47, 53, 57, 58, 61, 62], "shown": [12, 21, 24, 48, 49, 59, 61, 64], "shuang": [19, 37], "shuffl": 17, "shuip": [19, 37], "shunfeng": [19, 37], "sidestep": 56, "sigma": [5, 35, 36, 46, 47, 49, 53, 59, 61], "sigmoid": [5, 36, 46, 53], "signal": [15, 21, 28, 59, 60], "signatur": [13, 27, 29], "signific": [1, 2, 35, 37], "significantli": [9, 12, 22, 28, 29, 35, 37, 39, 41, 47, 58, 61], "silu": 36, "sim": [5, 21, 23, 35, 40, 46, 47, 48, 49, 53, 61, 64], "similar": [15, 19, 26, 27, 41, 58, 60], "similarili": 37, "similarli": [27, 47, 62, 64], "simpl": [4, 6, 9, 12, 17, 19, 23, 24, 26, 36, 39, 46, 59, 64], "simpler": [21, 46], "simpli": [9, 24, 40, 55], "simplic": 28, "simplifi": [9, 17, 36], "simul": [26, 56, 60], "simultan": [23, 62], "sin": [1, 2, 3, 4, 29, 36], "sinc": [2, 10, 21, 24, 27, 31, 32, 36, 37, 46, 47, 48, 53, 58, 59], "singl": [9, 10, 13, 26, 27, 28, 29, 31, 32, 41, 49, 60, 63], "sinusoid": 4, "six": 17, "size": [1, 2, 16, 19, 29, 31, 32, 34, 36, 37, 48, 57, 61], "skill": [16, 29, 62], "skywork": 8, "sl": 58, "slice": 37, "slight": 19, "slightli": 35, "slowli": [1, 2], "slp": [19, 37], "small": [2, 4, 10, 15, 19, 24, 26, 28, 29, 37, 62], "smaller": [22, 31, 32, 34, 35, 37, 40, 41], "smallest": [26, 36], "smallscal": 41, "smarter": 24, "smooth": 17, "snapshot": [26, 58], "snippet": [12, 29], "so": [1, 2, 10, 20, 26, 28, 35, 37, 47, 48, 56, 58, 62], "soft": [28, 59, 61], "softmax": [31, 32, 36, 37, 59], "sole": [21, 35, 57], "solid": 37, "solut": [4, 12, 13, 16, 26, 27, 28, 29, 37, 41, 46, 55, 59, 63], "solv": [13, 22, 26, 27, 28, 29, 40, 41], "solvabl": 13, "some": [9, 19, 26, 28, 31, 32, 35, 53, 55, 56, 57, 64], "someon": 58, "song": [19, 37], "sort": [36, 56], "sourc": [13, 17, 29, 30, 36, 53], "space": [3, 4, 17, 27, 28], "span": [19, 24, 29], "spars": 28, "speak": 53, "spearman": 55, "special": [19, 35, 36, 41, 64], "special_token": 36, "specif": [1, 2, 9, 17, 19, 21, 22, 28, 29, 31, 32, 36, 41, 46, 47, 53, 58, 61, 62], "specifi": [13, 36], "speed": 49, "sphinx": 19, "split": [27, 29, 36], "split_experience_batch": 50, "spm": 29, "sqrt": [1, 2, 4, 36, 37, 61], "squre": 36, "src": 42, "stabil": [34, 35, 36, 48], "stabl": 22, "stack": [12, 31, 32], "stackexchang": 34, "stage": [1, 2, 29, 35, 42, 48, 61], "stai": 21, "stale": 59, "stand": 19, "standalon": 29, "standard": [7, 13, 15, 22, 23, 26, 29, 30, 31, 32, 36, 41, 47, 48, 56, 57, 59, 60, 61], "star": 40, "starcod": [12, 17, 29], "starcoderdata": 12, "start": [10, 15, 17, 19, 20, 22, 27, 28, 29, 36, 46, 49, 53, 56, 62], "start_header_id": 36, "start_po": 36, "starter": 19, "state": [21, 24, 31, 32, 34, 55, 58], "statement": [13, 26, 29], "static": 21, "staticmethod": 36, "statu": 50, "std": [36, 48, 61], "steadi": 23, "steer": [24, 56, 64], "step": [2, 8, 10, 15, 17, 21, 23, 27, 28, 29, 34, 35, 39, 48, 49, 50, 58, 59, 63], "stepbi": 41, "still": [2, 24, 26, 46, 59], "stop": [23, 35], "stop_token": 36, "store": [19, 53], "str": [36, 53], "straightforward": [1, 2, 21, 53, 57], "straightforwardli": 55, "strategi": [22, 29, 31, 32, 35, 37, 40, 50, 55, 64], "stream": 23, "streamlin": 17, "strength": [49, 56, 57], "strict": [15, 36], "strictli": 62, "string": [10, 36, 40, 59], "strip": 36, "strong": [2, 19, 32, 37, 41, 55, 57, 61], "stronger": [12, 24, 37], "strongli": 58, "structur": [19, 28, 31, 32, 59], "struggl": [22, 61], "stuck": 21, "student": [12, 24], "studi": [15, 23, 24, 56, 57], "style": 29, "su": [19, 37], "sub": [3, 4, 28, 34, 36, 53], "subject": 29, "submiss": [26, 27], "submit": [27, 49, 56], "subsequ": [5, 29, 35, 36, 48, 56, 62], "subset": [13, 23], "substanti": [9, 17, 24, 40, 48, 57], "substitut": [31, 32, 46, 57], "subtract": 48, "subword": 6, "succ": [46, 53, 61, 64], "succeed": 28, "success": [24, 28, 35, 62, 63], "suffer": 40, "suffici": [2, 26, 35, 39, 47, 48], "suffix": 29, "suggest": [5, 22, 46, 47, 57, 59], "suitabl": [29, 55, 61], "sum": [4, 21, 36, 48, 55, 56], "sum_": [1, 2, 4, 6, 21, 31, 32, 36, 37, 40, 46, 48, 53, 57, 59, 61], "sumit": [19, 37], "summar": 2, "summari": 59, "sun": [19, 37], "sup": 8, "super": 36, "superalign": 24, "superhuman": 24, "superior": [22, 30, 62], "supervis": [3, 4, 15, 21, 24, 29, 46, 52, 53, 60, 62, 64], "supervison": 24, "supervisor": 24, "support": [7, 20, 29, 32, 50], "suppos": [55, 57], "sure": [9, 29, 58], "surfac": [27, 41, 60], "surpass": [17, 52], "surpris": 48, "surprisingli": 47, "surrog": 48, "surround": [10, 29], "suspect": 58, "swiglu": 34, "swish": [8, 36], "syntact": 26, "syntax": 19, "synthesi": 29, "synthet": [12, 52, 63, 64], "system": [36, 56], "systemat": 57, "t": [0, 2, 4, 10, 15, 17, 19, 21, 26, 31, 32, 36, 37, 48, 57, 62], "t1": 36, "t2": 36, "t_": [6, 47], "t_1": 6, "t_2": 6, "t_n": 6, "tabl": [37, 60], "tackl": 27, "tag": [10, 26, 27, 29], "tailor": [27, 56], "take": [3, 4, 5, 10, 12, 21, 29, 36, 41, 46, 47, 49, 53, 55, 56, 57, 62, 63, 64, 65], "taken": 21, "tan": [19, 37], "tang": [19, 37], "target": [2, 27, 36, 41, 53, 57, 58], "task": [2, 9, 10, 12, 13, 16, 21, 22, 24, 26, 28, 29, 41, 43, 48, 57, 58, 59, 61], "tau": [21, 40, 56], "td": 48, "teach": [24, 35], "teacher": 12, "team": 49, "technic": 24, "techniqu": [2, 8, 9, 17, 21, 22, 24, 28, 35, 61], "telecommun": 7, "tell": [24, 46], "temper": 26, "temperatur": [26, 27, 36, 56], "templat": [12, 15, 17, 42], "ten": [2, 29, 35], "tend": [56, 59], "tensor": [2, 36], "term": [2, 4, 5, 28, 35, 41, 46, 48, 57], "termin": 21, "terri": [46, 53, 55, 61], "test": [13, 16, 23, 24, 26, 27, 28, 29, 30, 40, 41, 62], "text": [1, 2, 5, 6, 7, 9, 13, 19, 20, 21, 23, 29, 31, 32, 35, 36, 37, 40, 41, 46, 47, 48, 49, 53, 55, 56, 57, 59, 61, 62, 64], "text_complet": 36, "textbf": 21, "th": [2, 17, 31, 32, 37, 47, 48, 62], "than": [1, 2, 9, 12, 15, 22, 24, 26, 27, 28, 29, 34, 37, 41, 46, 47, 53, 55, 58, 59, 60, 61], "thank": 57, "thei": [5, 7, 12, 19, 24, 26, 29, 35, 37, 41, 61, 62, 63], "them": [4, 15, 24, 27, 28, 37, 53, 60, 63], "themselv": [24, 49], "theoret": 47, "therebi": [31, 32], "therefor": [2, 10, 12, 15, 27, 35, 37, 41, 47, 48, 57, 61], "theta": [2, 3, 4, 21, 29, 35, 36, 40, 46, 47, 48, 49, 55, 56, 64], "theta_": [1, 2, 3, 4, 29, 36, 47, 48], "theta_0": [2, 36], "theta_1": [2, 36], "theta_j": 36, "thi": [1, 2, 4, 9, 12, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 40, 41, 46, 47, 48, 49, 53, 55, 56, 57, 58, 61, 62, 63, 64], "thing": [20, 58], "think": [2, 10, 58], "third": 10, "thompson": 56, "thorp": [19, 37], "those": [19, 22, 26, 31, 32, 35, 41, 56, 63], "thought": [10, 58, 59], "thousand": [2, 26, 27, 29, 35], "three": [5, 13, 21, 24, 29, 37, 41, 46, 49, 53, 57, 59, 61], "threshold": [36, 52, 64], "through": [1, 2, 3, 4, 5, 12, 17, 36, 37, 53, 55, 57, 59, 64], "thu": [17, 21, 23, 24, 35, 36, 40, 53, 55, 56, 60, 62], "tian": [19, 37], "tianyu": [19, 37], "tild": [35, 48, 56], "time": [17, 21, 26, 29, 31, 32, 35, 37, 40, 41, 43, 55, 59, 64], "titl": [7, 46], "to_remov": 53, "todai": 24, "togeth": [15, 26, 27, 58, 59], "tok": 36, "tok_embed": 36, "token": [0, 1, 2, 3, 4, 6, 8, 21, 26, 29, 30, 31, 32, 34, 35, 37, 40, 41, 47, 48, 49, 55, 57, 59], "token_logprob": 36, "tokenization\u4e4b\u540e": 0, "tokenization\u7b97\u6cd5\u4e4b\u4e00": 0, "tokenize\u7684\u610f\u601d\u662f\u628a\u4e00\u4e2a\u53e5\u5b50\u6216\u957f\u8bed\u6599\u5206\u6210token": 0, "token\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u7b26\u53f7": 0, "token\u6570": 0, "token\u66ff\u6362\u5b83\u4eec": 0, "toler": 41, "tolist": 36, "too": [2, 24], "tool": [6, 19, 26], "top": [12, 20, 22, 26, 35, 36, 55, 61, 64], "top_p": 36, "topic": 16, "topk": [31, 32], "torch": [2, 36], "total": [12, 15, 23, 27, 31, 32, 35, 37, 48], "total_len": 36, "toward": [15, 22, 31, 32, 40, 60, 64, 65], "toxic": 58, "trace": 40, "track": 53, "tractabl": 24, "tradeoff": 57, "train": [1, 2, 6, 9, 12, 15, 16, 19, 21, 22, 24, 26, 27, 29, 30, 35, 36, 37, 41, 46, 47, 48, 49, 50, 52, 53, 55, 57, 58, 59, 60, 61], "train_bash": 42, "train_batch_s": 50, "train_ppo": 50, "train_ppo_llama": 50, "trainabl": 43, "trainer": 50, "training_step_actor": 50, "training_step_crit": 50, "trajectori": 21, "transfer": [3, 4], "transform": [1, 2, 3, 4, 5, 19, 26, 29, 32, 34, 35, 37, 43], "transformerblock": 36, "transit": [21, 40], "transmit": 56, "transpos": 36, "trap": 40, "treat": [2, 20, 36, 61], "trend": 23, "tri": 62, "trick": [28, 50], "trigonometr": [1, 2, 36], "trim": 27, "triplet": [29, 53, 57], "triu": 36, "trl": 50, "troubl": 58, "trough": 29, "true": [35, 36, 42, 50], "truth": [13, 24, 46, 53, 55, 63], "try": [9, 28, 36, 47, 62], "trylimit": 28, "tune": [1, 2, 9, 15, 17, 30, 40, 41, 46, 47, 48, 50, 52, 53, 57, 60, 62], "tupl": [2, 36], "turbo": [12, 30, 36], "turn": [2, 29, 36, 41], "two": [2, 5, 10, 15, 17, 19, 20, 21, 22, 24, 26, 27, 28, 29, 31, 32, 35, 36, 37, 40, 41, 46, 47, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64], "tx": 56, "txt": 9, "type": [2, 9, 15, 17, 24, 26, 29, 34, 36, 53, 57, 58, 59, 61], "type_a": [2, 36], "typeddict": 36, "typic": [1, 2, 3, 4, 22, 24, 31, 32, 34, 47, 48, 56, 57, 58, 60, 64], "u": [10, 26, 27, 31, 32, 37, 41, 46, 53, 57, 61, 63], "u_": [31, 32], "uation": 10, "uk": 37, "ultim": [17, 24], "ultrafeedback": 55, "unambigu": 13, "unbias": [36, 48], "uncertainti": 56, "unchang": 40, "unclear": [24, 40], "uncur": 63, "under": [12, 21, 22, 46, 47], "underli": 2, "underset": [35, 40, 48, 55, 56, 64], "understand": [20, 24, 28, 29], "undesir": 21, "unembed": 49, "uneth": 58, "unicode\u548cutf": 7, "unicode\u5f53\u524d\u9ed8\u8ba4\u7684\u7248\u672c\u662fuc": 7, "unicode\u662fascii": 7, "unicode\u7684\u5b57\u7b26\u96c6\u8303\u56f4": 7, "unicode\u76f4\u63a5\u517c\u5bb9\u4e86\u521d\u671fascii": 7, "unifi": 17, "uniform": [29, 41, 53], "uniformli": [41, 56], "union": 36, "uniqu": [28, 29], "unit": [1, 2, 29, 35], "univers": 2, "unk": 53, "unknown": [46, 53], "unlabel": 64, "unlikelihood": 57, "unlock": 29, "unmerg": 50, "unpack": 8, "unsatisfactori": 57, "unsimplifi": 10, "unsupervis": 24, "unsur": 35, "until": [15, 27, 28, 53, 56], "unveil": 17, "up": [2, 9, 15, 16, 27, 35, 41, 49, 56, 57, 58], "updat": [23, 27, 50], "upgrad": 17, "upon": 22, "upper": [2, 22], "upweight": 21, "uq": 37, "url": [19, 37], "us": [1, 2, 3, 4, 5, 9, 10, 12, 15, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 34, 35, 36, 37, 41, 46, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65], "usag": 17, "use_fast_token": 42, "user": [9, 24, 29, 35, 36, 49, 61, 62, 63], "usual": [3, 4, 15, 31, 32, 37, 46, 48, 53, 63], "uszkoreit": [19, 37], "ut": 57, "util": [17, 28, 29, 35, 46, 58, 61], "uv": 37, "v": [3, 4, 5, 21, 36, 37, 55, 57, 60], "v0": 50, "v1": [12, 35], "v2": [8, 19, 35, 37], "v3": 35, "v5": [29, 35], "v_": [48, 55], "valid": [15, 16, 26, 28, 46, 49, 61, 64], "valu": [1, 2, 4, 10, 23, 26, 31, 32, 36, 47, 48, 49, 53, 57, 59, 64], "valuabl": [3, 4], "valueerror": 36, "vanish": 56, "var": 36, "vare": 23, "vari": [17, 23, 27, 31, 32, 34], "variabl": [3, 4], "varianc": [21, 35, 48, 56], "variant": [29, 36, 62], "variat": [5, 19, 26, 36, 60], "varieti": 23, "variou": [2, 10, 12, 15, 17, 23, 34, 58, 62], "vaswani": [19, 37], "vdot": [3, 4], "ve": 36, "vector": [1, 2, 4, 5, 29, 36, 37, 47, 55, 56], "verb": 9, "verbos": 55, "verdict": 63, "veri": [1, 2, 23, 24, 26, 49, 58, 60, 65], "verifi": [13, 40], "version": [5, 12, 27, 29, 35, 36, 42, 46, 63], "veryeasyhack": 58, "via": [22, 28, 29, 39, 46, 52, 55, 63], "view": [2, 36], "view_as_complex": [2, 36], "view_as_r": [2, 36], "violat": 60, "visual": 9, "vocab": 47, "vocab_s": 36, "vocabulari": 47, "vote": 41, "vsp": [19, 37], "w": [0, 3, 4, 5, 19, 36, 37, 46, 47, 49, 53, 55, 62, 63], "w1": 36, "w2": [5, 36], "w3": 36, "w_": [4, 5, 21, 36, 43], "wa": [10, 13, 17, 26, 27, 29, 35, 40, 62], "wai": [1, 2, 15, 21, 22, 24, 28, 53, 58], "wake": 9, "wang": [19, 37], "wangd": [19, 37], "want": [2, 15, 21, 49, 53], "warmup": 34, "wast": 26, "we": [1, 2, 3, 4, 5, 9, 10, 12, 13, 15, 17, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 39, 40, 41, 43, 46, 47, 48, 49, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65], "weak": [2, 8, 57], "weaker": 12, "weakli": [23, 24], "web": 53, "webpag": 49, "websit": 34, "webtext2": 23, "wei": [19, 37], "weigh": 46, "weight": [2, 4, 5, 21, 26, 34, 35, 36, 43, 46, 57, 59], "well": [2, 21, 30, 47, 57, 58], "wellcalibr": 58, "wen": [19, 37], "wenfeng": [19, 37], "wenjun": [19, 37], "wentao": [19, 37], "were": [35, 41], "west": 8, "what": [2, 9, 24, 34, 56], "when": [4, 5, 9, 10, 15, 19, 20, 21, 23, 24, 27, 28, 36, 40, 41, 47, 48, 55, 56, 57, 60, 61, 63], "where": [1, 2, 3, 4, 5, 15, 17, 21, 22, 23, 28, 29, 31, 32, 35, 36, 37, 39, 43, 46, 47, 48, 49, 53, 55, 56, 57, 59, 61, 62, 63], "wherea": [19, 21, 26], "wherebi": 35, "wherein": 57, "whether": [15, 19, 24, 26, 36, 40, 41, 57, 59, 63], "which": [1, 2, 3, 4, 5, 9, 10, 12, 13, 15, 17, 20, 21, 22, 23, 26, 27, 28, 29, 32, 35, 36, 41, 43, 46, 47, 48, 49, 53, 55, 56, 58, 59, 60, 61, 62, 63, 64], "while": [2, 4, 6, 12, 21, 23, 27, 28, 29, 31, 32, 40, 47, 48, 53, 56, 58, 61, 62], "whiten": 35, "whole": 57, "whose": 36, "why": [24, 28], "wide": [23, 24, 27, 48, 55, 61], "width": 36, "wifi": 58, "wiki": 34, "wikipedia": 34, "win": [53, 56, 59, 62, 63], "winner": 63, "wise": [2, 5, 36, 58], "within": [2, 10, 58, 63, 64], "without": [4, 10, 21, 24, 41, 46, 47, 49, 55, 56, 58, 63], "wizard": 8, "wk": 36, "wo": 36, "word": [0, 3, 4, 6, 9, 60], "wordpiece\u6bcf\u6b21\u9009\u62e9\u5408\u5e76\u7684\u4e24\u4e2a\u5b50\u8bcd": 6, "wordpiece\u7b97\u6cd5\u4e5f\u662f\u6bcf\u6b21\u4ece\u8bcd\u8868\u4e2d\u9009\u51fa\u4e24\u4e2a\u5b50\u8bcd\u5408\u5e76\u6210\u65b0\u7684\u5b50\u8bcd": 6, "work": [2, 5, 10, 12, 15, 21, 24, 34, 36, 46, 47, 58, 63], "world": 9, "world_siz": 50, "wors": 53, "worst": [22, 64], "would": [21, 24, 35, 41, 55, 58, 63], "wq": 36, "write": [4, 9, 13, 19, 20, 29, 35, 37, 49], "written": [15, 19, 20, 58], "wrong": [28, 41, 47], "wrote": [9, 58], "wu": [19, 37], "wv": 36, "wx": 43, "x": [0, 1, 2, 3, 4, 5, 6, 10, 19, 21, 29, 35, 36, 37, 40, 43, 46, 47, 48, 49, 52, 53, 55, 56, 57, 59, 61, 63, 64], "x9j": 10, "x9ja": 10, "x_": [1, 2, 4, 15, 36, 40, 63], "x_0": [1, 2, 36], "x_1": [1, 2, 36, 40, 52, 57], "x_2": [36, 40], "x_i": [40, 62, 63], "x_m": 57, "x_n": 52, "xdxac": 0, "xia": [19, 37], "xiangyu": [19, 37], "xianzu": [19, 37], "xiao": [19, 37], "xiaodong": [19, 37], "xiaohan": [19, 37], "xiaojin": [19, 37], "xiaokang": [19, 37], "xiaosha": [19, 37], "xiaotao": [19, 37], "xiaowen": [19, 37], "xiaoxiang": [19, 37], "xie": [19, 37], "xin": [19, 37], "xingkai": [19, 37], "xinnan": [19, 37], "xinyi": [19, 37], "xinyu": [19, 37], "xiong": [19, 37], "xk": [2, 36], "xk_": [2, 36], "xk_out": [2, 36], "xp": 5, "xq": [2, 36], "xq_": [2, 36], "xq_out": [2, 36], "xu": [19, 37], "xuan": [19, 37], "xuecheng": [19, 37], "xv": [5, 36], "xw": [5, 36], "xw_": [5, 36], "x\u4e3a\u5b57\u7b26\u7684unicode\u4e8c\u8fdb\u5236": 7, "y": [0, 6, 19, 21, 35, 36, 37, 40, 46, 47, 49, 52, 53, 55, 56, 57, 59, 61, 63], "y1": 46, "y2": 46, "y3": 46, "y_": [15, 21, 35, 40, 46, 47, 49, 52, 53, 55, 57, 61, 62, 63, 64], "y_1": [40, 46, 57, 59, 61, 64], "y_2": [40, 46, 59, 61, 64], "y_c": 61, "y_i": 40, "y_l": 47, "y_n": 57, "y_r": 61, "y_t": 57, "y_w": 47, "yaml": 28, "yan": [19, 37], "yang": [19, 37], "yanhong": [19, 37], "yanp": [19, 37], "yao": [19, 37], "yaofeng": [19, 37], "yaohui": [19, 37], "ye": [19, 37], "yi": [19, 37], "yichao": [19, 37], "yield": [13, 43, 48, 56, 61], "yiliang": [19, 37], "yilong": [19, 37], "ying": [19, 37], "yishi": [19, 37], "yixin": [19, 37], "yixuan": [19, 37], "yiyuan": [19, 37], "yongji": [19, 37], "yongqiang": [19, 37], "you": [9, 10, 19, 20, 29, 35, 37, 58, 61], "your": [10, 19, 20, 29, 58], "yu": [19, 37], "yuan": [19, 37], "yuchen": [19, 37], "yuduan": [19, 37], "yuheng": [19, 37], "yukun": [19, 37], "yunfeng": [19, 37], "yunxian": [19, 37], "yuri": [19, 37], "yute": [19, 37], "yuxiang": [19, 37], "yuxuan": [19, 37], "z": [0, 6, 19, 37, 46, 53, 56], "z_": 53, "zabdzabac": 0, "zehui": [19, 37], "zemlyanskii": [19, 37], "zeng": [19, 37], "zero": [4, 21, 35, 36], "zero_stag": 50, "zeros_lik": 36, "zha": [19, 37], "zhang": [19, 37], "zhangli": [19, 37], "zhao": [19, 37], "zhe": [19, 37], "zhen": [19, 37], "zhenda": [19, 37], "zheng": [19, 37], "zhewen": [19, 37], "zhihong": [19, 37], "zhiniu": [19, 37], "zhipeng": [19, 37], "zhongyu": [19, 37], "zhou": [19, 37], "zhu": [19, 37], "zhuoshu": [19, 37], "zihan": [19, 37], "zihui": [19, 37], "zilin": [19, 37], "zip": [36, 53], "ziwei": [19, 37], "zou": [19, 37], "zy": [0, 10], "zydzyac": 0, "\u4e00": 7, "\u4e00\u4e2a\u5728\u5f00\u5934": 0, "\u4e00\u822c\u4e0d\u76f4\u63a5\u4f7f\u7528unicod": 7, "\u4e00\u90e8\u5206\u6b63\u8d1f\u62b5\u6d88\u4e00\u90e8\u5206\u632f\u8361": 1, "\u4e00\u95e8\u8bed\u8a00\u4e2d": 0, "\u4e0a\u9762\u4ecb\u7ecd\u4e86\u6587\u5b57\u5b57\u7b26\u6620\u5c04\u4e3aunicode\u5b57\u7b26\u96c6": 7, "\u4e0b\u4e00\u4e2a\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u662f": 0, "\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50": 0, "\u4e0b\u9762\u7684\u793a\u4f8b\u5c06\u89e3\u91ca": 0, "\u4e0d\u4f1a\u51fa\u73b0\u53ea\u5b66\u90a3\u4e9b\u7b80\u5355\u4e14": 48, "\u4e0d\u4f1a\u5355\u72ec\u51fa\u73b0": 0, "\u4e0d\u8868\u793a\u5176\u4ed6\u8bed\u8a00": 7, "\u4e0d\u8db3\u7684\u5728\u9ad8\u4f4d\u75280\u8865\u5145": 7, "\u4e0ebpe\u7684\u6700\u5927\u533a\u522b\u5728\u4e8e": 6, "\u4e0ebpe\u7b97\u6cd5\u7c7b\u4f3c": 6, "\u4e14\u5047\u8bbe\u5404\u4e2a\u5b50\u8bcd\u4e4b\u95f4\u662f\u72ec\u7acb\u5b58\u5728\u7684": 6, "\u4e2a": 0, "\u4e2a\u4e0d\u540c\u7684token": 0, "\u4e2a\u5355\u8bcd": 0, "\u4e2a\u5b50\u8bcd\u7ec4\u6210": 6, "\u4e2d\u4f7f\u7528\u4e86\u4e0a\u8ff0\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53": 0, "\u4e2d\u51cf\u5c11\u8ba1\u6570": 0, "\u4e2d\u5b58\u5728": 0, "\u4e2d\u6587": 7, "\u4e2d\u76f8\u5bf9\u597d\u7684": 48, "\u4e2d\u88ab\u9996\u6b21\u63d0\u51fa": 0, "\u4e3a\u4e86\u4ee5\u6700\u6709\u6548\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u6599\u5e93": 0, "\u4e3a\u4e86\u5408\u5e76": 0, "\u4e3a\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3": 0, "\u4e3a\u4e86\u672c\u6587\u7684\u7b80\u5355\u8d77\u89c1": 0, "\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4": 7, "\u4e3a\u4e86\u89e3\u51b3": 7, "\u4e3a\u53e5\u5b50\u7684\u4e00\u4e2a\u5206\u8bcd\u7ed3\u679c": 6, "\u4e3a\u8865\u5145": 7, "\u4e3e\u4f8b1": 7, "\u4e3e\u4f8b2": 7, "\u4e4b\u524d": 7, "\u4e5f\u53eb\u5b57\u7b26\u96c6": 7, "\u4e5f\u5c31\u662f\u4e24\u5b50\u8bcd\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u5173\u8054\u6027": 6, "\u4e5f\u5c31\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u770b\u6210\u4e00\u4e2atoken": 0, "\u4e5f\u5c31\u662f\u7528\u5b9a\u957f2\u4e2a\u5b57\u8282\u6765\u8868\u793a\u5b57\u7b26": 7, "\u4e5f\u662fnlp\u4e2d\u6700\u91cd\u8981\u7684\u7f16\u7801\u65b9\u5f0f\u4e4b\u4e00": 0, "\u4e5f\u80fd\u88ab\u7b97\u4f5c\u5b57\u7b26\u5bf9\u7684\u4e00\u90e8\u5206": 0, "\u4e8c\u8fdb\u5236\u5c31\u662f01000001": 7, "\u4e8c\u8fdb\u5236\u5c31\u662f110000": 7, "\u4eca\u5929\u5c31\u6765\u4e86\u89e3\u4e0b\u5b57\u7b26\u5728\u8ba1\u7b97\u673a\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f": 7, "\u4ece\u6700\u957f\u5230\u6700\u77ed": 0, "\u4ece\u800c\u6211\u4eec\u77e5\u9053\u5269\u4f59\u7684": 0, "\u4ed6\u4eec\u5177\u6709\u6700\u5927\u7684\u4e92\u4fe1\u606f\u503c": 6, "\u4ee5\u4e2d\u6587": 7, "\u4f1a\u4e0d\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5f88\u6162": 48, "\u4f1a\u4e0d\u4f1a\u66f4\u597d": 48, "\u4f3c\u7136\u503c\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a": 6, "\u4f46\u4e00\u4e2a\u8bcd\u5728\u7ed3\u5c3e\u6709\u4e00\u4e2a": 0, "\u4f46\u4ecd\u6709\u53ef\u80fd\u51fa\u73b0\u4e0d\u5728\u91cc\u9762\u7684\u5355\u8bcd": 0, "\u4f46\u5b83\u5177\u6709\u826f\u597d\u7684\u6027\u80fd": 0, "\u4f46\u6211\u4eec\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u5305\u542b\u8fd9\u4e9b\u5b57\u7b26": 0, "\u4f46\u662funicode\u8fd8\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6269\u5c55\u673a\u5236": 7, "\u4f46\u662f\u5176\u4ed6\u6b27\u6d32\u56fd\u5bb6\u7684\u8bed\u8a00\u6bd4\u5982\u6cd5\u8bed": 7, "\u4f46\u662f\u5b83\u548c\u6c49\u5b57\u7684\u6620\u5c04\u4e0eunicode\u548c\u6c49\u5b57\u7684\u6620\u5c04\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb": 7, "\u4f46\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u5408\u7406\u7684\u7f16\u7801\u65b9\u5f0f": 0, "\u4f4e\u7ef4": 1, "\u4f4e\u9891\u5185\u63d2\u7684\u65b9\u5f0f": 1, "\u4f60\u53ef\u80fd\u4e0d\u6e05\u695awordpiece\u662f\u5982\u4f55\u9009\u53d6\u5b50\u8bcd\u7684": 6, "\u4f8b\u5982\u7f16\u7801\u5e8f\u5217": 0, "\u4fee\u6539\u540e\u663e\u793a\u7ed3\u679c\u5982\u4e0b": 7, "\u5047\u8bbe\u5355\u8bcd\u7684\u5e8f\u5217\u662f": 0, "\u5047\u8bbe\u53e5\u5b50": 6, "\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8bed\u6599\u5e93": 0, "\u5047\u8bbe\u6211\u4eec\u6709\u9700\u8981\u7f16\u7801": 0, "\u5047\u8bbe\u628a\u76f8\u90bb\u4f4d\u7f6e\u7684x\u548cy\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 6, "\u5047\u8bbe\u8fd9\u4e9b\u8bcd\u51fa\u73b0\u7684\u9891\u7387\u5982\u4e0b": 0, "\u50cf": 0, "\u5141\u8bb8\u8868\u793a\u4e00\u767e\u591a\u4e07\u4e2a\u5b57\u7b26": 7, "\u5168\u7403\u7edd\u5927\u90e8\u5206\u5b57\u7b26\u7684\u5b57\u7b26\u96c6": 7, "\u5176\u4e2d": 0, "\u5176\u4e2d\u4e0d\u6b62utf": 7, "\u5176\u4e2d\u4f1a\u6d89\u53ca\u5230ascii": 7, "\u5176\u4e2d\u5305\u542b\u5355\u8bcd": 0, "\u5176\u4ed6\u5b57\u8282": 7, "\u5176\u4ed6\u8bed\u8a00": 7, "\u5176\u4ed6\u8bed\u8a00\u53ef\u80fd\u6709\u6240\u4e0d\u540c": 0, "\u51fa\u73b0\u4e86": 0, "\u5219\u53e5\u5b50": 6, "\u521d\u59cbtoken\u5c06\u662f\u6240\u6709\u5b57\u7b26\u548c": 0, "\u524d\u9762\u5168\u90e8\u586b\u51450": 7, "\u5269\u4e0b\u7684\u552f\u4e00\u5b57\u8282\u5bf9\u662f": 0, "\u52a0\u4e0a\u63a7\u5236\u7801\u540e\u5bf9\u5e94\u7684utf": 7, "\u5341\u516d\u8fdb\u5236": 7, "\u5355\u5b57\u8282256\u4e2a\u5b57\u7b26\u80af\u5b9a\u6ca1\u6cd5\u5b8c\u5168\u8868\u793a": 7, "\u5373": 0, "\u538b\u7f29": 0, "\u539f\u672c\u5728\u4f4e\u7ef4\u5ea6\u4e0a": 1, "\u53cd\u5411\u6267\u884c\u4ee5\u4e0a\u8fc7\u7a0b\u5c31\u884c\u4e86": 0, "\u53cd\u590d\u8fed\u4ee3\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6": 0, "\u53ea\u9700\u8981\u4e00\u4e2a\u5b57\u8282\u8868\u793a": 7, "\u53ea\u9700\u8981\u4f7f\u7528\u540e\u97627\u4f4d\u5c31\u8db3\u591f\u4e86": 7, "\u53ef\u4ee5\u4f7f\u75281": 7, "\u5404\u4e2a\u56fd\u5bb6\u4fbf\u7740\u624b\u81ea\u5df1\u56fd\u5bb6\u8bed\u8a00\u7684\u7f16\u7801": 7, "\u5408\u5e76\u505c\u6b62token": 0, "\u5408\u5e76\u540e\u4ea7\u751f\u7684\u5b50\u8bcd\u8bb0\u4e3az": 6, "\u5408\u5e76\u5b57\u7b26\u53ef\u4ee5\u8ba9\u4f60": 0, "\u5408\u5e76\u5b83\u4eec": 0, "\u540c\u7406\u8fd8\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u7279\u6709\u5b57\u7b26\u96c6": 7, "\u548c": [0, 1], "\u548cascii\u7684\u76ee\u7684\u4e00\u6837": 7, "\u548cascii\u7801\u4e00\u81f4": 7, "\u56de\u8f6613\u7b49\u7b49\u4e00\u4e9b\u952e\u76d8\u4e0a\u6240\u89c1\u7684\u7b26\u53f7": 7, "\u56e0\u4e3a": 0, "\u56e0\u4e3a\u4eba\u7c7b\u8bed\u8a00\u4e5f\u7ecf\u5e38\u4ee5\u5355\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u4ea4\u6d41": 0, "\u56e0\u4e3a\u5b83\u4eec\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 0, "\u56e0\u4e3a\u6211\u4eec\u7edf\u8ba1\u76f8\u90bb\u5b57\u7b26\u5bf9\u65f6\u4e0d\u80fd\u628a\u5206\u522b\u4f4d\u4e8e\u4e24\u4e2a\u5355\u8bcd\u4e2d\u7684\u5b57\u7b26\u5bf9\u7b97\u8fdb\u53bb": 0, "\u56e0\u4e3a\u6ca1\u6709\u51fa\u73b0\u591a\u6b21\u7684\u5b57\u8282\u5bf9": 0, "\u56e0\u6b64": 0, "\u56e0\u6b64bpe\u4e5f\u662f\u5178\u578b\u7684\u57fa\u4e8esubword\u7684tokenization\u7b97\u6cd5": 0, "\u56e0\u6b64\u6211\u4eec\u53ef\u91c7\u7528\u9ad8\u9891\u5916\u63a8": 1, "\u56e0\u6b64\u6211\u4eec\u5c06\u7528\u4e00\u4e2a\u65b0\u5b57\u8282": 0, "\u56e0\u6b64\u6211\u4eec\u6ca1\u6709\u5c06\u5b83\u4eec\u5408\u5e76": 0, "\u5728finest\u548clowest\u4e24\u4e2a\u8bcd\u4e2d": 0, "\u5728unicode\u8bde\u751f": 7, "\u5728\u5b9e\u8df5\u4e2d": 0, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d": 0, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 0, "\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0": 0, "\u5728\u8ba1\u7b97\u673a\u4e2d\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u4f4d0\u548c1\u6765\u5b58\u50a8\u7684": 7, "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u65f6\u5019\u9700\u8981\u5728\u8fd9\u4e2a\u62e5\u6709\u51e0\u4e07\u4e2a\u5355\u8bcd\u7684\u5217\u8868\u4e0a\u8ba1\u7b97\u4e00\u4e2a\u6982\u7387\u5206\u5e03": 0, "\u5728\u8fd9\u91cc": 0, "\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u6bd4\u8f83token\u7684\u9891\u7387\u5927\u5c0f\u6765\u7a77\u5c3d\u6bcf\u4e00\u79cd\u53ef\u80fd": 0, "\u5927\u5199\u5b57\u6bcda\u5bf9\u5e94\u7684ascii\u7801\u662f65": 7, "\u5927\u5bb6\u90fd\u77e5\u9053\u7535\u8111\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u548c\u5b58\u50a8\u7684": 7, "\u5927\u6982\u5c31\u662f\u8bf4ascii\u662f\u7f8e\u56fd\u4fe1\u606f\u4ea4\u6362\u6807\u51c6\u4ee3\u7801": 7, "\u5927\u90e8\u5206\u662f2\u5b57\u8282": 7, "\u5982\u4f55\u6765\u8868\u793aunicod": 7, "\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u5c31\u662f\u8981\u8868\u793a\u4e00\u4e2a\u5b57\u7b26\u8fd8\u662f\u8fde\u7eed\u7684\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 7, "\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u8bfb\u61c2unicod": 7, "\u5982\u4f55\u8bfb\u53d6unicode\u5b57\u7b26\u96c6": 7, "\u5982\u4f55\u9009\u62e9\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 6, "\u5982\u679c\u4f1a\u7559\u4e0b\u51e0\u4e2a\u5b50\u4e32": 0, "\u5982\u679c\u5728\u4f4e\u7ef4\u5ea6\u8fdb\u884c\u5185\u63d2": 1, "\u5982\u679c\u6309\u7167unicode\u7684\u65b9\u5f0f\u7edf\u4e00\u7528\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 7, "\u5982\u679c\u7b97\u6cd5\u770b\u5230token": 0, "\u5b57\u6bcd": 7, "\u5b57\u7b26\u7801\u5c31\u662f\u5bf9\u5e94\u7684unicod": 7, "\u5b57\u7b26\u7801\u7ec4\u6210": 7, "\u5b57\u7b26\u7b49": 0, "\u5b57\u7b26\u96c6\u5373\u662f\u6587\u5b57\u7b26\u53f7\u548c\u4e8c\u8fdb\u5236\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 7, "\u5b57\u8282\u957f\u5ea6": 7, "\u5b66\u540c\u4e00\u4e2a": 48, "\u5b83\u4e0d\u80fd\u88ab\u8fdb\u4e00\u6b65\u538b\u7f29": 0, "\u5b83\u4eec\u51fa\u73b0\u4e86": 0, "\u5b83\u4eec\u7ecf\u5e38\u5728\u8bed\u6599\u4e2d\u4ee5\u76f8\u90bb\u65b9\u5f0f\u540c\u65f6\u51fa\u73b0": 6, "\u5b83\u53ea\u6709\u4e00\u4e2a": 0, "\u5b83\u5728": 0, "\u5b83\u5c31\u4f1a\u77e5\u9053\u5b83\u662f": 0, "\u5b83\u7684\u4f5c\u7528\u662f\u628a\u5404\u4e2a\u8bed\u8a00\u7684\u5b57\u7b26\u6620\u5c04\u4e3a\u4e8c\u8fdb\u5236": 7, "\u5b83\u7684\u7279\u70b9\u662f\u53d8\u957f\u7f16\u7801": 7, "\u5b83\u9075\u5faa\u4e00\u79cd\u8d2a\u5a6a\u7684\u7b56\u7565\u6765\u5c3d\u53ef\u80fd\u53d6\u5f97\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848": 0, "\u5b8c\u5168\u517c\u5bb9ascii": 7, "\u5bf9\u4e0eascii\u7a7a\u95f4\u6d6a\u8d39": 7, "\u5bf9\u4e8e\u5355\u5b57\u8282\u7684\u5b57\u7b26": 7, "\u5bf9\u4e8e\u53e5\u5b50": 6, "\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u662f\u6781\u5927\u7684\u6d6a\u8d39": 7, "\u5bf9\u4e8e\u672a\u77e5": 0, "\u5bf9\u4e8e\u82f1\u6587\u56fd\u5bb6\u6765\u8bf4\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528": 7, "\u5bf9\u4e8e\u9700\u8981n\u4e2a\u5b57\u8282\u7684\u5b57\u7b26": 7, "\u5bf9\u5e94\u7684unicode\u5b57\u7b26\u96c6\u662f4e00": 7, "\u5bf9\u5e94\u7684unicode\u662fu": 7, "\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a01000001": 7, "\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u7f16\u7801\u7684\u8fc7\u7a0b\u8fd8\u662f\u6bd4\u8f83\u7b80\u5355\u7684": 0, "\u5bf9\u7528\u4f4e\u7ef4\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u95f4\u7684\u80fd\u529b\u5f71\u54cd\u66f4\u5927": 1, "\u5bfb\u627e\u6700\u5e38\u51fa\u73b0\u7684\u5b57\u8282\u5bf9": 0, "\u5c31\u4ee3\u8868\u4e00\u4e2a\u8bed\u8a00\u5355\u4f4d": 0, "\u5c31\u50cf\u5355\u8bcd": 0, "\u5c31\u662f\u4f7f\u7528\u63a7\u5236\u7801": 7, "\u5c31\u80fd\u4ee3\u8868\u4e86\u6240\u6709\u952e\u76d8\u4e0a\u7684\u666e\u901a\u7b26\u53f7": 7, "\u5c31\u8bde\u751f\u4e86utf": 7, "\u5c3d\u7ba1\u8d2a\u5a6a": 0, "\u5e74\u53d1\u8868\u7684\u6587\u7ae0": 0, "\u5e76\u4e00\u6b21\u53c8\u4e00\u6b21\u5730\u6267\u884c\u76f8\u540c\u7684\u8fed\u4ee3": 0, "\u5e76\u4e14\u6211\u4eec\u7684\u5b50\u5b57\u7b26\u4e32\u5c06\u88ab\u66ff\u6362\u4e3a\u6211\u4eectoken\u5217\u8868\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684token\u7ec4\u5408": 0, "\u5e76\u4e14\u7531utf": 7, "\u5e76\u5c06\u5176\u9891\u7387\u8bb0\u4e3a": 0, "\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230token\u5217\u8868\u4e2d": 0, "\u5e76\u5c06\u65b0\u8bcd\u7684token\u6dfb\u52a0\u5230\u6211\u4eec\u7684token\u5b57\u5178\u4e2d\u4ee5\u5907\u5c06\u6765\u7528\u5230": 0, "\u5e76\u5c1d\u8bd5\u4f7f\u7528\u8fd9\u4e9btoken\u66ff\u6362\u7ed9\u5b9a\u5355\u8bcd\u5e8f\u5217\u4e2d\u7684\u5b50\u5b57\u7b26\u4e32": 0, "\u5e76\u88ab\u4f5c\u4e3a\u673a\u5668\u7ffb\u8bd1\u7b49\u4e3b\u6d41nlp\u4efb\u52a1\u7684\u9996\u9009tokenize\u65b9\u6cd5\u4e4b\u4e00": 0, "\u5e76\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2atoken\u51fa\u73b0\u7684\u9891\u7387": 0, "\u5f00\u5934": 7, "\u5f00\u59cb": 0, "\u5f53\u524d\u5206\u8bcd\u4e0b\u53e5\u5b50s\u7684\u4f3c\u7136\u503c\u53ef\u4ee5\u8868\u793a\u4e3a": 6, "\u5f53\u7136": 0, "\u610f\u5473\u7740\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u53f7\u53d8\u5316\u975e\u5e38\u8fc5\u901f": 1, "\u6211\u4eec\u4f1a\u5c06": 0, "\u6211\u4eec\u5148\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5b83\u7684\u6838\u5fc3\u601d\u60f3": 0, "\u6211\u4eec\u53ef\u4ee5\u770b\u5230": 0, "\u6211\u4eec\u53ef\u4ee5\u9012\u5f52\u5730\u4f7f\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u5c06": 0, "\u6211\u4eec\u5c06tokenized\u597d\u7684\u5355\u8bcd\u4fdd\u5b58\u5728\u5b57\u5178\u4e2d": 0, "\u6211\u4eec\u5c06\u4ece\u7b2c\u4e8c\u5e38\u89c1\u7684\u6807\u8bb0": 0, "\u6211\u4eec\u5c06\u5b57\u7b26\u89c6\u4e3a\u4e0e\u5b57\u8282\u7b49\u4ef7": 0, "\u6211\u4eec\u5c06\u5b83\u4eec\u5408\u5e76\u4ee5\u5f62\u6210\u4e00\u4e2a\u65b0\u7684token": 0, "\u6211\u4eec\u5c06\u6bcf\u4e2a\u5355\u8bcd\u62c6\u5206\u4e3a\u5b57\u7b26\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684\u51fa\u73b0\u6b21\u6570": 0, "\u6211\u4eec\u5c06\u7528unknown": 0, "\u6211\u4eec\u5c06\u7ee7\u7eed\u6267\u884c\u6b64\u5408\u5e76\u6b65\u9aa4": 0, "\u6211\u4eec\u5c06\u88ab\u89e3\u7801\u4e3a": 0, "\u6211\u4eec\u5c06\u904d\u5386\u6211\u4eec\u5728\u8bed\u6599\u5e93\u4e2d\u627e\u5230\u7684\u6240\u6709token": 0, "\u6211\u4eec\u5c06\u904d\u5386\u6240\u6709token": 0, "\u6211\u4eec\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8bcd\u6c47\u5217\u8868\u662f\u5f88\u5927\u7684": 0, "\u6211\u4eec\u5e94\u7528\u4e0a\u8ff0\u7f16\u7801\u65b9\u6cd5\u5bf9\u65b0\u8bcd\u8fdb\u884ctoken": 0, "\u6211\u4eec\u5fc5\u987b\u7b80\u5355\u5730\u5c06\u6240\u6709token\u8fde\u63a5\u5728\u4e00\u8d77\u4ee5\u83b7\u5f97\u6574\u4e2a\u5355\u8bcd": 0, "\u6211\u4eec\u603b\u5171\u6709": 0, "\u6211\u4eec\u6709\u4e00\u4e2a\u9891\u7387\u4e3a": 0, "\u6211\u4eec\u6765\u67e5\u51fa\u8fd9\u51e0\u4e2a\u5b57\u5bf9\u5e94\u7684utf": 7, "\u6211\u4eec\u73b0\u5728\u5c06\u5408\u5e76token": 0, "\u6211\u4eec\u73b0\u5728\u6709": 0, "\u6211\u4eec\u73b0\u5728\u6709\u4e86": 0, "\u6211\u4eec\u73b0\u5728\u770b\u5230\u5b57\u8282\u5bf9": 0, "\u6211\u4eec\u7684\u6570\u636e\u73b0\u5728\u5df2\u8f6c\u6362\u4e3a": 0, "\u6211\u4eec\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6ca1\u6709\u770b\u5230\u7684\u8bcd": 0, "\u6211\u4eec\u770b\u5230\u5b57\u8282\u5bf9": 0, "\u6211\u4eec\u77e5\u9053": 0, "\u6211\u4eec\u8ba1\u7b97\u8fd9\u4e9b\u8bcd\u5728\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387": 0, "\u6211\u4eec\u8fd8\u5c06\u4ece\u5355\u4e2atoken": 0, "\u6211\u4eec\u90fd\u4e86\u89e3\u4e00\u79cd\u6700\u57fa\u672c\u7684token": 0, "\u6216": 0, "\u6216\u8005\u53eb": 7, "\u6240\u4ee5": [0, 6], "\u6240\u4ee5ascii\u7684\u5b57\u7b26": 7, "\u6240\u4ee5\u4ed6\u4eec\u5c31\u628a\u7b2c\u4e00\u4e2a\u7a7a\u95f20\u4f7f\u7528\u4e86\u8d77\u6765": 7, "\u6240\u4ee5\u4ed6\u4eec\u628a\u6bcf\u4e2a\u5b57\u8282\u7684\u7b2c\u4e00\u4f4d\u7f6e\u7f6e0": 7, "\u6240\u4ee5\u4f7f\u7528\u4e24\u4e2a\u5b57\u8282\u5df2\u7ecf\u8db3\u591f": 7, "\u6240\u4ee5\u5bf9\u5e94\u7684utf": 7, "\u6240\u4ee5\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u5168\u7403\u7edf\u4e00\u7684\u7f16\u7801\u89c4\u5219\u53ebunicod": 7, "\u6240\u4ee5\u6211\u4eec\u4e0d\u5bf9\u5b83\u8fdb\u884c\u7f16\u7801": 0, "\u6240\u4ee5\u6211\u4eec\u6709": 0, "\u6240\u4ee5\u8fd9\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898": 7, "\u63a5\u4e0b\u6765": 0, "\u63a7\u5236\u7801\u5c31\u662f\u544a\u8bc9\u8ba1\u7b97\u673a\u5f53\u524d\u662f\u5355\u5b57\u8282\u8fd8\u662f\u591a\u5b57\u8282": 7, "\u6563\u5ea6\u76f4\u63a5\u653e\u5728": 48, "\u6570\u5b57\u548c\u5b57\u6bcd\u90fd\u672a\u4e71\u7801": 7, "\u6570\u636e\u7684\u538b\u7f29": 0, "\u659c\u4f53": 7, "\u65b0": 0, "\u65b0\u5efa\u4e00\u4e2ahtml\u8f93\u5165": 7, "\u65cb\u8f6c\u5f97\u8d8a\u591a": 1, "\u65cb\u8f6c\u5f97\u8d8a\u5c11": 1, "\u65cb\u8f6c\u89d2\u5ea6\u8f83\u5927": 1, "\u65e0\u8bba\u5982\u4f55": 0, "\u65e0\u8bba\u662fascii\u7f16\u7801\u8fd8\u662futf": 7, "\u65e5\u6587": 7, "\u65f6": 1, "\u662f\u4e00\u79cd\u7b80\u5355\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5": 0, "\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684sub": 0, "\u662f\u7684": 0, "\u666e\u901a\u7b26\u53f7\u7684\u5b57\u7b26\u96c6": 7, "\u66ff\u6362\u5b83": 0, "\u6700\u5e38\u51fa\u73b0": 0, "\u6700\u5e38\u89c1\u7684\u5e26\u6709": 0, "\u6700\u7ec8": 0, "\u6700\u7ec8\u5bfc\u81f4": 1, "\u6709\u4e00\u79cd\u7f16\u7801\u65b9\u5f0f\u80fd\u5927\u5927\u51cf\u5c0ftoken": 0, "\u6709\u5f88\u591a\u9ad8\u9891\u7ef4\u5ea6\u8f6c\u4e86\u5f88\u591a\u5708": 1, "\u672a\u63d0\u53ca\u7684\u4f4d\u4f7f\u7528\u5bf9\u5e94\u7684unicode\u8865\u5145": 7, "\u6765\u505a\u4e00\u4e2a\u5c0f\u5b9e\u9a8c\u5e76\u4e14\u9a8c\u8bc1\u4e0b": 7, "\u6765\u8bf4": 7, "\u67e5\u770b\u5176\u4ed6token": 0, "\u6807\u8bb0\u4ee5\u6807\u8bc6\u5355\u8bcd\u8fb9\u754c\u80fd\u591f\u8ba9\u7b97\u6cd5\u77e5\u9053\u6bcf\u4e2a\u5355\u8bcd\u7684\u7ed3\u675f\u4f4d\u7f6e": 0, "\u6807\u8bb0\u7684\u96c6\u5408": 0, "\u6a21\u4eff\u663e\u8457\u6027": 24, "\u6b21": 0, "\u6b27\u6d32\u90e8\u5206\u8bed\u8a00\u5b57\u6bcd\u7684\u5b57\u7b26\u96c6": 7, "\u6b64\u65f6\u53e5\u5b50": 6, "\u6bd4\u5982utf": 7, "\u6bd4\u5982\u4e2d\u56fd1980\u5e74\u53d1\u884c\u4e86gb2312\u4ee5\u53ca\u540e\u9762\u51fa\u73b0\u5b83\u7684\u6269\u5c55\u7248\u672cgbk": 7, "\u6bd4\u5982\u5728ascii\u4e2d": 7, "\u6bd4\u5982\u5927\u5199\u5b57\u6bcda": 7, "\u6bd4\u5982\u6c49\u5b57": 7, "\u6bd4\u5982\u6c49\u5b57\u4e00\u5728unicode\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662f4e00": 7, "\u6bd4\u5982\u82f1\u6587\u5b57\u6bcda\u5bf9\u5e94\u7684unicode\u662fu": 7, "\u6bd4\u5982\u8bf4\u4e2d\u6587": 7, "\u6c49\u5b57": 7, "\u6c49\u5b57\u7684\u5b57\u7b26\u96c6": 7, "\u6ca1\u6709": 48, "\u6d4f\u89c8\u5668\u6253\u5f00\u540e\u663e\u793a\u6b63\u5e38": 7, "\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7": 0, "\u7136\u540e\u6211\u4eec\u4f7f\u7528chrome\u7684charset\u63d2\u4ef6\u6765\u4fee\u6539\u5f53\u524d\u9875\u9762\u89e3\u7801\u7684\u5b57\u7b26\u96c6": 7, "\u7136\u800c": 0, "\u73b0\u5728\u6211\u4eec\u53d1\u73b0": 0, "\u73b0\u5728\u6211\u4eec\u5c06\u6700\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u5408\u5e76\u6210\u4e00\u4e2atoken": 0, "\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u89e3\u7801\u6211\u4eec\u7684\u793a\u4f8b": 0, "\u7528\u6700\u5c11\u7684token\u6765\u8868\u793a\u8bed\u6599\u5e93": 0, "\u7528\u6765\u8868\u793a\u7535\u8111\u548c\u5176\u4ed6\u7535\u4fe1\u8bbe\u5907\u7684\u6587\u672c": 7, "\u7531": 6, "\u7531m\u4e2a\u5b50\u8bcd\u7ec4\u6210": 6, "\u7531\u4e8eascii\u8868\u793a\u7684\u8303\u56f4\u6709\u9650": 7, "\u7531\u4e8e\u6211\u4eec\u603b\u5171\u6709": 0, "\u7684": 0, "\u7684\u4f18\u52bf": 48, "\u7684\u5b57\u7b26\u91cf\u5df2\u7ecf\u8db3\u4ee5\u7528\u4e8e\u5168\u7403\u4e3b\u8981\u8bed\u8a00\u7684\u5927\u591a\u6570\u5b57\u7b26": 7, "\u7684\u5b57\u8282\u5bf9\u662f": 0, "\u7684\u60c5\u51b5": 48, "\u7684\u6548\u679c": 48, "\u7684\u6570\u636e": 0, "\u7684\u65b0token": 0, "\u7684\u7b2c\u4e00\u5b57\u8282\u5168\u662f0": 7, "\u7684\u8bed\u8a00\u6a21\u578b\u4f3c\u7136\u503c\u7b49\u4ef7\u4e8e\u6240\u6709\u5b50\u8bcd\u6982\u7387\u7684\u4e58\u79ef": 6, "\u7684\u9891\u7387\u4e3a": 0, "\u7684\u9891\u7387\u51cf\u5c11": 0, "\u76f4\u5230\u8fbe\u5230\u6211\u4eec\u9884\u5148\u8bbe\u7f6e\u7684token\u6570\u9650\u5236\u6216\u8fed\u4ee3\u9650\u5236": 0, "\u76f8\u6bd4": 48, "\u76f8\u90bb\u5b57\u8282\u5bf9": 0, "\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u5728bpe\u4e2d\u770b\u4f5c\u76f8\u90bb\u5b57\u8282\u5bf9": 0, "\u7701\u8d44\u6e90": 48, "\u770b\u5230\u8fd9\u91cc": 6, "\u770b\u5b8c\u4e0b\u9762\u5b8c\u6574\u7684\u8fed\u4ee3\u8fc7\u7a0b": 0, "\u770b\u770b\u6211\u4eec\u6700\u7ec8\u7684token\u5217\u8868": 0, "\u771f\u5b9e\u7684": 57, "\u77e5\u9053\u4e86\u7f16\u7801\u7684\u539f\u7406\u540e\u81ea\u7136\u80fd\u60f3\u5230\u7684\u5c31\u662f\u6587\u672c\u7f16\u7801\u548c\u89e3\u7801\u6240\u4f7f\u7528\u7684\u5b57\u7b26\u96c6\u4e0d\u540c": 7, "\u786e\u4fdd\u6700\u5e38\u89c1\u7684\u8bcd\u5728token\u5217\u8868\u4e2d\u8868\u793a\u4e3a\u5355\u4e2atoken": 0, "\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230": 0, "\u7a7a\u95f4\u6781\u5927\u6d6a\u8d39": 7, "\u7b2cn": 7, "\u7b2c\u4e00\u4e2a\u5b57\u8282": 7, "\u7b2c\u4e00\u4e2a\u5b57\u8282\u7684\u7b2c\u4e8c\u4e2a0": 7, "\u7b2c\u4e8c\u9ad8\u9891\u7387\u6807\u8bb0\u662f": 0, "\u7b49\u8bcd\u4e4b\u95f4\u7684\u533a\u522b": 0, "\u7b97\u6cd5\u7684\u4e0b\u4e00\u6b65\u662f\u5bfb\u627e\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9": 0, "\u7b97\u6cd5\u7684\u4e3b\u8981\u76ee\u6807": 0, "\u7f16\u7801\u4e3a": 0, "\u7f16\u7801\u672c\u8eab\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u8f83\u9ad8": 0, "\u7f16\u7801\u7c7b\u578b": 7, "\u8001\u89c4\u77e9": 0, "\u800cwordpiece\u9009\u62e9\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6700\u5927\u7684\u76f8\u90bb\u5b50\u8bcd\u52a0\u5165\u8bcd\u8868": 6, "\u800c\u4e0d\u662f": 0, "\u800c\u4e14\u8fc7\u5927\u7684token\u5217\u8868\u5341\u5206\u5f71\u54cd\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6": 0, "\u800c\u5728gb2312\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662fd2bb": 7, "\u800c\u662f\u5c06\u5b83\u4ee5utf": 7, "\u800c\u6c49\u5b57\u4e00\u4e8c\u4e09\u4e71\u7801\u4e86": 7, "\u800c\u7f55\u89c1\u7684\u8bcd\u88ab\u5206\u89e3\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2asubword": 0, "\u80fd\u591f\u6e05\u695a\u5730\u7406\u89e3wordpiece\u5728\u5408\u5e76\u8fd9\u4e00\u6b65\u662f\u5982\u4f55\u4f5c\u51fa\u9009\u62e9\u7684": 6, "\u80fd\u591f\u7cbe\u7ec6\u5730\u533a\u5206\u76f8\u90bb\u4f4d\u7f6e": 1, "\u82e5\u4f7f\u7528\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f": 0, "\u82f1\u6587\u5b57\u6bcd": 7, "\u8461\u8404\u7259\u8bed\u7b49\u65e0\u6cd5\u7528127\u4e2a\u5b57\u7b26\u8868\u793a\u5b8c\u5168": 7, "\u8868\u793a\u5b50\u8bcd": 6, "\u8981\u89e3\u7801": 0, "\u89c4\u52191": 7, "\u89c4\u52192": 7, "\u8ba1\u7b97": 1, "\u8ba1\u7b97\u673a\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u662f\u6309\u7167\u4e00\u4e2a\u5b57\u8282\u7684\u5927\u5c0f\u6765\u8bfb\u53d6\u8bc6\u522b\u7684": 7, "\u8ba1\u7b97\u673a\u6309\u7167\u5b57\u8282\u6765\u8bfb\u53d6\u6570\u636e\u65f6": 7, "\u8ba1\u7b97\u673a\u662f\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u8868\u793a\u7684\u662f\u4ec0\u4e48\u610f\u601d\u5462": 7, "\u8ba9\u6211\u4eec\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0\u4e00\u4e2a\u7279\u6b8a\u7684\u7ed3\u675f\u6807\u8bb0": 0, "\u8ba9\u6211\u4eec\u73b0\u5728\u505c\u6b62\u8fed\u4ee3\u5e76": 0, "\u8ba9\u6211\u4eec\u73b0\u5728\u8003\u8651": 0, "\u8ba9\u6211\u4eec\u7528": 0, "\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\u6765\u4e86\u89e3\u4e00\u4e0b\u5b83\u7684nlp\u7248\u672c": 0, "\u8bcd": 0, "\u8bf4\u660e": 7, "\u8bf4\u660eunicode\u548cgbk\u90fd\u5411\u4e0b\u517c\u5bb9\u4e86ascii": 7, "\u8d8a\u8fd1": 1, "\u8d8a\u8fdc": 1, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f0100": 7, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f100": 7, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f19968": 7, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f65": 7, "\u8fd8\u6709\u5176\u4ed6\u7f16\u7801\u65b9\u5f0f": 7, "\u8fd8\u6709\u7a7a\u683c32": 7, "\u8fd9\u4e00\u95ee\u9898": 7, "\u8fd9\u4e24\u4e2a\u8bcd\u90fd\u6709\u4e00\u4e2a\u5171\u540c\u7684": 0, "\u8fd9\u4e2a\u4e8c\u8fdb\u5236\u670915\u4f4d": 7, "\u8fd9\u4e2a\u8bcd\u7684token": 0, "\u8fd9\u4e5f\u662f": 0, "\u8fd9\u53ea\u662f\u82f1\u8bed\u7684\u7528\u6cd5": 0, "\u8fd9\u5b8c\u5168\u7b49\u540c\u4e8e127\u4f4d\u6700\u521d\u7684ascii\u7801": 7, "\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u9891\u7387\u8ba1\u6570\u5c06\u5728\u6bcf\u4e2a\u5408\u5e76\u6b65\u9aa4\u540e\u53d1\u751f\u53d8\u5316": 0, "\u8fd9\u662f\u66f4\u65b0\u540e\u7684\u8868\u683c": 0, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u67e5\u770b\u6bcf\u4e2a\u5b57\u7b26\u5e76\u627e\u5230\u9891\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u914d\u5bf9": 0, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u7406\u89e3": 0, "\u8fd9\u6837\u7684token\u5c06\u88ab\u4e0d\u540c\u5730\u5904\u7406": 0, "\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e4b\u4e3a": 1, "\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f\u5341\u5206\u7b26\u5408\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef": 0, "\u8fd9\u91cc": 6, "\u8fd9\u91cc\u4fee\u6539\u4e3agbk": 7, "\u8fd9\u91cc\u7b80\u5355\u4ecb\u7ecd\u4e0b\u8fd9\u51e0\u79cd\u7f16\u7801\u65b9\u5f0f\u7684\u533a\u522b": 7, "\u8fdc\u7a0b\u8870\u51cf\u66f2\u7ebf\u5982\u4e0b": 1, "\u8fed\u4ee3": 0, "\u901a\u5e38\u6709\u51e0\u4e07\u5230\u51e0\u5341\u4e07\u91cf\u7ea7\u7684\u5355\u8bcd\u6570": 0, "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5": 6, "\u90a3\u4e48\u4eba\u4eec\u80fd\u8bc6\u522b\u7684\u6587\u5b57\u548c\u8ba1\u7b97\u673a\u4e2d\u7684\u4e8c\u8fdb\u5236\u5fc5\u7136\u5b58\u5728\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 7, "\u90a3\u4e48\u9762\u5bf9\u5168\u4e16\u754c\u8fd9\u4e48\u591a\u8bed\u8a00": 7, "\u90a3\u5982\u4f55\u628a\u538b\u7f29\u7684\u7f16\u7801\u590d\u539f\u5462": 0, "\u90a3\u5c31\u662f\u672c\u6587\u5373\u5c06\u4ecb\u7ecd\u7684byte": 0, "\u90a3\u6837\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u6050\u6016\u7684": 0, "\u90a3\u82f1\u6587\u5b57\u7b26": 7, "\u90e8\u5206\u9891\u7387\u4f4e": 1, "\u90e8\u5206\u9891\u7387\u9ad8": 1, "\u90fd\u4e00\u6837": 7, "\u91cc\u548c\u653e\u5728": 48, "\u91cc\u7684\u533a\u522b": 48, "\u95f4\u76f8\u4e92\u9694\u5f00": 48, "\u963f\u62c9\u4f2f\u6570\u5b570\u5bf9\u5e94\u7684ascii\u7801\u662f48": 7, "\u963f\u62c9\u4f2f\u6570\u5b57\u548c\u82f1\u6587\u5b57\u6bcd": 7, "\u968f\u673a\u6027\u5f88\u5927": 1, "\u968f\u7740\u8ba1\u7b97\u673a\u5728\u5168\u7403\u7684\u53d1\u5c55\u548c\u666e\u53ca": 7, "\u9700\u8981\u81f3\u5c112\u4e2a\u5b57\u8282\u8868\u793a": 7, "\u975e\u5e38\u91cd\u8981": 0, "\u9996\u5148\u6765\u660e\u786e\u4e00\u4e0b\u57fa\u7840\u6982\u5ff5": 0, "\u9996\u5148\u770b\u4e0bwiki\u5bf9\u5b83\u7684\u5b9a\u4e49": 7, "\u9ad8\u4f4d\u4ee5": 7, "\u9ad8\u4f4d\u524dn\u4f4d\u4e3a": 7, "\u9ad8\u7684": 48, "\u9ad8\u7ef4": 1, "\u9ad8\u9891\u4fe1\u606f\u7684\u635f\u5931": 1, "\u9ad8\u9891\u7ef4\u5ea6\u5c11\u4f4e\u9891\u7ef4\u5ea6\u591a": 1, "\ud835\udc41": 56}, "titles": ["Byte Pair Encoding (BPE)", "Extending context window of LLMs", "Extending context window of large language models via position interpolation", "RoPE", "Rotary Positional Embeddings (RoPE)", "SwiGLU", "WordPiece, ULM and SentencePiece", "ASCII,UNICODE,UTF8", "Contents", "Code Alpaca", "CRUXEval", "LiveCodeBench", "Magicoder", "MBPP", "RewardBench", "SELF-INSTRUCT", "TACO", "WizardCoder", "Introduction", "Markdown Files", "Notebooks with MyST Markdown", "GOLD", "Evaluation of LLMs Should Not Ignore Non-Determinism", "Scaling Laws for Neural Language Models", "Weak to Strong Generalization", "Models", "AlphaCode", "AlphaCode 2", "AlphaCodium", "Code Llama", "DeepSeek-Coder-V2", "DeepSeekMoE", "DeepSeek-V2", "DeepSeek V3", "Llama", "Llama 2", "Llama3", "Multi-Head Latent Attention", "Path to o1", "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "Training Language Models to Self-Correct via Reinforcement Learning", "Let\u2019s Verify Step by Step", "Llama Factory", "LORA", "OpenRLHF", "Preference Optimization", "DPO", "DPOP", "Group Relative Policy Optimization (GRPO)", "Instruct GPT", "OpenRLHF", "RFT", "RS-DPO", "RSO", "Reward Model", "ArmoRM-MoE", "Efficient Exploration for LLMs", "Aligning Language Models with Judgments", "Constitutional AI: Harmlessness from AI Feedback", "RLAIF vs. RLHF", "RLCD", "Secrets of RLHF in Large Language Models: Reward Modeling", "Self-Rewarding Language Models", "Self-Taught Evaluators", "West-of-N", "A General Language Assistant as a Laboratory for Alignment", "Model-oriented Data Selection for Instruction Tuning"], "titleterms": {"": 41, "1": 55, "16": 7, "2": [27, 29, 35, 55], "2d": [3, 4], "32\u7b49": 7, "8": 7, "A": 65, "Not": 22, "The": [21, 28, 55], "abil": 62, "ablat": 37, "absolut": 4, "activ": [36, 41, 56], "adapt": 61, "add": 20, "addit": 28, "aggreg": 55, "ai": [58, 59], "algorithm": [21, 53, 56, 62], "align": [22, 57, 62, 65], "alpaca": 9, "alphacod": [26, 27], "alphacodium": 28, "an": [20, 56], "analyz": 61, "annot": 63, "appendix": 46, "approach": [4, 26, 34, 53], "architectur": [32, 34, 56], "armorm": 55, "ascii": 7, "assess": 56, "assist": 65, "attent": [32, 36, 37], "background": [1, 2, 4], "balanc": [31, 32], "base": 41, "basic": 23, "batchnorm": 36, "behavior": 65, "better": 61, "between": 37, "bpe": 0, "byte": 0, "cach": 37, "case": [3, 4], "cell": 20, "chain": 39, "chart": 23, "chatformat": 36, "citat": 19, "classif": 15, "cluster": [26, 27], "code": [9, 17, 28, 29], "coder": 30, "collaps": 40, "collect": [30, 35, 41], "comparison": 37, "compress": 37, "comput": 23, "concept": 28, "condit": 65, "consider": [31, 32], "constitut": 58, "construct": 63, "content": 8, "context": [1, 2, 29], "contrast": 57, "correct": 40, "count": 23, "creat": 20, "creation": 62, "critiqu": 58, "cruxev": 10, "data": [9, 15, 23, 30, 34, 35, 41, 61, 66], "dataset": [23, 26, 29, 49], "decoupl": 37, "deepseek": [30, 32, 33], "deepseekmo": [31, 32], "deriv": 46, "design": 28, "detail": [12, 50], "determin": 22, "differ": 61, "direct": [2, 19, 46], "divers": 61, "dpo": [46, 47, 52], "dpop": 47, "effect": 22, "effici": 56, "elicit": 39, "embed": [1, 2, 4, 23, 37], "empir": [23, 56], "encod": 0, "enn": 56, "epistem": 56, "estim": 56, "evalu": [10, 12, 17, 22, 26, 27, 59, 63], "evol": 17, "exampl": 20, "experi": [2, 62], "experiment": [22, 56, 62], "expert": [31, 32, 55], "explor": 56, "extend": [1, 2], "extrapol": [1, 2], "factor": 22, "factori": 42, "failur": 47, "feedback": [58, 59], "feedforward": 36, "ffn": 5, "file": 19, "filter": [15, 26, 27], "fine": [26, 27, 29, 31, 32, 35, 49, 63], "finetun": 15, "flip": 61, "flow": 28, "follow": [15, 62], "form": [3, 4], "formul": [3, 4], "framework": 21, "from": [12, 21, 57, 58, 59], "full": 22, "fullest": 61, "function": 36, "gate": 5, "gb2312": 7, "gbk\u7b49\u5176\u4ed6\u7f16\u7801": 7, "gener": [3, 4, 15, 22, 24, 36, 41, 65], "glu": 5, "gold": 21, "gpt": 49, "gqa": 37, "gradient": [21, 46], "grain": [31, 32], "group": 48, "grpo": 48, "harmless": 58, "head": [32, 37], "how": [22, 61], "human": [35, 61], "i": [19, 22, 40], "identif": 15, "ignor": 22, "ii": 40, "impact": 61, "implement": [2, 12, 50], "incorpor": 57, "infil": 29, "infinit": 23, "influenc": 22, "initi": [40, 62, 63], "insight": 28, "instanc": 15, "instruct": [12, 15, 17, 29, 49, 62, 63, 66], "interpol": [1, 2], "interpret": 55, "introduct": [2, 12, 18, 24, 29, 30, 34, 57, 60], "isol": [31, 32], "iter": [35, 48, 63], "its": 61, "joint": 37, "judgment": [57, 63], "kei": 37, "kv": 37, "label": [59, 61], "laboratori": 65, "languag": [2, 6, 23, 39, 40, 57, 61, 62, 65], "larg": [2, 26, 39, 41, 61], "latent": [32, 37], "law": 23, "layernorm": 36, "learn": [19, 40, 41, 49, 56, 57, 58, 59], "let": 41, "leverag": 61, "limit": 23, "linear": 5, "livecodebench": 11, "llama": [2, 29, 34, 35, 42], "llama3": 36, "llm": [1, 22, 56, 59], "lm": 15, "load": [31, 32], "long": 29, "lora": 43, "loss": 46, "low": 37, "magicod": 12, "main": 58, "margin": 61, "markdown": [19, 20], "mbpp": 13, "measur": 61, "mechan": 37, "metadata": 20, "method": [41, 58, 63], "methodologi": [24, 49, 59], "mha": 37, "mixtur": [31, 55], "mla": 37, "mle": 21, "mode": 47, "model": [2, 6, 23, 25, 27, 35, 36, 39, 40, 41, 49, 54, 55, 56, 57, 61, 62, 63, 64, 66], "moe": 55, "more": 19, "mqa": 37, "multi": [32, 37, 40, 55], "myst": [19, 20], "n": [23, 64], "need": 55, "network": 56, "neural": [23, 56], "nlp\u5b9e\u4f8b": 0, "non": [22, 23], "normal": 36, "notebook": 20, "o1": 38, "object": 55, "off": 21, "ood": 41, "open": 12, "openrlhf": [44, 50], "optim": [34, 45, 46, 48], "orient": [28, 66], "orm": 41, "oss": 12, "outcom": [41, 48], "overal": [27, 62], "overfit": 23, "overview": 28, "pair": [0, 63], "paramet": 23, "passiv": 56, "path": 38, "pattern": 22, "perform": [23, 61], "pi_": 46, "pipelin": 56, "point": 56, "polici": [21, 27, 48], "posit": [1, 2, 4, 37], "postprocess": 15, "potenti": [22, 61], "power": 23, "ppo": [48, 50], "pre": [32, 34], "prefer": [35, 45, 46, 59, 61, 64], "preliminari": [4, 31, 37, 40, 46, 53, 61], "pretrain": 35, "prevent": 40, "prm": 41, "problem": [40, 57], "process": [41, 48], "prompt": [10, 17, 39, 59], "properti": 4, "propos": [4, 28], "queri": 37, "quickli": 20, "r": [46, 52], "rank": 37, "reason": 39, "refer": 37, "reinforc": [40, 49, 58, 59], "reject": 53, "rel": 48, "relat": 64, "respons": 63, "result": [22, 23, 56, 58, 59, 62], "review": 48, "revis": 58, "reward": [21, 35, 40, 41, 49, 54, 55, 56, 61, 62], "rewardbench": 14, "rft": 51, "rl": [21, 40, 48, 49], "rlaif": 59, "rlcd": 60, "rlhf": [35, 59, 61], "rm": [49, 61], "rmsnorm": 36, "role": 19, "rope": [1, 2, 3, 4, 36], "rotari": [1, 2, 4, 37], "rso": 53, "sampl": [19, 26, 27, 53], "scale": [22, 23, 26, 41], "score": [27, 40], "secret": 61, "segment": [31, 32], "select": [63, 66], "self": [15, 40, 62, 63, 64], "sentencepiec": 6, "set": 57, "setup": [40, 62], "sft": [35, 42, 44, 49], "shape": 40, "share": [31, 32], "should": 22, "size": 23, "small": 41, "smooth": 61, "sourc": 12, "special": 29, "stage": [28, 40, 55], "standard": 37, "stanford": 9, "statist": 53, "step": 41, "strength": 61, "strong": 24, "supervis": [41, 48, 49, 58], "surfac": 22, "swiglu": [5, 36], "swish": 5, "synthet": 41, "system": 27, "taco": 16, "takeawai": [41, 61], "task": 15, "taught": 63, "techniqu": 59, "temperatur": 22, "thought": 39, "tiktoken": 36, "time": 23, "token": 36, "train": [17, 23, 32, 34, 40, 56, 62, 63, 64], "transform": [23, 31, 36], "tune": [12, 26, 27, 29, 35, 49, 63, 66], "turn": 40, "ulm": 6, "unicod": 7, "unigram": 6, "unit": 5, "utf": 7, "utf8": 7, "v": [41, 59], "v2": [30, 32], "v3": 33, "valu": 37, "variant": 5, "variou": 22, "verifi": 41, "via": [2, 40], "weak": 24, "west": 64, "what": [19, 22], "why": 37, "window": [1, 2], "wizardcod": 17, "wizardlm": 17, "wordpiec": 6, "work": 64, "yaml": 20, "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": 7, "\u521d\u8bc6bpe": 0, "\u603b\u7ed3": 7, "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5": 0, "\u7684\u8fdc\u7a0b\u8870\u51cf": 1, "\u7f16\u7801\u548c\u89e3\u7801": 0}})