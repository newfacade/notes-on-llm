Search.setIndex({"alltitles": {"2D case": [[80, "d-case"], [81, "d-case"]], "A Recipe for Instruction Data": [[44, "a-recipe-for-instruction-data"]], "ASCII": [[84, "ascii"]], "ASCII,UNICODE,UTF8": [[84, "ascii-unicode-utf8"]], "Ablation of Attention Mechanisms": [[78, "ablation-of-attention-mechanisms"]], "Ablation of MHA, GQA, and MQA": [[78, "ablation-of-mha-gqa-and-mqa"]], "Absolute position embedding": [[81, "absolute-position-embedding"]], "Active Exploration with a Point Estimate": [[49, "active-exploration-with-a-point-estimate"]], "Active Exploration with an ENN": [[49, "active-exploration-with-an-enn"]], "Active Learning": [[67, "active-learning"]], "Adaptive Margin": [[59, "adaptive-margin"]], "Additional insights": [[33, "additional-insights"]], "Aligning Language Models with Judgments": [[52, "aligning-language-models-with-judgments"]], "Alignment": [[35, "alignment"], [36, "alignment"]], "Alignment Benchmarks": [[7, "alignment-benchmarks"]], "Alignment Effect on Non-Determinism": [[27, "alignment-effect-on-non-determinism"]], "AlphaCode": [[31, "alphacode"]], "AlphaCode 2": [[32, "alphacode-2"]], "AlphaCodium": [[33, "alphacodium"]], "An example cell": [[25, "an-example-cell"]], "Analyze and Leverage Diverse Data to its Fullest Potential": [[59, "analyze-and-leverage-diverse-data-to-its-fullest-potential"]], "Appendix": [[47, "appendix"]], "Approach": [[3, "approach"], [4, "approach"], [31, "approach"], [38, "approach"]], "Architecture": [[36, "architecture"], [37, "architecture"], [38, "architecture"]], "Architecture & Tokenizer": [[43, "architecture-tokenizer"]], "Arena-Hard": [[7, "arena-hard"]], "ArmoRM-MoE": [[46, "armorm-moe"]], "Assessment Pipeline": [[49, "assessment-pipeline"]], "Attention": [[1, "attention"], [41, "attention"], [41, "id1"], [42, "attention"], [42, "id1"]], "Attention Is All You Need": [[1, "attention-is-all-you-need"]], "Background": [[81, "background"]], "Background: Rotary Position Embedding (RoPE)": [[76, "background-rotary-position-embedding-rope"], [77, "background-rotary-position-embedding-rope"]], "Base": [[0, "base"]], "Base Models": [[43, "base-models"], [44, "base-models"], [67, "base-models"]], "Basic Architecture": [[37, "basic-architecture"]], "Batch Normalization": [[79, "batch-normalization"]], "BatchNorm": [[41, "batchnorm"]], "Benchmarks": [[6, "benchmarks"]], "Byte Pair Encoding (BPE)": [[74, "byte-pair-encoding-bpe"]], "CRUXEval": [[9, "cruxeval"]], "Capabilities": [[40, "capabilities"]], "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [[64, "chain-of-thought-prompting-elicits-reasoning-in-large-language-models"]], "Charting the Infinite Data Limit and Overfitting": [[28, "charting-the-infinite-data-limit-and-overfitting"]], "Chat Dialog Format": [[40, "chat-dialog-format"]], "ChatFormat": [[41, "chatformat"]], "Citations": [[24, "citations"]], "Classification Task Identification": [[18, "classification-task-identification"]], "Clustering": [[31, "clustering"], [32, "clustering"]], "Code": [[40, "code"]], "Code Alpaca": [[8, "code-alpaca"], [8, "id1"]], "Code Correctness Evaluation: HumanEval(+) or MBPP(+)": [[10, "code-correctness-evaluation-humaneval-or-mbpp"]], "Code Llama": [[34, "code-llama"]], "Code Llama: Specializing Llama 2 for code": [[34, "code-llama-specializing-llama-2-for-code"]], "Code-Oriented Design Concepts": [[33, "code-oriented-design-concepts"]], "Cold Start": [[65, "cold-start"]], "Communication Balance Loss": [[75, "communication-balance-loss"]], "Comparison Between MLA and MHA": [[78, "comparison-between-mla-and-mha"]], "Comparison of Key-Value Cache": [[78, "comparison-of-key-value-cache"]], "Constitutional AI: Harmlessness from AI Feedback": [[54, "constitutional-ai-harmlessness-from-ai-feedback"]], "Contents": [[21, "contents"], [22, "contents"]], "Create a notebook with MyST Markdown": [[25, "create-a-notebook-with-myst-markdown"]], "Critiques, Revisions, and Supervised Learning": [[54, "critiques-revisions-and-supervised-learning"]], "DPO": [[47, "dpo"]], "DPOP": [[48, "dpop"], [48, "id1"]], "Data": [[8, "data"]], "Data Collection": [[35, "data-collection"], [67, "data-collection"]], "Data Composition": [[44, "data-composition"]], "Data Construction": [[36, "data-construction"], [37, "data-construction"]], "Data Generation": [[18, "data-generation"]], "Data Mixture": [[44, "data-mixture"]], "Data Processing and Quality Control": [[40, "data-processing-and-quality-control"]], "Dataset": [[5, "dataset"], [34, "dataset"], [51, "dataset"]], "Datasets": [[31, "datasets"]], "Decontamination": [[44, "decontamination"]], "Decoupled Rotary Position Embedding": [[78, "decoupled-rotary-position-embedding"]], "DeepSeek V3": [[37, "deepseek-v3"]], "DeepSeek-Coder-V2": [[35, "deepseek-coder-v2"]], "DeepSeek-R1": [[65, "deepseek-r1"]], "DeepSeek-R1-Zero: Reinforcement Learning on the Base Model": [[65, "deepseek-r1-zero-reinforcement-learning-on-the-base-model"]], "DeepSeek-R1: Reinforcement Learning with Cold Start": [[65, "deepseek-r1-reinforcement-learning-with-cold-start"]], "DeepSeek-V2": [[36, "deepseek-v2"]], "DeepSeekMoE": [[75, "deepseekmoe"]], "Derivation of \\pi_{r}": [[47, "derivation-of-pi-r"]], "Device-Level Balance Loss": [[75, "device-level-balance-loss"]], "Direct Preference Optimization": [[40, "direct-preference-optimization"], [47, "direct-preference-optimization"]], "Direct extrapolation": [[77, "direct-extrapolation"]], "Discussion": [[36, "discussion"]], "Dynamic Scaling - \u201cDynamic NTK\u201d interpolation": [[76, "dynamic-scaling-dynamic-ntk-interpolation"]], "Efficient Exploration for LLMs": [[49, "efficient-exploration-for-llms"]], "Embeddings and Softmax": [[1, "embeddings-and-softmax"]], "Empirical Results": [[49, "empirical-results"]], "Empirical Results and Basic Power Laws": [[28, "empirical-results-and-basic-power-laws"]], "Encoder and Decoder Stacks": [[1, "encoder-and-decoder-stacks"]], "Epistemic Neural Network": [[49, "epistemic-neural-network"]], "EvalPlus": [[10, "evalplus"]], "Evaluation": [[4, "evaluation"], [14, "evaluation"], [20, "evaluation"], [31, "evaluation"], [32, "evaluation"], [43, "evaluation"], [44, "evaluation"], [55, "evaluation"]], "Evaluation Results": [[36, "evaluation-results"], [36, "id3"], [37, "evaluation-results"], [37, "id4"]], "Evaluation of LLMs Should Not Ignore Non-Determinism": [[27, "evaluation-of-llms-should-not-ignore-non-determinism"]], "Evol-Instruct": [[20, "evol-instruct"]], "Evol-Instruct Prompts for Code": [[20, "evol-instruct-prompts-for-code"]], "Experimental Results": [[27, "experimental-results"], [35, "experimental-results"]], "Experimental Setup": [[60, "experimental-setup"]], "Experimentation Pipeline": [[49, "experimentation-pipeline"]], "Experiments": [[3, "experiments"], [60, "experiments"], [77, "experiments"]], "Expert-Level Balance Loss": [[75, "expert-level-balance-loss"]], "Exploration Algorithms": [[49, "exploration-algorithms"]], "Extending context window of LLMs": [[76, "extending-context-window-of-llms"]], "Extending context window of large language models via position interpolation": [[77, "extending-context-window-of-large-language-models-via-position-interpolation"]], "FFN": [[82, "ffn"]], "Failure Mode of DPO": [[48, "failure-mode-of-dpo"]], "FeedForward": [[41, "feedforward"], [42, "feedforward"]], "Filtering": [[31, "filtering"], [32, "filtering"]], "Filtering and Postprocessing": [[18, "filtering-and-postprocessing"]], "Fine-Grained Expert Segmentation": [[75, "fine-grained-expert-segmentation"]], "Fine-tuning": [[31, "fine-tuning"]], "Finetuning the LM to Follow Instructions": [[18, "finetuning-the-lm-to-follow-instructions"]], "Flipping the Labels": [[59, "flipping-the-labels"]], "Flow stages": [[33, "flow-stages"]], "Formulation": [[80, "formulation"], [81, "formulation"]], "Framework": [[2, "framework"]], "From MLE to RL framework": [[26, "from-mle-to-rl-framework"]], "Functional Correctness": [[12, "functional-correctness"]], "GB2312\u3001GBK\u7b49\u5176\u4ed6\u7f16\u7801": [[84, "gb2312gbk"]], "GOLD": [[26, "gold"]], "GPQA": [[15, "gpqa"]], "GPT": [[2, "gpt"]], "GPT2": [[3, "gpt2"]], "GPT3": [[4, "gpt3"]], "GRPO": [[50, "id3"]], "GSM8K": [[15, "gsm8k"]], "Gated Linear Units (GLU) and Variants": [[82, "gated-linear-units-glu-and-variants"]], "General Benchmarks": [[11, "general-benchmarks"]], "General form": [[80, "general-form"], [81, "general-form"]], "Generation": [[41, "generation"]], "Generator": [[67, "generator"]], "Gradient of DPO Loss": [[47, "gradient-of-dpo-loss"]], "Group Relative Policy Optimization": [[50, "group-relative-policy-optimization"]], "High-level methodology": [[5, "high-level-methodology"]], "How Various Factors Influence Non-Determinism?": [[27, "how-various-factors-influence-non-determinism"]], "How to Better Model Human Preference?": [[59, "how-to-better-model-human-preference"]], "Human Preference Data Collection": [[39, "human-preference-data-collection"]], "HumanEval": [[12, "humaneval"]], "Hyper-Parameters": [[36, "hyper-parameters"]], "IFEval": [[7, "ifeval"]], "Impacts of Different Data on RM Performance": [[59, "impacts-of-different-data-on-rm-performance"]], "Implementation Details": [[14, "implementation-details"]], "Incorporating Judgments for Alignment": [[52, "incorporating-judgments-for-alignment"]], "Infilling": [[34, "infilling"]], "Initialization": [[60, "initialization"], [61, "initialization"]], "Input Representation": [[3, "input-representation"]], "Installation": [[13, "installation"]], "Instance Generation": [[18, "instance-generation"]], "Instruct GPT": [[51, "instruct-gpt"]], "Instruct Models": [[44, "instruct-models"]], "InstructGPT": [[5, "instructgpt"]], "Instruction Following Ability Results": [[60, "instruction-following-ability-results"]], "Instruction Following Training": [[60, "instruction-following-training"]], "Instruction Generation": [[18, "instruction-generation"]], "Instruction Selection": [[61, "instruction-selection"]], "Instruction fine-tuning": [[34, "instruction-fine-tuning"]], "Instruction-tuned Model": [[43, "instruction-tuned-model"]], "Introduction": [[14, "introduction"], [23, "introduction"], [29, "introduction"], [34, "introduction"], [38, "introduction"], [52, "introduction"], [56, "introduction"], [77, "introduction"]], "Iterative Fine-Tuning": [[39, "iterative-fine-tuning"]], "Iterative RL with GRPO": [[50, "iterative-rl-with-grpo"]], "Iterative Rounds": [[40, "iterative-rounds"]], "Iterative Training": [[61, "iterative-training"]], "Judgment Annotation": [[61, "judgment-annotation"]], "LORA": [[86, "lora"]], "Label Smoothing": [[59, "label-smoothing"]], "Large scale sampling": [[31, "large-scale-sampling"]], "Large-scale Supervision": [[67, "large-scale-supervision"]], "Layer Normalization": [[79, "layer-normalization"]], "LayerNorm": [[41, "layernorm"]], "Learn more": [[24, "learn-more"]], "Learning Pipeline": [[49, "learning-pipeline"]], "Learning from Contrasting": [[52, "learning-from-contrasting"]], "Let\u2019s Verify Step by Step": [[67, "lets-verify-step-by-step"]], "LiveCodeBench": [[13, "livecodebench"]], "Llama": [[38, "llama"]], "Llama 2": [[39, "llama-2"]], "Llama 3": [[40, "llama-3"]], "Llama 3 Source Code": [[42, "llama-3-source-code"]], "Llama Factory": [[85, "llama-factory"]], "Llama implementation": [[77, "llama-implementation"]], "Llama3": [[41, "llama3"]], "Load Balance Consideration": [[75, "load-balance-consideration"]], "Long Context Extension": [[37, "long-context-extension"]], "Long context fine-tuning": [[34, "long-context-fine-tuning"]], "Loss": [[47, "loss"]], "Loss of High Frequency information - \u201cNTK-aware\u201d interpolation": [[76, "loss-of-high-frequency-information-ntk-aware-interpolation"]], "Loss of Relative Local Distances - \u201cNTK-by-parts\u201d interpolation": [[76, "loss-of-relative-local-distances-ntk-by-parts-interpolation"]], "Low-Rank Compression for Queries": [[78, "low-rank-compression-for-queries"]], "Low-Rank Key-Value Joint Compression": [[78, "low-rank-key-value-joint-compression"]], "MATH": [[15, "math"]], "MATH 500": [[15, "math-500"]], "MBPP": [[16, "mbpp"]], "MMLU": [[11, "mmlu"]], "MMLU-Pro": [[11, "mmlu-pro"]], "MMLU-Redux": [[11, "mmlu-redux"]], "Magicoder": [[14, "magicoder"]], "Main Result": [[54, "main-result"]], "Main Results": [[54, "main-results"]], "Markdown Files": [[24, "markdown-files"]], "Math & Science Benchmarks": [[15, "math-science-benchmarks"]], "Measuring the Strength of Preferences": [[59, "measuring-the-strength-of-preferences"]], "Method": [[54, "method"], [54, "id1"], [61, "method"]], "Methodology": [[29, "methodology"], [55, "methodology"]], "Methods": [[67, "methods"]], "Methods and experimental details": [[5, "methods-and-experimental-details"]], "Model": [[3, "model"], [41, "model"], [42, "model"]], "Model Accuracy VS. Augmented Data Count": [[72, "model-accuracy-vs-augmented-data-count"]], "Model Accuracy VS. Pre-training Loss": [[72, "model-accuracy-vs-pre-training-loss"]], "Model Accuracy VS. Supervised Data Count": [[72, "model-accuracy-vs-supervised-data-count"]], "Model Architecture": [[1, "model-architecture"]], "Model Averaging": [[40, "model-averaging"]], "Model Fine-tuning (Iterative Training)": [[61, "model-fine-tuning-iterative-training"]], "Model and Architectures": [[4, "model-and-architectures"]], "Modeling": [[40, "modeling"]], "Models": [[5, "models"], [30, "models"]], "Multi-Head Attention": [[1, "multi-head-attention"]], "Multi-Head Latent Attention": [[78, "multi-head-latent-attention"]], "Multi-Token Prediction": [[37, "multi-token-prediction"]], "NLP\u5b9e\u4f8b": [[74, "nlp"]], "Normalization": [[41, "normalization"], [79, "normalization"]], "Notebooks with MyST Markdown": [[25, "notebooks-with-myst-markdown"]], "OOD Generalization": [[67, "ood-generalization"]], "OSS-INSTRUCT: Instruction Tuning from Open Source": [[14, "oss-instruct-instruction-tuning-from-open-source"]], "Off-policy policy gradient": [[26, "off-policy-policy-gradient"]], "Offline Reinforcement Learning": [[43, "offline-reinforcement-learning"]], "Online Reinforcement Learning": [[43, "online-reinforcement-learning"]], "OpenRLHF": [[53, "openrlhf"], [87, "openrlhf"]], "Optimizer": [[38, "optimizer"]], "Outcome Supervision RL with GRPO": [[50, "outcome-supervision-rl-with-grpo"]], "Outcome-supervised Reward Models (ORMs)": [[67, "outcome-supervised-reward-models-orms"]], "Overall Self-Alignment Algorithm": [[60, "overall-self-alignment-algorithm"]], "Overall System": [[32, "overall-system"]], "Overview": [[33, "overview"]], "PPO Review": [[50, "ppo-review"]], "PPO implementation detail": [[53, "ppo-implementation-detail"]], "Parameter and Compute Scaling of Transformers": [[28, "parameter-and-compute-scaling-of-transformers"]], "Passive Exploration": [[49, "passive-exploration"]], "Performance with Dataset Size and Compute": [[28, "performance-with-dataset-size-and-compute"]], "Performance with Non-Embedding Parameter Count N": [[28, "performance-with-non-embedding-parameter-count-n"]], "Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero": [[65, "performance-self-evolution-process-and-aha-moment-of-deepseek-r1-zero"]], "Point Estimate": [[49, "point-estimate"]], "Policy and Fine-Tuning": [[32, "policy-and-fine-tuning"]], "Position interpolation": [[76, "position-interpolation"]], "Position-wise Feed-Forward Networks": [[1, "position-wise-feed-forward-networks"]], "Positional Encoding": [[1, "positional-encoding"]], "Positional Interpolation": [[77, "positional-interpolation"]], "Post-Training": [[37, "post-training"], [40, "post-training"]], "Post-trained Language Model": [[40, "post-trained-language-model"]], "Post-training": [[43, "post-training"], [44, "post-training"]], "Post-training Data": [[40, "post-training-data"]], "Pre-Training": [[36, "pre-training"], [37, "pre-training"]], "Pre-trained Language Model": [[40, "pre-trained-language-model"]], "Pre-training": [[43, "pre-training"], [44, "pre-training"]], "Pre-training Data": [[43, "pre-training-data"]], "Pre-training data": [[38, "pre-training-data"]], "Preference Data": [[40, "preference-data"]], "Preference Labeling with LLMs": [[55, "preference-labeling-with-llms"]], "Preference Optimization": [[45, "preference-optimization"]], "Preliminaries": [[47, "preliminaries"], [58, "preliminaries"], [59, "preliminaries"]], "Preliminaries and Problem Setup": [[66, "preliminaries-and-problem-setup"]], "Preliminaries: Mixture-of-Experts for Transformers": [[75, "preliminaries-mixture-of-experts-for-transformers"]], "Preliminaries: Standard Multi-Head Attention": [[78, "preliminaries-standard-multi-head-attention"]], "Preliminary": [[81, "preliminary"]], "Pretrain": [[39, "pretrain"]], "Problem Setting": [[52, "problem-setting"]], "Process Supervision RL with GRPO": [[50, "process-supervision-rl-with-grpo"]], "Process vs Outcome Supervision": [[67, "process-vs-outcome-supervision"]], "Process-supervised Reward Models (PRMs)": [[67, "process-supervised-reward-models-prms"]], "Prompting Techniques": [[55, "prompting-techniques"]], "Properties of RoPE": [[81, "properties-of-rope"]], "Proposed approach": [[81, "proposed-approach"]], "Quick Start": [[10, "quick-start"]], "Quickly add YAML metadata for MyST Notebooks": [[25, "quickly-add-yaml-metadata-for-myst-notebooks"]], "Qwen 2.5": [[43, "qwen-2-5"]], "Qwen2.5-Coder": [[44, "qwen2-5-coder"]], "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED": [[70, "rethinking-data-selection-at-scale-random-selection-is-almost-all-you-need"]], "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold": [[71, "rl-on-incorrect-synthetic-data-scales-the-efficiency-of-llm-math-reasoning-by-eight-fold"]], "RLAIF vs. RLHF": [[55, "rlaif-vs-rlhf"], [55, "id1"]], "RLCD": [[56, "rlcd"], [56, "id1"]], "RLHF": [[39, "rlhf"]], "RMSNorm": [[41, "rmsnorm"], [42, "rmsnorm"], [79, "rmsnorm"]], "RS-DPO": [[57, "rs-dpo"]], "RSO": [[58, "rso"]], "RSO APPROACH": [[58, "rso-approach"]], "Reasoning Models": [[63, "reasoning-models"]], "Reasoning-oriented Reinforcement Learning": [[65, "reasoning-oriented-reinforcement-learning"]], "References": [[68, "references"]], "Reinforcement Learning": [[35, "reinforcement-learning"], [36, "reinforcement-learning"], [37, "reinforcement-learning"]], "Reinforcement Learning Algorithm": [[65, "reinforcement-learning-algorithm"]], "Reinforcement Learning for all Scenarios": [[65, "reinforcement-learning-for-all-scenarios"]], "Reinforcement Learning from AI Feedback": [[54, "reinforcement-learning-from-ai-feedback"], [55, "reinforcement-learning-from-ai-feedback"]], "Reinforcement learning (RL)": [[51, "reinforcement-learning-rl"]], "Rejection Sampling and Supervised Fine-Tuning": [[65, "rejection-sampling-and-supervised-fine-tuning"]], "Related Work": [[62, "related-work"]], "Response Pair Construction": [[61, "response-pair-construction"]], "Results": [[5, "results"], [40, "results"], [55, "results"]], "Reward": [[26, "reward"]], "Reward Model Architectures and Training": [[49, "reward-model-architectures-and-training"]], "Reward Modeling": [[39, "reward-modeling"], [40, "reward-modeling"], [65, "reward-modeling"]], "Reward Modeling Ability Results": [[60, "reward-modeling-ability-results"]], "Reward modeling (RM)": [[51, "reward-modeling-rm"]], "RewardBench": [[17, "rewardbench"]], "RoPE": [[41, "rope"], [42, "rope"], [80, "rope"]], "RoPE \u7684\u8fdc\u7a0b\u8870\u51cf": [[76, "rope"]], "Rotary Positional Embeddings (RoPE)": [[81, "rotary-positional-embeddings-rope"]], "SCoRe: Self-Correction via Multi-Turn Reinforcement Learning": [[66, "score-self-correction-via-multi-turn-reinforcement-learning"]], "SELF-INSTRUCT": [[18, "self-instruct"]], "SFT": [[39, "sft"], [69, "sft"], [85, "sft"], [87, "sft"]], "SFT Data": [[40, "sft-data"]], "STATISTICAL REJECTION SAMPLING ALGORITHM": [[58, "statistical-rejection-sampling-algorithm"]], "Sample Roles and Directives": [[24, "sample-roles-and-directives"]], "Sampling": [[32, "sampling"]], "Scaled Dot-Product Attention": [[1, "scaled-dot-product-attention"]], "Scaling Effect on Non-Determinism": [[27, "scaling-effect-on-non-determinism"]], "Scaling Law for Hyper-parameters": [[43, "scaling-law-for-hyper-parameters"]], "Scaling Laws for Neural Language Models": [[28, "scaling-laws-for-neural-language-models"]], "Scaling Laws with Model Size and Training Time": [[28, "scaling-laws-with-model-size-and-training-time"]], "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": [[72, "scaling-relationship-on-learning-mathematical-reasoning-with-large-language-models"]], "Scoring Model": [[32, "scoring-model"]], "Secrets of RLHF in Large Language Models: Reward Modeling": [[59, "secrets-of-rlhf-in-large-language-models-reward-modeling"]], "Self-Instruction Creation": [[60, "self-instruction-creation"]], "Self-Rewarding Language Models": [[60, "self-rewarding-language-models"]], "Self-Taught Evaluators": [[61, "self-taught-evaluators"]], "Self-Training for Preference Modeling": [[62, "self-training-for-preference-modeling"]], "SentencePiece": [[83, "sentencepiece"]], "Shared Expert Isolation": [[75, "shared-expert-isolation"]], "Small-scale Synthetic Supervision": [[67, "small-scale-synthetic-supervision"]], "Stage I: Training a Model Initialization to Prevent Collapse": [[66, "stage-i-training-a-model-initialization-to-prevent-collapse"]], "Stage II: Multi-Turn RL with Reward Shaping": [[66, "stage-ii-multi-turn-rl-with-reward-shaping"]], "Stage-1: Multi-Objective Reward Modeling": [[46, "stage-1-multi-objective-reward-modeling"]], "Stage-2: Mixture-of-Experts Aggregation of Reward Objectives": [[46, "stage-2-mixture-of-experts-aggregation-of-reward-objectives"]], "Stanford Alpaca": [[8, "stanford-alpaca"]], "Summarization": [[3, "summarization"]], "Supervised Fine-Tuning": [[35, "supervised-fine-tuning"], [36, "supervised-fine-tuning"], [37, "supervised-fine-tuning"]], "Supervised Fine-tuning": [[43, "supervised-fine-tuning"]], "Supervised Finetuning": [[40, "supervised-finetuning"]], "Supervised fine-tuning": [[2, "supervised-fine-tuning"]], "Supervised fine-tuning (SFT)": [[51, "supervised-fine-tuning-sft"]], "Surface Patterns in Non-Determinism Generation?": [[27, "surface-patterns-in-non-determinism-generation"]], "SwiGLU": [[82, "swiglu"]], "SwiGLU activation function": [[41, "swiglu-activation-function"], [42, "swiglu-activation-function"]], "Swish": [[82, "swish"]], "TACO": [[19, "taco"]], "Takeaway": [[40, "takeaway"], [80, "takeaway"]], "Takeaways": [[59, "takeaways"], [67, "takeaways"]], "Task-specific input transformations": [[2, "task-specific-input-transformations"]], "Techniques": [[73, "techniques"]], "Temperature Effect on Non-Determinism": [[27, "temperature-effect-on-non-determinism"]], "The Factors of Math Reasoning Ability in Supervised LLM": [[72, "the-factors-of-math-reasoning-ability-in-supervised-llm"]], "The GOLD algorithm": [[26, "the-gold-algorithm"]], "The Need for Interpretable Reward Models": [[46, "the-need-for-interpretable-reward-models"]], "The Proposed Flow": [[33, "the-proposed-flow"]], "Tiktoken": [[41, "tiktoken"]], "Token-Dropping Strategy": [[75, "token-dropping-strategy"]], "Tokenizer": [[41, "tokenizer"], [41, "id2"]], "Training Dataset": [[3, "training-dataset"], [4, "training-dataset"]], "Training Language Models to Self-Correct via Reinforcement Learning": [[66, "training-language-models-to-self-correct-via-reinforcement-learning"]], "Training Policy": [[44, "training-policy"], [44, "id1"]], "Training Template": [[65, "training-template"]], "Training WizardCoder": [[20, "training-wizardcoder"]], "Transformer": [[41, "transformer"], [42, "transformer"]], "UTF-16\u3001UTF-32\u7b49": [[84, "utf-16utf-32"]], "UTF-8": [[84, "utf-8"]], "Unigram Language Model (ULM)": [[83, "unigram-language-model-ulm"]], "Unsupervised pre-training": [[2, "unsupervised-pre-training"]], "Weak to Strong Generalization": [[29, "weak-to-strong-generalization"]], "West-of-N": [[62, "west-of-n"]], "West-of-N Self-Training": [[62, "west-of-n-self-training"]], "What is MyST?": [[24, "what-is-myst"]], "What is the Full Potential of Non-Determinism?": [[27, "what-is-the-full-potential-of-non-determinism"]], "Why KV cache": [[78, "why-kv-cache"]], "Why Layer Normalization": [[79, "why-layer-normalization"]], "Why decoder-only": [[2, "why-decoder-only"]], "WizardCoder": [[20, "wizardcoder"]], "WizardLM": [[20, "wizardlm"]], "WordPiece": [[83, "wordpiece"]], "WordPiece, ULM and SentencePiece": [[83, "wordpiece-ulm-and-sentencepiece"]], "YaRN": [[76, "id5"]], "YaRN: Efficient ContextWindow Extension of Large Language Models": [[76, "yarn-efficient-contextwindow-extension-of-large-language-models"]], "methodology": [[51, "methodology"]], "unicode": [[84, "unicode"]], "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": [[84, "id1"]], "\u521d\u8bc6BPE": [[74, "bpe"]], "\u603b\u7ed3": [[84, "id2"]], "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff1f": [[74, "id2"]], "\u672c\u5730 Evaluate": [[10, "evaluate"], [13, "evaluate"]], "\u7f16\u7801\u548c\u89e3\u7801": [[74, "id1"]], "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": [[76, "id4"]]}, "docnames": ["base/0", "base/attention", "base/gpt", "base/gpt2", "base/gpt3", "base/instruct-gpt", "bench/0", "bench/alignment", "bench/code-alpaca", "bench/cruxeval", "bench/evalplus", "bench/general", "bench/humaneval", "bench/livecodebench", "bench/magic", "bench/math-science", "bench/mbpp", "bench/reward-bench", "bench/self-instruct", "bench/taco", "bench/wizard", "content", "content-Copy1", "intro", "markdown", "markdown-notebooks", "methodology/gold", "methodology/non-determin", "methodology/scaling-law", "methodology/weak-to-strong", "models/0", "models/alphacode", "models/alphacode2", "models/alphacodium", "models/codellama", "models/deepseek-coder-v2", "models/deepseek-v2", "models/deepseek-v3", "models/llama", "models/llama2", "models/llama3", "models/llama3-code copy", "models/llama3-source-code", "models/qwen25", "models/qwen25-coder", "preference/0", "preference/armo", "preference/dpo", "preference/dpop", "preference/ee", "preference/grpo", "preference/instruct-gpt", "preference/judge", "preference/openrlhf", "preference/rlaif-1", "preference/rlaif-2", "preference/rlcd", "preference/rs-dpo", "preference/rso", "preference/secret-rm", "preference/self-reward", "preference/self-taught", "preference/west-of-n", "reasoning/0", "reasoning/cot", "reasoning/deepseek-r1", "reasoning/self-correct-rl", "reasoning/verify", "reference", "sft/0", "sft/random", "sft/rl-eight-fold", "sft/rs", "techniques/0", "techniques/bpe", "techniques/deepseek-moe", "techniques/extending", "techniques/extending-old", "techniques/mla", "techniques/norm", "techniques/rope", "techniques/rope-old", "techniques/swiglu", "techniques/tokenize", "techniques/unicode-utf8", "tools/llama-factory", "tools/lora", "tools/openrlhf"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["base/0.ipynb", "base/attention.ipynb", "base/gpt.ipynb", "base/gpt2.ipynb", "base/gpt3.ipynb", "base/instruct-gpt.ipynb", "bench/0.ipynb", "bench/alignment.ipynb", "bench/code-alpaca.ipynb", "bench/cruxeval.ipynb", "bench/evalplus.ipynb", "bench/general.ipynb", "bench/humaneval.ipynb", "bench/livecodebench.ipynb", "bench/magic.ipynb", "bench/math-science.ipynb", "bench/mbpp.ipynb", "bench/reward-bench.ipynb", "bench/self-instruct.ipynb", "bench/taco.ipynb", "bench/wizard.ipynb", "content.ipynb", "content-Copy1.ipynb", "intro.md", "markdown.md", "markdown-notebooks.md", "methodology/gold.ipynb", "methodology/non-determin.ipynb", "methodology/scaling-law.ipynb", "methodology/weak-to-strong.ipynb", "models/0.ipynb", "models/alphacode.ipynb", "models/alphacode2.ipynb", "models/alphacodium.ipynb", "models/codellama.ipynb", "models/deepseek-coder-v2.ipynb", "models/deepseek-v2.ipynb", "models/deepseek-v3.ipynb", "models/llama.ipynb", "models/llama2.ipynb", "models/llama3.ipynb", "models/llama3-code copy.ipynb", "models/llama3-source-code.ipynb", "models/qwen25.ipynb", "models/qwen25-coder.ipynb", "preference/0.ipynb", "preference/armo.ipynb", "preference/dpo.ipynb", "preference/dpop.ipynb", "preference/ee.ipynb", "preference/grpo.ipynb", "preference/instruct-gpt.ipynb", "preference/judge.ipynb", "preference/openrlhf.ipynb", "preference/rlaif-1.ipynb", "preference/rlaif-2.ipynb", "preference/rlcd.ipynb", "preference/rs-dpo.ipynb", "preference/rso.ipynb", "preference/secret-rm.ipynb", "preference/self-reward.ipynb", "preference/self-taught.ipynb", "preference/west-of-n.ipynb", "reasoning/0.ipynb", "reasoning/cot.ipynb", "reasoning/deepseek-r1.ipynb", "reasoning/self-correct-rl.ipynb", "reasoning/verify.ipynb", "reference.ipynb", "sft/0.ipynb", "sft/random.ipynb", "sft/rl-eight-fold.ipynb", "sft/rs.ipynb", "techniques/0.ipynb", "techniques/bpe.ipynb", "techniques/deepseek-moe.ipynb", "techniques/extending.ipynb", "techniques/extending-old.ipynb", "techniques/mla.ipynb", "techniques/norm.ipynb", "techniques/rope.ipynb", "techniques/rope-old.ipynb", "techniques/swiglu.ipynb", "techniques/tokenize.ipynb", "techniques/unicode-utf8.ipynb", "tools/llama-factory.ipynb", "tools/lora.ipynb", "tools/openrlhf.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 5, 10, 11, 15, 24, 25, 26, 28, 29, 33, 34, 36, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 61, 66, 68, 72, 74, 75, 76, 77, 83], "0": [1, 2, 10, 12, 13, 18, 20, 26, 27, 28, 31, 32, 35, 36, 37, 38, 39, 40, 41, 42, 46, 47, 48, 50, 52, 53, 54, 55, 58, 59, 60, 62, 72, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86], "000": [11, 15, 19, 31, 34], "0000": [77, 84], "0000j": 77, "0001": 84, "0010": 84, "003": 8, "0041": 84, "005": 12, "007f": 84, "0080": 84, "01": 53, "0100j": 77, "01825": [24, 68], "02120": [14, 24, 68], "02150": [24, 68], "02155": [24, 68], "02954": [24, 68], "03": 38, "03065": [24, 68], "0314": 7, "03300": [24, 68], "03374": [24, 68], "03762": [24, 68], "04434": [24, 68], "0461": 77, "04805": [24, 68], "0596": 77, "0596j": 77, "06": 38, "06066": [24, 68], "06347": [24, 68], "0674": 77, "0674j": 77, "07074": [24, 68], "076": 28, "07911": [24, 68], "07974": [24, 68], "07ff": 84, "0800": 84, "08361": [24, 68], "08568": 20, "09288": [24, 68], "096": 34, "09864": [24, 68], "0xxxxxxx": 84, "1": [1, 2, 5, 7, 8, 10, 12, 13, 14, 18, 19, 20, 22, 24, 26, 27, 28, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 66, 67, 68, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "10": [10, 13, 15, 27, 28, 32, 34, 35, 36, 38, 40, 44, 50, 55, 59, 74, 75, 84, 85], "100": [3, 8, 11, 12, 32, 34, 44, 46, 49, 67], "1000": [20, 37, 67, 76, 77], "10000": [1, 32, 41, 42, 76, 77, 80, 81], "100000": 53, "10000000": 84, "100k": 36, "10111000": 84, "1024": [44, 53], "102400": 36, "1048576000": 36, "105": 13, "10509": [24, 68], "10560": 18, "106": 13, "107": 13, "10k": 36, "10x": 4, "10xxxxxx": 84, "11": [13, 81], "1106": 14, "110k": 14, "110xxxxx": 84, "110\u8868\u793a\u9700\u8981\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u5f53\u524d\u5b57\u7b26": 84, "1110": 84, "1110xxxx": 84, "1110\u8868\u793a\u9700\u8981\u4e09\u4e2a\u5b57\u8282": 84, "11110xxx": 84, "11110\u8868\u793a\u9700\u8981\u56db\u4e2a\u5b57\u8282": 84, "117": 13, "11931": [24, 68], "12": [11, 13, 15, 28, 32, 36, 74, 81], "12000": 85, "12288": 36, "123abc\u4e00\u4e8c\u4e09": 84, "125": [4, 13], "128": [36, 53], "128k": [36, 37, 40], "128\u4f4dascii\u7801\u662f\u6570\u5b57": 84, "12b": 12, "12k": 67, "12n_": 28, "13": [13, 28, 41, 74], "13245": [24, 68], "13971": [24, 68], "13b": 34, "13k": 5, "14": [11, 13, 34, 37, 78], "14165": [24, 68], "14168": [24, 68], "14196": [24, 68], "149225472": 36, "15": [13, 14, 38, 39], "151": 43, "1536": 36, "15595": [24, 68], "15b": 20, "16": [11, 13, 38, 51, 53, 54, 72], "160": 36, "1609": 41, "164": 12, "16k": 40, "17": [12, 13, 24, 50, 68], "1706": [24, 68], "1707": [24, 68], "175": [4, 18], "18": [13, 43], "1810": [24, 68], "18290": [24, 68], "185b": 35, "188743680": 36, "19": [3, 4, 24, 68], "1904": [24, 68], "1911": [24, 68], "198": 15, "1990\u5e74\u5f00\u59cb\u7814\u53d1": 84, "1994": 74, "1_gnu": 13, "1e": [41, 42, 79, 85], "1k": 15, "1l": 57, "1qvx610cu7": [24, 68], "1t": [36, 40], "1w": 57, "1\u4f4d\u4e3a": 84, "2": [1, 2, 3, 4, 5, 8, 10, 11, 13, 15, 18, 22, 24, 25, 28, 29, 31, 33, 35, 36, 37, 38, 40, 41, 42, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 62, 66, 67, 68, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84], "20": [4, 5, 8, 13, 24, 59, 67, 68], "200": [5, 8, 12, 67], "2000": 38, "2001": [24, 68], "2005": [24, 68], "20050": [24, 68], "2009": [24, 68], "2017": [24, 68], "2019": [24, 68], "2020": [24, 68], "2021": [24, 68], "2022": [24, 68], "2023": [24, 35, 68], "2024": [13, 24, 44, 68], "20240602": 13, "2048": [41, 42, 76, 77], "20k": [8, 14, 20, 35], "21": [11, 12, 13, 14, 15, 24, 68, 72, 81], "2104": [24, 68], "2107": [24, 68], "2110": [24, 68], "21326725120": 36, "21783": [24, 68], "21b": 36, "22": [5, 13, 24, 68, 81], "2203": [24, 68], "2212": 18, "2294": 41, "23": [1, 2, 7, 13, 15, 24, 37, 38, 40, 68, 72, 74, 76, 78, 79, 80], "2302": [24, 68], "2305": [24, 68], "2306": [20, 24, 68], "2307": [24, 68], "2308": [24, 68], "2311": [24, 68], "2312": [14, 24, 68], "235692359680": 36, "236b": 36, "24": [9, 11, 13, 24, 35, 36, 37, 40, 50, 68, 75, 78], "2401": [24, 68], "2402": [24, 68], "2403": [24, 68], "2405": [24, 68], "2406": [24, 68], "2407": [24, 68], "25": [7, 13, 19, 59, 78], "256": [41, 42, 60], "256\u4f4dascii\u6269\u5c55\u7801\u662fascii": 84, "26": 13, "27": 39, "29": 13, "2900": 77, "2d": 76, "2d_": 28, "2i": [1, 34, 81], "2j": [41, 42, 76, 77], "2m": 36, "2n": 28, "2n_": [28, 78], "2t": 81, "2\u62164\u5b57\u8282\u53d8\u957f": 84, "3": [2, 3, 4, 5, 7, 13, 14, 24, 27, 28, 31, 33, 34, 35, 36, 37, 41, 43, 51, 53, 54, 60, 65, 68, 72, 74, 75, 76, 77, 79, 82], "30": [11, 35, 40], "3000": 77, "300m": 35, "30k": 35, "31k": 5, "32": [13, 41, 42, 49, 72, 84], "3200": 49, "32768": [76, 77], "32k": 37, "33": 11, "338": 35, "33k": 5, "33t": 78, "34": [13, 15], "34b": [9, 34, 53], "35x": 10, "374": 41, "37b": 37, "38": 13, "3822059520": 36, "39": 15, "3m": 36, "4": [5, 7, 11, 13, 14, 15, 28, 29, 34, 38, 40, 41, 42, 48, 49, 51, 53, 55, 60, 67, 72, 74, 77, 78, 79, 84, 85], "40": [43, 46, 54, 59], "400": 7, "405b": [40, 43], "4096": [41, 42, 85], "40k": 35, "41": 13, "426": 16, "43": 13, "443": 19, "448": 15, "45": [3, 13, 38], "4d": [41, 42], "4e00": 84, "4e00\u57280800": 84, "4e00\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a100": 84, "4k": 37, "4t": 38, "4\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 84, "4\u5b57\u8282\u53d8\u957f": 84, "4\u5b57\u8282\u8868\u793a": 84, "5": [11, 13, 14, 15, 21, 22, 31, 34, 35, 36, 37, 38, 41, 42, 46, 47, 48, 49, 59, 60, 62, 74, 77, 85], "50": [32, 34], "500": 7, "500000": [41, 42], "500b": 34, "512": [1, 36], "5120": 36, "52": 34, "52k": [8, 18], "54": [13, 31], "540": 39, "5403": 77, "55m": 19, "57": 11, "5963": 41, "5b": 67, "5e": 53, "5k": 15, "5m": 36, "5pm": 8, "6": [1, 10, 13, 14, 18, 28, 33, 34, 35, 36, 41, 42, 53, 55, 67, 77, 79, 85], "60": [35, 36, 46, 54], "62": [13, 34], "63": 13, "64": [13, 36, 38], "643": 43, "65": 15, "65b": 38, "66": 13, "67": 38, "671b": 37, "67b": 36, "6n": 28, "6nb": 28, "6w": 84, "7": [12, 13, 15, 18, 29, 32, 39, 43, 44, 53, 72, 74, 77], "70": 13, "70b": [34, 39, 40, 53, 60], "72": 13, "72b": 43, "75k": [14, 67], "77": 32, "788m": 37, "7b": [8, 10, 14, 34, 38, 39, 53, 78, 85], "8": [4, 13, 15, 18, 24, 28, 33, 34, 36, 37, 43, 53, 54, 68, 72, 77, 78], "80": [29, 67], "800": 9, "8000": 32, "800k": 67, "80gb": 53, "80k": 14, "80x": 10, "821b": 35, "82k": 18, "83": 41, "8415j": 77, "85": [32, 40], "8b": [27, 40, 53], "8binstruct": 27, "8\u4e2abit\u4f4d\u4e2d\u9ad8\u4f4d\u5fc5\u987b\u7b49\u4e8e0": 84, "8\u4e2abit\u4f4d\u662f\u4e00\u4e2a\u5b57\u8282": 84, "8\u4e3a11100100": 84, "8\u4e3a\u4e09\u5b57\u8282": 84, "8\u4f4d\u53ef\u8868\u793a256\u4e2a\u5b57\u7b26": 84, "8\u548cgbk\u7f16\u7801": 84, "8\u6765\u5b9e\u73b0\u7f16\u7801": 84, "8\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u89e3\u7801\u4f7f\u7528": 84, "8\u7684\u6620\u5c04\u5173\u7cfb\u5982\u4e0b": 84, "8\u7684\u7f16\u7801\u65b9\u5f0f": 84, "8\u7684\u89c4\u5219\u5f88\u7b80\u5355": 84, "8\u7b49": 84, "8\u7f16\u7801": 84, "9": [5, 12, 13, 24, 38, 41, 51, 56, 68, 74, 78], "92": 44, "9297": 77, "95": [13, 38], "974": 16, "9901": 85, "9999": 77, "9e": 53, "A": [3, 8, 15, 18, 24, 26, 27, 32, 39, 41, 42, 43, 46, 49, 50, 54, 55, 58, 61, 62, 65, 68, 74, 75, 76, 81, 82, 86], "And": [50, 72], "As": [26, 29, 32, 33, 35, 39, 40, 48, 49, 50, 62, 65, 67, 75, 78], "At": [1, 3, 18, 26, 31, 37, 39, 61, 67, 76, 77], "By": [4, 35, 37, 40, 41, 49, 59, 76], "FOR": 54, "For": [2, 5, 8, 14, 16, 18, 24, 27, 28, 29, 32, 33, 34, 36, 37, 39, 40, 43, 44, 46, 48, 49, 50, 52, 54, 56, 57, 58, 59, 65, 67, 72, 75, 76, 77, 78, 86], "If": [7, 25, 26, 29, 33, 41, 42, 44, 49, 50, 54, 58, 61, 75, 77, 82], "In": [1, 2, 5, 8, 14, 18, 20, 24, 26, 27, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 62, 64, 65, 68, 72, 75, 76, 77, 78, 80, 81], "It": [5, 7, 8, 11, 20, 24, 28, 29, 33, 34, 36, 39, 40, 41, 44, 47, 50, 54, 66, 75, 77], "Its": 32, "No": [27, 37, 41, 44], "Not": 8, "OF": 54, "Of": 18, "On": [1, 29, 37, 49], "One": [7, 26, 31, 40, 49, 52, 54, 55, 58, 76, 77, 81], "Or": 10, "Such": [24, 61, 68], "That": [1, 25], "The": [1, 2, 3, 4, 5, 8, 9, 11, 12, 14, 15, 16, 18, 20, 24, 25, 27, 28, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 65, 67, 68, 75, 76, 77, 78, 79, 81, 82], "Their": 67, "Then": [5, 14, 40, 48, 49, 50, 54, 55, 58, 75, 78, 80], "There": 76, "These": [1, 2, 8, 15, 19, 20, 40, 43, 54, 58, 60, 61], "To": [1, 3, 4, 5, 11, 14, 15, 18, 20, 26, 27, 28, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 46, 50, 51, 52, 55, 58, 60, 62, 65, 67, 75, 76, 79, 82], "Will": [24, 68], "With": [11, 15, 25, 33, 76], "_": [1, 5, 18, 20, 26, 34, 37, 39, 41, 42, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 62, 66, 67, 72, 75, 76, 78, 80, 81, 82], "_1": [1, 66], "__init__": [36, 41, 42, 79], "__main__": 10, "__name__": 10, "_bsz": [41, 42], "_h": 1, "_i": 72, "_libgcc_mutex": 13, "_mergeable_rank": 41, "_norm": [41, 42, 79], "_openmp_mutex": 13, "_t": 78, "a100": 53, "a_": [26, 50, 77, 81], "a_i": 72, "aa": 74, "aaabdaaabac": 74, "aaditya": [24, 68], "aaron": [24, 68], "aayushi": [24, 68], "ab": [24, 68, 74, 77], "abbrevi": [15, 84], "abha": [24, 68], "abhimanyu": [24, 68], "abhinav": [24, 68], "abhishek": [24, 68], "abil": [3, 11, 14, 15, 29, 35, 36, 43, 48, 50, 58, 64, 65, 67], "abl": [8, 9, 15, 29, 39], "ablat": 67, "about": [1, 5, 8, 14, 24, 25, 29, 32, 33, 34, 36, 49, 59, 75, 77], "abov": [2, 29, 32, 34, 40, 58, 59, 61, 62, 65, 66, 75, 76], "absenc": 37, "absolut": [1, 38, 46, 80], "absorb": 78, "abstract": [3, 44], "abstractset": 41, "ac": 74, "academ": 11, "acceler": [2, 78], "accept": [24, 58], "access": [29, 39, 49, 58, 60, 61, 62, 66], "accommod": [40, 67], "accompani": 52, "accomplish": [27, 40], "accord": [32, 37, 49, 59, 62, 67, 75, 77], "account": [28, 34], "accumul": 33, "accur": [11, 16, 19, 39, 43, 50, 59], "accuraci": [11, 15, 37, 43, 55, 59, 65], "achiam": [24, 68], "achiev": [4, 11, 15, 31, 35, 37, 38, 39, 40, 43, 47, 48, 52, 55, 58, 59, 62, 78], "acquir": [11, 36, 39, 65, 75], "across": [11, 13, 29, 32, 40, 43, 44, 49, 67, 75, 76, 78, 79], "action": [8, 26], "activ": [1, 2, 36, 37, 38, 43, 75, 78, 82], "actor": [50, 53], "actor_learning_r": 53, "actual": [5, 50, 66], "ad": [2, 3, 18, 20, 31, 40, 50, 59, 66, 81], "adam": [24, 68], "adam_offload": 53, "adamw": 38, "adapt": [2, 20, 52, 75, 76, 77, 86], "add": [1, 3, 5, 20, 33, 34, 37, 38, 39, 41, 42, 46, 51, 59, 60], "addit": [1, 3, 5, 26, 29, 31, 32, 34, 35, 37, 41, 42, 49, 51, 52, 56, 60, 65, 66, 67, 75, 76, 78, 82, 84], "addition": [2, 11, 18, 37, 49, 75], "additionali": 50, "address": [15, 20, 33, 40, 44, 50, 55, 58], "adher": [29, 43, 44, 65], "adi": [24, 68], "adina": [24, 68], "adithya": [24, 68], "aditya": [24, 68], "adjust": [36, 40, 46, 58, 65, 78], "adkin": [24, 68], "adolfo": [24, 68], "adopt": [8, 14, 27, 31, 36, 37, 44, 65, 78], "advanc": [11, 32, 43], "advantag": [29, 43, 50, 52, 53, 78], "advis": 54, "affect": [21, 27, 75], "affin": [37, 41, 75], "aforement": 55, "after": [2, 3, 18, 20, 27, 31, 32, 35, 37, 38, 39, 40, 41, 44, 48, 49, 50, 51, 55, 58, 59, 60, 65, 67, 75, 76, 77], "again": [1, 55, 82], "against": [5, 7, 33, 44, 54, 56], "agarw": [24, 68], "agent": [43, 44, 49, 58], "aggreg": 32, "aggress": 8, "agnost": [4, 52], "ahm": [24, 68], "ahmad": [24, 68], "ahuva": [24, 68], "ai": [7, 13, 15, 24, 33, 40, 60, 62, 68], "aidan": [24, 68], "aiesha": [24, 68], "aif": 60, "aift": 60, "aim": [15, 26, 27, 50, 58, 60, 61, 66, 75], "ainsli": [24, 68], "aiohttp": 13, "aiosign": 13, "aixin": [24, 68], "ajai": [24, 68], "ajayi": [24, 68], "ajudg": 44, "akhil": [24, 68], "al": [24, 68], "alan": [24, 68], "alao": [24, 68], "albadawi": [24, 68], "albert": [24, 68], "albiero": [24, 68], "alec": [24, 68], "alethea": [24, 68], "alex": [24, 68], "alexei": [24, 68], "algorithm": [5, 12, 18, 19, 24, 31, 32, 33, 35, 36, 38, 39, 40, 43, 44, 47, 50, 68, 74], "alibi": 77, "align": [1, 2, 5, 15, 21, 28, 29, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 55, 58, 75, 76, 77, 78, 80, 81, 82], "align_n": 52, "alignmentrelev": 29, "alik": 34, "all": [3, 5, 8, 12, 16, 20, 24, 25, 26, 28, 31, 32, 35, 36, 39, 40, 41, 44, 47, 48, 49, 50, 51, 54, 55, 57, 58, 59, 66, 67, 68, 72, 75, 76, 77, 78, 79, 82], "allclos": [41, 79], "allevi": 75, "alli": [24, 68], "alloc": [44, 65], "allonsiu": [24, 68], "allow": [1, 3, 4, 24, 26, 31, 32, 37, 40, 41, 54, 61, 75, 77, 81], "allowed_speci": 41, "allowed_token": 41, "almahairi": [24, 68], "almeida": [24, 68], "almost": 59, "alon": [55, 59, 60], "along": [2, 31, 33, 34], "alongsid": [37, 50], "alpaca": [14, 20, 21, 22], "alpacaev": [27, 60], "alpha": [52, 59, 66, 76], "alpha_": [28, 75], "alphacod": 34, "alrassi": [24, 68], "alreadi": [29, 31, 35, 41, 49, 60], "also": [1, 5, 8, 11, 13, 15, 16, 18, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 60, 61, 62, 75, 76, 78, 82], "altdj": [24, 68, 78], "alter": 33, "altern": [4, 39, 40, 47, 49, 52, 55], "although": [7, 26, 35, 37, 65, 75, 84], "alvarado": [24, 68], "alwai": [31, 40, 52, 59, 75, 76, 77], "alwala": [24, 68], "amanda": [24, 68], "ambigu": 59, "amc": 15, "american": 84, "ami": [24, 68], "amit": [24, 68], "amjad": [24, 68], "amo": [24, 68], "amodei": [24, 68], "among": [7, 9, 34, 36, 44, 49, 58, 75, 78], "amount": [28, 32, 36, 40, 60, 65, 67, 72, 76, 78, 82], "an": [1, 2, 3, 4, 5, 7, 8, 11, 12, 14, 18, 20, 24, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 46, 47, 48, 50, 52, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 68, 72, 75, 76, 77, 78], "anaconda3": 13, "analogi": 29, "analysi": [33, 36, 40, 44, 52, 55], "analyz": [24, 44, 68, 72], "anam": [24, 68], "anchor": 33, "anderson": [24, 68], "andi": [24, 68], "andr": [24, 68], "andrei": [24, 68], "andrew": [24, 68], "angela": [24, 68], "angl": [77, 80], "ani": [1, 3, 4, 8, 12, 14, 18, 25, 26, 29, 33, 37, 40, 41, 44, 51, 54, 62, 65, 67, 76, 77, 78, 80, 81], "anirudh": [24, 68], "ankit": [24, 68], "ann": [24, 68], "anni": [24, 68], "annot": [11, 13, 34, 37, 39, 40, 55, 60], "anoth": [8, 26, 31, 33, 39, 50, 52, 55, 59, 77], "answer": [2, 3, 10, 11, 15, 19, 27, 34, 37, 39, 43, 44, 54, 61, 65, 66, 67, 72, 77], "answer_1": 40, "anthoni": [24, 68], "anthrop": [13, 49], "anticip": 44, "anuj": [24, 68], "anyio": 13, "anywher": [5, 51], "aobo": [24, 68], "aparajita": [24, 68], "api": [5, 13, 43, 51], "app": 54, "appear": [28, 33, 77], "append": [18, 41, 42, 53, 54, 58], "appli": [1, 2, 5, 14, 20, 27, 32, 33, 34, 35, 37, 40, 41, 42, 46, 47, 49, 50, 51, 52, 59, 61, 62, 65, 66, 72, 75, 76, 77, 82], "applic": [4, 5, 15, 34, 39, 76, 77], "apply_chat_templ": 53, "apply_rotary_emb": [41, 42, 77], "approach": [14, 18, 26, 28, 32, 34, 36, 37, 39, 40, 44, 46, 47, 52, 55, 56, 60, 61, 62, 65, 66, 75, 76, 77], "appropri": [1, 8, 34], "approx": [28, 37, 76, 80], "approxim": [3, 4, 7, 26, 35, 36, 40, 49, 59, 62, 67, 72, 75, 77], "aptitud": 15, "ar": [1, 2, 3, 4, 5, 7, 8, 9, 12, 14, 15, 18, 20, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 64, 67, 68, 72, 75, 76, 77, 78, 79, 81, 84], "arang": [12, 41, 42, 47, 77], "arbitrari": [5, 77], "arcaut": [24, 68], "archi": [24, 68], "archit": [24, 68], "architectur": [2, 3, 28, 31, 34, 44, 75, 77, 78, 79, 81, 86], "archiv": 3, "area": [11, 43], "arg": [39, 41, 42, 53, 58, 77], "argmax": 41, "argu": [36, 58], "ariel": [24, 68], "arini": [24, 68], "aris": [54, 55], "arithmet": 15, "arkabandhu": [24, 68], "armand": [24, 68], "armando": [24, 68], "armo": 22, "armorm": 27, "around": [1, 7, 43, 78], "arrang": 13, "arrieta": [24, 68], "art": [4, 15, 29, 38, 43], "artem": [24, 68], "arthur": [24, 68], "articl": 3, "arun": [24, 68], "arvind": [24, 68], "arxiv": [14, 18, 20, 24, 38, 68], "ascertain": 49, "ascii\u5c31\u662f\u6700\u521d\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 84, "ascii\u8d77\u521d\u53ea\u89c4\u5b9a\u4e86127\u4e2a\u5b57\u7b26": 84, "asher": [24, 68], "ashish": [24, 68], "ashlei": [24, 68], "ashwin": [24, 68], "ask": [5, 8, 16, 18, 33, 39, 40, 51, 55, 61], "askel": [24, 68], "aspect": [33, 43, 52, 60], "aspegren": [24, 68], "assaf": [24, 68], "assert": [34, 41, 42, 77], "assertionerror": [41, 77], "assess": [11, 12, 15, 20, 40, 44, 57], "assign": [1, 26, 31, 39, 40, 46, 49, 50, 52, 58, 59, 62, 66, 67, 75], "assist": [8, 29, 34, 41, 54, 56, 60, 61], "associ": [34, 58], "assum": [2, 26, 48, 52, 58, 60, 61, 62, 66, 79, 83], "ast": [47, 58, 66, 81], "aston": [24, 68], "asymptot": 15, "async": 13, "atcod": 13, "atol": [41, 79], "att": 75, "attach": 46, "attain": 49, "attempt": [29, 66, 67], "attend": 1, "attent": [2, 3, 4, 21, 22, 24, 28, 36, 37, 43, 48, 68, 75, 76, 77, 79, 80, 81], "attention_bia": 36, "attention_norm": [41, 42], "attn": 28, "attr": 13, "attract": 77, "attribut": [32, 56], "audio": 8, "augment": 60, "aurelien": [24, 68], "austen": [24, 68], "auth": 13, "authent": 52, "author": [47, 60], "auto": [1, 7], "autom": [18, 43, 44], "automat": [7, 14, 18, 20, 40, 44, 46, 56, 75], "autonom": 65, "autoregress": [2, 4, 26, 34, 39, 76], "auxiliari": [2, 29, 31, 37, 66], "ava": [24, 68], "avail": [19, 34, 38, 40, 43], "avalani": [24, 68], "avenu": 5, "averag": [12, 31, 32, 41, 42, 50, 55, 75], "avoid": [5, 26, 29, 31, 32, 33, 48, 50, 58, 59, 76], "await": 20, "ax": 40, "axi": [41, 79], "ayub": [24, 68], "azadeh": [24, 68], "azhar": [24, 68], "b": [2, 24, 26, 28, 41, 42, 49, 54, 61, 66, 68, 76, 82, 86], "b_": [41, 42, 82], "b_1": 1, "b_2": 1, "b_i": 37, "b_j": 37, "babaei": [24, 68], "babuschkin": [24, 68], "backbon": 46, "backend": 10, "background": 12, "backpropag": 39, "backtransl": 40, "backward": 28, "bad": [26, 29, 40], "badeer": [24, 68], "baevski": [24, 68], "bag": 39, "baker": [24, 68], "balaji": [24, 68], "balanc": [1, 37, 40, 44, 61], "band": 4, "bansal": [24, 68], "baptist": [24, 68], "bar": 76, "barn": [24, 68], "barrier": [24, 68], "basart": [24, 68], "base": [1, 2, 3, 5, 8, 14, 15, 18, 20, 22, 25, 26, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 46, 47, 49, 50, 51, 52, 54, 58, 59, 60, 61, 62, 66, 72, 76, 77, 80, 81, 84, 85], "baselin": [7, 15, 27, 60, 61, 67], "bashlykov": [24, 68], "basi": [41, 77], "basic": [15, 16, 21, 33, 43, 44], "basu": [24, 68], "batch": [5, 8, 28, 34, 38, 39, 40, 41, 49, 51, 78], "batchnorm1d": [41, 79], "batchnorm2d": 41, "batra": [24, 68], "battei": [24, 68], "bavarian": [24, 68], "bawa": [24, 68], "bax": 86, "bbpe": [36, 43], "beati": [24, 68], "beau": [24, 68], "becaus": [1, 8, 18, 33, 40, 46, 54, 65, 79], "becom": [48, 55, 66, 75, 77, 78], "been": [26, 32, 33, 36, 37, 41, 43, 49, 50, 59, 62], "befor": [18, 29, 31, 35, 39, 44, 56, 76, 77], "begin": [1, 2, 3, 5, 28, 34, 37, 39, 40, 41, 42, 47, 48, 49, 50, 51, 54, 58, 62, 65, 75, 76, 77, 78, 80, 81, 82], "begin_of_text": 41, "behav": [29, 32, 77], "behavior": [3, 5, 15, 26, 29, 32, 33, 44, 54, 65, 77, 79], "behaviour": 31, "behind": 77, "bei": [24, 68], "being": [1, 4, 14, 24, 31, 40, 62], "believ": 46, "bell": [24, 68], "belong": 75, "below": [8, 14, 29, 34, 48, 59], "ben": [24, 68], "bench": 21, "benchmark": [3, 4, 9, 19, 20, 24, 29, 35, 36, 40, 68, 78], "benefici": [1, 33, 59], "benefit": [3, 39, 59, 72], "benjamin": [24, 68], "berner": [24, 68], "berni": [24, 68], "bert": [3, 24, 68], "best": [5, 15, 24, 27, 28, 31, 32, 33, 38, 39, 40, 44, 49, 51, 59, 60, 62, 66, 67, 68], "bestof": 27, "beta": [5, 39, 41, 47, 48, 50, 51, 58, 76, 79, 82], "beta_": [38, 66], "beth": [24, 68], "bethani": [24, 68], "beto": [24, 68], "better": [5, 11, 29, 32, 33, 35, 37, 38, 39, 40, 43, 44, 48, 54, 55, 58, 61, 67, 72, 78], "between": [1, 5, 8, 11, 14, 15, 26, 27, 29, 31, 32, 34, 36, 39, 40, 41, 42, 47, 48, 50, 51, 54, 55, 58, 59, 60, 65, 66, 67, 72, 75, 76, 79, 80, 81, 82], "beyond": [13, 29, 55, 75, 77], "bf16": [53, 85], "bhalla": [24, 68], "bharamb": [24, 68], "bhargava": [24, 68], "bhargavi": [24, 68], "bhatt": [24, 68], "bhosal": [24, 68], "bi": [24, 68], "bia": [36, 37, 41, 42, 43, 46, 55, 61, 66, 82], "bias": [18, 26], "bib": 24, "bibliographi": 24, "bibtex": 24, "bidirect": [24, 68], "bigger": [5, 76], "biggest": 32, "bikel": [24, 68], "bilinear": 82, "billion": 4, "billock": [24, 68], "bin": [24, 68], "binari": [39, 40, 55, 59], "bing": [24, 68], "bingxuan": [24, 68], "binh": [24, 68], "binom": [5, 12, 51], "biologi": [11, 15], "biron": [24, 68], "bit": [49, 76], "bitton": [24, 68], "black": 28, "blecher": [24, 68], "bleu": 26, "blind": 11, "block": [2, 3, 10, 25, 34, 40, 75], "blog": [5, 24, 44, 50, 68], "blue": 20, "bmr": [4, 5, 24, 68], "bn": [41, 79], "bo": [24, 41, 68], "bob": [24, 68], "bobbi": [24, 68], "bodi": [12, 84], "boesenberg": [24, 68], "bogoychev": [24, 68], "boltzmann": 49, "bondu": [24, 68], "bontrag": [24, 68], "bonu": 66, "book": [3, 24, 25, 38], "bool": 41, "bootstrap": [14, 18, 29, 40], "borodinski": [24, 68], "bos_id": 41, "both": [1, 4, 7, 9, 11, 14, 15, 24, 27, 31, 34, 37, 39, 40, 43, 44, 50, 51, 52, 54, 55, 56, 60, 62, 66, 67, 76, 77, 78, 79], "boto3": 13, "botocor": 13, "bottleneck": 78, "bottom": [1, 59], "bouaziz": [24, 68], "bound": [27, 75, 77], "boundari": [14, 18, 76], "bowen": [24, 68], "box": [15, 24, 37, 65], "boyu": [24, 68], "bpe": [3, 34, 38], "bpe\u6bcf\u4e00\u6b65\u90fd\u5c06\u6700\u5e38\u89c1\u7684\u4e00\u5bf9\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u66ff\u6362\u4e3a\u8be5\u6570\u636e\u4e2d\u6ca1\u6709\u51fa\u73b0\u8fc7\u7684\u4e00\u4e2a\u65b0\u5355\u4f4d": 74, "bpe\u9009\u62e9\u9891\u6570\u6700\u9ad8\u7684\u76f8\u90bb\u5b50\u8bcd\u5408\u5e76": 83, "braden": [24, 68], "bradlei": [5, 46, 47, 58, 59], "brahma": [24, 68], "brainstorm": 61, "bram": [24, 68], "branch": 40, "brandon": [24, 68], "brani": [24, 68], "breadth": [11, 20], "break": [18, 24, 41, 58, 68], "breviti": [75, 78], "brian": [24, 68], "bridg": [11, 26, 44], "brief": 4, "bright": 15, "bring": 50, "brinkman": [24, 68], "britt": [24, 68], "broad": 18, "broadcast": 77, "broader": [11, 13], "broadli": 4, "brockman": [24, 68], "brook": [24, 68], "brown": [24, 68], "brundag": [24, 68], "brute": 33, "bsz": [41, 42], "bt": 58, "bucket": 40, "budget": [31, 32, 34, 38, 43, 75], "buffer": [49, 53], "bug": [33, 40, 53], "build": [3, 11, 13, 24, 27, 35, 40, 41, 43, 44, 46, 56, 60, 61], "built": [25, 36, 39, 44], "bullet": 33, "burda": [24, 68], "burden": 50, "burn": [24, 68], "burton": [24, 68], "busi": 11, "byte": [3, 34, 36, 38, 43], "bzip2": 13, "c": [2, 9, 12, 28, 31, 32, 36, 39, 40, 41, 42, 44, 49, 59, 76, 77, 78, 79, 82], "c4": 38, "c_": [28, 36], "ca": 13, "cabral": [24, 68], "cach": [10, 41, 42, 43], "cache_k": [41, 42], "cache_len": [41, 42], "cache_v": [41, 42], "cachecontrol": 13, "cachetool": 13, "caggioni": [24, 68], "cai": [24, 54, 68], "caichat": 53, "calcul": [12, 15, 36, 41, 42, 49, 50, 54, 55, 59, 72, 75, 77, 79], "calder": [24, 68], "calibr": [27, 54], "call": [1, 3, 4, 5, 12, 20, 24, 26, 29, 33, 37, 39, 40, 41, 51, 52, 54, 58, 64, 67, 77, 78, 82], "can": [1, 2, 4, 5, 12, 13, 14, 15, 18, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 62, 65, 67, 72, 75, 76, 77, 78, 79, 81, 82, 83], "cancel": 47, "candid": [31, 32, 40, 44, 49, 55, 58, 60, 62, 72], "cannot": [8, 15, 26, 29, 77, 78], "canon": 55, "canton": [24, 68], "capabl": [7, 13, 14, 15, 20, 27, 29, 34, 37, 39, 43, 44, 52, 60, 65, 77], "capac": [2, 49, 75], "capl": [24, 68], "captur": [59, 65, 75], "cardin": [32, 49], "care": [29, 40], "carefulli": [11, 36, 40, 43], "carl": [24, 68], "carli": [24, 68], "carlo": [26, 50], "carr": [24, 68], "carri": [37, 78], "carrol": [24, 68], "carvil": [24, 68], "cascad": 34, "case": [5, 8, 14, 16, 18, 26, 31, 32, 33, 34, 35, 37, 39, 43, 44, 48, 52, 54, 62, 65, 75, 76], "cast": 41, "catalina": [24, 68], "catastroph": 77, "catch": 40, "categor": [32, 40, 44, 59, 61], "categori": [7, 61], "caucheteux": [24, 68], "caus": [11, 41, 47, 48, 56, 75], "causal": [2, 34], "cd": [10, 13], "cdot": [1, 36, 47, 48, 52, 58, 66, 75, 76, 81, 82], "ce": [24, 49, 68], "ceas": 28, "ceil": 29, "cell": 41, "central": 59, "centroid": 75, "certain": [2, 26, 37, 40, 61, 62, 75, 76, 77], "certif": 13, "certifi": 13, "cffi": 13, "cfg": 10, "cgrs19": [4, 24, 68], "chain": [11, 37, 54, 55, 61, 72], "chainof": 72, "challeng": [7, 8, 11, 15, 19, 29, 33, 40, 43, 44, 47, 59, 61, 65, 67], "chan": [24, 68], "chanc": [11, 33], "chang": [8, 13, 24, 56, 66, 68], "changhan": [24, 68], "changkyu": [24, 68], "channel": [13, 41], "chantzi": [24, 68], "chao": [24, 68], "charact": [33, 34, 84], "character": [28, 36, 43], "characterist": [20, 36], "charlott": [24, 68], "charset": [13, 84], "chat": [24, 35, 36, 39, 41, 68], "chat_complet": 41, "chatbot": 7, "chatgpt": [14, 29], "chatterji": [24, 68], "chawla": [24, 68], "chaya": [24, 68], "cheaper": 7, "check": [5, 16, 34, 40, 43, 44, 66, 67], "checklist": 44, "checkpoint": [24, 35, 37, 39, 40, 41, 43, 53, 65, 68], "chelsea": [24, 68], "chemistri": [11, 15], "chen": [24, 68], "cheng": [24, 68], "chenggang": [24, 68], "chengpeng": [24, 68], "chengqi": [24, 68], "chennabasappa": [24, 68], "chern": [24, 68], "chernoguz": [24, 68], "chess": [24, 29, 68], "chester": [24, 68], "chi": [24, 68], "child": [24, 68], "chines": 36, "ching": [24, 68], "chintala": [24, 68], "chiu": [24, 68], "chloe": [24, 68], "cho": [24, 68], "choic": [2, 11, 15, 26, 39, 48, 49, 54, 58, 67, 81], "chong": [24, 68], "choos": [20, 31, 33, 39, 54, 59, 61, 67, 76], "chose": 1, "chosen": [28, 39, 40, 46, 59], "chosen_1": 40, "chosen_2": 40, "chou": [24, 68], "choudhari": [24, 68], "choudhuri": [24, 68], "chowdhuri": [24, 68], "chri": [24, 68], "christian": [24, 68], "christiano": [24, 68], "christoph": [24, 68], "chu": [24, 68], "chuanqi": [24, 68], "chugh": [24, 68], "chunqiu": [24, 68], "chunyang": [24, 68], "ci": 77, "cindi": [24, 68], "cite": 24, "civin": [24, 68], "ckb": [15, 24, 68, 72], "ckpt_dir": 41, "ckpt_path": 41, "cl": 14, "clamp": 54, "clarifi": 28, "clariti": [37, 44], "clark": [24, 68], "class": [13, 18, 36, 41, 42, 48, 79], "classif": [2, 8, 29, 40, 59, 67], "classifi": [13, 31, 40, 44, 52, 61], "claud": 35, "clean": [35, 39, 40, 44], "clear": [44, 53, 59, 77], "clearli": [33, 35], "clemen": [24, 68], "cleo": 13, "clever": 47, "cli": [10, 53], "client": 13, "clip": [38, 50], "clone": [10, 13], "close": [14, 24, 26, 32, 33, 35, 37, 41, 54, 68], "closer": 58, "closest": 33, "cluster": 40, "cnn": 3, "co": [1, 34, 41, 42, 76, 77, 80, 81], "coars": [40, 44], "cobb": [24, 68], "code": [9, 12, 13, 14, 19, 21, 22, 24, 25, 27, 29, 31, 32, 35, 36, 37, 38, 43, 44, 61, 65, 68, 84], "code1": 13, "code2": 13, "code_alpaca_20k": 8, "code_generation_lit": 13, "code_list": 13, "codealpaca": [8, 14, 21, 22], "codebert": 44, "codecontest": [31, 32], "codeexecut": 13, "codeforc": [13, 31, 32], "codegen": 10, "codellama": 14, "codeqwen1": 44, "coder": [14, 21, 22, 24, 37, 43, 68, 85], "codex": [12, 21, 34], "coeffici": [5, 46, 47, 51, 77], "cognit": 65, "coher": [13, 55], "collabor": [43, 44], "collect": [3, 5, 13, 14, 18, 34, 36, 38, 40, 41, 44, 51, 52, 53, 54, 61, 62, 65, 72], "collin": [24, 68], "collot": [24, 68], "colon": 56, "com": [10, 13], "combin": [3, 5, 8, 14, 32, 33, 34, 37, 39, 40, 44, 51, 52, 55, 57, 58, 65, 75, 76], "come": [1, 5, 8, 18, 35, 76, 77], "command": [13, 25], "commbal": 75, "comment": [34, 40, 44], "common": [3, 5, 13, 26, 33, 35, 40, 44, 46, 49, 75], "commoncrawl": 38, "commonli": 14, "commonmark": 24, "commun": [37, 65, 84], "commut": 78, "compar": [7, 11, 26, 27, 35, 37, 40, 43, 44, 48, 49, 50, 52, 60, 62, 66, 67, 82], "comparison": [5, 27, 34, 35, 36, 42, 51, 52, 54, 58, 59], "compat": [1, 34, 77, 79], "compet": [4, 40], "competit": [1, 4, 13, 15, 31, 32, 37, 43], "competitor": 5, "compil": [35, 36, 37, 40, 65], "complementari": [37, 40], "complet": [5, 8, 12, 20, 27, 33, 34, 37, 39, 40, 41, 44, 47, 48, 51], "complex": [2, 11, 14, 20, 29, 34, 40, 41, 42, 43, 44, 50, 64, 65, 76, 77, 81], "complex64": [41, 42, 77], "compli": 32, "complic": [20, 29, 50], "compon": [32, 39, 41, 42, 43, 59, 60, 82], "compos": [1, 15, 75], "composit": 40, "comprehens": [3, 12, 20, 37, 43, 44, 52], "compress": [36, 74], "compris": [11, 36, 37, 40, 43, 44, 49, 75], "comput": [1, 9, 11, 12, 29, 32, 34, 38, 39, 41, 42, 43, 44, 49, 50, 54, 55, 57, 65, 67, 75, 76, 77, 78, 79, 81, 82, 84], "concat": 1, "concaten": [1, 18, 39, 55, 66], "concept": [34, 44], "concis": [37, 43, 49], "conclud": 36, "conclus": [36, 78], "concret": [20, 66], "concurr": 33, "conda": 13, "condit": [2, 18, 26, 31, 52], "conduct": [32, 36, 40, 52, 55, 58, 67, 77], "conduct_rejection_sampl": 58, "confer": [24, 52, 68], "confid": [29, 54, 62], "config": [36, 75], "configur": [27, 36, 43], "confin": 39, "conform": 40, "conjug": 81, "connect": 1, "consecut": [14, 32], "consequ": [40, 52], "consid": [12, 26, 29, 40, 44, 46, 48, 49, 52, 54, 55, 58, 59, 61, 76, 77], "consider": [35, 52], "consist": [1, 2, 5, 9, 11, 14, 15, 29, 34, 35, 36, 44, 46, 47, 51, 62, 65, 72, 75, 79], "console_script": 10, "consolid": 75, "constabl": [24, 68], "constant": [26, 75, 76, 81, 82], "constrain": [47, 58], "constraint": [20, 33, 39], "construct": [7, 9, 20, 34, 35, 44, 52, 56, 58, 60, 65, 75], "consum": [1, 62], "contain": [1, 3, 5, 7, 8, 10, 11, 14, 15, 16, 18, 29, 31, 32, 33, 34, 36, 38, 39, 40, 41, 44, 56, 67, 72, 77, 78], "container": 40, "contamin": [13, 24, 68], "content": [8, 24, 25, 41, 52, 54], "contest": [13, 32], "context": [2, 3, 8, 18, 24, 26, 28, 36, 40, 46, 50, 52, 54, 55, 56, 68, 75, 81], "context_messag": 53, "contextwindow": 37, "contigu": [2, 41, 42], "continu": [1, 5, 13, 14, 15, 33, 40, 44, 46, 50, 51, 54, 58, 59], "contrast": [4, 11, 26, 33, 56, 62, 77], "contribut": 59, "control": [5, 29, 41, 47, 51, 55], "convei": 52, "convent": 78, "converg": [2, 75, 79], "convers": [28, 40, 41, 54, 77], "convert": [1, 25, 55, 58], "convinc": 67, "convolut": 1, "coordin": 76, "copet": [24, 68], "copi": 12, "core": [3, 7, 13, 29, 78], "corinn": [24, 68], "corpora": 44, "corpu": [2, 4, 14, 35, 36, 37, 44, 49, 77], "corr": 46, "correct": [16, 21, 22, 24, 26, 31, 32, 33, 34, 37, 40, 43, 44, 46, 48, 52, 61, 65, 67, 68, 72], "correctli": [15, 33, 62, 66, 77], "correl": [4, 7, 46, 52, 60, 72], "correspond": [1, 5, 15, 18, 20, 26, 32, 33, 34, 35, 37, 41, 42, 46, 47, 50, 52, 58, 77, 80, 81], "correspondingli": 50, "cosin": [1, 38, 40, 85], "cost": [8, 35, 37, 40, 75], "costli": 75, "cot": [11, 21, 22, 54, 55, 65], "coudert": [24, 68], "could": [27, 29, 31, 32, 40, 46, 59, 62, 77], "count": 12, "counteract": [1, 40], "counterclockwis": 80, "counterpart": [39, 40], "coupl": [37, 66], "cover": [11, 33, 44, 60, 75], "coverag": [18, 35, 43, 55, 62], "cpu": 41, "cr": 49, "crack": 22, "craft": 49, "crashtest": 13, "crawl": [3, 35, 44], "creat": [3, 5, 8, 13, 15, 18, 20, 29, 34, 35, 40, 43, 44, 56, 60], "creation": 33, "creativ": [29, 37], "credit": 26, "cristian": [24, 68], "criteria": [39, 40, 43, 56], "critic": [31, 35, 43, 50, 53, 66], "critic_learning_r": 53, "critiqu": [21, 22, 52], "cross": [28, 31, 40, 49, 55], "cross_entropi": 41, "crowd": 16, "crowdwork": 54, "crucial": [35, 36, 44], "crux": 22, "cruxev": [24, 68], "cryptographi": 13, "ctj": [12, 24, 68], "ctx": 28, "cu12": 13, "cubla": 13, "cucurel": [24, 68], "cucurul": [24, 68], "cuda": [13, 41], "cudnn": 13, "cufft": 13, "cum": [24, 68], "cumbersom": 49, "cumsum": 41, "cumul": 41, "cup": 72, "cupti": 13, "cur_po": 41, "curand": 13, "curat": [11, 31, 36, 37, 40, 44, 46, 65], "curiou": [7, 59], "current": [3, 4, 5, 8, 19, 20, 26, 43, 49, 50, 51, 58, 61, 67, 76, 78], "curv": [28, 39], "cusolv": 13, "cuspars": 13, "custom": 5, "custom_evalu": 13, "custom_output_fil": 13, "cut": [41, 52], "cutoff_len": 85, "cwct23": [24, 68, 76], "cycl": 40, "cynthia": [24, 68], "cyru": [24, 68], "d": [5, 10, 20, 24, 25, 26, 28, 34, 39, 41, 42, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 62, 66, 68, 72, 74, 75, 76, 77, 78, 80, 81, 86], "d_": [1, 5, 28, 36, 39, 51, 58, 59, 78, 82], "d_c": [36, 78], "d_h": [36, 78], "d_k": 1, "d_v": 1, "dab": [24, 36, 68], "dahl": [24, 68], "dai": [24, 68], "daili": 3, "dalf": [24, 35, 36, 37, 68, 75, 78], "damai": [24, 68], "damien": [24, 68], "damlaj": [24, 68], "damon": [24, 68], "dan": [24, 68], "dana": [24, 68], "danger": 54, "daniel": [24, 68], "danni": [24, 68], "dario": [24, 68], "data": [2, 3, 4, 5, 14, 20, 21, 22, 26, 27, 29, 34, 46, 47, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 62, 65, 66, 74, 77, 79], "dataclass": [41, 42], "datalabel": 67, "dataset": [2, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 29, 32, 35, 36, 37, 38, 39, 40, 43, 44, 46, 49, 50, 52, 57, 58, 59, 60, 62, 65, 66, 67, 72, 85], "dateutil": 13, "datta": [24, 68], "dave": [24, 68], "david": [24, 68], "davinci": 8, "dawn": [24, 68], "daya": [24, 68], "dazg": [24, 35, 37, 68], "dclt19": [3, 24, 68], "ddot": [80, 81], "ddz": [24, 68, 75], "de": [24, 34, 68], "deal": 61, "debat": 36, "debias": 43, "debug": [20, 40, 44], "debugg": 46, "decad": 15, "decai": [38, 77, 81], "decid": [35, 44, 60, 65, 67, 75], "decis": [26, 33, 46], "declin": [20, 36], "decod": [3, 8, 14, 24, 27, 31, 41, 43, 46, 55, 68, 72], "decompos": 39, "decomposit": 86, "decoupl": [36, 37], "decreas": [11, 27, 28, 37, 47, 48, 52, 58, 75], "dedic": 75, "deduc": 66, "dedupl": [5, 34, 35, 40, 72], "deem": 61, "deep": [24, 68], "deepen": 20, "deepseek": [14, 21, 22, 24, 50, 68, 75, 78, 85], "deepseekcod": [37, 85], "deepseekmath": [24, 35, 68], "deepseekmo": [24, 36, 37, 68], "deepseekv2attent": 36, "deepseekv2config": 36, "deepseekv2forcausallm": 36, "deepseekv2mlp": 36, "deepseekv2model": 36, "deepseekv2pretrainedmodel": 36, "deepseekv2rmsnorm": 36, "deepspe": 85, "def": [10, 12, 36, 41, 42, 58, 77, 79], "default": [7, 13, 25, 41, 77], "defin": [18, 25, 26, 28, 29, 39, 40, 41, 42, 43, 44, 47, 60, 72, 76, 77, 80, 81, 82], "definit": 76, "degener": 47, "degrad": [37, 40], "degre": [4, 39], "dejian": [24, 68], "deli": [24, 68], "delia": [24, 68], "deliber": 67, "delimit": 2, "deliv": 40, "delpierr": [24, 68], "delta": [26, 39, 86], "delta_": 50, "demonstr": [2, 3, 4, 5, 11, 26, 27, 37, 43, 44, 49, 51, 52, 59, 64, 65, 76, 77, 78], "deng": [24, 68], "dengr": [24, 68], "denni": [24, 68], "denomin": 26, "denot": [26, 28, 31, 34, 46, 48, 49, 58, 59, 66, 75, 78, 79, 81], "dens": [4, 40, 43, 78], "densifi": 37, "densiti": 58, "depend": [2, 4, 13, 24, 28, 41, 42, 47, 49, 52, 62, 76, 77, 79, 80, 81], "depict": [3, 54, 65], "deploi": [40, 75], "deploy": 78, "depth": 20, "der": [24, 68], "deriv": [26, 34, 37, 58, 60, 77], "descend": 41, "descent": 2, "describ": [1, 2, 8, 33, 40, 55, 60, 76], "descript": [16, 31, 32, 33, 40, 56], "design": [11, 16, 19, 37, 43, 44, 48, 54, 56, 65, 67, 75, 78], "desir": [5, 26, 40, 52, 56, 58], "despit": [4, 29, 37, 51, 52], "detail": [3, 25, 32, 33, 40, 42, 43, 44, 50, 52], "detect": [18, 31, 40, 43, 52], "determin": [37, 40, 43, 44, 49, 62], "determinist": [27, 37, 65], "detoken": 83, "devbal": 75, "develop": [29, 34, 37, 40, 43, 54, 58, 61, 65, 66], "devi": [24, 68], "deviat": [27, 41, 47, 50, 59], "devic": [37, 41, 42, 77, 84], "devis": [14, 15], "devito": [24, 68], "devlin": [24, 68], "dhariw": [24, 68], "dhillon": [24, 68], "dhruv": [24, 68], "diagon": [34, 41, 42], "dialog": 41, "dialogu": [34, 39, 40], "diamond": 15, "diana": [24, 68], "dict": 41, "dictionari": [8, 58], "did": [44, 55], "didem": [24, 68], "diego": [24, 68], "dieuwk": [24, 68], "differ": [1, 4, 5, 8, 9, 11, 18, 24, 26, 27, 29, 31, 32, 33, 34, 36, 38, 39, 40, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 58, 67, 72, 75, 76, 78, 80, 81], "differenti": 56, "difficult": [15, 29, 33, 72], "difficulti": [11, 15, 19, 20, 32, 40, 44], "dill": 13, "dim": [41, 42, 77, 79], "dimens": [1, 28, 34, 36, 41, 42, 46, 48, 75, 76, 77, 78, 79, 81, 82], "dimension": [1, 46, 80, 81], "diminish": [40, 52, 72], "dinan": [24, 68], "ding": [24, 68], "dingkang": [24, 68], "diogo": [24, 68], "direct": [4, 11, 15, 20, 25, 33, 43, 44, 52, 55, 56, 57, 58, 65, 68], "directli": [2, 12, 14, 27, 34, 35, 40, 47, 50, 55, 58, 66, 76, 77, 81, 83], "directori": 41, "disagr": 40, "disagre": 61, "disallowed_speci": 41, "disallowed_token": 41, "disanalogi": 29, "discard": [8, 40, 44, 61], "discontinu": 20, "discrep": [26, 31, 39, 59], "discret": 39, "discrimin": [2, 31], "discuss": [34, 54, 67, 81], "displai": [25, 52], "dispref": [47, 48], "disproportion": 40, "distanc": [48, 77], "distil": [14, 39, 56, 62], "distinct": [36, 37, 43, 49, 52, 59, 72], "distinguish": [49, 58], "distlib": 13, "distort": 79, "distribut": [2, 4, 5, 20, 26, 31, 34, 37, 39, 41, 46, 47, 49, 50, 51, 54, 55, 58, 59, 61, 62, 65, 66, 67, 75], "distro": 13, "div_": 41, "diverg": [5, 39, 47, 50], "divers": [2, 3, 5, 8, 11, 18, 19, 20, 27, 31, 32, 33, 34, 37, 40, 43, 44, 60, 61, 65], "divid": [1, 31, 33, 43, 50, 80, 81], "divis": 32, "dkv": 78, "do": [4, 8, 9, 14, 18, 24, 26, 29, 32, 33, 35, 39, 40, 41, 42, 51, 61, 65, 66, 67, 68, 76, 78], "do_train": 85, "docstr": [12, 34], "doctyp": 84, "document": [2, 3, 14, 24, 25, 34, 40, 44, 77], "doe": [5, 18, 34, 37, 41, 44, 47, 59, 72, 77, 78, 79], "doesn": 77, "dollar": [24, 68], "domain": [3, 11, 15, 20, 26, 37, 43, 65], "domin": 26, "done": [20, 44], "dong": [24, 68], "dongji": [24, 68], "dot": [2, 26, 41, 42, 44, 48, 50, 52, 57, 60, 61, 75, 76, 77, 78, 80, 81, 83], "doubl": [33, 49, 72], "dowl": [24, 68], "down": [32, 76, 77, 79], "down_proj": 36, "downstream": [4, 40, 86], "dpo": [21, 22, 27, 40, 43, 44, 53, 58, 60, 61], "dpop": [21, 40], "dq": 78, "dr": 3, "draw": [14, 58], "drawback": 65, "drawn": [43, 49], "drive": 31, "drop": [11, 37], "drop_last": 53, "dschat": 53, "dtype": [41, 42], "du": [24, 68], "dubal": [24, 68], "dubei": [24, 68], "duc": [24, 68], "duchenn": [24, 68], "due": [33, 37, 44, 46, 75, 77, 79], "dulwich": 13, "dunbar": [24, 68], "duplic": 34, "dure": [1, 2, 8, 11, 19, 26, 28, 31, 34, 35, 37, 39, 40, 43, 44, 47, 54, 65, 67, 72, 75, 77, 78, 79], "dustin": [24, 68], "dynam": [40, 52], "dz": 49, "e": [2, 5, 8, 9, 10, 12, 13, 14, 18, 26, 29, 37, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 65, 66, 74, 75, 76, 77, 79], "e501": 41, "e_": 61, "e_j": 72, "each": [1, 2, 3, 5, 7, 8, 11, 12, 14, 15, 16, 18, 19, 20, 26, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 72, 75, 76, 77, 78, 79, 86], "earli": 54, "earlier": [5, 39, 40, 54], "easi": [7, 26, 29, 33, 34, 44, 53, 58], "easier": [2, 29, 33, 58, 77], "easili": [1, 9, 14, 31], "eason": 9, "echo": [41, 72], "econom": [11, 24, 36, 37, 68], "ecosystem": 24, "ecut": 9, "edg": 44, "edit": [8, 16, 33, 40, 48, 66], "editor": 34, "edouard": [24, 68], "educ": 44, "edunov": [24, 68], "edward": [24, 68], "ee": [21, 22], "effect": [1, 14, 19, 29, 33, 35, 37, 43, 48, 50, 55, 58, 59, 60, 72, 77, 80, 81], "effici": [2, 24, 32, 36, 37, 43, 50, 67, 68, 75, 78], "effort": [35, 36, 37, 40, 62], "eft": 60, "egebo": [24, 68], "egor": [24, 68], "ehab": [24, 68], "eisenman": [24, 68], "eissa": [24, 68], "either": [8, 32, 36, 39, 40, 52, 66, 67], "el": [24, 68], "elain": [24, 68], "electron": 84, "element": [1, 5, 34, 51, 77, 78, 80, 81], "elementari": [11, 15], "elena": [24, 68], "eleonora": [24, 68], "elev": 36, "elicit": [29, 49, 54, 55], "elimin": 20, "elina": [24, 68], "elizabeth": [24, 68], "ellen": [24, 68], "elment": 41, "elo": 54, "els": [36, 41, 42, 54, 62, 77], "embed": [2, 24, 34, 36, 38, 41, 42, 43, 68, 80], "embed_token": 36, "emerg": 64, "emili": [24, 68], "emit": 48, "emphas": [3, 66], "empir": [3, 26, 29, 72, 76, 77], "emploi": [1, 5, 7, 14, 20, 27, 34, 35, 36, 37, 40, 41, 43, 44, 46, 50, 59, 65, 75], "empow": [20, 24, 68], "empti": [8, 75], "emptyset": 62, "enabl": [4, 15, 33, 34, 37, 43, 52, 65, 75, 76, 77, 80, 81], "encod": [2, 3, 18, 31, 34, 36, 38, 41, 43, 76, 77, 80, 81, 84], "encode_dialog_prompt": 41, "encode_head": 41, "encode_messag": 41, "encoding_for_model": 41, "encompass": 35, "encount": [1, 40, 75], "encourag": [3, 18, 26, 29, 32, 40, 56], "end": [1, 2, 5, 7, 8, 14, 18, 28, 32, 34, 37, 39, 41, 42, 47, 48, 50, 51, 54, 55, 56, 58, 62, 66, 67, 75, 76, 77, 78, 80, 81, 82], "end_header_id": 41, "end_of_text": 41, "enforc": [65, 77], "engin": [11, 44, 53], "english": [8, 36, 40], "enhanc": [11, 14, 24, 27, 36, 37, 43, 44, 59, 68], "enlarg": 72, "enlighten": 14, "enlist": 37, "enough": [4, 9, 29, 36, 39, 48, 58, 78], "ensembl": [27, 59], "ensur": [1, 5, 9, 15, 16, 19, 20, 31, 37, 39, 40, 43, 44, 48, 62, 67, 75, 79], "entail": 2, "entir": [38, 66, 67, 79], "entri": [14, 16, 34, 41, 42], "entropi": [28, 31, 40, 49, 55], "entry_point": 10, "enumer": [41, 42, 77], "env": 13, "environ": [5, 13, 26, 40, 44, 51], "eo": 41, "eos_id": 41, "eos_idx": 41, "eos_reach": 41, "eot_id": 41, "ep": [41, 42, 79], "episod": [5, 51, 53], "epoch": [20, 36, 38, 39, 49, 51, 53, 65, 67], "epsilon": [41, 42, 50, 79], "equal": [26, 38, 76, 78, 80], "equat": [58, 66, 72, 81], "equip": [66, 78, 84], "equival": [3, 31, 33, 56, 58, 75], "erhang": [24, 68], "eric": [24, 68], "erik": [24, 68], "ermon": [24, 68], "error": [18, 29, 33, 40, 41, 44, 50, 82], "esiobu": [24, 68], "especi": [18, 44, 72, 79], "essenti": [31, 33, 52], "est": 74, "establish": [37, 58], "estat": 74, "esteban": [24, 68], "estim": [12, 26, 28, 32, 39, 47, 50, 58, 74], "estrang": 74, "etc": [8, 18, 36], "ethic": [11, 54], "eval": [7, 9, 21, 22, 49], "eval_step": 53, "evalperf": 10, "evalplu": [14, 22], "evalu": [7, 8, 11, 12, 19, 24, 26, 28, 29, 35, 39, 54, 57, 59, 60, 65, 66, 67, 68, 72, 78], "evan": [24, 68], "evas": 54, "even": [4, 20, 26, 29, 37, 40, 44, 47, 48, 58, 77, 78, 80, 81], "evenli": 32, "event": [5, 49, 50], "everi": [1, 4, 15, 18, 55, 76, 79], "evid": [29, 77], "evol": 14, "evolut": 20, "evolutionari": 20, "evolv": 20, "evtimov": [24, 68], "exact": [15, 34], "exactli": 26, "exam": 11, "exampl": [4, 5, 8, 12, 14, 18, 24, 26, 29, 31, 33, 34, 36, 39, 40, 43, 46, 47, 48, 52, 54, 55, 56, 59, 60, 61, 62, 65, 76, 77, 79], "exce": [8, 27, 41], "exceed": [76, 77], "excel": 37, "except": [4, 20, 27, 36, 37, 40, 41, 48, 78], "exceptiongroup": 13, "excess": 37, "exclus": [11, 38, 67], "execut": [9, 13, 24, 25, 31, 32, 34, 40, 43, 44, 68, 77], "executor": 44, "exemplar": [55, 64], "exemplifi": 56, "exhibit": [36, 52, 65, 66], "exist": [11, 12, 14, 18, 31, 40, 43, 44, 61, 76, 77, 83], "exp": [5, 41, 42, 46, 47, 58, 81, 82], "expand": [37, 43], "expans": 77, "expbal": 75, "expect": [5, 18, 26, 32, 37, 40, 44, 50, 52, 54, 72, 77], "expens": [29, 34, 47, 62], "experi": [1, 2, 5, 15, 20, 36, 39, 40, 47, 49, 51, 53, 54, 55, 59, 67], "experience_mak": 53, "experiment": 11, "expert": [15, 24, 36, 37, 40, 44, 68], "expert1": 75, "expert2": 75, "expert3": 75, "expertis": 40, "explain": [33, 40, 44, 46, 55], "explan": [40, 55], "explicit": [3, 37, 76, 77, 80, 81], "explicitli": [8, 39, 40, 54, 56, 66], "exploit": 4, "explor": [33, 39, 50, 52, 64, 65], "exponenti": 77, "export": 13, "express": [4, 12, 47, 49], "extend": [22, 24, 34, 36, 37, 40, 41, 43, 53, 62, 65, 68], "extens": [13, 24, 33, 43, 52, 77], "extern": 65, "extra": [2, 9, 33, 76, 77], "extract": [14, 40, 44, 46, 55], "extractor": 46, "extrapol": [1, 76], "extrem": [1, 15, 26, 29, 37], "f": [10, 41, 42, 74, 76, 77, 82], "f_": [46, 62, 75, 80, 81], "face": [59, 65], "facilit": [1, 31, 52], "fact": 77, "factor": [1, 28, 44, 46, 75, 76, 77, 82], "factual": [40, 43, 65], "fail": [33, 40, 43, 44], "failur": [29, 40, 44], "fair": 78, "faisal": [24, 68], "faith": 40, "faithfulli": [29, 52], "fake": 52, "fals": [36, 41, 42, 79], "famili": [29, 32, 34, 77], "fan": [24, 68], "fangyun": [24, 68], "fanjia": [24, 68], "far": [40, 49], "fashion": [18, 66], "fast": [24, 41, 68], "fastavro": 13, "faster": 7, "fastjsonschema": 13, "faulti": 40, "favor": 46, "featur": [29, 34, 41, 46, 53, 79], "februari": 44, "fed": [2, 44], "federico": [24, 68], "feed": [28, 41, 42, 43, 75, 82], "feed_forward": [41, 42], "feedback": [5, 24, 29, 34, 35, 36, 37, 40, 43, 44, 47, 49, 52, 58, 60, 62, 65, 67, 68], "feedforward": 2, "fei": [24, 68], "feichtenhof": [24, 68], "feinstein": [24, 68], "felip": [24, 68], "felix": [24, 68], "feng": [24, 68], "fernand": [24, 68], "ferrer": [24, 68], "few": [3, 4, 5, 11, 18, 24, 31, 32, 34, 54, 55, 60, 62, 64, 67, 68], "fewer": [33, 36, 76, 77], "ff": [28, 82], "ffff": 84, "ffff\u7684\u8303\u56f4": 84, "ffn": [1, 36, 37, 41, 42, 43, 75], "ffn_norm": [41, 42], "fiction": 3, "field": [8, 15, 18, 19, 44], "fifo": 49, "figur": [1, 28, 35, 37, 39, 49, 52, 54, 65, 72], "file": [8, 13, 25, 34, 41, 44], "filelock": 13, "filip": [24, 68], "filippo": [24, 68], "fill": [34, 37, 39], "filter": [5, 9, 14, 35, 36, 40, 43, 44, 61, 62, 67, 72], "fim": [37, 44], "final": [1, 2, 3, 5, 15, 18, 20, 26, 32, 35, 36, 37, 38, 39, 40, 44, 46, 47, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 65, 67, 75], "find": [8, 11, 27, 28, 29, 31, 32, 36, 39, 40, 51, 54, 55, 58, 60, 65, 66, 67, 72, 78], "fine": [4, 5, 8, 19, 20, 24, 40, 44, 47, 50, 52, 56, 57, 58, 60, 66, 67, 68, 72, 76, 77], "finer": 75, "finest": 74, "finetun": [4, 14, 20, 29, 43, 54, 62, 67], "finetuning_typ": 85, "finn": [24, 68], "firat": [24, 68], "fire": 10, "first": [1, 2, 3, 5, 9, 14, 18, 26, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 51, 52, 53, 55, 58, 59, 60, 61, 65, 66, 67, 72, 75, 78, 81, 82], "first_k_dense_replac": 36, "firstli": 33, "fit": [28, 49, 53, 58, 77], "five": [20, 44], "fix": [1, 5, 28, 33, 40, 49, 51, 67, 76, 79], "flag": 41, "flagopen": 19, "flagship": 43, "flash": [21, 22], "flash_attn": 53, "flatten": [41, 42, 77], "flavor": 24, "flaw": 44, "flexibl": 75, "flexibli": 75, "flip": [52, 66], "float": [41, 42, 58, 77, 79], "float32": [41, 42], "florez": [24, 68], "fluenci": 26, "focu": [8, 26, 38, 43, 49, 67], "focus": [7, 11, 13, 19, 35, 37, 43, 52, 65], "follow": [1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 15, 20, 24, 25, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 50, 51, 52, 54, 55, 56, 58, 59, 61, 65, 68, 75, 76, 77, 78], "fool": 67, "foral": 2, "forc": [15, 31, 33, 66], "forgo": 49, "form": [1, 20, 32, 34, 37, 47, 49, 56, 60, 67, 76, 77], "formal": 50, "format": [13, 15, 18, 20, 34, 37, 54, 65], "formatt": 41, "formul": [26, 47, 59, 75], "fortun": 47, "forum": [24, 68], "forward": [28, 41, 42, 43, 75, 76, 79, 82, 86], "foss": [24, 68], "fotio": [24, 68], "found": [1, 2, 5, 11, 18, 31, 32, 33, 39, 44, 54, 76, 77], "foundat": [14, 20, 24, 34, 38, 40, 44, 68], "four": [3, 11, 20, 34, 39, 40, 59, 65, 78], "fowler": [24, 68], "frac": [1, 5, 12, 26, 28, 41, 42, 46, 47, 48, 50, 51, 52, 58, 59, 75, 76, 77, 78, 79, 80, 81, 82, 83], "fraction": 12, "framework": [10, 18, 36, 37, 43, 44, 52], "francesco": [24, 68], "francisco": [24, 68], "franco": [24, 68], "frank": [24, 68], "fraser": [24, 68], "free": [13, 24, 37, 44, 61, 68], "freez": [46, 86], "freq": [41, 42, 77], "freqs_ci": [41, 42, 77], "frequenc": [1, 34, 75, 77, 80, 81], "frequent": [76, 77], "fresh": 67, "friendli": 54, "from": [1, 3, 4, 5, 7, 8, 10, 11, 12, 13, 15, 18, 20, 21, 24, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 72, 75, 76, 77, 78, 79, 81, 83, 84], "frontier": 15, "frozenlist": 13, "fsfairx": 27, "fsspec": 13, "fu": [24, 68], "fulfil": 52, "fuli": [24, 68], "full": [29, 33, 34, 35, 37, 41, 42, 53, 85], "fuller": [24, 68], "fulli": [1, 8, 29, 37, 44], "function": [1, 4, 5, 9, 16, 24, 26, 29, 33, 34, 38, 39, 43, 44, 47, 48, 49, 50, 51, 52, 58, 59, 66, 76, 77, 79, 80, 81, 82], "fundament": [4, 29], "further": [8, 14, 27, 32, 34, 35, 36, 39, 40, 43, 44, 49, 50, 62, 75, 77, 81], "furthermor": [37, 54], "futur": [29, 36, 37], "g": [13, 14, 18, 37, 39, 40, 44, 46, 50, 55, 56, 58, 61, 65, 66, 76, 80, 81], "g_": [37, 46, 75], "gabriel": [24, 68], "gabriela": [24, 68], "gabriella": [24, 68], "gada": [24, 68], "gae": 50, "gain": [2, 4, 14, 33, 39, 44, 52, 55], "gamido": [24, 68], "gamma": [5, 26, 37, 41, 42, 50, 51, 52, 76, 79], "ganapathi": [24, 68], "gangidi": [24, 68], "gao": [24, 68], "gap": [11, 14, 26, 27, 29, 40, 44, 57], "garcia": [24, 68], "garg": [24, 68], "gat": [24, 68], "gate": [37, 46, 75], "gate_proj": 36, "gather": [39, 41, 43], "gating_dim": 75, "gaur": [24, 68], "gaussian": 82, "gautier": [24, 68], "gave": 8, "gaya": [24, 68], "gb2312\u56e0\u4e3a\u53ea\u8868\u793a\u666e\u901a\u6570\u5b57": 84, "gbk\u662fascii": 84, "gdj": [24, 40, 68], "ge": [12, 18, 24, 46, 48, 50, 58, 68], "geboski": [24, 68], "geffert": [24, 68], "geglu": 82, "gelu": 82, "gemini": [32, 35, 49], "gen": 41, "gener": [1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 19, 20, 24, 26, 31, 32, 33, 34, 35, 36, 37, 39, 40, 43, 44, 47, 48, 49, 50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 72, 76, 78], "generate_kwarg": 53, "generate_max_len": 53, "generation_logprob": 41, "generation_token": 41, "generativeai": 13, "generativelanguag": 13, "geometr": [1, 81], "geometri": 40, "georgia": [24, 68], "georgiou": [24, 68], "get": [15, 24, 25, 26, 34, 44, 46, 58], "get_unique_el": 34, "gg": 28, "gibb": 47, "gibberish": 26, "gil": [24, 68], "ginsburg": [24, 68], "girdhar": [24, 68], "girish": [24, 68], "git": [10, 13], "github": [8, 10, 13, 19, 31, 35, 38, 41, 42, 43, 44], "give": [2, 60, 61, 77], "given": [1, 2, 5, 8, 18, 20, 26, 28, 29, 31, 33, 34, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 55, 56, 58, 60, 61, 62, 66, 67, 72, 76, 77], "glaser": [24, 68], "glob": 41, "glu": [41, 42], "go": 53, "goal": [2, 33, 44, 47, 58, 61, 66], "gold": [21, 31, 32], "goldman": [24, 68], "goldschlag": [24, 68], "goldstand": [24, 68], "gomez": [24, 68], "gonguet": [24, 68], "good": [9, 21, 26, 29, 31, 37, 40, 50, 58, 61], "googl": [10, 13], "googleapi": 13, "google\u7684bert\u6a21\u578b\u5728\u5206\u8bcd\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662fwordpiece\u7b97\u6cd5": 83, "goswami": [24, 68], "gou": [24, 68], "govind": [24, 68], "govindaprasad": [24, 68], "goyal": [24, 68], "gpt": [3, 4, 5, 7, 8, 14, 15, 21, 22, 24, 29, 40, 41, 60, 67, 68, 72], "gpt2": 21, "gpt3": 21, "gpt4": 35, "gpu": [37, 85], "gqa": [24, 43, 68], "grade": 15, "gradient": [1, 2, 5, 38, 48, 49, 51], "gradient_accumulation_step": 85, "gradient_checkpoint": 53, "gradual": 34, "graem": [24, 68], "grai": [24, 68], "grain": [19, 40, 52], "gram": 44, "grammar": 18, "grammat": 18, "grant": [24, 68], "granular": 11, "graphic": 15, "grattafiori": [24, 68], "grave": [24, 68], "great": 41, "greater": 11, "greatli": [4, 86], "greedi": [3, 10, 14, 27, 40, 41, 72], "greg": [24, 68], "gregerson": [24, 68], "gregoir": [24, 68], "gretchen": [24, 68], "grid": 77, "grigori": [24, 68], "grl": [9, 24, 68], "groshev": [24, 68], "ground": [16, 29, 35, 36, 37, 44, 47, 58, 61], "group": [31, 32, 35, 36, 37, 41, 43, 44, 59, 65, 75, 78], "grow": [1, 4, 49], "grpcio": 13, "grpo": [21, 22, 35, 43], "gsm8k": [21, 27, 44, 72], "gu": [24, 68], "guan": [24, 68], "guangbo": [24, 68], "guangyi": [24, 68], "guant": [24, 68], "guarante": [12, 48, 50, 75], "guess": 11, "guid": [18, 27, 58, 59, 65], "guillaum": [24, 68], "guillem": [24, 68], "guna": [24, 68], "guo": [24, 68], "guowei": [24, 68], "gupta": [24, 68], "gururangan": [24, 68], "guss": [24, 68], "guzm\u00e1n": [24, 68], "gzy": [24, 35, 68], "h": [1, 24, 36, 39, 41, 42, 68, 75, 76, 78, 86], "h06a4308_0": 13, "h11": 13, "h1181459_1": 13, "h1234567_1": 13, "h39e8969_0": 13, "h5eee18b_0": 13, "h5eee18b_1": 13, "h5eee18b_6": 13, "h6a678d5_0": 13, "h6a678d5_1": 13, "h800": 37, "h955ad1f_1": 13, "h_": [2, 77], "h_j": 77, "h_n": 2, "ha": [1, 3, 4, 5, 7, 15, 18, 26, 29, 35, 36, 39, 40, 41, 42, 43, 49, 50, 59, 62, 66, 72, 76, 78, 82], "habeeb": [24, 68], "hack": [37, 39, 46, 54, 65], "had": [5, 16, 31], "hahn": [24, 68], "hailei": [24, 68], "hakan": [24, 68], "half": [29, 31, 34], "hallucin": 44, "hallucinatori": 36, "halpern": [24, 68], "halv": 1, "ham": 48, "hambro": [24, 68], "hamid": [24, 68], "han": [24, 68], "hancock": [24, 68], "hand": [12, 16, 28, 29, 37, 49], "handl": [2, 43, 44], "handwritten": 12, "hannah": [24, 68], "hanwei": [24, 68], "hanwen": [24, 68], "hao": [24, 68], "haowei": [24, 68], "haoyu": [24, 68], "happen": 77, "har": 37, "hard": [32, 33, 47, 56, 78], "harder": 32, "harm": [54, 56], "harmless": [43, 55, 56, 60], "haroun": [24, 68], "harri": [24, 68], "harrison": [24, 68], "hart": [24, 68], "hartshorn": [24, 68], "hassan": [24, 68], "hasson": [24, 68], "hat": [26, 47, 50, 59, 66], "have": [1, 2, 3, 12, 14, 15, 18, 25, 26, 28, 29, 32, 33, 35, 37, 39, 40, 43, 44, 46, 47, 48, 54, 58, 59, 60, 61, 72, 75, 76, 77, 79, 82], "hbb": [11, 24, 68], "hd_": 1, "he": [24, 68], "head": [2, 24, 28, 36, 37, 41, 42, 60, 68, 76, 77, 84], "head_dim": [41, 42], "heafield": [24, 68], "health": 11, "heart": 61, "heavi": [28, 66, 78], "hebgen": [24, 68], "heewoo": [24, 68], "heidi": [24, 68], "height": 41, "held": 4, "helen": [24, 68], "help": [2, 5, 15, 24, 33, 34, 36, 37, 39, 40, 43, 44, 46, 49, 51, 54, 56, 60, 76], "helpfulli": 51, "helpsteer2": 21, "henc": [35, 47, 60], "hendryck": [24, 68], "henighan": [24, 68], "henri": [24, 68], "henriqu": [24, 68], "herbert": [24, 68], "herd": [24, 40, 68], "here": [1, 4, 8, 20, 24, 26, 28, 38, 39, 40, 72, 76, 77], "herman": [24, 68], "hermoso": [24, 68], "hess": [24, 68], "heurist": [5, 14, 15, 18], "hf": 58, "hh": 54, "hidden": [36, 41, 42, 46, 75, 76, 82], "hidden_dim": [41, 42], "hidden_s": [36, 75], "high": [2, 12, 14, 15, 26, 27, 31, 37, 39, 40, 43, 44, 46, 48, 49, 59, 60, 61, 62, 66, 74, 80, 81], "highconfid": 62, "higher": [19, 27, 32, 33, 37, 40, 43, 44, 49, 52, 59, 75, 76], "highest": [7, 8, 15, 20, 27, 37, 40, 49, 59, 60, 74, 75, 80], "highli": [15, 29, 44, 46, 61, 62, 67], "highlight": 40, "highqual": 37, "hilton": [24, 68], "hinder": 59, "hing": 47, "hinsvark": [24, 68], "histor": 50, "histori": [11, 26], "ho": [24, 68], "hoc": 55, "hogan": [24, 68], "hold": [28, 67], "holdgraf_evidence_2014": 24, "holist": [13, 24, 68], "holland": [24, 68], "home": 13, "honesti": 46, "hong": [24, 68], "honghui": [24, 68], "hongyi": [24, 68], "hongyuan": [24, 68], "hood": 14, "hook": 13, "hope": 15, "hosseini": [24, 68], "hotfix": 13, "hou": [24, 68], "hour": 37, "hous": 35, "how": [5, 7, 11, 15, 24, 25, 26, 29, 32, 40, 44, 46, 47, 50, 55, 56, 64, 65, 67, 68, 72, 77], "howev": [12, 18, 26, 27, 29, 36, 39, 40, 46, 47, 51, 52, 56, 58, 59, 75, 76, 77, 79, 81], "hsiang": [24, 68], "hstack": [41, 42], "html": 84, "http": [10, 13, 14, 18, 20, 24, 68], "httpcore": 13, "httplib2": 13, "httpx": 13, "hu": [24, 68], "huajian": [24, 68], "huang": [24, 68], "huazuo": [24, 68], "hub": 13, "huge": [33, 77], "huggingfac": [13, 53], "hugh": [24, 68], "hugo": [24, 68], "hui": [24, 68], "human": [4, 5, 7, 9, 11, 15, 16, 18, 20, 24, 26, 29, 34, 36, 37, 40, 43, 44, 47, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 65, 67, 68], "humanev": [20, 22, 27, 44], "humanevalplu": 10, "humanevalplus_releas": 10, "hundr": [37, 77], "hunt": [24, 68], "hunter": [24, 68], "hupk": [24, 68], "hurt": 44, "hybridengin": 53, "hyper": [37, 38, 41, 42, 50, 52], "hyperparamet": [28, 32, 43, 48, 49, 52], "hypothes": 1, "hypothesi": 4, "i": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 65, 67, 68, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84], "i_": 18, "i_t": 18, "ibarra": [24, 68], "ibrahim": [24, 68], "icl": 72, "id": [5, 24, 41, 68], "id1": 13, "id2": 13, "idea": [52, 62, 76, 77], "ideal": [8, 11, 77], "ident": [1, 43, 47, 49, 61, 67, 75], "identif": [40, 44], "identifi": [5, 7, 11, 18, 27, 40, 43, 44, 49, 52, 54, 56, 59, 62], "idna": 13, "ifev": 36, "ift": 60, "ignor": [26, 31, 41, 77], "ignore_index": 41, "igor": [24, 68], "ij": 72, "ik_": [41, 42, 76, 77], "ilia": [24, 68], "iliyan": [24, 68], "illeg": 54, "illia": [24, 68], "illustr": [29, 35, 37, 39, 41, 42, 65], "ilya": [24, 68], "im": [41, 42, 76, 77], "imag": 28, "imaginari": [76, 77], "imanol": [24, 68], "imbal": [37, 75], "imit": 29, "impact": [27, 32, 44, 67, 76], "imper": 8, "imperfect": 62, "implement": [5, 12, 20, 36, 37, 38, 43, 44, 62], "implicit": 47, "implicitli": [29, 47, 66], "import": [10, 12, 26, 29, 39, 41, 42, 47, 58, 60, 61, 77, 79], "importantli": [44, 47, 78], "importlib": 13, "impress": 44, "improv": [2, 4, 14, 26, 29, 31, 33, 34, 36, 37, 38, 39, 40, 41, 43, 44, 48, 50, 55, 59, 60, 61, 62, 64, 65, 66, 67, 72, 79], "inan": [24, 68], "inappropri": 52, "incentiv": 66, "includ": [2, 8, 11, 12, 15, 19, 20, 25, 27, 28, 29, 31, 32, 34, 36, 37, 39, 40, 41, 43, 44, 47, 54, 57, 58, 76, 77, 79, 85], "inclus": 44, "incorpor": [1, 37, 39, 40, 43, 50, 80, 81], "incorrect": [31, 33, 40, 59, 62, 66, 67], "incorrectli": [15, 47], "increas": [11, 14, 20, 32, 34, 37, 40, 47, 48, 52, 72, 75, 77, 81], "increasingli": 65, "increment": 76, "inde": 52, "indent": 44, "independ": [18, 34, 79, 83], "index": [41, 42, 49, 50, 76, 77, 78], "indic": [5, 11, 32, 41, 46, 49, 52, 56, 72, 76, 77, 78, 80], "individu": [28, 79, 80, 81], "induc": [3, 37, 58], "inequ": 47, "inf": [41, 42], "infer": [8, 26, 34, 36, 37, 38, 40, 41, 52, 53, 55, 58, 61, 75, 77, 78, 79], "inference_mod": [41, 42], "inflat": 44, "influenc": 72, "infomax": 49, "inform": [1, 5, 8, 15, 24, 25, 31, 39, 40, 43, 50, 59, 68, 75, 77, 80, 81, 84], "infrastructur": 77, "infti": 28, "inher": [2, 5], "inherit": 46, "init": 25, "init_kl_coef": 53, "initi": [5, 14, 18, 20, 33, 34, 36, 39, 40, 41, 47, 49, 51, 54, 56, 62, 65], "inject": [1, 76, 77, 86], "inlin": [24, 47], "inner": [80, 81], "innov": [36, 78], "input": [1, 5, 8, 9, 14, 18, 20, 24, 31, 32, 33, 34, 38, 39, 41, 42, 44, 48, 49, 51, 52, 55, 58, 61, 76, 77, 78, 79, 80, 81, 82, 83], "input_kei": 53, "input_text_mask": 41, "inputgen": 10, "inputoutput": 33, "insert": [1, 24, 31, 41, 49], "insid": 50, "insight": 47, "inspect": 16, "inspir": 14, "inst": 34, "instabl": [12, 79], "instag": [24, 40, 68], "instal": 10, "instanc": [2, 8, 36, 37, 41, 46, 54, 65], "instead": [1, 3, 5, 8, 12, 20, 29, 32, 34, 38, 41, 42, 49, 50, 52, 54, 62, 76, 77, 79, 81], "instruciton": 8, "instruct": [4, 5, 7, 8, 21, 22, 24, 25, 27, 29, 35, 36, 39, 40, 46, 52, 54, 55, 59, 65, 66, 68], "instructgpt": 51, "instruction_prefix": 10, "instructionfollow": 60, "int": [36, 41, 42, 58, 77, 79], "int_": 49, "integ": 41, "integr": [11, 37, 43, 44], "intellig": [24, 68], "intens": [36, 40, 44], "intent": [5, 40, 59], "intention": 52, "interact": [26, 40, 41, 42, 49, 52, 79], "interc": [46, 75, 76, 77, 78, 80], "interchang": 84, "interdepend": 79, "interest": [29, 40, 58], "interesting": 26, "interestingli": 44, "interfac": 5, "interfer": 79, "interleav": 66, "interlm2": 21, "intermedi": [28, 29, 35, 36, 37, 64, 65, 67, 75], "intermediate_s": 36, "intern": [29, 37, 40], "internet": 51, "interpol": [24, 34, 68], "interpret": [5, 39, 50], "interv": 72, "interview": 34, "intric": 43, "intrigu": 65, "intrins": 65, "introduc": [7, 11, 14, 15, 18, 26, 32, 37, 40, 41, 43, 44, 50, 55, 58, 65, 75, 76, 77, 79], "introduct": 55, "intuit": [26, 29, 47, 81], "invas": 54, "invest": [36, 49, 76, 77], "investig": [37, 52, 67, 72], "involv": [8, 15, 28, 37, 40, 75], "ion": [24, 68], "ionescu": [24, 68], "ip": 55, "ipo": 47, "ipynb": 24, "iq_": [41, 42, 76, 77], "irina": [24, 68], "is_safeti": 39, "isabel": [24, 68], "ise": 10, "ishan": [24, 68], "isin": 41, "isol": 44, "issu": [3, 35, 37, 40, 46, 54, 55, 65, 66, 75, 77, 79], "itai": [24, 68], "item": [53, 58], "iter": [5, 18, 20, 33, 41, 43, 49, 51, 52, 58, 59, 60, 66], "itertool": 13, "its": [4, 14, 16, 18, 29, 31, 32, 34, 36, 37, 40, 41, 42, 43, 44, 46, 47, 49, 52, 54, 58, 60, 65, 66, 67, 72, 75, 76, 77, 78, 79, 81, 82], "itself": [18, 35, 60, 66], "ivan": [24, 68], "ivanov": [24, 68], "ix_": [41, 42, 76, 77], "iyer": [24, 68], "izacard": [24, 68], "j": [24, 26, 37, 41, 42, 48, 50, 52, 61, 68, 75, 76, 77, 78, 81], "j_": [50, 61], "j_1": 52, "j_q": 52, "jack": [24, 68], "jacob": [24, 68], "jade": [24, 68], "jaewon": [24, 68], "jagadeesh": [24, 68], "jai": [24, 68], "jain": [24, 68], "jake": [24, 68], "jakob": [24, 68], "jame": [24, 68], "jamil": [24, 68], "jan": [24, 68], "jana": [24, 68], "janic": [24, 68], "japhet": [24, 68], "jaraco": 13, "jare": [24, 68], "jason": [24, 68], "jauhri": [24, 68], "java": 44, "javascript": 44, "jayesh": [24, 68], "jean": [24, 68], "jeepnei": 13, "jeet": [24, 68], "jeff": [24, 68], "jeffrei": [24, 68], "jelmer": [24, 68], "jenkin": [24, 68], "jenni": [24, 68], "jennif": [24, 68], "jenya": [24, 68], "jeremi": [24, 68], "jerri": [24, 68], "jessica": [24, 68], "jhg": [13, 24, 68], "ji": [24, 68], "jia": [24, 68], "jian": [24, 68], "jianfeng": [24, 68], "jiang": [24, 68], "jianlin": [24, 68], "jianyu": [24, 68], "jianzhong": [24, 68], "jiaqi": [24, 68], "jiashi": [24, 68], "jiawei": [24, 68], "jiawen": [24, 68], "jie": [24, 68], "jiecao": [24, 68], "jin": [24, 68], "jingren": [24, 68], "jingxiang": [24, 68], "jingyang": [24, 68], "jingyi": [24, 68], "jinja2": 13, "jmespath": 13, "joanna": [24, 68], "joblib": 13, "joe": [24, 68], "john": [24, 68], "johnstun": [24, 68], "jointli": 1, "jon": [24, 68], "jonathan": [24, 68], "jone": [24, 68], "jong": [24, 68], "jongsoo": [24, 68], "joseph": [24, 68], "josh": [24, 68], "joshua": [24, 68], "joulin": [24, 68], "journal": [24, 68], "json": [8, 36, 41, 85], "jsonl": 10, "jsonlin": 13, "jubert": [24, 68], "jude": [24, 68], "judg": [7, 22, 32, 33, 37, 40, 52, 60, 61], "judgement": 52, "judgment": [26, 44], "jun": [24, 68], "junji": [24, 68], "junteng": [24, 68], "junxiao": [24, 68], "junyang": [24, 68], "jupyt": [24, 25], "jupyterbook": 24, "jupytext": 25, "just": [11, 13, 24], "k": [1, 2, 3, 5, 12, 15, 20, 24, 31, 37, 39, 40, 41, 42, 46, 48, 49, 51, 57, 68, 72, 75, 76, 77, 78, 80, 81, 86], "k_": [37, 41, 42, 50, 75, 76, 77], "k_1": 50, "k_i": 50, "k_r": [37, 75], "kadian": [24, 68], "kai": [24, 68], "kaig": [24, 68], "kaiser": [24, 68], "kalinli": [24, 68], "kallet": [24, 68], "kalyan": [24, 68], "kam": [24, 68], "kambadur": [24, 68], "kanayet": [24, 68], "kang": [24, 68], "kaplan": [24, 68], "karan": [24, 68], "karda": [24, 68], "karl": [24, 68], "karma": 3, "karn": [24, 68], "karthik": [24, 68], "kartikai": [24, 68], "kartikeya": [24, 68], "katarina": [24, 68], "katayoun": [24, 68], "kate": [24, 68], "kathi": [24, 68], "kati": [24, 68], "kaushik": [24, 68], "ke": [24, 68], "keep": [32, 36, 37, 39, 40, 44, 66, 75, 82], "keepdim": [41, 42, 79], "keho": [24, 68], "kei": [1, 15, 29, 32, 33, 34, 36, 37, 40, 41, 42, 43, 44, 52, 58, 72, 76, 77, 79, 80, 81], "keller": [24, 68], "kelli": [24, 68], "kelsei": [24, 68], "kelton": [24, 68], "keme": [24, 68], "keneal": [24, 68], "kenneth": [24, 68], "kent": [24, 68], "kenton": [24, 68], "keqian": [24, 68], "kerkez": [24, 68], "kernel": 25, "kevin": [24, 68], "keyr": 13, "keyword": 7, "khabsa": [24, 68], "khalid": [24, 68], "khandelw": [24, 68], "khlaaf": [24, 68], "kim": [24, 68], "kind": [5, 24, 52], "king": [24, 68], "kiran": [24, 68], "kl": [5, 39, 47, 50, 51, 58], "kleinman": [24, 68], "klimov": [24, 68], "kloumann": [24, 68], "kmh": [4, 24, 68], "knew": 26, "knight": [24, 68], "know": [26, 29, 72], "knowledg": [11, 14, 33, 39, 75, 80, 81], "known": [26, 41, 42, 59, 77], "koehler": [24, 68], "kohli": [24, 68], "kokkino": [24, 68], "korenev": [24, 68], "korevaar": [24, 68], "kosaraju": [24, 68], "koura": [24, 68], "koushik": [24, 68], "kr": 78, "kreuk": [24, 68], "kreymer": [24, 68], "krishnan": [24, 68], "kristina": [24, 68], "krithika": [24, 68], "krueger": [24, 68], "kshitiz": [24, 68], "kto": [21, 27], "kuan": [24, 68], "kuenlei": [24, 68], "kumar": [24, 68], "kun": [24, 68], "kunal": [24, 68], "kushal": [24, 68], "kv": [36, 43], "kv_a_layernorm": 36, "kv_a_proj_with_mqa": 36, "kv_b_proj": 36, "kv_lora_rank": 36, "kw_": 1, "kyle": [24, 68], "l": [2, 5, 18, 24, 26, 28, 39, 41, 42, 47, 48, 49, 50, 51, 58, 59, 60, 61, 62, 66, 68, 74, 75, 76, 77, 78, 79], "l_": [2, 47, 52, 59], "l_1": 52, "l_2": 52, "label": [2, 4, 5, 18, 19, 29, 35, 36, 39, 40, 43, 51, 54, 56, 58, 61, 62, 67, 72], "labor": 44, "lachaux": [24, 68], "lack": 58, "lacroix": [24, 68], "lailin": [24, 68], "lakhotia": [24, 68], "lakomkin": [24, 68], "lakshminarayanan": [24, 68], "lakshya": [24, 68], "lam": [24, 68], "lambda": [2, 48, 49, 50, 52, 76, 77], "lambda_": [46, 76], "lampl": [24, 68], "land": 54, "landzaat": [24, 68], "langl": [41, 42, 76, 77, 81], "languag": [2, 3, 4, 5, 7, 8, 11, 12, 15, 18, 23, 24, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 44, 47, 49, 51, 62, 65, 67, 68, 75, 80, 81], "laptev": [24, 68], "larg": [1, 2, 3, 4, 5, 7, 9, 12, 18, 23, 24, 26, 29, 32, 36, 37, 39, 40, 41, 42, 44, 47, 48, 49, 51, 62, 65, 68, 75, 78, 81], "larger": [3, 19, 39, 40, 43, 67, 77, 81], "largest": [3, 19, 31, 32, 38, 39, 40], "last": [1, 4, 31, 40, 41, 46, 50, 54, 67], "latent": [36, 37], "later": [18, 40], "latest": [10, 39, 40], "latex": 15, "lathi": [24, 68], "lauren": [24, 68], "lavend": [24, 68], "lavril": [24, 68], "law": [4, 11, 24, 29, 68, 78], "lawrenc": [24, 68], "layer": [1, 2, 3, 4, 5, 28, 31, 36, 38, 41, 42, 43, 46, 51, 53, 75, 76, 77, 78, 82, 86], "layer_id": [41, 42], "layer_idx": 36, "layernorm": [1, 79], "lcb": 13, "lcb_runner": 13, "lcft": 40, "ld_impl_linux": 13, "le": [12, 20, 24, 37, 48, 68, 75, 77, 82], "lead": [26, 29, 33, 34, 37, 38, 40, 48, 54, 67, 76, 77, 79], "leakag": [29, 44], "lean": [24, 68], "leandro": [24, 68], "learn": [1, 2, 3, 4, 5, 11, 15, 26, 27, 28, 29, 31, 34, 38, 41, 42, 44, 47, 50, 56, 58, 59, 60, 68, 75, 82], "learnabl": 41, "learner": [3, 4, 24, 68], "learning_r": 85, "least": [3, 4, 7, 32, 54], "leather": [24, 68], "leav": [31, 33], "lebr\u00f3n": [24, 68], "lecong": [24, 68], "led": [39, 40, 54], "lee": [24, 68], "leed": 75, "leetcod": [13, 22, 35, 37, 65], "left": [1, 5, 12, 26, 28, 32, 34, 41, 42, 46, 47, 48, 50, 51, 52, 55, 58, 66, 76, 77, 78, 80, 81, 83], "leftarrow": 78, "legal": 54, "lei": [24, 68], "leik": [24, 68], "len": [41, 53, 58], "length": [1, 28, 34, 36, 37, 39, 40, 41, 46, 48, 52, 55, 75, 76, 77, 78, 79], "lengthi": 33, "lenni": [24, 68], "leonhardi": [24, 68], "leontiadi": [24, 68], "less": [1, 5, 8, 18, 21, 22, 27, 35, 40, 49, 50, 54, 59, 67, 72, 76], "let": [15, 24, 25, 26, 36, 46, 48, 54, 58, 62, 68, 76, 78, 80, 81], "letman": [24, 68], "level": [3, 11, 15, 16, 19, 20, 26, 29, 32, 34, 36, 37, 39, 40, 43, 44, 49, 67], "leverag": [14, 18, 33, 37, 39, 43, 65, 77, 80, 81], "lewi": [24, 68], "lex": 77, "leyi": [24, 68], "lezama": [24, 68], "li": [24, 68], "liang": [24, 68], "liangjian": [24, 68], "liangpeng": [24, 68], "libffi": 13, "libgcc": 13, "libgomp": 13, "librari": 34, "libstdcxx": 13, "libuuid": 13, "licheng": [24, 68], "lie": [54, 78], "lightman": [24, 68], "like": [2, 8, 11, 24, 25, 26, 29, 33, 37, 43, 44, 48, 49, 54, 56, 61, 65, 67], "likelihood": [2, 26, 27, 31, 47, 48, 55, 58, 59, 62, 67], "limit": [4, 5, 18, 24, 29, 31, 32, 35, 37, 39, 40, 49, 55, 58, 68, 75, 76, 77, 78], "lin": [24, 68], "lind": [24, 68], "lindsai": [24, 68], "line": [14, 18, 20, 24, 25, 28, 29, 34, 41], "linear": [1, 2, 34, 36, 38, 39, 41, 42, 43, 46, 72, 77, 81], "linearli": [1, 32], "lingm": [24, 68], "link": 3, "linter": 40, "liron": [24, 68], "liskovich": [24, 68], "list": [8, 20, 32, 33, 34, 41, 53, 58, 72, 74], "liter": 41, "littl": 44, "litwin": [24, 68], "liu": [24, 68], "livecodebench": [21, 22, 24, 68], "livshit": [24, 68], "liyu": [24, 68], "liz": [24, 68], "lkb": [15, 24, 68], "ll": [24, 41, 78, 86], "llama": [8, 9, 21, 24, 27, 41, 43, 53, 60, 68, 72, 76, 79], "llama2": [21, 39, 72], "llama3": [21, 22, 42], "llion": [24, 68], "llm": [7, 13, 14, 20, 23, 24, 33, 34, 37, 39, 40, 43, 44, 46, 47, 48, 50, 52, 56, 60, 61, 65, 66, 68, 77], "llm4code": 10, "lm": [3, 51], "lm_head": 36, "ln": [41, 49, 77, 79], "load": [37, 41], "load_checkpoint": 53, "load_state_dict": 41, "load_tiktoken_bp": 41, "lobanova": [24, 68], "local": [4, 66], "localhost": 85, "locat": [34, 77], "log": [2, 3, 5, 26, 32, 39, 41, 47, 48, 50, 51, 52, 54, 55, 58, 59, 66, 67, 72, 83], "logging_step": [53, 85], "logic": [33, 37, 43, 44, 65], "logist": 59, "logit": [31, 39, 41, 47, 48, 76], "logprob": 41, "logprobs_i": 41, "long": [2, 5, 8, 24, 40, 41, 44, 48, 65, 68, 76, 77, 81], "longer": [1, 34, 36, 46, 48, 55, 76, 77], "longterm": [24, 68], "look": 33, "loos": 77, "lora": [21, 22], "lose": 60, "loss": [4, 5, 26, 28, 29, 31, 36, 37, 39, 40, 46, 48, 49, 50, 51, 52, 55, 59], "lot": [24, 76], "loui": [24, 68], "lovish": [24, 68], "low": [9, 18, 24, 26, 39, 44, 48, 50, 62, 68, 76, 81, 86], "lower": [8, 40, 48, 72, 76], "lowest": [59, 60, 74, 75, 76], "loyd": [24, 68], "lr_scheduler_typ": 85, "lu": [24, 68], "luan": [24, 68], "lubo": [24, 68], "luca": [24, 68], "luka": [24, 68], "lukasz": [24, 68], "luke": [24, 68], "luo": [24, 68], "lupu": [24, 68], "lxwz23": [10, 24, 68], "lyi": [24, 40, 68], "m": [2, 13, 18, 24, 37, 39, 41, 42, 48, 49, 52, 58, 59, 68, 75, 76, 77, 80, 81], "m_": 58, "m_0": 60, "m_1": 60, "m_2": 60, "m_3": 60, "m_t": 60, "ma": [24, 68], "maaten": [24, 68], "macei": [24, 68], "machin": [1, 3, 34], "madaan": [24, 68], "maddi": [24, 68], "made": [20, 43, 49, 55, 59], "madelin": [24, 68], "madian": [24, 68], "magic": [21, 22], "magicod": [10, 24, 40, 44, 68], "magnitud": [1, 3, 4, 29, 31, 77, 78], "mahadeokar": [24, 68], "mahajan": [24, 68], "mahesh": [24, 68], "maheswari": [24, 68], "mai": [1, 27, 29, 33, 35, 37, 40, 48, 50, 54, 55, 56, 59, 65, 75, 77], "mail": 3, "main": [10, 13, 27, 29, 32, 33, 34, 38, 39, 40, 44], "mainli": [29, 33, 37, 44, 59, 65], "mainstream": 44, "maintain": [35, 36, 37, 39, 43, 44, 75], "major": [15, 40, 44, 56, 67], "make": [1, 2, 5, 8, 11, 18, 19, 26, 29, 32, 34, 41, 42, 43, 46, 47, 49, 52, 53, 54, 60, 65, 66, 77, 79, 80, 81], "make_experience_list": 53, "malik": [24, 68], "malo": [24, 68], "man": [24, 68], "manag": 13, "manav": [24, 68], "mangla": [24, 68], "mani": [3, 4, 15, 18, 24, 25, 34, 44, 51, 77, 84], "manish": [24, 68], "manku": [24, 68], "mann": [24, 68], "mannat": [24, 68], "manner": [60, 61], "manohar": [24, 68], "manta": [24, 68], "manual": [16, 18], "mao": [24, 68], "map": 1, "map_loc": 41, "marcin": [24, 68], "marcu": [24, 68], "margin": [20, 27, 39, 40], "mari": [24, 68], "maria": [24, 68], "mark": [24, 34, 40, 68], "markdown": [10, 35], "markdownfil": 25, "markedli": 24, "markup": 24, "markupsaf": 13, "marra": [24, 68], "martin": [24, 68], "martinet": [24, 68], "martyna": [24, 68], "mask": [1, 31, 34, 40, 41, 42], "mass": [20, 26, 41], "massiv": [11, 24, 43, 44, 68], "master_port": 85, "matan": [24, 68], "match": [15, 19, 37, 41, 43, 66, 76, 77, 78], "mateusz": [24, 68], "math": [11, 24, 35, 36, 37, 40, 41, 42, 43, 44, 48, 50, 65, 67, 68], "mathbb": [1, 5, 12, 26, 39, 46, 47, 48, 50, 51, 52, 58, 59, 66, 75, 76, 78, 80, 81, 86], "mathbf": [1, 26, 34, 37, 41, 42, 50, 52, 75, 76, 77, 78, 79, 80, 81], "mathcal": [2, 26, 39, 46, 47, 48, 49, 57, 58, 59, 61, 62, 66, 72, 75, 78, 82], "mathemat": [11, 12, 15, 24, 35, 36, 37, 40, 43, 44, 47, 50, 68], "mathew": [24, 68], "mathieu": [24, 68], "mathmix": 67, "mathrm": 57, "mathur": [24, 68], "matmul": [41, 42], "matosich": [24, 68], "matplotlib": 47, "matric": [1, 41, 42, 78, 82, 86], "matrix": [1, 2, 34, 41, 42, 78, 80, 81, 82], "matthew": [24, 68], "matthia": [24, 68], "maurer": [24, 68], "max": [1, 24, 39, 41, 42, 48, 58, 62, 66, 68, 76, 82], "max_": [47, 58, 77], "max_batch_s": [41, 42], "max_epoch": 53, "max_gen_len": 41, "max_prompt_len": 41, "max_reward": 58, "max_sampl": 53, "max_seq_len": [41, 42], "maxim": [2, 5, 8, 14, 20, 24, 26, 32, 38, 47, 49, 50, 51, 58, 62, 66, 67, 68, 76, 77], "maximum": [26, 31, 34, 39, 40, 41, 47, 49, 58, 76, 77, 78], "maya": [24, 68], "mayer": [24, 68], "mazeika": [24, 68], "mbox": 81, "mbpp": [20, 21, 22, 44], "mbppplu": 10, "mbppplus_releas": 10, "mccandlish": [24, 68], "mcconnel": [24, 68], "mceval": 44, "mcgrew": [24, 68], "mcphie": [24, 68], "md": [24, 25], "me": 54, "mean": [1, 39, 41, 42, 48, 49, 50, 59, 60, 75, 79, 81], "meaning": 33, "meansquar": [41, 42, 79], "meanwhil": [76, 77, 80, 81], "measur": [5, 11, 24, 26, 31, 40, 50, 55, 62, 68], "mechan": [1, 32, 37, 43, 44, 50, 75, 79, 80, 81], "media": 3, "median": 39, "medina": [24, 68], "medium": 34, "meer": [24, 68], "meet": [24, 68], "meghan": [24, 68], "mehta": [24, 68], "mejia": [24, 68], "melani": [24, 68], "memori": [1, 2, 9, 50, 78], "meng": [24, 68], "menon": [24, 68], "mention": 7, "merg": 20, "mergeable_rank": 41, "messag": [33, 41], "met": 40, "meta": [41, 84], "metadata": [13, 32], "metanat": [24, 68], "method": [4, 14, 20, 27, 37, 39, 40, 41, 43, 44, 47, 49, 52, 56, 59, 64, 76, 77, 80, 81], "methodologi": [37, 65], "meticul": [36, 44], "metric": [12, 20, 26, 29, 31, 46, 55, 72], "mialon": [24, 68], "miao": [24, 68], "miaojun": [24, 68], "michael": [24, 68], "michal": [24, 68], "michel": [24, 68], "michelena": [24, 68], "michiel": [24, 68], "micro_rollout_batch_s": 53, "micro_train_batch_s": 53, "middl": [15, 18, 34, 37], "might": [7, 40, 79], "mihailescu": [24, 68], "mihaylov": [24, 68], "mihir": [24, 68], "mik": [24, 68], "mikayel": [24, 68], "mike": [24, 68], "mikhail": [24, 68], "mile": [24, 68], "miller": [24, 68], "million": [3, 4, 29, 31, 32, 34, 40, 43, 44], "min": [24, 41, 46, 50, 58, 68, 86], "min_": 47, "min_prompt_len": 41, "mine": 58, "ming": [24, 68], "mingchuan": [24, 68], "minghua": [24, 68], "minghui": [24, 68], "mingm": [24, 68], "mini": [41, 79], "minim": [37, 47, 49, 76, 77], "minimis": [31, 48], "minimum": 47, "minor": 66, "minu": 41, "minut": 9, "miquel": [24, 68], "mira": [24, 68], "misalign": 52, "mishkin": [24, 68], "mishra": [24, 68], "mismatch": [48, 66], "misra": [24, 68], "miss": [24, 34, 68], "mistak": [33, 52, 66], "mistralai": 13, "mitchel": [24, 68], "mitesh": [24, 68], "mitig": [5, 36, 37, 40, 44, 46, 50, 51, 55, 59, 62, 66, 75, 77], "mitra": [24, 68], "mix": [5, 31, 34, 35, 40, 44, 51, 58, 65], "mixtral": 53, "mixtur": [24, 36, 37, 43, 53, 68], "mk": 75, "ml": [4, 77], "mla": [22, 36, 37], "mle": [47, 52, 58], "mlp": 46, "mmlu": 27, "mn": 75, "mo": [24, 68], "mode": [29, 47], "model": [2, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 31, 33, 34, 35, 36, 37, 38, 47, 48, 50, 53, 54, 55, 56, 57, 58, 68, 75, 78, 79, 80, 81, 86], "model_arg": 41, "model_name_or_path": 85, "modelarg": [41, 42], "modern": [29, 84], "modest": 67, "modif": [2, 3, 8, 20, 31, 40, 76], "modifi": [1, 8, 34, 39, 40, 56, 60, 61, 66, 77, 86], "modul": [13, 36, 41, 42, 44, 75, 79], "modular": 33, "modulelist": [41, 42], "modulenotfounderror": 41, "moe": [22, 36, 37, 43, 75, 78], "moe_intermediate_s": 36, "moegat": 75, "mohammad": [24, 68], "mohan": [24, 68], "molybog": [24, 68], "mona": [24, 68], "monoton": 58, "mont": [26, 50], "montalvo": [24, 68], "montanez": [24, 68], "montgomeri": [24, 68], "month": 39, "more": [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 18, 19, 20, 21, 22, 25, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 54, 56, 58, 59, 65, 67, 72, 75, 76, 78], "moreov": [24, 36, 66], "morikawa": [24, 68], "moshkovich": [24, 68], "most": [1, 3, 4, 15, 24, 27, 34, 37, 39, 40, 41, 44, 46, 52, 60, 67, 75, 77, 84], "mostli": [16, 40], "motiv": [3, 47, 58, 62], "move": [3, 34], "moya": [24, 68], "mpmath": 13, "msgpack": 13, "mt": 75, "mtp": 37, "much": [8, 29, 34, 40, 47, 54, 67, 76, 77, 81], "multi": [2, 21, 24, 28, 34, 36, 38, 40, 41, 42, 44, 68], "multidict": 13, "multihead": 1, "multilingu": [40, 43, 44], "multinomi": 41, "multipl": [5, 11, 15, 18, 27, 33, 37, 40, 41, 42, 43, 44, 49, 53, 54, 60, 66, 75, 76, 78, 81], "multiple_of": [41, 42], "multipli": [1, 37, 46, 80, 81], "multiprocess": 13, "multistag": 43, "multitask": [3, 11, 24, 34, 68], "munish": [24, 68], "murati": [24, 68], "murtadha": [24, 68], "murthi": [24, 68], "must": [1, 24, 26, 28, 34, 48, 67, 76, 77], "muzzi": [24, 68], "my": 54, "n": [1, 2, 10, 12, 13, 20, 21, 22, 24, 26, 27, 31, 34, 37, 41, 42, 49, 52, 58, 60, 61, 66, 67, 68, 74, 75, 76, 77, 79, 80, 81, 82, 83], "n_": [18, 28, 78], "n_h": [36, 78], "n_head": [41, 42], "n_layer": [41, 42], "n_routed_expert": [36, 75], "n_shared_expert": 36, "n_t": 18, "n_vocab": 41, "n_word": 41, "nabla_": [26, 47, 48], "nail": [24, 68], "naiv": [29, 47, 72, 75], "nakano": [24, 68], "nam": [24, 68], "naman": [24, 68], "name": [13, 20, 31, 33, 41, 44, 47, 82], "nandhini": [24, 68], "nano": 49, "narang": [24, 68], "narj": [24, 68], "narrow": [4, 14], "natascha": [24, 68], "natasha": [24, 68], "nativ": 40, "natur": [3, 4, 7, 18, 29, 31, 33, 34, 35, 40, 41, 44, 55, 64, 65, 76, 77, 79], "naumov": [24, 68], "navyata": [24, 68], "nayak": [24, 68], "nayan": [24, 68], "nayani": [24, 68], "nccl": 13, "ncurs": 13, "nderstand": 9, "ndim": [41, 42, 77], "ne": [48, 72], "nearbi": 80, "nearli": [1, 3, 29, 43, 44, 49], "necess": 36, "necessari": [46, 60], "necessit": 75, "necssari": 8, "need": [4, 18, 24, 25, 29, 33, 35, 39, 40, 41, 42, 50, 59, 68, 72, 77, 78], "neelakantan": [24, 68], "neg": [26, 43, 44, 46, 48, 52, 56, 59, 62, 66, 67, 72], "negligibli": 39, "neighbor": 54, "net": [24, 68], "network": [2, 38, 41, 42, 43, 46, 75, 82], "networkx": 13, "neural": [1, 2, 24, 41, 42, 65, 68, 82, 83], "neutral": 67, "never": 75, "new": [1, 3, 4, 5, 8, 11, 13, 14, 18, 20, 29, 31, 32, 34, 39, 40, 41, 42, 43, 46, 48, 49, 50, 51, 60, 72, 74, 82], "newli": 20, "newlygener": 18, "next": [1, 2, 13, 18, 26, 31, 33, 40, 49, 51, 54, 60, 61, 77, 81], "next_token": 41, "ng": 13, "nguyen": [24, 68], "ni": [24, 68], "nichol": [24, 68], "nichola": [24, 68], "nick": [24, 68], "nicola": [24, 68], "nie": [24, 68], "nikhil": [24, 68], "niki": [24, 68], "nikola": [24, 68], "nikolai": [24, 68], "nikolaidi": [24, 68], "niladri": [24, 68], "ning": [24, 68], "nl": 57, "nll": 40, "nlp": [2, 4, 5, 29, 51, 74, 79], "nn": [36, 41, 42, 75, 77, 79], "noam": [24, 68], "node": [37, 44, 75], "nois": 59, "noisi": [35, 59, 61, 62], "non": [4, 8, 15, 18, 37, 38, 43, 46, 54, 58, 65, 81], "none": [36, 41, 42], "nonlinear": [41, 42, 82], "noqa": 41, "norm": [41, 42], "norm_ep": [41, 42], "normal": [1, 3, 13, 38, 42, 43, 50, 53, 54, 55, 59, 75], "normalize_reward": 53, "normalized_shap": 41, "norman": [24, 68], "notabl": [7, 27, 35, 46, 77], "note": [23, 24, 28, 33, 37, 41, 47, 48, 49, 50, 61], "notebook": 24, "notin": [52, 58], "novel": [14, 20, 52, 58, 61, 80, 81], "novelti": 12, "novemb": 35, "now": [33, 36, 46, 47, 48, 61, 66, 77], "np": [12, 47, 58], "nuanc": [43, 65], "nucleu": 41, "num": 78, "num_attention_head": 36, "num_base_token": 41, "num_channel": 41, "num_episod": 53, "num_experts_per_tok": 36, "num_featur": [41, 79], "num_head": 36, "num_reserved_special_token": 41, "num_sampl": [41, 58], "num_step": 1, "num_train_epoch": 85, "number": [2, 4, 5, 12, 18, 20, 27, 28, 29, 31, 34, 35, 36, 41, 43, 49, 50, 58, 67, 75, 76, 77, 78, 79, 81, 82, 86], "numer": [12, 48, 72], "numpi": [12, 13, 47, 58], "nvidia": 13, "nvjitlink": 13, "nvrtc": 13, "nvtx": 13, "nw": 57, "o": [1, 9, 50, 56, 74, 78, 81], "o1": 21, "o_": [36, 50], "o_1": [50, 56], "o_2": [50, 56], "o_g": 50, "o_proj": 36, "obei": 78, "object": [2, 5, 26, 31, 32, 34, 37, 39, 40, 43, 47, 50, 51, 52, 58, 62, 75], "observ": [20, 27, 29, 33, 36, 40, 46, 49, 55, 59, 65, 72, 76, 78], "obstacl": 26, "obtain": [1, 2, 8, 14, 20, 32, 35, 36, 40, 43, 44, 46, 49, 55, 58, 66, 72], "obviou": 26, "occasion": [4, 40], "occur": 65, "occurr": 65, "od": 9, "off": [18, 24, 25, 27, 52, 55], "offer": [40, 44, 49, 52, 55], "offlin": [21, 22, 26, 31, 36, 44, 52], "offset": 1, "often": [2, 4, 18, 26, 33, 52, 55, 56, 59, 62, 79], "ofthought": 64, "ol": 74, "olano": [24, 68], "old": [50, 74], "older": 74, "oldham": [24, 68], "oleg": [24, 68], "oliveira": [24, 68], "olivi": [24, 68], "olivia": [24, 68], "omit": [36, 75, 78, 82], "omkar": [24, 68], "onc": [1, 8, 20, 28, 78], "one": [1, 4, 5, 7, 18, 20, 24, 26, 27, 29, 31, 32, 34, 37, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 55, 56, 58, 60, 67, 68, 72, 75, 77, 79, 82], "ones": [1, 36, 39, 40, 41, 42, 44, 62, 75, 77, 79], "ones_lik": [41, 42, 77], "onli": [4, 5, 8, 9, 11, 15, 18, 29, 31, 32, 34, 37, 39, 40, 41, 42, 44, 46, 47, 48, 50, 52, 54, 56, 60, 61, 62, 66, 67, 76, 77, 78, 80, 81], "onlin": [21, 22, 32, 36, 52], "onur": [24, 68], "open": [7, 8, 20, 22, 24, 37, 41, 43, 44, 60, 65, 68], "openai": [3, 5, 13, 15, 24, 41, 51, 68], "opencod": 22, "openr1": 22, "openreview": [24, 68], "opensourc": 43, "openssl": 13, "oper": [2, 15, 20, 49, 77, 79], "opportun": 49, "oppos": [34, 82], "opposit": [52, 56], "optim": [2, 5, 8, 21, 24, 26, 27, 28, 33, 35, 36, 37, 39, 43, 44, 49, 51, 57, 58, 61, 65, 66, 68, 77], "optima": 66, "optimis": 48, "optimizatio": 40, "option": [8, 10, 26, 36, 41, 42, 54, 55, 77], "opu": 35, "oracl": [26, 27, 66], "order": [1, 2, 3, 4, 5, 29, 31, 32, 33, 34, 36, 39, 47, 51, 54, 55, 59, 60, 61, 75, 76, 77, 78, 80, 81], "org": [14, 18, 20, 24, 68], "organ": [44, 47], "origin": [3, 10, 11, 18, 20, 32, 33, 37, 38, 39, 40, 46, 52, 55, 59, 60, 61, 75, 76, 77, 81, 82], "orjson": 13, "orthogon": 14, "oss": [24, 68], "other": [1, 2, 5, 11, 20, 24, 25, 26, 29, 33, 34, 36, 37, 40, 41, 42, 44, 49, 52, 58, 60, 62, 66, 68, 72, 75, 79, 82, 84], "otherwis": [26, 37, 39, 52, 58, 67, 75, 76], "otim": [41, 42, 82], "our": [1, 2, 3, 5, 8, 9, 11, 14, 15, 18, 20, 26, 29, 31, 32, 34, 35, 36, 37, 38, 39, 40, 43, 44, 47, 48, 49, 50, 51, 54, 55, 57, 59, 60, 61, 65, 66, 67, 72, 77, 80, 81, 86], "ourselv": 32, "out": [5, 32, 39, 40, 41, 42, 44, 49, 51, 72, 76, 77, 78], "out_logprob": 41, "out_token": 41, "outbound": 3, "outcom": 65, "outer": [41, 42, 77], "outermost": 53, "outlin": [20, 59, 65], "outperform": [27, 29, 34, 35, 36, 37, 43, 44, 55, 67, 72], "output": [1, 2, 5, 8, 9, 13, 14, 18, 25, 26, 27, 28, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 50, 51, 52, 56, 59, 61, 62, 75, 78, 79, 81], "output_dir": 85, "outsid": 59, "ouyang": [24, 68], "over": [1, 2, 3, 4, 5, 11, 13, 26, 28, 32, 34, 36, 39, 40, 41, 42, 43, 44, 49, 50, 51, 52, 53, 55, 59, 60, 62, 66, 67, 78, 79, 81], "overal": [1, 2, 18, 28, 31, 37, 40, 46, 50, 52, 55], "overconfid": 59, "overfit": [19, 51, 59], "overlap": 44, "overload": 37, "oversight": 15, "overthink": 37, "overview": [24, 41, 42], "overwrite_cach": 85, "owj": [5, 24, 68], "own": [40, 52, 54, 60, 66, 67], "ozgenel": [24, 68], "ozlem": [24, 68], "p": [2, 5, 26, 27, 39, 41, 47, 49, 50, 52, 56, 58, 81, 83], "p_": [26, 49, 59, 62, 66, 75], "p_1": 66, "pack": [1, 85], "packag": 13, "pad": 79, "pad_id": 41, "padding_idx": 36, "page": [24, 25], "paino": [24, 68], "pair": [1, 2, 3, 5, 8, 9, 26, 29, 33, 34, 36, 38, 43, 44, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 62, 66], "pairwis": [5, 39, 46, 56, 57, 58, 60, 61], "palm": [41, 42], "paluri": [24, 68], "pamela": [24, 68], "pan": [24, 68], "panda": 13, "pandei": [24, 68], "pang": [24, 68], "panpan": [24, 68], "paola": [24, 68], "papakipo": [24, 68], "paper": [5, 12, 14, 15, 18, 20, 23, 26, 32, 33, 34, 40, 72, 77], "par": 55, "paradigm": [4, 52], "parallel": [1, 31, 41, 44, 75, 79], "paralleliz": 1, "param": [12, 41, 42], "paramet": [1, 2, 3, 4, 5, 14, 27, 32, 34, 37, 38, 39, 40, 41, 42, 46, 47, 48, 49, 50, 51, 52, 58, 59, 72, 75, 76, 77, 78, 79, 80, 81, 82, 86], "parameter": [28, 62], "parametr": 47, "paranjap": [24, 68], "parekh": [24, 68], "parenthes": 56, "parikh": [24, 68], "park": [24, 68], "parker": [24, 68], "parkin": [24, 68], "parmar": [24, 68], "pars": [40, 44], "parsed_arg": 10, "parser": 40, "part": [29, 34, 44, 49, 75, 81], "parth": [24, 68], "parthasarathi": [24, 68], "partial": [26, 33], "particip": [16, 31, 32], "particular": [1, 40, 41, 42, 47, 49, 50, 64, 76, 82], "particularli": [13, 43, 52, 65], "partit": [47, 59, 75], "pass": [2, 9, 12, 16, 20, 28, 31, 33, 34, 35, 40, 41, 42, 43, 44, 46, 76, 82, 86], "pass_at_k": 12, "past": 49, "pasupuleti": [24, 68], "pat_str": 41, "patel": [24, 68], "path": [25, 41, 72], "path_to_custom_output": 13, "patil": [24, 68], "patrick": [24, 68], "pattern": [4, 37, 41], "paul": [24, 68], "pavan": [24, 68], "pavlov": [24, 68], "pavlova": [24, 68], "pavlovich": [24, 68], "pbar": 53, "pdf": [14, 18, 20], "pe_": 1, "peak": 8, "pearson": 46, "pebbl": 13, "pedro": [24, 68], "pei": [24, 68], "peiyi": [24, 68], "penal": [29, 59], "penalti": [5, 39, 46, 50, 51, 66], "peng": [24, 68], "pengchuan": [24, 68], "pengwei": [24, 68], "per": [5, 11, 12, 26, 28, 31, 32, 36, 41, 50, 51, 56, 57, 60, 67, 78], "per_device_train_batch_s": 85, "percent": 54, "percentag": [31, 55], "perceptu": 26, "perfect": [40, 60], "perform": [1, 3, 4, 5, 7, 8, 9, 11, 14, 15, 27, 29, 31, 32, 33, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 51, 52, 55, 58, 60, 62, 64, 67, 72, 75, 76, 78, 79], "perino": [24, 68], "period": [34, 36, 81], "permit": 8, "permut": [41, 79], "perplex": 76, "person": [5, 54], "perspect": [4, 81], "petar": [24, 68], "peter": [24, 68], "petroski": [24, 68], "petrov": [24, 68], "pexpect": 13, "pgr": 29, "phase": [18, 33, 34, 37, 39, 43, 47, 54, 65], "phd": 15, "phenomenon": [29, 46, 65], "phi": [5, 46, 47, 50, 51, 55, 61, 82], "phi4": 21, "philip": [24, 68], "philipp": [24, 68], "philosophi": 11, "php": 40, "phrase": 2, "physic": [11, 15], "pi": [1, 5, 26, 39, 47, 49, 51, 58, 59, 62, 66, 72, 76, 77], "pi_": [5, 26, 39, 48, 50, 51, 58, 62, 66, 72], "piao": [24, 68], "pick": [27, 31], "piec": [38, 40, 54, 55], "piecewis": 39, "pierr": [24, 68], "pii": 5, "pile": 77, "pinto": [24, 68], "pintz": [24, 68], "pioneer": 37, "piotr": [24, 68], "pip": [10, 13], "pipelin": [7, 8, 35, 37, 43, 47, 56, 65, 67], "pivot": 27, "pkginfo": 13, "place": [41, 42, 56, 82], "placehold": 8, "plai": [27, 35, 36, 37], "plain": [5, 33], "plan": [37, 77], "plane": 81, "plappert": [24, 68], "platform": [3, 13, 31, 32, 44], "platformdir": 13, "plawiak": [24, 68], "playground": 5, "pleas": [10, 54], "plethora": 40, "plot": [28, 47, 49], "plot_loss": 85, "plt": 47, "plu": 13, "plugin": 13, "pm": 62, "pmatrix": [34, 80, 81], "po": 1, "poenaru": [24, 68], "poetri": 13, "point": [1, 27, 32, 33, 36, 39, 40, 44, 60, 65, 77], "pointwis": 58, "polar": [41, 42, 76, 77], "polici": [5, 24, 35, 36, 37, 39, 40, 43, 47, 49, 51, 54, 55, 58, 62, 65, 66, 68], "polidoro": [24, 68], "polina": [24, 68], "polit": 54, "polosukhin": [24, 68], "pond": [24, 68], "pool": [18, 31, 58, 61, 62], "poor": [33, 37, 49, 65, 79], "poorli": 29, "pop": 58, "popular": [7, 29], "portion": [34, 40, 44, 65], "posit": [2, 24, 29, 34, 37, 38, 41, 42, 43, 48, 50, 52, 55, 56, 60, 61, 62, 67, 68, 79, 80, 82], "positionwis": 1, "possess": 60, "possibl": [3, 18, 29, 32, 33, 37, 38, 40, 49, 54, 56, 57, 61, 66, 67], "possibli": [44, 54], "post": 55, "post0": 13, "postpon": 33, "potenti": [4, 5, 33, 36, 39, 44, 52, 55, 65], "poulton": [24, 68], "pow": [41, 42, 79], "power": [4, 14, 24, 31, 32, 41, 42, 65, 68], "ppo": [5, 21, 22, 35, 39, 51, 56], "ppo_train": 53, "practic": [1, 4, 26, 29, 33, 44, 46, 47, 49, 59, 62, 75, 77], "practition": 14, "prafulla": [24, 68], "prajjwal": [24, 68], "pranav": [24, 68], "prasad": [24, 68], "prashant": [24, 68], "pratik": [24, 68], "praveen": [24, 68], "pre": [1, 4, 22, 24, 31, 33, 35, 41, 46, 54, 68, 74, 76, 77, 80, 81, 83], "preambl": 55, "preced": [2, 39], "precis": [26, 34, 52], "precomput": 77, "precompute_freqs_ci": [41, 42, 77], "predecessor": [43, 44], "predefin": [14, 57, 65], "predict": [1, 2, 5, 9, 13, 29, 31, 32, 34, 41, 46, 49, 51, 59, 62, 66, 67, 77], "predominantli": 34, "prefer": [5, 7, 21, 22, 24, 26, 27, 35, 36, 37, 43, 44, 46, 48, 49, 51, 54, 56, 57, 58, 60, 61, 65, 66, 67, 68, 77, 79], "prefix": [5, 13, 18, 26, 34, 67], "preliminari": [36, 65], "prepar": 43, "prepend": [41, 54], "presani": [24, 68], "prescrib": 49, "presenc": [25, 44], "present": [5, 33, 37, 40, 43, 49, 51, 52, 54, 55, 61, 67, 76, 77], "preserv": [44, 76, 77], "pressur": 76, "pretrain": [4, 5, 11, 18, 29, 34, 36, 44, 51, 53, 54, 60, 67, 76, 77, 86], "pretrained_weight": 85, "prev_po": 41, "prevent": [1, 34, 37], "previou": [1, 4, 18, 20, 36, 40, 41, 42, 43, 49, 52, 66, 76, 77], "previous": 1, "primarili": [5, 15, 35, 40, 43, 51, 52], "princip": 75, "principl": [54, 56], "print": [25, 41], "prior": [3, 4, 15, 39, 47, 52, 54, 62], "priorit": [40, 43], "pritish": [24, 68], "privaci": 54, "prm800k": 67, "pro": [32, 35, 49], "prob": 41, "probabl": [1, 2, 5, 12, 26, 27, 41, 47, 48, 49, 50, 52, 54, 55, 58, 62, 67], "problem": [4, 9, 10, 11, 12, 13, 14, 15, 16, 19, 24, 29, 31, 32, 33, 34, 37, 40, 44, 47, 58, 59, 65, 67, 68], "probs_idx": 41, "probs_sort": 41, "probs_sum": 41, "proce": 20, "procedur": [2, 5, 29, 32, 48, 49, 51, 55, 60], "process": [3, 18, 20, 24, 26, 27, 29, 33, 35, 36, 37, 41, 43, 44, 46, 49, 52, 68, 77, 79, 81, 83], "prod": 12, "produc": [1, 2, 5, 8, 14, 18, 20, 26, 27, 31, 32, 33, 36, 37, 40, 41, 44, 46, 49, 51, 52, 55, 56, 59, 62, 66, 78], "product": [12, 26, 41, 42, 80, 81, 82], "profession": [11, 34], "profici": 36, "program": [12, 16, 24, 31, 32, 33, 34, 35, 37, 40, 43, 44, 68], "programm": [9, 16], "programmat": 12, "progress": [1, 33, 37, 39, 49, 50], "project": [1, 31, 78], "promin": 20, "promis": [3, 4, 27, 44, 55], "promot": 18, "prompt": [5, 7, 8, 10, 11, 12, 14, 18, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 46, 49, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 65], "prompt_data": 53, "prompt_max_len": 53, "prompt_token": 41, "prompts_dataload": 53, "prone": [19, 59], "prop": 38, "proper": [44, 46], "properli": [24, 39], "properti": [77, 80], "proport": [34, 36, 44, 48, 75], "propos": [1, 18, 26, 29, 34, 41, 42, 44, 46, 47, 50, 52, 58, 61, 62, 66, 72, 75, 78, 82, 86], "proprietari": [34, 43], "propto": 48, "proto": 13, "protobuf": 13, "protocol": 40, "prove": 81, "proven": [35, 50], "provid": [2, 5, 8, 10, 11, 12, 13, 16, 19, 29, 34, 35, 37, 39, 41, 44, 47, 48, 50, 52, 59, 60, 64, 65, 67, 77, 81], "proxim": [24, 50, 68], "prune": 16, "pseudo": [40, 62], "pseudolabel": 62, "psi": [47, 50, 58, 59], "psi_": 59, "psm": 34, "psychologi": 11, "pth": 41, "ptx": [5, 51], "ptyprocess": 13, "public": [5, 31, 32, 33, 35, 44, 51], "publicli": [34, 38, 40, 43], "punit": [24, 68], "pure": 65, "puri": [24, 68], "purpos": [24, 29, 34, 77], "pursu": 15, "push": [1, 14, 24, 52, 68], "pushkar": [24, 68], "put": [8, 18, 26, 31, 65], "puxin": [24, 68], "puzzl": [29, 37], "py": [10, 85], "py310h06a4308_0": 13, "pyarrow": 13, "pyasn1": 13, "pycpars": 13, "pydant": 13, "pyext": 13, "pypars": 13, "pyplot": 47, "pyproject": 13, "python": [9, 10, 13, 14, 16, 31, 32, 34, 40, 44, 72], "pytz": 13, "pyyaml": 13, "q": [1, 5, 24, 26, 41, 42, 43, 44, 50, 52, 68, 72, 76, 77, 78, 80, 81], "q_": [41, 42, 76, 77], "q_0": [41, 42], "q_1": [41, 42], "q_2": [41, 42], "q_3": [41, 42], "q_a_layernorm": 36, "q_a_proj": 36, "q_b_proj": 36, "q_head_dim": 36, "q_i": 72, "q_lora_rank": 36, "qa": [38, 65], "qi": [24, 68], "qian": [24, 68], "qihao": [24, 68], "qime": [24, 68], "qing": [24, 68], "qingxiao": [24, 68], "qinyu": [24, 68], "qiu": [24, 68], "qiushi": [24, 68], "qk": 1, "qk_nope_head_dim": 36, "qk_rope_head_dim": 36, "qkv": 43, "qlora": 53, "qr": 78, "qu": [24, 68], "quad": [2, 28, 37, 39, 59, 62, 75, 76, 77], "qualiti": [1, 3, 14, 15, 18, 19, 21, 26, 32, 36, 37, 39, 43, 44, 46, 55, 56, 57, 60, 61, 62, 76, 77], "quantifi": 59, "quantil": 62, "quantiti": [21, 40], "quartil": 40, "queri": [1, 5, 7, 24, 34, 36, 41, 42, 43, 44, 49, 50, 59, 62, 68, 76, 77, 80, 81], "query_1": 40, "query_2": 40, "question": [2, 3, 8, 10, 11, 15, 16, 20, 27, 33, 34, 37, 44, 50, 55, 67, 72, 76, 77], "question_id": 13, "quit": [33, 35], "qw_": 1, "qwen": 21, "qwen2": [21, 22, 43], "r": [1, 5, 9, 20, 24, 26, 34, 36, 37, 39, 40, 41, 46, 48, 49, 50, 58, 59, 66, 68, 72, 75, 76, 78, 80, 81, 86], "r1": [22, 37], "r_": [5, 26, 36, 39, 46, 47, 49, 50, 51, 55, 58, 59, 60, 72, 80, 81], "r_1": 50, "r_h": 39, "r_i": [50, 72], "rachad": [24, 68], "rachel": [24, 68], "racist": 54, "rad18": [2, 3, 24, 68], "radenov": [24, 68], "radford": [24, 68], "radford2018improv": [24, 68], "rafael": [24, 68], "rafailov": [24, 68], "rafi": [24, 68], "ragavan": [24, 68], "raghotham": [24, 68], "raghu": [24, 68], "rahul": [24, 68], "rai": [24, 68], "raileanu": [24, 68], "rais": [11, 41, 77], "rait": [24, 68], "raj": [24, 68], "ramanathan": [24, 68], "ramaswami": [24, 68], "ramchandani": [24, 68], "ramesh": [24, 68], "ramon": [24, 68], "ramp": 76, "ran": 32, "rand_prompt": 53, "randn": [41, 79], "random": [3, 11, 14, 31, 32, 41, 49, 58, 59, 61], "randomli": [9, 11, 14, 20, 31, 34, 44, 54, 56], "rang": [2, 4, 5, 11, 13, 14, 29, 34, 38, 39, 40, 41, 42, 53, 54, 55, 74, 77], "rangaprabhu": [24, 68], "rangl": [41, 42, 76, 77, 81], "ranjan": [24, 68], "rank": [5, 27, 31, 33, 39, 40, 47, 51, 58, 59, 60, 86], "rantala": [24, 68], "rao": [24, 68], "raparthi": [24, 68], "rapidfuzz": 13, "rapidli": 52, "rashi": [24, 68], "rastegari": [24, 68], "ratanchandani": [24, 68], "rate": [29, 31, 32, 33, 36, 38, 39, 40, 46, 49, 51, 55, 67], "rater": 49, "rather": [47, 56, 65], "ratio": [37, 44, 48, 76], "rational": 55, "raul": [24, 68], "raw": [35, 83], "raymond": [24, 68], "re": [33, 41, 42, 47, 58, 76, 77, 81], "reach": [4, 15, 18, 32, 33, 39, 67, 75], "read": [3, 41], "readabl": [40, 65], "readlin": 13, "real": [34, 53, 77, 81], "realist": [8, 15], "realiti": [58, 77], "realiz": 2, "realli": [24, 68], "realm": [14, 20], "rearrang": [47, 58], "reason": [4, 11, 12, 20, 22, 24, 26, 27, 33, 34, 36, 37, 40, 43, 48, 50, 55, 61, 67, 68, 77, 79], "rebekkah": [24, 68], "recal": [26, 40, 49, 52], "receiv": [3, 26, 39, 49, 75], "recent": [4, 31, 32, 38, 39, 40, 41, 46, 51], "recip": [34, 40, 61], "recommend": [7, 60], "recov": [29, 49], "rectifi": [41, 42, 82], "recurr": 1, "red": [20, 78], "reddit": 3, "reduc": [3, 8, 11, 26, 27, 39, 48, 66, 75, 77, 78, 82, 86], "reduct": [41, 48], "redund": [32, 37, 75], "reevalu": 65, "ref": [47, 48, 50, 66], "refer": [5, 16, 19, 24, 26, 34, 39, 40, 46, 47, 48, 49, 50, 54, 60, 67, 76], "refin": [37, 40, 49], "reflect": [16, 33, 52], "regardless": 46, "regex": 41, "regim": 67, "region": [1, 26, 77], "reglu": [41, 42, 82], "regress": [1, 5, 34, 39, 40, 46, 51], "regular": [24, 40, 43, 49, 50], "regularli": [37, 44], "rehears": 34, "reiichiro": [24, 68], "reinforc": [5, 29, 34, 47, 50, 56, 67], "reizenstein": [24, 68], "reject": [21, 22, 34, 37, 39, 40, 44, 46, 57, 59, 61, 62, 72], "rejected_1": 40, "rejected_2": 40, "rel": [1, 5, 27, 31, 35, 36, 37, 41, 42, 43, 48, 54, 65, 77, 80, 81], "relat": [8, 13, 27, 34, 35, 37, 43, 44, 50, 58, 72, 75, 78, 81], "relationship": [24, 68], "releas": [8, 10, 34], "relev": [29, 33, 43, 44, 61, 62, 67], "reli": [14, 26, 29, 32, 33, 37, 62, 79], "reliabl": [9, 11, 15, 29, 36, 37, 43, 65, 67], "relianc": 79, "relu": [1, 38, 41, 42, 47, 82], "remain": [18, 28, 29, 31, 32, 48, 59, 62, 67], "remark": 65, "remez": [24, 68], "remind": 8, "remov": [5, 20, 32, 34, 38, 40, 44, 51, 54, 58, 61, 72], "ren": [24, 68], "render": 24, "renorm": 41, "reorder": 34, "repair": 13, "reparameter": 47, "repeat": [8, 18, 33], "repeatedli": 31, "repetit": 3, "replac": [38, 41, 42, 43, 54, 55, 77, 82], "replai": [49, 50, 53], "replay_buff": 53, "repo": [40, 44], "report": [12, 44, 59, 72], "repositori": [13, 31, 34, 35, 44], "repres": [1, 18, 20, 26, 34, 40, 41, 42, 48, 59, 75, 76, 77, 81, 82, 84], "represent": [1, 29, 31, 37, 41, 42, 47, 55, 81, 82], "request": [8, 13, 54, 60], "requir": [1, 2, 4, 8, 9, 29, 32, 33, 34, 37, 39, 40, 41, 49, 58, 65, 75, 76, 77, 78, 79, 80, 81], "rerank": 32, "resampl": [43, 49], "rescal": 77, "research": [15, 39, 52], "reserv": 36, "reserved_special_token_": 41, "reserved_special_token_0": 41, "reserved_special_token_1": 41, "reserved_special_token_2": 41, "reserved_special_token_3": 41, "reserved_special_token_4": 41, "reshap": [41, 42, 77], "reshape_for_broadcast": [41, 42, 77], "residu": [1, 28], "reso": [24, 68], "resolv": [31, 40, 46], "resort": 65, "resourc": [33, 39, 44], "respect": [1, 5, 27, 48, 50, 51, 52, 55, 56, 59, 75, 78], "respons": [5, 7, 8, 10, 13, 20, 27, 36, 37, 39, 40, 41, 43, 44, 46, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 62, 65, 66, 75], "response_candid": 58, "response_reward": 58, "rest": 25, "restrepo": [24, 68], "restrict": [26, 37, 48], "result": [1, 3, 4, 11, 12, 14, 19, 26, 29, 32, 33, 34, 39, 44, 50, 52, 58, 59, 65, 67, 72, 75, 76, 77, 78, 80, 81], "retain": [34, 37, 40, 44, 54, 62], "return": [12, 26, 41, 42, 52, 58, 77, 79], "reus": [43, 65, 77], "reveal": [37, 40], "revers": 55, "review": [43, 47], "revis": [40, 66], "reward": [5, 21, 22, 24, 27, 29, 33, 34, 35, 36, 37, 43, 47, 50, 52, 53, 55, 57, 58, 61, 62, 68], "reward_pretrain": 53, "rewon": [24, 68], "rewrit": 54, "rft": [21, 72], "rho": 72, "rho_": 58, "ricardo": [24, 68], "rich": 43, "right": [1, 5, 12, 26, 28, 34, 41, 42, 46, 47, 48, 50, 51, 52, 55, 58, 66, 67, 76, 77, 78, 81, 83], "rigor": [10, 11, 24, 68], "rinott": [24, 68], "rise": [24, 68], "risk": [37, 44], "rita": [24, 68], "rittner": [24, 68], "rl": [5, 21, 22, 31, 35, 36, 37, 39, 43, 47, 54, 55, 56, 62, 65, 67], "rlaif": [22, 54, 56, 62], "rlcd": [21, 22, 62], "rlhf": [29, 34, 46, 47, 49, 51, 53, 54, 58], "rlhf1": 22, "rlhf2": 22, "rm": [5, 21, 29, 37, 39, 40, 46, 53, 55, 57], "rm_": 36, "rmboost": 21, "rmsnorm": [36, 38, 43], "robert": [24, 68], "roberta": [24, 40, 68], "robin": [24, 68], "robinson": [24, 68], "robust": [18, 33, 35, 43, 54], "rocca": [24, 68], "rocki": [24, 68], "rodriguez": [24, 68], "roform": [24, 68], "rohan": [24, 68], "rohit": [24, 68], "role": [27, 35, 36, 37, 41], "rollout": 66, "rollout_batch_s": 53, "romain": [24, 68], "ronni": [24, 68], "room": 33, "rope": [21, 22, 34, 37, 38, 43, 78], "rope_theta": [41, 42], "roshan": [24, 68], "rosnbrick": [24, 68], "ross": [24, 68], "rotari": [24, 34, 38, 43, 68, 80], "rotat": [34, 80, 81], "roug": 18, "roughli": [28, 32, 38, 59, 67], "round": [20, 32], "rout": [36, 37, 75], "roux": [24, 68], "row": [41, 42, 77], "rozier": [24, 68], "rozi\u00e8r": [24, 68], "rsa": 13, "rsm": [24, 40, 68], "rso": [21, 22], "rsqrt": [41, 42, 79], "rtol": [41, 79], "rtx4090": 53, "ruan": [24, 68], "rudolph": [24, 68], "rui": [24, 68], "ruiqi": [24, 68], "ruizh": [24, 68], "rule": [15, 33, 35, 36, 37, 40, 65], "rulebas": 37, "run": [9, 25, 33, 34, 40, 48, 54, 66], "rungta": [24, 68], "runji": [24, 68], "runner": 13, "runtim": [13, 32], "runxin": [24, 68], "russ": [24, 68], "ruti": [24, 68], "ruyi": [24, 68], "rwc": [3, 4, 24, 68], "rx": 49, "ryan": [24, 68], "ryder": [24, 68], "s3transfer": 13, "s_": [26, 37, 48, 75, 77], "s_1": [44, 77], "s_2": 77, "s_n": 44, "saab": [24, 68], "sachin": [24, 68], "safe": 51, "safeti": [29, 34, 36, 39], "saghar": [24, 68], "sahana": [24, 68], "sahil280114": 8, "sai": [24, 54, 68], "sajuyigb": [24, 68], "saladi": [24, 68], "salienc": 29, "salient": 29, "salpekar": [24, 68], "sam": [24, 68], "same": [1, 4, 20, 24, 31, 32, 33, 34, 35, 36, 40, 44, 47, 48, 54, 56, 58, 59, 60, 65, 72, 75, 76, 77, 78, 79], "sampl": [3, 9, 10, 11, 12, 14, 18, 20, 21, 22, 26, 27, 34, 35, 37, 38, 39, 40, 41, 43, 44, 47, 49, 50, 54, 55, 56, 57, 60, 61, 62, 67, 72, 79], "sample_top_p": 41, "samvelyan": [24, 68], "samyak": [24, 68], "sandbox": [43, 44], "sandhini": [24, 68], "sangani": [24, 68], "sanghai": [24, 68], "sanit": 10, "sanjai": [24, 68], "santhanam": [24, 68], "sara": [24, 68], "saraf": [24, 68], "sargun": [24, 68], "sasha": [24, 68], "sastri": [24, 68], "satadru": [24, 68], "satisfactori": [36, 52], "satisfi": 52, "satish": [24, 68], "satterfield": [24, 68], "saunder": [24, 68], "saurabh": [24, 68], "sauvestr": [24, 68], "save": [33, 78], "save_path": 53, "save_step": [53, 85], "sax": [24, 68], "saxena": [24, 68], "scalabl": [2, 15, 44, 52, 55], "scalar": [5, 39, 46, 51, 52], "scale": [2, 4, 18, 19, 24, 29, 39, 40, 41, 42, 44, 47, 52, 65, 68, 77, 78], "scan": 28, "scarciti": 44, "scenario": [13, 44], "schedul": 38, "schelten": [24, 68], "scheme": [39, 49, 84], "school": 15, "schulman": [24, 68], "schwarz": [24, 68], "scialom": [24, 68], "scienc": [11, 38], "scope": 37, "score": [11, 37, 39, 40, 41, 42, 43, 44, 46, 49, 50, 51, 54, 55, 56, 58, 59, 60, 62, 67, 75, 76, 77], "scorer": 44, "scott": [24, 68], "scrape": [3, 31], "scratch": [21, 59, 76, 77], "script": [10, 85], "sean": [24, 68], "search": [32, 33, 67], "seattl": 74, "second": [1, 3, 8, 9, 26, 32, 36, 37, 44, 49, 55, 66, 82], "secret": [21, 22], "secretli": [24, 68], "secretstorag": 13, "section": [35, 43, 54, 65, 77, 81], "secur": 44, "see": [7, 9, 11, 24, 25, 26, 28, 40, 42, 48, 55, 77], "seed": [8, 14, 18, 44, 60, 61], "seek": 39, "seen": [40, 62], "segment": [15, 39, 83], "seid": [24, 68], "seiji": [24, 68], "select": [7, 9, 20, 27, 31, 32, 33, 34, 37, 39, 40, 41, 46, 49, 51, 67, 72, 75], "selector": 67, "self": [1, 2, 3, 5, 8, 10, 13, 14, 16, 21, 22, 34, 36, 40, 41, 42, 44, 50, 53, 75, 76, 77, 79, 80, 81], "selfattent": 81, "selfinstruct": 18, "seltzer": [24, 68], "semant": [16, 31, 32, 33, 40, 44, 61], "semi": 18, "sen": [24, 68], "send": [28, 49, 75], "sensit": [5, 11, 78, 79], "sent": [37, 75], "sentenc": [1, 2, 3, 8, 38, 55, 83], "seohyun": [24, 68], "separ": [1, 7, 32, 34, 39, 67], "seq_len": [41, 79], "seqlen": [41, 42], "sequenc": [1, 2, 15, 24, 26, 34, 37, 39, 41, 42, 43, 49, 52, 58, 60, 68, 75, 76, 78, 79, 80, 81, 82, 83], "sequenti": [26, 49], "sergei": [24, 68], "seri": [14, 38, 43, 44, 60, 64, 67], "serv": [24, 27, 37, 49, 59, 75], "servic": 43, "set": [1, 4, 5, 7, 8, 9, 11, 12, 15, 18, 19, 20, 26, 27, 29, 31, 34, 35, 36, 37, 39, 40, 41, 43, 44, 49, 50, 51, 54, 58, 59, 60, 61, 67, 72, 75, 76, 77, 81], "setup": [10, 29], "setuptool": 13, "seventh": [24, 68], "sever": [12, 27, 31, 32, 34, 35, 39, 40, 43, 44, 49, 65, 79], "sexist": 54, "sft": [5, 21, 22, 36, 37, 43, 44, 47, 48, 50, 53, 55, 57, 58, 59, 60, 65, 66, 72], "sh": 53, "sha": [24, 68], "sha19": [24, 68, 78], "shah": [24, 68], "shajnfeld": [24, 68], "shake": [24, 68], "shallow": 46, "shanghao": [24, 68], "shangyan": [24, 68], "shanhuang": [24, 68], "shankar": [24, 68], "shantanu": [24, 68], "shao": [24, 68], "shaoliang": [24, 68], "shaoq": [24, 68], "shape": [28, 41, 42, 77, 79], "sharadh": [24, 68], "sharan": [24, 68], "sharath": [24, 68], "share": [1, 5, 36, 37, 65, 78], "sharma": [24, 68], "shaun": [24, 68], "shazeer": [24, 68], "sheasha": [24, 68], "shelf": [27, 52, 55], "shellingham": 13, "shen": [24, 68], "sheng": [24, 68], "shengfeng": [24, 68], "shenghao": [24, 68], "shengxin": [24, 68], "shengy": [24, 68], "shepard": [24, 68], "sherman": [24, 68], "shift": 67, "shirong": [24, 68], "shishir": [24, 68], "shiva": [24, 68], "shiyu": [24, 68], "shojanazeri": [24, 68], "short": [9, 16, 37, 77], "shorter": 27, "shot": [4, 5, 11, 18, 24, 54, 55, 60, 62, 67, 68, 72], "should": [4, 8, 9, 15, 25, 28, 29, 32, 48, 52, 54, 56, 58, 78], "shouyuan": [24, 68], "show": [1, 4, 5, 11, 24, 25, 26, 34, 38, 40, 47, 48, 52, 54, 58, 59, 60, 64, 65, 67, 77, 78, 81], "shown": [1, 5, 12, 14, 26, 29, 50, 51, 55, 59, 62], "shruti": [24, 68], "shuang": [24, 68], "shuffl": 20, "shuip": [24, 68], "shun": [24, 68], "shunfeng": [24, 68], "shuqiang": [24, 68], "shyam": [24, 68], "si": [24, 68], "sibi": [24, 68], "sida": [24, 68], "siddhartha": [24, 68], "sidestep": 49, "sidorov": [24, 68], "sigler": [24, 68], "sigma": [5, 39, 41, 42, 47, 48, 51, 55, 58, 59, 82], "sigmoid": [41, 42, 47, 58, 82], "signal": [18, 26, 33, 35, 37, 40, 43, 55, 56, 65], "signatur": [12, 16, 32, 34], "signific": [3, 11, 36, 39, 40, 43, 76, 77, 78, 79], "significantli": [1, 8, 11, 14, 27, 33, 34, 36, 39, 40, 43, 48, 54, 59, 64, 67, 78], "silu": [41, 42], "silva": [24, 68], "silveira": [24, 68], "sim": [5, 26, 28, 39, 47, 48, 50, 51, 58, 59, 62, 66, 82], "simen": [24, 68], "similar": [4, 7, 11, 18, 24, 31, 32, 40, 44, 54, 56, 67, 72, 76], "similarili": [76, 78], "similarli": [1, 32, 37, 48, 60, 62, 65], "simon": [24, 68], "simpl": [1, 4, 8, 12, 14, 20, 24, 28, 29, 31, 37, 41, 42, 47, 55, 62, 64, 81, 83], "simpler": [2, 26, 47], "simpli": [5, 8, 29, 46, 66, 76], "simplic": [2, 33], "simplifi": [8, 12, 20, 41, 72], "simul": [31, 49, 56], "simultan": [1, 28, 60], "sin": [1, 34, 41, 42, 76, 77, 80, 81], "sinc": [1, 2, 26, 29, 32, 35, 41, 42, 44, 47, 48, 50, 54, 55, 58, 75, 77, 78, 79], "sine": 1, "singh": [24, 68], "singhal": [24, 68], "singl": [3, 5, 8, 12, 16, 31, 32, 33, 34, 37, 51, 56, 61, 67, 75], "sinong": [24, 68], "sinusoid": [1, 81], "situat": 75, "six": [13, 20, 40], "size": [2, 3, 4, 19, 24, 34, 36, 38, 41, 42, 43, 50, 52, 59, 68, 75, 76, 77, 78, 79], "sizov": [24, 68], "skill": [15, 19, 34, 44, 60], "skywork": 21, "sl": 54, "slama": [24, 68], "slice": 78, "slight": 24, "slightli": [39, 40], "slow": 79, "slowli": [76, 77], "slp": [24, 37, 68, 76, 78, 80], "small": [1, 9, 18, 24, 29, 31, 33, 34, 40, 44, 60, 65, 76, 77, 78, 79, 81], "smaller": [27, 38, 39, 66, 67, 75, 76, 78, 80], "smallest": [3, 31, 41], "smallscal": 67, "smarter": 29, "smith": [24, 68], "smooth": [4, 20], "smother": [24, 68], "snapshot": [31, 54], "sneha": [24, 68], "sniffio": 13, "snippet": [14, 34, 40, 43, 44], "so": [5, 9, 25, 31, 33, 39, 40, 48, 49, 50, 54, 60, 75, 76, 77, 78], "social": [3, 11], "soft": [33, 55, 59], "softmax": [2, 41, 42, 55, 75, 76, 78], "soji": [24, 68], "solar": [24, 68], "sole": [1, 26, 39, 52], "solid": 78, "solut": [10, 14, 15, 16, 19, 31, 32, 33, 34, 40, 46, 47, 55, 61, 67, 78, 79, 81], "solv": [10, 11, 12, 15, 16, 24, 27, 31, 32, 33, 34, 40, 65, 66, 67, 68], "solvabl": 16, "some": [1, 2, 8, 24, 31, 33, 35, 39, 40, 46, 49, 52, 58, 62, 75], "someon": 54, "someth": 4, "sometim": 4, "song": [24, 68], "sonia": [24, 68], "sootla": [24, 68], "sort": [40, 41, 49], "soumith": [24, 68], "soumya": [24, 68], "sourc": [3, 7, 12, 16, 20, 24, 34, 35, 37, 40, 41, 43, 44, 58, 65, 68], "space": [3, 20, 32, 33, 80, 81], "span": [11, 15, 24, 29, 34, 44], "spars": [4, 24, 33, 68], "spataru": [24, 68], "speak": 58, "spearman": 46, "special": [11, 24, 39, 40, 41, 43, 62, 67, 68, 75], "special_token": 41, "specif": [4, 5, 8, 20, 24, 26, 27, 33, 34, 37, 40, 41, 43, 44, 47, 48, 54, 58, 59, 60, 67, 75, 76, 77], "specifi": [16, 41, 65], "speckbach": [24, 68], "speed": [5, 37, 51], "spenc": [24, 68], "spencer": [24, 68], "spent": 35, "sphinx": 24, "spisak": [24, 68], "split": [5, 32, 34, 41, 42], "split_experience_batch": 53, "spm": 34, "spot": 11, "spread": 76, "spuriou": 4, "sqlite": 13, "sqrt": [1, 41, 42, 59, 76, 77, 78, 79, 81], "squre": 41, "sravankumar": [24, 68], "src": 85, "srinivasan": [24, 68], "srivastava": [24, 68], "sse": 13, "stabil": [11, 38, 39, 41, 50, 79], "stabl": [10, 12, 27, 43], "stack": [14, 75], "stackexchang": 38, "stage": [2, 34, 36, 37, 39, 43, 44, 50, 59, 65, 76, 77, 85], "stai": 26, "stale": 55, "stand": 24, "standalon": 34, "standard": [2, 15, 16, 18, 27, 28, 31, 34, 35, 40, 41, 43, 44, 48, 49, 50, 52, 55, 56, 59, 67, 75, 84], "star": 66, "starcod": [14, 20, 34], "starcoderdata": 14, "starkli": 11, "start": [5, 18, 20, 24, 25, 27, 32, 33, 34, 40, 41, 47, 49, 51, 58, 60], "start_header_id": 41, "start_po": [41, 42], "starter": 24, "state": [4, 5, 15, 26, 29, 38, 43, 46, 54, 75, 76], "statement": [16, 31, 34], "static": [26, 40, 43, 44], "staticmethod": 41, "statist": 79, "statu": [13, 53], "std": [41, 50, 59, 79], "steadi": 28, "steer": [29, 40, 49, 62], "steerabl": 40, "stefano": [24, 68], "steinhardt": [24, 68], "stem": [11, 43], "sten": [24, 68], "step": [1, 5, 15, 18, 20, 21, 22, 24, 26, 28, 32, 33, 34, 36, 37, 38, 39, 40, 50, 51, 53, 54, 55, 61, 64, 65, 68, 76, 77], "stepbi": 67, "stephan": [24, 68], "stephani": [24, 68], "stephen": [24, 68], "steve": [24, 68], "steven": [24, 68], "still": [4, 29, 31, 35, 37, 47, 55, 77], "stochast": 2, "stoica": [24, 68], "stojkov": [24, 68], "stojnic": [24, 68], "stone": [24, 68], "stop": [28, 39], "stop_token": 41, "store": [24, 44, 58], "str": [41, 58], "straightforward": [2, 7, 15, 26, 40, 52, 58, 65, 72, 76, 77], "straightforwardli": 46, "strateg": [37, 40], "strategi": [27, 34, 36, 37, 39, 43, 46, 53, 62, 66, 76, 78], "stream": 28, "streamlin": 20, "strength": [5, 37, 40, 49, 51, 52], "strict": [18, 41], "strictli": 60, "string": [41, 55, 66], "stringent": 40, "strip": [10, 41], "strong": [24, 36, 37, 46, 52, 59, 65, 67, 68, 76, 77], "stronger": [14, 29, 37, 78], "strongest": 15, "strongli": 54, "structur": [1, 2, 24, 33, 55, 75], "struggl": [4, 27, 59, 65], "stuck": 26, "student": [14, 15, 29, 44], "studi": [4, 18, 28, 29, 43, 49, 52], "style": [11, 34, 40], "su": [24, 68], "sub": [1, 3, 33, 35, 38, 41, 58, 79, 80, 81], "subbiah": [24, 68], "subject": [11, 34], "sublay": 1, "submiss": [31, 32], "submit": [5, 32, 49, 51], "suboptim": 79, "subramanian": [24, 68], "subsequ": [1, 34, 39, 40, 41, 42, 49, 50, 60, 82], "subset": [3, 5, 15, 16, 28], "subspac": 1, "substanti": [4, 8, 20, 29, 50, 52, 66], "substitut": [36, 47, 52, 75], "subtract": 50, "subword": 83, "succ": [5, 47, 58, 59, 62], "succeed": 33, "success": [11, 12, 29, 33, 39, 44, 60, 61], "successfulli": 44, "suchin": [24, 68], "suchir": [24, 68], "sudarshan": [24, 68], "suffer": [37, 65, 66], "suffici": [4, 5, 31, 39, 44, 48, 50, 64, 77], "suffix": 34, "suggest": [4, 27, 44, 47, 48, 52, 55, 82], "sui": [24, 68], "suit": 2, "suitabl": [34, 46, 59], "sujoi": [24, 68], "suk": [24, 68], "sum": [1, 26, 37, 41, 46, 49, 50, 75, 81], "sum_": [2, 26, 41, 42, 47, 50, 52, 55, 58, 59, 66, 75, 76, 77, 78, 81, 83], "sumbali": [24, 68], "sumit": [24, 68], "summar": 77, "summari": [3, 55], "summer": [24, 68], "sun": [24, 68], "sungmin": [24, 68], "sunni": [24, 68], "sup": 21, "super": [36, 41, 42, 79], "superalign": 29, "superhuman": 29, "superior": [1, 27, 35, 60], "supervis": [3, 4, 5, 15, 18, 24, 26, 29, 34, 44, 47, 56, 57, 58, 60, 62, 68, 80, 81], "supervison": 29, "supervisor": 29, "supplement": 40, "suppli": 72, "support": [25, 34, 36, 40, 44, 53, 84], "suppos": [46, 52, 75], "suraj": [24, 68], "sure": [8, 34, 54], "surfac": [32, 56, 67], "surpass": [4, 15, 20, 44, 57], "surpris": [5, 40, 50], "surprisingli": 48, "surrog": 50, "surround": [34, 36], "suspect": [1, 54], "sutskev": [24, 68], "swaroop": [24, 68], "swd": [24, 50, 68], "swee": [24, 68], "swiglu": [38, 43], "swish": [21, 41, 42], "swz": [24, 35, 50, 68], "sy": [24, 68], "sydnei": [24, 68], "symbol": 1, "sympi": 13, "syncheck": 10, "synnaev": [24, 68], "syntact": [31, 40], "syntax": [24, 40, 44], "synthes": [43, 44], "synthesi": [34, 44], "synthet": [14, 40, 43, 44, 57, 61, 62], "system": [4, 15, 24, 37, 40, 41, 49, 65, 68, 76], "systemat": 52, "t": [1, 2, 18, 20, 24, 26, 31, 37, 41, 42, 50, 52, 60, 68, 74, 75, 76, 77, 78, 81], "t1": [41, 79], "t2": [41, 79], "t_": [48, 83], "t_1": 83, "t_2": 83, "t_n": 83, "tabl": [3, 56, 78], "tackl": 32, "taco": 22, "tag": [24, 31, 32, 34, 44, 65, 68], "tail": 44, "tailor": [32, 37, 49], "take": [5, 14, 15, 26, 34, 41, 42, 46, 47, 48, 49, 51, 52, 58, 60, 61, 62, 67, 80, 81, 82], "taken": 26, "tal": [24, 68], "talent": 15, "tamar": [24, 68], "tamara": [24, 68], "tan": [24, 68], "tang": [24, 68], "tara": [24, 68], "tarek": [24, 68], "target": [2, 32, 40, 41, 52, 54, 58, 67, 72, 75, 77], "task": [1, 3, 4, 5, 8, 9, 11, 12, 14, 16, 19, 26, 27, 29, 31, 33, 34, 36, 37, 40, 43, 44, 50, 52, 54, 55, 59, 65, 67, 76, 77, 79, 86], "task_id": 10, "taskspecif": 3, "tau": [26, 49, 66], "taught": 22, "taylor": [24, 68], "td": 50, "teach": [29, 39], "teacher": 14, "team": [5, 51], "teboul": [24, 68], "technic": 29, "techniqu": [8, 20, 21, 22, 26, 27, 29, 33, 39, 40, 59, 76, 77], "teddi": [24, 68], "telecommun": 84, "tell": [29, 47], "temper": 31, "temperatur": [13, 31, 32, 37, 41, 43, 49, 72, 76], "templat": [14, 18, 20, 85], "ten": [4, 11, 34, 39, 44, 77], "tend": [49, 55], "tensor": [41, 42, 77], "teo": [24, 68], "term": [2, 5, 12, 33, 35, 37, 39, 40, 43, 47, 50, 52, 67, 77, 81, 82], "termin": 26, "terri": [5, 46, 47, 58, 59], "test": [3, 4, 5, 10, 11, 12, 13, 15, 16, 19, 28, 29, 31, 32, 33, 34, 35, 37, 40, 43, 44, 60, 65, 66, 67, 72], "tester": 40, "testuggin": [24, 68], "text": [1, 2, 3, 4, 5, 8, 12, 16, 24, 25, 26, 28, 34, 35, 37, 39, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 55, 58, 59, 60, 62, 66, 67, 72, 75, 76, 77, 78, 82, 83, 84], "text_complet": 41, "textbf": 26, "textbook": 11, "textual": 2, "tezak": [24, 68], "th": [20, 48, 50, 60, 75, 76, 77, 78], "than": [1, 3, 4, 7, 8, 10, 14, 18, 27, 29, 31, 32, 33, 34, 36, 38, 40, 46, 47, 48, 54, 55, 56, 58, 59, 67, 72, 75, 76, 77, 78], "thank": 52, "thattai": [24, 68], "thei": [3, 5, 14, 24, 29, 31, 34, 39, 40, 59, 60, 61, 67, 75, 78, 79, 82, 84], "them": [2, 5, 18, 29, 32, 33, 35, 36, 40, 43, 56, 58, 61, 65, 75, 78, 79, 81], "themselv": [5, 29, 51], "theoret": [40, 48], "therebi": [37, 75], "therefor": [14, 18, 32, 35, 36, 37, 39, 48, 50, 52, 59, 67, 77, 78], "theta": [2, 5, 26, 34, 39, 41, 42, 46, 47, 48, 49, 50, 51, 62, 66, 76, 77, 80, 81], "theta_": [34, 41, 42, 48, 50, 76, 77, 80, 81], "theta_0": [41, 42, 77], "theta_1": [41, 42, 77], "theta_d": 76, "theta_j": [41, 42], "thi": [1, 2, 3, 4, 5, 8, 11, 12, 14, 15, 18, 19, 20, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 58, 59, 60, 61, 62, 65, 66, 67, 72, 75, 76, 77, 78, 79, 81], "thibaut": [24, 68], "thilo": [24, 68], "thing": [25, 54], "think": [54, 65, 75, 77], "third": [1, 9], "thirti": [24, 68], "thoma": [24, 68], "thompson": 49, "thorough": [36, 40], "thoroughli": 37, "thorp": [24, 68], "those": [1, 5, 7, 24, 27, 31, 35, 37, 39, 40, 43, 49, 61, 67, 75], "though": 12, "thought": [11, 37, 40, 54, 55, 72], "thousand": [4, 31, 32, 34, 39, 40, 77], "three": [4, 5, 12, 13, 16, 26, 29, 34, 40, 44, 47, 51, 52, 55, 58, 59, 67, 78, 82], "threshold": [40, 41, 57, 62], "through": [2, 11, 14, 20, 40, 41, 42, 43, 44, 46, 52, 55, 58, 62, 65, 76, 77, 78, 80, 81, 82], "throughout": [40, 65], "thu": [20, 26, 28, 29, 39, 41, 42, 46, 49, 56, 58, 60, 66, 76], "tian": [24, 68], "tianh": [24, 68], "tianjian": [24, 68], "tianjun": [24, 68], "tianyu": [24, 68], "tiberiu": [24, 68], "tild": [39, 49, 50], "tillet": [24, 68], "tim": [24, 68], "time": [1, 7, 13, 20, 26, 31, 34, 39, 40, 43, 46, 55, 62, 65, 66, 67, 75, 78, 79, 86], "timeout": [13, 44], "timothi": [24, 68], "timoth\u00e9": [24, 68], "tindal": [24, 68], "tini": 4, "titl": [47, 84], "tk": 13, "tl": 3, "tli": [24, 68, 76, 79], "tm": [24, 40, 68], "to_remov": 58, "tobia": [24, 68], "todai": 29, "todor": [24, 68], "togeth": [1, 18, 31, 32, 40, 54, 55], "tok": 41, "tok_embed": [41, 42], "token": [1, 2, 3, 5, 13, 21, 22, 26, 31, 34, 35, 36, 38, 39, 40, 42, 44, 46, 48, 50, 51, 52, 55, 66, 67, 74, 76, 77, 78, 79, 80, 81, 83], "token1": 75, "token2": 75, "token3": 75, "token_logprob": 41, "tokenization\u4e4b\u540e": 74, "tokenization\u7b97\u6cd5\u4e4b\u4e00": 74, "tokenize\u7684\u610f\u601d\u662f\u628a\u4e00\u4e2a\u53e5\u5b50\u6216\u957f\u8bed\u6599\u5206\u6210token": 74, "token\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u7b26\u53f7": 74, "token\u6570": 74, "token\u66ff\u6362\u5b83\u4eec": 74, "toler": 67, "tolist": 41, "tom": [24, 68], "tomli": 13, "tomlkit": 13, "tone": 40, "tong": [24, 68], "tongzheng": [24, 68], "too": [29, 44, 77], "tool": [7, 15, 24, 31, 40, 83], "toolbelt": 13, "top": [3, 14, 25, 27, 31, 37, 39, 40, 41, 42, 46, 59, 62, 75], "top_p": 41, "topic": [19, 36, 40], "topk": [37, 75], "topp": 13, "torabi": [24, 68], "torch": [13, 41, 42, 75, 77, 79], "toreproduc": 7, "torr": [24, 68], "total": [12, 14, 18, 28, 32, 35, 36, 37, 39, 50, 75, 78], "total_len": 41, "touret": [24, 68], "toutanova": [24, 68], "touvron": [24, 68], "toward": [18, 24, 27, 56, 62, 66, 68, 75], "toxic": [5, 54], "tqdm": 13, "trace": 66, "traceback": 41, "track": 58, "tractabl": 29, "tradeoff": 52, "tradit": [4, 11], "train": [1, 5, 8, 14, 15, 18, 19, 24, 26, 27, 29, 31, 32, 34, 35, 39, 41, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 67, 68, 75, 76, 77, 78, 79, 83], "train_bash": 85, "train_batch_s": 53, "train_ppo": 53, "train_ppo_llama": 53, "trainabl": 86, "trainer": 53, "training_step_actor": 53, "training_step_crit": 53, "trajectori": [26, 65], "transduct": 1, "transfer": [80, 81], "transform": [1, 3, 4, 24, 31, 34, 36, 37, 38, 39, 40, 43, 68, 76, 77, 78, 79, 80, 81, 82, 86], "transformerblock": [2, 41, 42], "transit": [26, 66], "translat": [1, 3, 40, 65], "transmit": 49, "transpos": [41, 42], "trap": 66, "treat": [25, 41, 43, 59, 77], "tree": 44, "tremend": 36, "trend": 28, "tri": 60, "trick": [33, 53, 76], "trigonometr": [41, 42, 76, 77], "trigonometri": 40, "trillion": [35, 37, 43, 44], "trim": 32, "triplet": [2, 34, 52, 58], "triton": 13, "triu": [41, 42], "trl": 53, "troubl": 54, "trough": 34, "trove": 13, "true": [39, 41, 42, 53, 79, 85], "truth": [15, 16, 29, 35, 36, 37, 40, 43, 46, 47, 58, 61], "try": [7, 8, 33, 41, 44, 48, 60, 72], "trylimit": 33, "tsimpoukelli": [24, 68], "tuan": [24, 68], "tufanov": [24, 68], "tune": [4, 5, 7, 8, 18, 20, 24, 40, 44, 47, 48, 50, 52, 53, 56, 57, 58, 60, 66, 67, 68, 72, 76, 77], "tupl": [41, 42, 77], "turbo": [7, 14, 35, 41], "turn": [34, 40, 41, 67, 77], "tutori": 44, "two": [1, 2, 9, 18, 20, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 46, 47, 48, 49, 52, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 75, 76, 77, 78, 82], "tworek": [24, 68], "tx": 49, "txt": 8, "type": [7, 8, 13, 18, 20, 29, 31, 34, 37, 38, 41, 42, 52, 54, 55, 58, 59, 65, 77], "type_a": [41, 42, 77, 79], "typeddict": 41, "typescript": 40, "typic": [3, 4, 27, 29, 38, 40, 48, 49, 50, 52, 54, 56, 62, 75, 76, 77, 80, 81], "tzdata": 13, "tzook": [24, 68], "u": [2, 3, 4, 9, 24, 31, 32, 37, 47, 52, 58, 59, 61, 67, 68, 75, 78], "u_": [2, 75], "u_1": 2, "u_i": 2, "u_n": 2, "uation": 9, "uiuc": 10, "ujjwal": [24, 68], "uk": 78, "ultim": [20, 24, 29, 40, 68, 75], "ultrafeedback": 46, "unambigu": 16, "unbalanc": 75, "unbias": [12, 41, 50, 79], "uncertainti": 49, "unchang": 66, "unclear": [29, 66], "uncur": 61, "under": [11, 14, 26, 27, 36, 47, 48], "underli": 77, "underload": 37, "underset": [39, 46, 49, 50, 62, 66], "understand": [2, 11, 24, 25, 29, 33, 34, 40, 44, 68, 72], "undesir": 26, "unembed": [5, 36, 51], "uneth": 54, "unexpect": 65, "unicod": 44, "unicode\u548cutf": 84, "unicode\u5f53\u524d\u9ed8\u8ba4\u7684\u7248\u672c\u662fuc": 84, "unicode\u662fascii": 84, "unicode\u7684\u5b57\u7b26\u96c6\u8303\u56f4": 84, "unicode\u76f4\u63a5\u517c\u5bb9\u4e86\u521d\u671fascii": 84, "unifi": 20, "uniform": [34, 58, 67, 76, 79], "uniformli": [3, 49, 67], "union": 41, "uniqu": [33, 34, 36], "unit": [12, 15, 34, 39, 40, 43, 44, 76, 77], "univers": 77, "unk": 58, "unknown": [47, 58], "unlabel": [2, 62], "unleash": 44, "unlik": [15, 76], "unlikelihood": 52, "unlimit": 3, "unlock": [34, 36], "unmerg": 53, "unpack": [21, 22], "unsatisfactori": 52, "unsupervis": [3, 24, 29, 44, 68], "unsur": 39, "until": [18, 32, 33, 40, 49, 58, 75], "untruth": 5, "unveil": 20, "up": [2, 4, 5, 8, 18, 19, 32, 39, 40, 49, 51, 52, 54, 67, 76, 77], "up_proj": 36, "upasani": [24, 68], "updat": [28, 32, 37, 44, 53, 76], "upgrad": [10, 20], "upon": [27, 37, 43, 44], "upper": [27, 77], "upweight": 26, "uq": 78, "uritempl": 13, "url": [24, 68], "urllib3": 13, "us": [1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 67, 72, 76, 77, 78, 79, 80, 81, 82], "usag": [20, 40], "use_fast_token": 85, "user": [5, 7, 8, 29, 34, 39, 40, 41, 51, 59, 60, 61], "usual": [1, 18, 40, 47, 50, 58, 61, 75, 78, 80, 81], "usuni": [24, 68], "uszkoreit": [24, 68], "ut": 52, "util": [11, 20, 33, 34, 37, 39, 40, 43, 44, 47, 54, 59, 65], "uv": 78, "uw_": 2, "v": [1, 26, 41, 42, 46, 52, 56, 78, 80, 81, 82], "v0": [7, 10, 53], "v1": [14, 39], "v2": [21, 22, 24, 37, 39, 68, 75, 78], "v3": [22, 39, 65], "v5": [34, 39], "v_": [46, 50], "v_head_dim": 36, "valid": [4, 5, 15, 18, 19, 31, 33, 37, 43, 44, 47, 51, 59, 62], "valko": [24, 68], "valu": [1, 5, 15, 28, 31, 37, 41, 42, 44, 48, 50, 51, 52, 55, 58, 62, 75, 76, 77, 81], "valuabl": [80, 81], "valueerror": 41, "van": [24, 68], "vandenhend": [24, 68], "vanish": 49, "var": [41, 79], "vare": 28, "vari": [3, 11, 20, 28, 32, 36, 38, 43, 75, 76], "variabl": [44, 79, 80, 81], "varianc": [12, 26, 39, 43, 49, 50, 79], "variant": [2, 34, 41, 42, 60], "variat": [11, 24, 31, 41, 42, 56, 82], "varieti": [28, 40], "variou": [9, 14, 18, 20, 28, 35, 38, 40, 43, 44, 54, 60, 76, 77], "varun": [24, 68], "vasic": [24, 68], "vast": 44, "vasuden": [24, 68], "vaswani": [24, 68], "vaughan": [24, 68], "vdot": [80, 81], "ve": 41, "vector": [1, 2, 15, 34, 41, 42, 46, 48, 49, 76, 77, 78, 79, 81, 82], "vedant": [24, 68], "vedanuj": [24, 68], "veeraraghavan": [24, 68], "velich": [24, 68], "verb": 8, "verbos": 46, "verdict": 61, "veri": [5, 12, 28, 29, 31, 40, 44, 51, 54, 56, 76, 77], "verif": [40, 44, 65], "verifi": [7, 15, 16, 24, 37, 44, 65, 66, 68], "verma": [24, 68], "version": [1, 5, 11, 14, 32, 34, 36, 39, 40, 41, 42, 47, 61, 65, 72, 82, 85], "versu": 72, "veryeasyhack": 54, "via": [5, 24, 27, 33, 34, 40, 46, 47, 57, 61, 64, 65, 68], "vibhor": [24, 68], "victoria": [24, 68], "view": [41, 42, 77], "view_as_complex": [41, 42, 77], "view_as_r": [41, 42, 77], "vignesh": [24, 68], "vijai": [24, 68], "viktor": [24, 68], "vinai": [24, 68], "vincent": [24, 68], "vineet": [24, 68], "violat": 56, "virgini": [24, 68], "virk": [24, 68], "virtualenv": 13, "vish": [24, 68], "vishal": [24, 68], "visual": 8, "vlad": [24, 68], "vladan": [24, 68], "vladimir": [24, 68], "vllm": 10, "vocab": 48, "vocab_s": [36, 41, 42], "vocabulari": [36, 43, 48], "vogeti": [24, 68], "vontimitta": [24, 68], "voss": [24, 68], "vote": 67, "vrane": [24, 68], "vsp": [1, 2, 24, 68, 78], "vw_": 1, "vyatskov": [24, 68], "v\u00edtor": [24, 68], "w": [1, 5, 24, 41, 42, 46, 47, 48, 51, 58, 60, 61, 68, 74, 78, 80, 81, 82], "w1": [41, 42], "w2": [41, 42, 82], "w3": [41, 42], "w_": [1, 2, 26, 41, 42, 81, 82, 86], "w_1": 44, "w_2": 1, "w_e": 2, "w_n": 44, "w_p": 2, "w_y": 2, "wa": [2, 3, 9, 16, 20, 31, 32, 34, 35, 37, 39, 44, 60, 66], "wai": [12, 15, 18, 26, 27, 29, 33, 44, 54, 58, 72, 75, 76, 77], "wainwright": [24, 68], "waitlist": 5, "wake": 8, "wan": [24, 68], "wang": [24, 68], "wangd": [24, 68], "want": [5, 18, 26, 51, 58, 72, 76, 77], "warmup": 38, "wast": 31, "wastag": 75, "wasti": [24, 68], "wavecod": 44, "wavelength": [1, 76], "we": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 18, 20, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 72, 75, 76, 77, 78, 80, 81, 82, 86], "weak": [21, 52, 77], "weaker": 14, "weakli": [28, 29], "web": [3, 35, 58], "webpag": [3, 51], "websit": [38, 43, 44], "webtext": 3, "webtext2": 28, "wehrstedt": [24, 68], "wei": [24, 68], "weigh": 47, "weight": [1, 2, 26, 31, 36, 38, 39, 41, 42, 43, 44, 47, 52, 55, 75, 77, 79, 81, 82, 86], "weissman": [24, 68], "weiwei": [24, 68], "welind": [24, 68], "well": [1, 2, 7, 26, 43, 48, 52, 54, 76, 77], "wellcalibr": 54, "wen": [24, 68], "wenchen": [24, 68], "wenfeng": [24, 68], "weng": [24, 68], "wenhan": [24, 68], "wenji": [24, 68], "wenjun": [24, 68], "wentao": [24, 68], "wenwen": [24, 68], "wenyin": [24, 68], "were": [12, 37, 39, 67], "west": [21, 22], "what": [8, 29, 35, 38, 49, 77], "wheel": 13, "when": [1, 3, 5, 8, 15, 18, 24, 25, 26, 28, 29, 32, 33, 40, 41, 42, 46, 48, 49, 50, 52, 56, 59, 61, 66, 67, 68, 72, 75, 79, 81, 82], "where": [1, 2, 5, 12, 15, 18, 20, 26, 27, 28, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 58, 59, 60, 61, 64, 72, 75, 76, 77, 78, 79, 80, 81, 82, 86], "wherea": [24, 26, 31], "wherebi": 39, "wherein": 52, "wherev": 37, "whether": [18, 24, 29, 31, 35, 37, 41, 44, 52, 55, 61, 65, 66, 67, 75], "which": [1, 2, 3, 4, 5, 8, 9, 11, 12, 14, 15, 16, 18, 20, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 65, 67, 72, 75, 76, 77, 79, 80, 81, 82, 86], "while": [1, 3, 4, 5, 14, 15, 26, 28, 32, 33, 34, 36, 37, 40, 43, 44, 48, 49, 50, 54, 58, 59, 60, 66, 72, 75, 76, 77, 81, 83], "white": [12, 24, 68], "whiten": 39, "whitman": [24, 68], "whitnei": [24, 68], "who": 15, "whole": 52, "whose": [5, 41, 44], "why": [29, 33], "wide": [2, 5, 11, 28, 29, 32, 40, 46, 50, 59], "width": 41, "wifi": 54, "wiki": 38, "wikipedia": [3, 38], "william": [24, 68], "win": [49, 55, 58, 60, 61], "window": [2, 24, 37, 40, 68], "winner": 61, "winter": [24, 68], "wise": [2, 36, 37, 41, 42, 54, 77, 79, 82], "within": [37, 40, 44, 54, 61, 62, 65, 76, 77, 79], "without": [3, 9, 26, 29, 44, 46, 47, 48, 49, 51, 54, 61, 65, 67, 81], "wizard": [21, 22], "wk": [41, 42], "wo": [41, 42], "wojciech": [24, 68], "wolski": [24, 68], "wong": [24, 68], "wood": [24, 68], "word": [2, 3, 5, 7, 8, 15, 24, 44, 56, 68, 74, 80, 81, 83], "wordpiece\u6bcf\u6b21\u9009\u62e9\u5408\u5e76\u7684\u4e24\u4e2a\u5b50\u8bcd": 83, "wordpiece\u7b97\u6cd5\u4e5f\u662f\u6bcf\u6b21\u4ece\u8bcd\u8868\u4e2d\u9009\u51fa\u4e24\u4e2a\u5b50\u8bcd\u5408\u5e76\u6210\u65b0\u7684\u5b50\u8bcd": 83, "work": [1, 3, 4, 14, 15, 18, 26, 29, 36, 38, 40, 41, 42, 47, 48, 54, 61, 77, 82], "world": [8, 11], "world_siz": 53, "wors": [58, 72], "worst": [27, 62], "would": [1, 26, 29, 39, 46, 54, 61, 67], "wq": [41, 42], "write": [5, 7, 8, 16, 24, 25, 34, 36, 37, 39, 51, 65, 68, 76, 81], "writer": 15, "written": [5, 12, 15, 18, 24, 25, 54], "wrong": [33, 48, 67, 72], "wrote": [8, 54], "wu": [24, 68], "wv": [41, 42], "wwl": [24, 40, 68], "wx": 86, "wyatt": [24, 68], "x": [1, 2, 5, 9, 24, 26, 34, 39, 41, 42, 46, 47, 48, 49, 50, 51, 52, 55, 57, 58, 59, 61, 62, 66, 68, 74, 76, 77, 79, 80, 81, 82, 83, 86], "x_": [18, 41, 42, 61, 66, 76, 77, 81], "x_0": [41, 42, 76, 77], "x_1": [1, 41, 42, 52, 57, 66, 76, 77], "x_2": [41, 42, 66], "x_i": [60, 61, 66], "x_m": 52, "x_n": [1, 57], "xavier": [24, 68], "xdxac": 74, "xia": [24, 68], "xiang": [24, 68], "xiangyu": [24, 68], "xianzu": [24, 68], "xiao": [24, 68], "xiaocheng": [24, 68], "xiaodong": [24, 68], "xiaofang": [24, 68], "xiaohan": [24, 68], "xiaojian": [24, 68], "xiaojin": [24, 68], "xiaokang": [24, 68], "xiaolan": [24, 68], "xiaoq": [24, 68], "xiaosha": [24, 68], "xiaotao": [24, 68], "xiaowen": [24, 68], "xiaoxiang": [24, 68], "xide": [24, 68], "xie": [24, 68], "xilun": [24, 68], "xin": [24, 68], "xinbo": [24, 68], "xinfeng": [24, 68], "xingkai": [24, 68], "xinnan": [24, 68], "xinyi": [24, 68], "xinyu": [24, 68], "xiong": [24, 68], "xk": [41, 42, 77], "xk_": [41, 42, 77], "xk_out": [41, 42, 77], "xp": 82, "xq": [41, 42, 77], "xq_": [41, 42, 77], "xq_out": [41, 42, 77], "xu": [24, 68], "xuan": [24, 68], "xuchao": [24, 68], "xuecheng": [24, 68], "xuewei": [24, 68], "xv": [41, 42, 82], "xw": [41, 42, 82], "xw_": [41, 42, 82], "xw_1": 1, "xx": [10, 22], "xxhash": 13, "xxx": 13, "xz": 13, "x\u4e3a\u5b57\u7b26\u7684unicode\u4e8c\u8fdb\u5236": 84, "y": [2, 5, 24, 26, 39, 41, 42, 46, 47, 48, 49, 51, 52, 55, 57, 58, 59, 61, 66, 68, 74, 76, 79, 83], "y1": 47, "y2": 47, "y3": 47, "y_": [5, 18, 26, 39, 46, 47, 48, 51, 52, 57, 58, 59, 60, 61, 62, 66], "y_1": [1, 5, 47, 52, 55, 59, 62, 66], "y_2": [5, 47, 55, 59, 62, 66], "y_c": 59, "y_i": 66, "y_l": 48, "y_m": 1, "y_n": 52, "y_r": 59, "y_t": 52, "y_w": 48, "yaell": [24, 68], "yamamoto": [24, 68], "yaml": [13, 33], "yan": [24, 68], "yang": [24, 68], "yanhong": [24, 68], "yaniv": [24, 68], "yanjun": [24, 68], "yanp": [24, 68], "yao": [24, 68], "yaofeng": [24, 68], "yaohui": [24, 68], "yarl": 13, "yarn": 37, "yashesh": [24, 68], "yasmin": [24, 68], "yazdan": [24, 68], "ye": [24, 68], "yeari": [24, 68], "yellow": 12, "yenda": [24, 68], "yi": [24, 68], "yichao": [24, 68], "yield": [1, 5, 16, 40, 49, 50, 59, 86], "yifeng": [24, 68], "yiliang": [24, 68], "yilin": [24, 68], "yilong": [24, 68], "ying": [24, 68], "yingfei": [24, 68], "yinghai": [24, 68], "yishi": [24, 68], "yiwen": [24, 68], "yixin": [24, 68], "yixuan": [24, 68], "yiyuan": [24, 68], "yml": 13, "yongji": [24, 68], "yongqiang": [24, 68], "yossi": [24, 68], "you": [7, 8, 13, 24, 25, 34, 39, 54, 59, 68, 72], "young": 15, "youngjin": [24, 68], "your": [7, 13, 24, 25, 34, 54, 68], "yu": [24, 68], "yuan": [24, 68], "yuandong": [24, 68], "yuchen": [24, 68], "yuduan": [24, 68], "yue": [24, 68], "yuheng": [24, 68], "yukun": [24, 68], "yuliang": 22, "yundi": [24, 68], "yune": [24, 68], "yunfeng": [24, 68], "yunlu": [24, 68], "yunu": [24, 68], "yunxian": [24, 68], "yura": [24, 68], "yuri": [24, 68], "yute": [24, 68], "yuvraj": [24, 68], "yuxiang": [24, 68], "yuxuan": [24, 68], "yuyao": [24, 68], "yuzi": [24, 68], "yyl": [24, 68, 72], "z": [1, 24, 47, 49, 58, 68, 74, 83], "z_": 58, "z_1": 1, "z_n": 1, "zabdzabac": 74, "zach": [24, 68], "zachari": [24, 68], "zand": [24, 68], "zaremba": [24, 68], "zarov": [24, 68], "zef": [24, 68], "zehui": [24, 68], "zemlyanskii": [24, 68], "zeng": [24, 68], "zero": [4, 11, 26, 39, 41, 42, 72, 81], "zero_stag": 53, "zeros_lik": 41, "zh": 35, "zha": [24, 68], "zhan": [24, 68], "zhang": [24, 68], "zhangli": [24, 68], "zhao": [24, 68], "zhaoduo": [24, 68], "zhe": [24, 68], "zhen": [24, 68], "zhenda": [24, 68], "zheng": [24, 68], "zhengx": [24, 68], "zhenyu": [24, 68], "zhewen": [24, 68], "zhibin": [24, 68], "zhifang": [24, 68], "zhihong": [24, 68], "zhiniu": [24, 68], "zhipeng": [24, 68], "zhiwei": [24, 68], "zhiyu": [24, 68], "zhong": [24, 68], "zhongyu": [24, 68], "zhou": [24, 68], "zhu": [24, 68], "zhuoshu": [24, 68], "ziegler": [24, 68], "zihan": [24, 68], "zihui": [24, 68], "zilin": [24, 68], "zip": [41, 58], "zipp": 13, "ziwei": [24, 68], "zlib": 13, "zlm": [7, 24, 68], "zoe": [24, 68], "zou": [24, 68], "zvyagina": [24, 68], "zy": 74, "zydzyac": 74, "\u00e7elebi": [24, 68], "\u4e00": 84, "\u4e00\u4e2a\u5728\u5f00\u5934": 74, "\u4e00\u822c\u4e0d\u76f4\u63a5\u4f7f\u7528unicod": 84, "\u4e00\u90e8\u5206\u6b63\u8d1f\u62b5\u6d88\u4e00\u90e8\u5206\u632f\u8361": 76, "\u4e00\u95e8\u8bed\u8a00\u4e2d": 74, "\u4e0a\u9762\u4ecb\u7ecd\u4e86\u6587\u5b57\u5b57\u7b26\u6620\u5c04\u4e3aunicode\u5b57\u7b26\u96c6": 84, "\u4e0b\u4e00\u4e2a\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u662f": 74, "\u4e0b\u8f7d": 10, "\u4e0b\u8f7d\u8bc4\u4f30\u6587\u4ef6": 13, "\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50": 74, "\u4e0b\u9762\u7684\u793a\u4f8b\u5c06\u89e3\u91ca": 74, "\u4e0d\u4f1a\u51fa\u73b0\u53ea\u5b66\u90a3\u4e9b\u7b80\u5355\u4e14": 50, "\u4e0d\u4f1a\u5355\u72ec\u51fa\u73b0": 74, "\u4e0d\u8868\u793a\u5176\u4ed6\u8bed\u8a00": 84, "\u4e0d\u8db3\u7684\u5728\u9ad8\u4f4d\u75280\u8865\u5145": 84, "\u4e0ebpe\u7684\u6700\u5927\u533a\u522b\u5728\u4e8e": 83, "\u4e0ebpe\u7b97\u6cd5\u7c7b\u4f3c": 83, "\u4e14\u5047\u8bbe\u5404\u4e2a\u5b50\u8bcd\u4e4b\u95f4\u662f\u72ec\u7acb\u5b58\u5728\u7684": 83, "\u4e24\u4e2a\u5b57\u6bb5": 10, "\u4e2a": 74, "\u4e2a\u4e0d\u540c\u7684token": 74, "\u4e2a\u5355\u8bcd": 74, "\u4e2a\u5b50\u8bcd\u7ec4\u6210": 83, "\u4e2d": 10, "\u4e2d\u4f7f\u7528\u4e86\u4e0a\u8ff0\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53": 74, "\u4e2d\u51cf\u5c11\u8ba1\u6570": 74, "\u4e2d\u5b58\u5728": 74, "\u4e2d\u62bd\u53d6\u51fa\u6765": 13, "\u4e2d\u6587": 84, "\u4e2d\u7684": 10, "\u4e2d\u76f8\u5bf9\u597d\u7684": 50, "\u4e2d\u88ab\u9996\u6b21\u63d0\u51fa": 74, "\u4e3a\u4e86\u4ee5\u6700\u6709\u6548\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u6599\u5e93": 74, "\u4e3a\u4e86\u5408\u5e76": 74, "\u4e3a\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3": 74, "\u4e3a\u4e86\u672c\u6587\u7684\u7b80\u5355\u8d77\u89c1": 74, "\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4": 84, "\u4e3a\u4e86\u89e3\u51b3": 84, "\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u8c03\u7528": 10, "\u4e3a\u53e5\u5b50\u7684\u4e00\u4e2a\u5206\u8bcd\u7ed3\u679c": 83, "\u4e3a\u8865\u5145": 84, "\u4e3e\u4f8b1": 84, "\u4e3e\u4f8b2": 84, "\u4e4b\u524d": 84, "\u4e5f\u53eb\u5b57\u7b26\u96c6": 84, "\u4e5f\u5c31\u662f\u4e24\u5b50\u8bcd\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u5173\u8054\u6027": 83, "\u4e5f\u5c31\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u770b\u6210\u4e00\u4e2atoken": 74, "\u4e5f\u5c31\u662f\u7528\u5b9a\u957f2\u4e2a\u5b57\u8282\u6765\u8868\u793a\u5b57\u7b26": 84, "\u4e5f\u662fnlp\u4e2d\u6700\u91cd\u8981\u7684\u7f16\u7801\u65b9\u5f0f\u4e4b\u4e00": 74, "\u4e5f\u80fd\u88ab\u7b97\u4f5c\u5b57\u7b26\u5bf9\u7684\u4e00\u90e8\u5206": 74, "\u4e8c\u8fdb\u5236\u5c31\u662f01000001": 84, "\u4e8c\u8fdb\u5236\u5c31\u662f110000": 84, "\u4eca\u5929\u5c31\u6765\u4e86\u89e3\u4e0b\u5b57\u7b26\u5728\u8ba1\u7b97\u673a\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f": 84, "\u4ece": 13, "\u4ece\u6700\u957f\u5230\u6700\u77ed": 74, "\u4ece\u800c\u6211\u4eec\u77e5\u9053\u5269\u4f59\u7684": 74, "\u4ed6\u4eec\u5177\u6709\u6700\u5927\u7684\u4e92\u4fe1\u606f\u503c": 83, "\u4ee5\u4e2d\u6587": 84, "\u4f1a\u4e0d\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5f88\u6162": 50, "\u4f1a\u4e0d\u4f1a\u66f4\u597d": 50, "\u4f20\u5165\u89e3\u6790\u540e\u7684\u53c2\u6570": 10, "\u4f3c\u7136\u503c\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a": 83, "\u4f46\u4e00\u4e2a\u8bcd\u5728\u7ed3\u5c3e\u6709\u4e00\u4e2a": 74, "\u4f46\u4ecd\u6709\u53ef\u80fd\u51fa\u73b0\u4e0d\u5728\u91cc\u9762\u7684\u5355\u8bcd": 74, "\u4f46\u5b83\u5177\u6709\u826f\u597d\u7684\u6027\u80fd": 74, "\u4f46\u6211\u4eec\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u5305\u542b\u8fd9\u4e9b\u5b57\u7b26": 74, "\u4f46\u662funicode\u8fd8\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6269\u5c55\u673a\u5236": 84, "\u4f46\u662f\u5176\u4ed6\u6b27\u6d32\u56fd\u5bb6\u7684\u8bed\u8a00\u6bd4\u5982\u6cd5\u8bed": 84, "\u4f46\u662f\u5b83\u548c\u6c49\u5b57\u7684\u6620\u5c04\u4e0eunicode\u548c\u6c49\u5b57\u7684\u6620\u5c04\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb": 84, "\u4f46\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u5408\u7406\u7684\u7f16\u7801\u65b9\u5f0f": 74, "\u4f4e\u7ef4": 76, "\u4f4e\u9891\u5185\u63d2\u7684\u65b9\u5f0f": 76, "\u4f60\u53ef\u80fd\u4e0d\u6e05\u695awordpiece\u662f\u5982\u4f55\u9009\u53d6\u5b50\u8bcd\u7684": 83, "\u4f7f\u7528\u4e0b\u8ff0\u547d\u4ee4\u8fdb\u884c\u8bc4\u4f30": 13, "\u4f8b\u5982\u5b57\u7b26\u4e32": 10, "\u4f8b\u5982\u7f16\u7801\u5e8f\u5217": 74, "\u4fee\u6539\u540e\u663e\u793a\u7ed3\u679c\u5982\u4e0b": 84, "\u5047\u8bbe\u5355\u8bcd\u7684\u5e8f\u5217\u662f": 74, "\u5047\u8bbe\u53e5\u5b50": 83, "\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8bed\u6599\u5e93": 74, "\u5047\u8bbe\u6211\u4eec\u6709\u9700\u8981\u7f16\u7801": 74, "\u5047\u8bbe\u628a\u76f8\u90bb\u4f4d\u7f6e\u7684x\u548cy\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 83, "\u5047\u8bbe\u8fd9\u4e9b\u8bcd\u51fa\u73b0\u7684\u9891\u7387\u5982\u4e0b": 74, "\u50cf": 74, "\u5141\u8bb8\u8868\u793a\u4e00\u767e\u591a\u4e07\u4e2a\u5b57\u7b26": 84, "\u5168\u7403\u7edd\u5927\u90e8\u5206\u5b57\u7b26\u7684\u5b57\u7b26\u96c6": 84, "\u5176\u4e2d": [13, 74], "\u5176\u4e2d\u4e0d\u6b62utf": 84, "\u5176\u4e2d\u4f1a\u6d89\u53ca\u5230ascii": 84, "\u5176\u4e2d\u5305\u542b\u5355\u8bcd": 74, "\u5176\u4ed6\u5b57\u8282": 84, "\u5176\u4ed6\u8bed\u8a00": 84, "\u5176\u4ed6\u8bed\u8a00\u53ef\u80fd\u6709\u6240\u4e0d\u540c": 74, "\u51fa\u73b0\u4e86": 74, "\u51fd\u6570": 10, "\u51fd\u6570\u5462": 10, "\u51fd\u6570\u5feb\u901f\u8f6c\u6362\u4e3a\u547d\u4ee4\u884c\u63a5\u53e3": 10, "\u51fd\u6570\u7684\u53c2\u6570\u5217\u8868": 10, "\u5206\u522b\u6765\u81ea": 10, "\u5219\u53e5\u5b50": 83, "\u521d\u59cbtoken\u5c06\u662f\u6240\u6709\u5b57\u7b26\u548c": 74, "\u524d\u9762\u5168\u90e8\u586b\u51450": 84, "\u5269\u4e0b\u7684\u552f\u4e00\u5b57\u8282\u5bf9\u662f": 74, "\u52a0\u4e0a\u63a7\u5236\u7801\u540e\u5bf9\u5e94\u7684utf": 84, "\u5339\u914d": 10, "\u5341\u516d\u8fdb\u5236": 84, "\u5355\u5b57\u8282256\u4e2a\u5b57\u7b26\u80af\u5b9a\u6ca1\u6cd5\u5b8c\u5168\u8868\u793a": 84, "\u5373": [10, 74], "\u538b\u7f29": 74, "\u539f\u672c\u5728\u4f4e\u7ef4\u5ea6\u4e0a": 76, "\u53c2\u6570\u4e3a": 13, "\u53cd\u5411\u6267\u884c\u4ee5\u4e0a\u8fc7\u7a0b\u5c31\u884c\u4e86": 74, "\u53cd\u590d\u8fed\u4ee3\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6": 74, "\u53ea\u9700\u8981\u4e00\u4e2a\u5b57\u8282\u8868\u793a": 84, "\u53ea\u9700\u8981\u4f7f\u7528\u540e\u97627\u4f4d\u5c31\u8db3\u591f\u4e86": 84, "\u53ef\u4ee5\u4f7f\u75281": 84, "\u5404\u4e2a\u56fd\u5bb6\u4fbf\u7740\u624b\u81ea\u5df1\u56fd\u5bb6\u8bed\u8a00\u7684\u7f16\u7801": 84, "\u5408\u5e76\u505c\u6b62token": 74, "\u5408\u5e76\u540e\u4ea7\u751f\u7684\u5b50\u8bcd\u8bb0\u4e3az": 83, "\u5408\u5e76\u5b57\u7b26\u53ef\u4ee5\u8ba9\u4f60": 74, "\u5408\u5e76\u5b83\u4eec": 74, "\u540c\u7406\u8fd8\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u7279\u6709\u5b57\u7b26\u96c6": 84, "\u548c": [10, 74, 76], "\u548cascii\u7684\u76ee\u7684\u4e00\u6837": 84, "\u548cascii\u7801\u4e00\u81f4": 84, "\u56de\u8f6613\u7b49\u7b49\u4e00\u4e9b\u952e\u76d8\u4e0a\u6240\u89c1\u7684\u7b26\u53f7": 84, "\u56e0\u4e3a": 74, "\u56e0\u4e3a\u4eba\u7c7b\u8bed\u8a00\u4e5f\u7ecf\u5e38\u4ee5\u5355\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u4ea4\u6d41": 74, "\u56e0\u4e3a\u5b83\u4eec\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 74, "\u56e0\u4e3a\u6211\u4eec\u7edf\u8ba1\u76f8\u90bb\u5b57\u7b26\u5bf9\u65f6\u4e0d\u80fd\u628a\u5206\u522b\u4f4d\u4e8e\u4e24\u4e2a\u5355\u8bcd\u4e2d\u7684\u5b57\u7b26\u5bf9\u7b97\u8fdb\u53bb": 74, "\u56e0\u4e3a\u6ca1\u6709\u51fa\u73b0\u591a\u6b21\u7684\u5b57\u8282\u5bf9": 74, "\u56e0\u6b64": 74, "\u56e0\u6b64bpe\u4e5f\u662f\u5178\u578b\u7684\u57fa\u4e8esubword\u7684tokenization\u7b97\u6cd5": 74, "\u56e0\u6b64\u6211\u4eec\u53ef\u91c7\u7528\u9ad8\u9891\u5916\u63a8": 76, "\u56e0\u6b64\u6211\u4eec\u5c06\u7528\u4e00\u4e2a\u65b0\u5b57\u8282": 74, "\u56e0\u6b64\u6211\u4eec\u6ca1\u6709\u5c06\u5b83\u4eec\u5408\u5e76": 74, "\u5728": 10, "\u5728finest\u548clowest\u4e24\u4e2a\u8bcd\u4e2d": 74, "\u5728unicode\u8bde\u751f": 84, "\u5728\u5b9e\u8df5\u4e2d": 74, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d": 74, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 74, "\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0": 74, "\u5728\u8ba1\u7b97\u673a\u4e2d\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u4f4d0\u548c1\u6765\u5b58\u50a8\u7684": 84, "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u65f6\u5019\u9700\u8981\u5728\u8fd9\u4e2a\u62e5\u6709\u51e0\u4e07\u4e2a\u5355\u8bcd\u7684\u5217\u8868\u4e0a\u8ba1\u7b97\u4e00\u4e2a\u6982\u7387\u5206\u5e03": 74, "\u5728\u8fd9\u91cc": 74, "\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u6bd4\u8f83token\u7684\u9891\u7387\u5927\u5c0f\u6765\u7a77\u5c3d\u6bcf\u4e00\u79cd\u53ef\u80fd": 74, "\u5927\u5199\u5b57\u6bcda\u5bf9\u5e94\u7684ascii\u7801\u662f65": 84, "\u5927\u5bb6\u90fd\u77e5\u9053\u7535\u8111\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u548c\u5b58\u50a8\u7684": 84, "\u5927\u6982\u5c31\u662f\u8bf4ascii\u662f\u7f8e\u56fd\u4fe1\u606f\u4ea4\u6362\u6807\u51c6\u4ee3\u7801": 84, "\u5927\u90e8\u5206\u662f2\u5b57\u8282": 84, "\u5982\u4f55\u6765\u8868\u793aunicod": 84, "\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u5c31\u662f\u8981\u8868\u793a\u4e00\u4e2a\u5b57\u7b26\u8fd8\u662f\u8fde\u7eed\u7684\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 84, "\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u8bfb\u61c2unicod": 84, "\u5982\u4f55\u8bfb\u53d6unicode\u5b57\u7b26\u96c6": 84, "\u5982\u4f55\u9009\u62e9\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 83, "\u5982\u679c\u4f1a\u7559\u4e0b\u51e0\u4e2a\u5b50\u4e32": 74, "\u5982\u679c\u5728\u4f4e\u7ef4\u5ea6\u8fdb\u884c\u5185\u63d2": 76, "\u5982\u679c\u6309\u7167unicode\u7684\u65b9\u5f0f\u7edf\u4e00\u7528\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 84, "\u5982\u679c\u7b97\u6cd5\u770b\u5230token": 74, "\u5b57\u6bcd": 84, "\u5b57\u7b26\u7801\u5c31\u662f\u5bf9\u5e94\u7684unicod": 84, "\u5b57\u7b26\u7801\u7ec4\u6210": 84, "\u5b57\u7b26\u7b49": 74, "\u5b57\u7b26\u96c6\u5373\u662f\u6587\u5b57\u7b26\u53f7\u548c\u4e8c\u8fdb\u5236\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 84, "\u5b57\u8282\u957f\u5ea6": 84, "\u5b66\u540c\u4e00\u4e2a": 50, "\u5b83\u4e0d\u80fd\u88ab\u8fdb\u4e00\u6b65\u538b\u7f29": 74, "\u5b83\u4eec\u51fa\u73b0\u4e86": 74, "\u5b83\u4eec\u7ecf\u5e38\u5728\u8bed\u6599\u4e2d\u4ee5\u76f8\u90bb\u65b9\u5f0f\u540c\u65f6\u51fa\u73b0": 83, "\u5b83\u53ea\u6709\u4e00\u4e2a": 74, "\u5b83\u5728": 74, "\u5b83\u5c31\u4f1a\u77e5\u9053\u5b83\u662f": 74, "\u5b83\u7684\u4f5c\u7528\u662f\u628a\u5404\u4e2a\u8bed\u8a00\u7684\u5b57\u7b26\u6620\u5c04\u4e3a\u4e8c\u8fdb\u5236": 84, "\u5b83\u7684\u7279\u70b9\u662f\u53d8\u957f\u7f16\u7801": 84, "\u5b83\u9075\u5faa\u4e00\u79cd\u8d2a\u5a6a\u7684\u7b56\u7565\u6765\u5c3d\u53ef\u80fd\u53d6\u5f97\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848": 74, "\u5b8c\u5168\u517c\u5bb9ascii": 84, "\u5bf9\u4e0eascii\u7a7a\u95f4\u6d6a\u8d39": 84, "\u5bf9\u4e8e\u5355\u5b57\u8282\u7684\u5b57\u7b26": 84, "\u5bf9\u4e8e\u53e5\u5b50": 83, "\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u662f\u6781\u5927\u7684\u6d6a\u8d39": 84, "\u5bf9\u4e8e\u672a\u77e5": 74, "\u5bf9\u4e8e\u82f1\u6587\u56fd\u5bb6\u6765\u8bf4\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528": 84, "\u5bf9\u4e8e\u9700\u8981n\u4e2a\u5b57\u8282\u7684\u5b57\u7b26": 84, "\u5bf9\u5e94\u7684unicode\u5b57\u7b26\u96c6\u662f4e00": 84, "\u5bf9\u5e94\u7684unicode\u662fu": 84, "\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a01000001": 84, "\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u7f16\u7801\u7684\u8fc7\u7a0b\u8fd8\u662f\u6bd4\u8f83\u7b80\u5355\u7684": 74, "\u5bf9\u7528\u4f4e\u7ef4\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u95f4\u7684\u80fd\u529b\u5f71\u54cd\u66f4\u5927": 76, "\u5bfb\u627e\u6700\u5e38\u51fa\u73b0\u7684\u5b57\u8282\u5bf9": 74, "\u5c06": 10, "\u5c06\u53c2\u6570\u503c\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u7c7b\u578b": 10, "\u5c31\u4ee3\u8868\u4e00\u4e2a\u8bed\u8a00\u5355\u4f4d": 74, "\u5c31\u50cf\u5355\u8bcd": 74, "\u5c31\u662f\u4f7f\u7528\u63a7\u5236\u7801": 84, "\u5c31\u80fd\u4ee3\u8868\u4e86\u6240\u6709\u952e\u76d8\u4e0a\u7684\u666e\u901a\u7b26\u53f7": 84, "\u5c31\u8bde\u751f\u4e86utf": 84, "\u5c3d\u7ba1\u8d2a\u5a6a": 74, "\u5e03\u5c14\u503c\u7b49": 10, "\u5e74\u53d1\u8868\u7684\u6587\u7ae0": 74, "\u5e76\u4e00\u6b21\u53c8\u4e00\u6b21\u5730\u6267\u884c\u76f8\u540c\u7684\u8fed\u4ee3": 74, "\u5e76\u4e14\u6211\u4eec\u7684\u5b50\u5b57\u7b26\u4e32\u5c06\u88ab\u66ff\u6362\u4e3a\u6211\u4eectoken\u5217\u8868\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684token\u7ec4\u5408": 74, "\u5e76\u4e14\u7531utf": 84, "\u5e76\u5c06\u5176\u91cd\u547d\u540d\u4e3a": 10, "\u5e76\u5c06\u5176\u9891\u7387\u8bb0\u4e3a": 74, "\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230token\u5217\u8868\u4e2d": 74, "\u5e76\u5c06\u65b0\u8bcd\u7684token\u6dfb\u52a0\u5230\u6211\u4eec\u7684token\u5b57\u5178\u4e2d\u4ee5\u5907\u5c06\u6765\u7528\u5230": 74, "\u5e76\u5c1d\u8bd5\u4f7f\u7528\u8fd9\u4e9btoken\u66ff\u6362\u7ed9\u5b9a\u5355\u8bcd\u5e8f\u5217\u4e2d\u7684\u5b50\u5b57\u7b26\u4e32": 74, "\u5e76\u88ab\u4f5c\u4e3a\u673a\u5668\u7ffb\u8bd1\u7b49\u4e3b\u6d41nlp\u4efb\u52a1\u7684\u9996\u9009tokenize\u65b9\u6cd5\u4e4b\u4e00": 74, "\u5e76\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2atoken\u51fa\u73b0\u7684\u9891\u7387": 74, "\u5e93": 10, "\u5f00\u5934": 84, "\u5f00\u59cb": 74, "\u5f53\u524d\u5206\u8bcd\u4e0b\u53e5\u5b50s\u7684\u4f3c\u7136\u503c\u53ef\u4ee5\u8868\u793a\u4e3a": 83, "\u5f53\u7136": 74, "\u5f53\u8fd0\u884c\u811a\u672c\u65f6": 10, "\u610f\u5473\u7740\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u53f7\u53d8\u5316\u975e\u5e38\u8fc5\u901f": 76, "\u6211\u4eec\u4f1a\u5c06": 74, "\u6211\u4eec\u5148\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5b83\u7684\u6838\u5fc3\u601d\u60f3": 74, "\u6211\u4eec\u53ef\u4ee5\u770b\u5230": 74, "\u6211\u4eec\u53ef\u4ee5\u9012\u5f52\u5730\u4f7f\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u5c06": 74, "\u6211\u4eec\u5c06tokenized\u597d\u7684\u5355\u8bcd\u4fdd\u5b58\u5728\u5b57\u5178\u4e2d": 74, "\u6211\u4eec\u5c06\u4ece\u7b2c\u4e8c\u5e38\u89c1\u7684\u6807\u8bb0": 74, "\u6211\u4eec\u5c06\u5b57\u7b26\u89c6\u4e3a\u4e0e\u5b57\u8282\u7b49\u4ef7": 74, "\u6211\u4eec\u5c06\u5b83\u4eec\u5408\u5e76\u4ee5\u5f62\u6210\u4e00\u4e2a\u65b0\u7684token": 74, "\u6211\u4eec\u5c06\u6bcf\u4e2a\u5355\u8bcd\u62c6\u5206\u4e3a\u5b57\u7b26\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684\u51fa\u73b0\u6b21\u6570": 74, "\u6211\u4eec\u5c06\u7528unknown": 74, "\u6211\u4eec\u5c06\u7ee7\u7eed\u6267\u884c\u6b64\u5408\u5e76\u6b65\u9aa4": 74, "\u6211\u4eec\u5c06\u88ab\u89e3\u7801\u4e3a": 74, "\u6211\u4eec\u5c06\u904d\u5386\u6211\u4eec\u5728\u8bed\u6599\u5e93\u4e2d\u627e\u5230\u7684\u6240\u6709token": 74, "\u6211\u4eec\u5c06\u904d\u5386\u6240\u6709token": 74, "\u6211\u4eec\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8bcd\u6c47\u5217\u8868\u662f\u5f88\u5927\u7684": 74, "\u6211\u4eec\u5e94\u7528\u4e0a\u8ff0\u7f16\u7801\u65b9\u6cd5\u5bf9\u65b0\u8bcd\u8fdb\u884ctoken": 74, "\u6211\u4eec\u5fc5\u987b\u7b80\u5355\u5730\u5c06\u6240\u6709token\u8fde\u63a5\u5728\u4e00\u8d77\u4ee5\u83b7\u5f97\u6574\u4e2a\u5355\u8bcd": 74, "\u6211\u4eec\u603b\u5171\u6709": 74, "\u6211\u4eec\u6709\u4e00\u4e2a\u9891\u7387\u4e3a": 74, "\u6211\u4eec\u6765\u67e5\u51fa\u8fd9\u51e0\u4e2a\u5b57\u5bf9\u5e94\u7684utf": 84, "\u6211\u4eec\u73b0\u5728\u5c06\u5408\u5e76token": 74, "\u6211\u4eec\u73b0\u5728\u6709": 74, "\u6211\u4eec\u73b0\u5728\u6709\u4e86": 74, "\u6211\u4eec\u73b0\u5728\u770b\u5230\u5b57\u8282\u5bf9": 74, "\u6211\u4eec\u7684\u6570\u636e\u73b0\u5728\u5df2\u8f6c\u6362\u4e3a": 74, "\u6211\u4eec\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6ca1\u6709\u770b\u5230\u7684\u8bcd": 74, "\u6211\u4eec\u770b\u5230\u5b57\u8282\u5bf9": 74, "\u6211\u4eec\u77e5\u9053": 74, "\u6211\u4eec\u8ba1\u7b97\u8fd9\u4e9b\u8bcd\u5728\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387": 74, "\u6211\u4eec\u8fd8\u5c06\u4ece\u5355\u4e2atoken": 74, "\u6211\u4eec\u90fd\u4e86\u89e3\u4e00\u79cd\u6700\u57fa\u672c\u7684token": 74, "\u6216": 74, "\u6216\u8005\u53eb": 84, "\u6240\u4ee5": [74, 83], "\u6240\u4ee5ascii\u7684\u5b57\u7b26": 84, "\u6240\u4ee5\u4ed6\u4eec\u5c31\u628a\u7b2c\u4e00\u4e2a\u7a7a\u95f20\u4f7f\u7528\u4e86\u8d77\u6765": 84, "\u6240\u4ee5\u4ed6\u4eec\u628a\u6bcf\u4e2a\u5b57\u8282\u7684\u7b2c\u4e00\u4f4d\u7f6e\u7f6e0": 84, "\u6240\u4ee5\u4f7f\u7528\u4e24\u4e2a\u5b57\u8282\u5df2\u7ecf\u8db3\u591f": 84, "\u6240\u4ee5\u5165\u53e3\u662f": 10, "\u6240\u4ee5\u5bf9\u5e94\u7684utf": 84, "\u6240\u4ee5\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u5168\u7403\u7edf\u4e00\u7684\u7f16\u7801\u89c4\u5219\u53ebunicod": 84, "\u6240\u4ee5\u6211\u4eec\u4e0d\u5bf9\u5b83\u8fdb\u884c\u7f16\u7801": 74, "\u6240\u4ee5\u6211\u4eec\u6709": 74, "\u6240\u4ee5\u8fd9\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898": 84, "\u628a": 10, "\u628a\u5b83\u653e\u5728\u672c\u5730": 13, "\u63a5\u4e0b\u6765": 74, "\u63a7\u5236\u7801\u5c31\u662f\u544a\u8bc9\u8ba1\u7b97\u673a\u5f53\u524d\u662f\u5355\u5b57\u8282\u8fd8\u662f\u591a\u5b57\u8282": 84, "\u653e\u5165\u7528\u6237\u4e3b\u76ee\u5f55\u4e0b\u7684": 10, "\u6563\u5ea6\u76f4\u63a5\u653e\u5728": 50, "\u6570\u5b57\u548c\u5b57\u6bcd\u90fd\u672a\u4e71\u7801": 84, "\u6570\u636e\u7684\u538b\u7f29": 74, "\u6587\u4ef6": 10, "\u6587\u4ef6\u4e2d\u6709\u5982\u4e0b\u914d\u7f6e": 10, "\u6587\u4ef6\u653e\u5165\u6b64\u76ee\u5f55\u5e76\u91cd\u547d\u540d\u4e3a": 10, "\u659c\u4f53": 84, "\u65b0": 74, "\u65b0\u5efa\u4e00\u4e2ahtml\u8f93\u5165": 84, "\u65cb\u8f6c\u5f97\u8d8a\u591a": 76, "\u65cb\u8f6c\u5f97\u8d8a\u5c11": 76, "\u65cb\u8f6c\u89d2\u5ea6\u8f83\u5927": 76, "\u65e0\u8bba\u5982\u4f55": 74, "\u65e0\u8bba\u662fascii\u7f16\u7801\u8fd8\u662futf": 84, "\u65e5\u6587": 84, "\u65f6": 76, "\u662f\u4e00\u79cd\u7b80\u5355\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5": 74, "\u662f\u4ee3\u7801\u7247\u6bb5": 13, "\u662f\u4f7f\u7528": 10, "\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684sub": 74, "\u662f\u7684": 74, "\u666e\u901a\u7b26\u53f7\u7684\u5b57\u7b26\u96c6": 84, "\u66ff\u6362\u5b83": 74, "\u6700\u5e38\u51fa\u73b0": 74, "\u6700\u5e38\u89c1\u7684\u5e26\u6709": 74, "\u6700\u7ec8": 74, "\u6700\u7ec8\u5bfc\u81f4": 76, "\u6709\u4e00\u79cd\u7f16\u7801\u65b9\u5f0f\u80fd\u5927\u5927\u51cf\u5c0ftoken": 74, "\u6709\u4ec0\u4e48\u7528": 10, "\u6709\u5f88\u591a\u9ad8\u9891\u7ef4\u5ea6\u8f6c\u4e86\u5f88\u591a\u5708": 76, "\u672a\u63d0\u53ca\u7684\u4f4d\u4f7f\u7528\u5bf9\u5e94\u7684unicode\u8865\u5145": 84, "\u6765\u505a\u4e00\u4e2a\u5c0f\u5b9e\u9a8c\u5e76\u4e14\u9a8c\u8bc1\u4e0b": 84, "\u6765\u8bf4": 84, "\u67e5\u770b\u5176\u4ed6token": 74, "\u6807\u8bb0\u4ee5\u6807\u8bc6\u5355\u8bcd\u8fb9\u754c\u80fd\u591f\u8ba9\u7b97\u6cd5\u77e5\u9053\u6bcf\u4e2a\u5355\u8bcd\u7684\u7ed3\u675f\u4f4d\u7f6e": 74, "\u6807\u8bb0\u7684\u96c6\u5408": 74, "\u6a21\u4eff\u663e\u8457\u6027": 29, "\u6b21": 74, "\u6b27\u6d32\u90e8\u5206\u8bed\u8a00\u5b57\u6bcd\u7684\u5b57\u7b26\u96c6": 84, "\u6b64\u65f6\u53e5\u5b50": 83, "\u6bd4\u5982utf": 84, "\u6bd4\u5982\u4e2d\u56fd1980\u5e74\u53d1\u884c\u4e86gb2312\u4ee5\u53ca\u540e\u9762\u51fa\u73b0\u5b83\u7684\u6269\u5c55\u7248\u672cgbk": 84, "\u6bd4\u5982\u5728ascii\u4e2d": 84, "\u6bd4\u5982\u5927\u5199\u5b57\u6bcda": 84, "\u6bd4\u5982\u6c49\u5b57": 84, "\u6bd4\u5982\u6c49\u5b57\u4e00\u5728unicode\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662f4e00": 84, "\u6bd4\u5982\u82f1\u6587\u5b57\u6bcda\u5bf9\u5e94\u7684unicode\u662fu": 84, "\u6bd4\u5982\u8bf4\u4e2d\u6587": 84, "\u6c49\u5b57": 84, "\u6c49\u5b57\u7684\u5b57\u7b26\u96c6": 84, "\u6ca1\u6709": 50, "\u6d4f\u89c8\u5668\u6253\u5f00\u540e\u663e\u793a\u6b63\u5e38": 84, "\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7": 74, "\u7136\u540e\u6211\u4eec\u4f7f\u7528chrome\u7684charset\u63d2\u4ef6\u6765\u4fee\u6539\u5f53\u524d\u9875\u9762\u89e3\u7801\u7684\u5b57\u7b26\u96c6": 84, "\u7136\u800c": 74, "\u73b0\u5728\u6211\u4eec\u53d1\u73b0": 74, "\u73b0\u5728\u6211\u4eec\u5c06\u6700\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u5408\u5e76\u6210\u4e00\u4e2atoken": 74, "\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u89e3\u7801\u6211\u4eec\u7684\u793a\u4f8b": 74, "\u751f\u6210\u5f85\u8bc4\u4f30\u7684\u6587\u4ef6": 13, "\u7528\u6700\u5c11\u7684token\u6765\u8868\u793a\u8bed\u6599\u5e93": 74, "\u7528\u6765\u8868\u793a\u7535\u8111\u548c\u5176\u4ed6\u7535\u4fe1\u8bbe\u5907\u7684\u6587\u672c": 84, "\u7531": 83, "\u7531m\u4e2a\u5b50\u8bcd\u7ec4\u6210": 83, "\u7531\u4e8eascii\u8868\u793a\u7684\u8303\u56f4\u6709\u9650": 84, "\u7531\u4e8e\u6211\u4eec\u603b\u5171\u6709": 74, "\u7684": [10, 74], "\u7684\u4f18\u52bf": 50, "\u7684\u5b57\u7b26\u91cf\u5df2\u7ecf\u8db3\u4ee5\u7528\u4e8e\u5168\u7403\u4e3b\u8981\u8bed\u8a00\u7684\u5927\u591a\u6570\u5b57\u7b26": 84, "\u7684\u5b57\u8282\u5bf9\u662f": 74, "\u7684\u60c5\u51b5": 50, "\u7684\u6548\u679c": 50, "\u7684\u6570\u636e": 74, "\u7684\u65b0token": 74, "\u7684\u6838\u5fc3\u673a\u5236": 10, "\u7684\u7b2c\u4e00\u5b57\u8282\u5168\u662f0": 84, "\u7684\u8bed\u8a00\u6a21\u578b\u4f3c\u7136\u503c\u7b49\u4ef7\u4e8e\u6240\u6709\u5b50\u8bcd\u6982\u7387\u7684\u4e58\u79ef": 83, "\u7684\u9891\u7387\u4e3a": 74, "\u7684\u9891\u7387\u51cf\u5c11": 74, "\u76ee\u5f55\u4e0b": 13, "\u76f4\u5230\u8fbe\u5230\u6211\u4eec\u9884\u5148\u8bbe\u7f6e\u7684token\u6570\u9650\u5236\u6216\u8fed\u4ee3\u9650\u5236": 74, "\u76f8\u6bd4": 50, "\u76f8\u90bb\u5b57\u8282\u5bf9": 74, "\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u5728bpe\u4e2d\u770b\u4f5c\u76f8\u90bb\u5b57\u8282\u5bf9": 74, "\u7701\u8d44\u6e90": 50, "\u770b\u5230\u8fd9\u91cc": 83, "\u770b\u5b8c\u4e0b\u9762\u5b8c\u6574\u7684\u8fed\u4ee3\u8fc7\u7a0b": 74, "\u770b\u770b\u6211\u4eec\u6700\u7ec8\u7684token\u5217\u8868": 74, "\u771f\u5b9e\u7684": 52, "\u77e5\u9053\u4e86\u7f16\u7801\u7684\u539f\u7406\u540e\u81ea\u7136\u80fd\u60f3\u5230\u7684\u5c31\u662f\u6587\u672c\u7f16\u7801\u548c\u89e3\u7801\u6240\u4f7f\u7528\u7684\u5b57\u7b26\u96c6\u4e0d\u540c": 84, "\u786e\u4fdd\u6700\u5e38\u89c1\u7684\u8bcd\u5728token\u5217\u8868\u4e2d\u8868\u793a\u4e3a\u5355\u4e2atoken": 74, "\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230": 74, "\u7a76\u7adf\u8c03\u7528\u7684\u662f\u4ec0\u4e48\u51fd\u6570": 10, "\u7a7a\u95f4\u6781\u5927\u6d6a\u8d39": 84, "\u7b2cn": 84, "\u7b2c\u4e00\u4e2a\u5b57\u8282": 84, "\u7b2c\u4e00\u4e2a\u5b57\u8282\u7684\u7b2c\u4e8c\u4e2a0": 84, "\u7b2c\u4e8c\u9ad8\u9891\u7387\u6807\u8bb0\u662f": 74, "\u7b49\u8bcd\u4e4b\u95f4\u7684\u533a\u522b": 74, "\u7b97\u6cd5\u7684\u4e0b\u4e00\u6b65\u662f\u5bfb\u627e\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9": 74, "\u7b97\u6cd5\u7684\u4e3b\u8981\u76ee\u6807": 74, "\u7c7b\u4f3c\u5730": 10, "\u7f16\u7801\u4e3a": 74, "\u7f16\u7801\u672c\u8eab\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u8f83\u9ad8": 74, "\u7f16\u7801\u7c7b\u578b": 84, "\u8001\u89c4\u77e9": 74, "\u800cwordpiece\u9009\u62e9\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6700\u5927\u7684\u76f8\u90bb\u5b50\u8bcd\u52a0\u5165\u8bcd\u8868": 83, "\u800c\u4e0d\u662f": 74, "\u800c\u4e14\u8fc7\u5927\u7684token\u5217\u8868\u5341\u5206\u5f71\u54cd\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6": 74, "\u800c\u5728gb2312\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662fd2bb": 84, "\u800c\u662f\u5c06\u5b83\u4ee5utf": 84, "\u800c\u6c49\u5b57\u4e00\u4e8c\u4e09\u4e71\u7801\u4e86": 84, "\u800c\u7f55\u89c1\u7684\u8bcd\u88ab\u5206\u89e3\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2asubword": 74, "\u80fd\u591f\u6e05\u695a\u5730\u7406\u89e3wordpiece\u5728\u5408\u5e76\u8fd9\u4e00\u6b65\u662f\u5982\u4f55\u4f5c\u51fa\u9009\u62e9\u7684": 83, "\u80fd\u591f\u7cbe\u7ec6\u5730\u533a\u5206\u76f8\u90bb\u4f4d\u7f6e": 76, "\u82e5\u4f7f\u7528\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f": 74, "\u82f1\u6587\u5b57\u6bcd": 84, "\u83b7\u53d6\u6a21\u578b\u7684": 10, "\u8461\u8404\u7259\u8bed\u7b49\u65e0\u6cd5\u7528127\u4e2a\u5b57\u7b26\u8868\u793a\u5b8c\u5168": 84, "\u8868\u793a\u5b50\u8bcd": 83, "\u8981\u89e3\u7801": 74, "\u89c4\u52191": 84, "\u89c4\u52192": 84, "\u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570": 10, "\u8ba1\u7b97": 76, "\u8ba1\u7b97\u673a\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u662f\u6309\u7167\u4e00\u4e2a\u5b57\u8282\u7684\u5927\u5c0f\u6765\u8bfb\u53d6\u8bc6\u522b\u7684": 84, "\u8ba1\u7b97\u673a\u6309\u7167\u5b57\u8282\u6765\u8bfb\u53d6\u6570\u636e\u65f6": 84, "\u8ba1\u7b97\u673a\u662f\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u8868\u793a\u7684\u662f\u4ec0\u4e48\u610f\u601d\u5462": 84, "\u8ba9\u6211\u4eec\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0\u4e00\u4e2a\u7279\u6b8a\u7684\u7ed3\u675f\u6807\u8bb0": 74, "\u8ba9\u6211\u4eec\u73b0\u5728\u505c\u6b62\u8fed\u4ee3\u5e76": 74, "\u8ba9\u6211\u4eec\u73b0\u5728\u8003\u8651": 74, "\u8ba9\u6211\u4eec\u7528": 74, "\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\u6765\u4e86\u89e3\u4e00\u4e0b\u5b83\u7684nlp\u7248\u672c": 74, "\u8bcd": 74, "\u8bf4\u660e": 84, "\u8bf4\u660eunicode\u548cgbk\u90fd\u5411\u4e0b\u517c\u5bb9\u4e86ascii": 84, "\u8c03\u7528": 10, "\u8d8a\u8fd1": 76, "\u8d8a\u8fdc": 76, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f0100": 84, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f100": 84, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f19968": 84, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f65": 84, "\u8f93\u51fa\u6587\u4ef6": 10, "\u8fd8\u6709\u5176\u4ed6\u7f16\u7801\u65b9\u5f0f": 84, "\u8fd8\u6709\u7a7a\u683c32": 84, "\u8fd9\u4e00\u95ee\u9898": 84, "\u8fd9\u4e24\u4e2a\u8bcd\u90fd\u6709\u4e00\u4e2a\u5171\u540c\u7684": 74, "\u8fd9\u4e2a\u4e8c\u8fdb\u5236\u670915\u4f4d": 84, "\u8fd9\u4e2a\u8bcd\u7684token": 74, "\u8fd9\u4e5f\u662f": 74, "\u8fd9\u53ea\u662f\u82f1\u8bed\u7684\u7528\u6cd5": 74, "\u8fd9\u5b8c\u5168\u7b49\u540c\u4e8e127\u4f4d\u6700\u521d\u7684ascii\u7801": 84, "\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u9891\u7387\u8ba1\u6570\u5c06\u5728\u6bcf\u4e2a\u5408\u5e76\u6b65\u9aa4\u540e\u53d1\u751f\u53d8\u5316": 74, "\u8fd9\u662f\u66f4\u65b0\u540e\u7684\u8868\u683c": 74, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u67e5\u770b\u6bcf\u4e2a\u5b57\u7b26\u5e76\u627e\u5230\u9891\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u914d\u5bf9": 74, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u7406\u89e3": 74, "\u8fd9\u6837\u7684token\u5c06\u88ab\u4e0d\u540c\u5730\u5904\u7406": 74, "\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e4b\u4e3a": 76, "\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f\u5341\u5206\u7b26\u5408\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef": 74, "\u8fd9\u91cc": [10, 83], "\u8fd9\u91cc\u4fee\u6539\u4e3agbk": 84, "\u8fd9\u91cc\u7b80\u5355\u4ecb\u7ecd\u4e0b\u8fd9\u51e0\u79cd\u7f16\u7801\u65b9\u5f0f\u7684\u533a\u522b": 84, "\u8fdc\u7a0b\u8870\u51cf\u66f2\u7ebf\u5982\u4e0b": 76, "\u8fed\u4ee3": 74, "\u901a\u5e38\u6709\u51e0\u4e07\u5230\u51e0\u5341\u4e07\u91cf\u7ea7\u7684\u5355\u8bcd\u6570": 74, "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5": 83, "\u90a3\u4e48\u4eba\u4eec\u80fd\u8bc6\u522b\u7684\u6587\u5b57\u548c\u8ba1\u7b97\u673a\u4e2d\u7684\u4e8c\u8fdb\u5236\u5fc5\u7136\u5b58\u5728\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 84, "\u90a3\u4e48\u9762\u5bf9\u5168\u4e16\u754c\u8fd9\u4e48\u591a\u8bed\u8a00": 84, "\u90a3\u5982\u4f55\u628a\u538b\u7f29\u7684\u7f16\u7801\u590d\u539f\u5462": 74, "\u90a3\u5c31\u662f\u672c\u6587\u5373\u5c06\u4ecb\u7ecd\u7684byte": 74, "\u90a3\u6837\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u6050\u6016\u7684": 74, "\u90a3\u82f1\u6587\u5b57\u7b26": 84, "\u90e8\u5206\u9891\u7387\u4f4e": 76, "\u90e8\u5206\u9891\u7387\u9ad8": 76, "\u90fd\u4e00\u6837": 84, "\u91cc\u548c\u653e\u5728": 50, "\u91cc\u7684\u533a\u522b": 50, "\u95f4\u76f8\u4e92\u9694\u5f00": 50, "\u963f\u62c9\u4f2f\u6570\u5b570\u5bf9\u5e94\u7684ascii\u7801\u662f48": 84, "\u963f\u62c9\u4f2f\u6570\u5b57\u548c\u82f1\u6587\u5b57\u6bcd": 84, "\u968f\u673a\u6027\u5f88\u5927": 76, "\u968f\u7740\u8ba1\u7b97\u673a\u5728\u5168\u7403\u7684\u53d1\u5c55\u548c\u666e\u53ca": 84, "\u9700": 10, "\u9700\u52a0\u4e0a": 10, "\u9700\u8981\u4ece": 13, "\u9700\u8981\u81f3\u5c112\u4e2a\u5b57\u8282\u8868\u793a": 84, "\u975e\u5e38\u91cd\u8981": 74, "\u9996\u5148\u6765\u660e\u786e\u4e00\u4e0b\u57fa\u7840\u6982\u5ff5": 74, "\u9996\u5148\u770b\u4e0bwiki\u5bf9\u5b83\u7684\u5b9a\u4e49": 84, "\u9ad8\u4f4d\u4ee5": 84, "\u9ad8\u4f4d\u524dn\u4f4d\u4e3a": 84, "\u9ad8\u7684": 50, "\u9ad8\u7ef4": 76, "\u9ad8\u9891\u4fe1\u606f\u7684\u635f\u5931": 76, "\u9ad8\u9891\u7ef4\u5ea6\u5c11\u4f4e\u9891\u7ef4\u5ea6\u591a": 76, "\ud835\udc41": 49}, "titles": ["Base", "Attention Is All You Need", "GPT", "GPT2", "GPT3", "InstructGPT", "Benchmarks", "Alignment Benchmarks", "Code Alpaca", "CRUXEval", "EvalPlus", "General Benchmarks", "HumanEval", "LiveCodeBench", "Magicoder", "Math &amp; Science Benchmarks", "MBPP", "RewardBench", "SELF-INSTRUCT", "TACO", "WizardCoder", "Contents", "Contents", "Introduction", "Markdown Files", "Notebooks with MyST Markdown", "GOLD", "Evaluation of LLMs Should Not Ignore Non-Determinism", "Scaling Laws for Neural Language Models", "Weak to Strong Generalization", "Models", "AlphaCode", "AlphaCode 2", "AlphaCodium", "Code Llama", "DeepSeek-Coder-V2", "DeepSeek-V2", "DeepSeek V3", "Llama", "Llama 2", "Llama 3", "Llama3", "Llama 3 Source Code", "Qwen 2.5", "Qwen2.5-Coder", "Preference Optimization", "ArmoRM-MoE", "DPO", "DPOP", "Efficient Exploration for LLMs", "Group Relative Policy Optimization", "Instruct GPT", "Aligning Language Models with Judgments", "OpenRLHF", "Constitutional AI: Harmlessness from AI Feedback", "RLAIF vs. RLHF", "RLCD", "RS-DPO", "RSO", "Secrets of RLHF in Large Language Models: Reward Modeling", "Self-Rewarding Language Models", "Self-Taught Evaluators", "West-of-N", "Reasoning Models", "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "DeepSeek-R1", "Training Language Models to Self-Correct via Reinforcement Learning", "Let\u2019s Verify Step by Step", "References", "SFT", "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED", "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold", "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "Techniques", "Byte Pair Encoding (BPE)", "DeepSeekMoE", "Extending context window of LLMs", "Extending context window of large language models via position interpolation", "Multi-Head Latent Attention", "Normalization", "RoPE", "Rotary Positional Embeddings (RoPE)", "SwiGLU", "WordPiece, ULM and SentencePiece", "ASCII,UNICODE,UTF8", "Llama Factory", "LORA", "OpenRLHF"], "titleterms": {"": 67, "1": 46, "16": 84, "2": [32, 34, 39, 43, 46], "2d": [80, 81], "3": [40, 42], "32\u7b49": 84, "5": [43, 44], "500": 15, "8": 84, "A": 44, "AT": 70, "Not": 27, "The": [26, 33, 46, 72], "abil": [60, 72], "ablat": 78, "absolut": 81, "accuraci": 72, "activ": [41, 42, 49, 67], "adapt": 59, "add": 25, "addit": 33, "aggreg": 46, "aha": 65, "ai": [54, 55], "algorithm": [26, 49, 58, 60, 65], "align": [7, 27, 35, 36, 52, 60], "all": [1, 65, 70], "almost": 70, "alpaca": 8, "alphacod": [31, 32], "alphacodium": 33, "an": [25, 49], "analyz": 59, "annot": 61, "appendix": 47, "approach": [3, 4, 31, 38, 58, 81], "architectur": [1, 4, 36, 37, 38, 43, 49], "arena": 7, "armorm": 46, "ascii": 84, "assess": 49, "attent": [1, 41, 42, 78], "augment": 72, "averag": 40, "awar": 76, "background": [76, 77, 81], "balanc": 75, "base": [0, 43, 44, 65, 67], "basic": [28, 37], "batch": 79, "batchnorm": 41, "benchmark": [6, 7, 11, 15], "better": 59, "between": 78, "bpe": 74, "byte": 74, "cach": 78, "capabl": 40, "case": [80, 81], "cell": 25, "chain": 64, "chart": 28, "chat": 40, "chatformat": 41, "citat": 24, "classif": 18, "cluster": [31, 32], "code": [8, 10, 20, 33, 34, 40, 42], "coder": [35, 44], "cold": 65, "collaps": 66, "collect": [35, 39, 67], "commun": 75, "comparison": 78, "composit": 44, "compress": 78, "comput": 28, "concept": 33, "consider": 75, "constitut": 54, "construct": [36, 37, 61], "content": [21, 22], "context": [34, 37, 76, 77], "contextwindow": 76, "contrast": 52, "control": 40, "correct": [10, 12, 66], "count": [28, 72], "creat": 25, "creation": 60, "critiqu": 54, "cruxev": 9, "data": [8, 18, 28, 35, 36, 37, 38, 39, 40, 43, 44, 59, 67, 70, 71, 72], "dataset": [3, 4, 5, 28, 31, 34, 51], "decod": [1, 2], "decontamin": 44, "decoupl": 78, "deepseek": [35, 36, 37, 65], "deepseekmo": 75, "deriv": 47, "design": 33, "detail": [5, 14, 53], "determin": 27, "devic": 75, "dialog": 40, "differ": 59, "direct": [24, 40, 47, 77], "discuss": 36, "distanc": 76, "divers": 59, "dot": 1, "dpo": [47, 48, 57], "dpop": 48, "drop": 75, "dynam": 76, "effect": 27, "effici": [49, 71, 76], "eight": 71, "elicit": 64, "embed": [1, 28, 76, 77, 78, 81], "empir": [28, 49], "encod": [1, 74], "enn": 49, "epistem": 49, "estim": 49, "evalplu": 10, "evalu": [4, 10, 13, 14, 20, 27, 31, 32, 36, 37, 43, 44, 55, 61], "evol": 20, "evolut": 65, "exampl": 25, "experi": [3, 60, 77], "experiment": [5, 27, 35, 49, 60], "expert": [46, 75], "explor": 49, "extend": [76, 77], "extens": [37, 76], "extrapol": 77, "factor": [27, 72], "factori": 85, "failur": 48, "feed": 1, "feedback": [54, 55], "feedforward": [41, 42], "ffn": 82, "file": 24, "filter": [18, 31, 32], "fine": [2, 31, 32, 34, 35, 36, 37, 39, 43, 51, 61, 65, 75], "finetun": [18, 40], "flip": 59, "flow": 33, "fold": 71, "follow": [18, 60], "form": [80, 81], "format": 40, "formul": [80, 81], "forward": 1, "framework": [2, 26], "frequenc": 76, "from": [14, 26, 52, 54, 55], "full": 27, "fullest": 59, "function": [12, 41, 42], "gate": 82, "gb2312": 84, "gbk\u7b49\u5176\u4ed6\u7f16\u7801": 84, "gener": [11, 18, 27, 29, 41, 67, 80, 81], "glu": 82, "gold": 26, "gpqa": 15, "gpt": [2, 51], "gpt2": 3, "gpt3": 4, "gqa": 78, "gradient": [26, 47], "grain": 75, "group": 50, "grpo": 50, "gsm8k": 15, "hard": 7, "harmless": 54, "head": [1, 78], "high": [5, 76], "how": [27, 59], "human": [39, 59], "humanev": [10, 12], "hyper": [36, 43], "i": [1, 24, 27, 66, 70], "identif": 18, "ifev": 7, "ignor": 27, "ii": 66, "impact": 59, "implement": [14, 53, 77], "incorpor": 52, "incorrect": 71, "infil": 34, "infinit": 28, "influenc": 27, "inform": 76, "initi": [60, 61, 66], "input": [2, 3], "insight": 33, "instal": 13, "instanc": 18, "instruct": [14, 18, 20, 34, 43, 44, 51, 60, 61], "instructgpt": 5, "interpol": [76, 77], "interpret": 46, "introduct": [14, 23, 29, 34, 38, 52, 56, 77], "isol": 75, "iter": [39, 40, 50, 61], "its": 59, "joint": 78, "judgment": [52, 61], "kei": 78, "kv": 78, "label": [55, 59], "languag": [28, 40, 52, 59, 60, 64, 66, 72, 76, 77, 83], "larg": [31, 59, 64, 67, 72, 76, 77], "latent": 78, "law": [28, 43], "layer": 79, "layernorm": 41, "learn": [24, 35, 36, 37, 43, 49, 51, 52, 54, 55, 65, 66, 67, 72], "let": 67, "level": [5, 75], "leverag": 59, "limit": 28, "linear": 82, "livecodebench": 13, "llama": [34, 38, 39, 40, 42, 77, 85], "llama3": 41, "llm": [27, 49, 55, 71, 72, 76], "lm": 18, "load": 75, "local": 76, "long": [34, 37], "lora": 86, "loss": [47, 72, 75, 76], "low": 78, "magicod": 14, "main": 54, "margin": 59, "markdown": [24, 25], "math": [15, 71, 72], "mathemat": 72, "mbpp": [10, 16], "measur": 59, "mechan": 78, "metadata": 25, "method": [5, 54, 61, 67], "methodologi": [5, 29, 51, 55], "mha": 78, "mixtur": [44, 46, 75], "mla": 78, "mle": 26, "mmlu": 11, "mode": 48, "model": [1, 3, 4, 5, 28, 30, 32, 39, 40, 41, 42, 43, 44, 46, 49, 51, 52, 59, 60, 61, 62, 63, 64, 65, 66, 67, 72, 76, 77, 83], "moe": 46, "moment": 65, "more": 24, "mqa": 78, "multi": [1, 37, 46, 66, 78], "myst": [24, 25], "n": [28, 62], "need": [1, 46, 70], "network": [1, 49], "neural": [28, 49], "nlp\u5b9e\u4f8b": 74, "non": [27, 28], "normal": [41, 79], "notebook": 25, "ntk": 76, "object": 46, "off": 26, "offlin": 43, "onli": 2, "onlin": 43, "ood": 67, "open": 14, "openrlhf": [53, 87], "optim": [38, 40, 45, 47, 50], "orient": [33, 65], "orm": 67, "oss": 14, "outcom": [50, 67], "overal": [32, 60], "overfit": 28, "overview": 33, "pair": [61, 74], "paramet": [28, 36, 43], "part": 76, "passiv": 49, "pattern": 27, "perform": [28, 59, 65], "pi_": 47, "pipelin": 49, "point": 49, "polici": [26, 32, 44, 50], "posit": [1, 76, 77, 78, 81], "post": [37, 40, 43, 44], "postprocess": 18, "potenti": [27, 59], "power": 28, "ppo": [50, 53], "pre": [2, 36, 37, 38, 40, 43, 44, 72], "predict": 37, "prefer": [39, 40, 45, 47, 55, 59, 62], "preliminari": [47, 58, 59, 66, 75, 78, 81], "pretrain": 39, "prevent": 66, "prm": 67, "pro": 11, "problem": [52, 66], "process": [40, 50, 65, 67], "product": 1, "prompt": [20, 55, 64], "properti": 81, "propos": [33, 81], "qualiti": 40, "queri": 78, "quick": 10, "quickli": 25, "qwen": 43, "qwen2": 44, "r": [47, 57], "r1": 65, "random": 70, "rank": 78, "reason": [63, 64, 65, 71, 72], "recip": 44, "redux": 11, "refer": 68, "reinforc": [35, 36, 37, 43, 51, 54, 55, 65, 66], "reject": [58, 65], "rel": [50, 76], "relat": 62, "relationship": 72, "represent": 3, "respons": 61, "result": [5, 27, 28, 35, 36, 37, 40, 49, 54, 55, 60], "rethink": 70, "review": 50, "revis": 54, "reward": [26, 39, 40, 46, 49, 51, 59, 60, 65, 66, 67], "rewardbench": 17, "rl": [26, 50, 51, 66, 71], "rlaif": 55, "rlcd": 56, "rlhf": [39, 55, 59], "rm": [51, 59], "rmsnorm": [41, 42, 79], "role": 24, "rope": [41, 42, 76, 77, 80, 81], "rotari": [76, 77, 78, 81], "round": 40, "rso": 58, "sampl": [24, 31, 32, 58, 65], "scale": [1, 27, 28, 31, 43, 67, 70, 71, 72, 76], "scenario": 65, "scienc": 15, "score": [32, 66], "secret": 59, "segment": 75, "select": [61, 70], "self": [18, 60, 61, 62, 65, 66], "sentencepiec": 83, "set": 52, "setup": [60, 66], "sft": [39, 40, 51, 69, 85, 87], "shape": 66, "share": 75, "should": 27, "size": 28, "small": 67, "smooth": 59, "softmax": 1, "sourc": [14, 42], "special": 34, "specif": 2, "stack": 1, "stage": [33, 46, 66], "standard": 78, "stanford": 8, "start": [10, 65], "statist": 58, "step": 67, "strategi": 75, "strength": 59, "strong": 29, "summar": 3, "supervis": [2, 35, 36, 37, 40, 43, 50, 51, 54, 65, 67, 72], "surfac": 27, "swiglu": [41, 42, 82], "swish": 82, "synthet": [67, 71], "system": 32, "taco": 19, "takeawai": [40, 59, 67, 80], "task": [2, 18], "taught": 61, "techniqu": [55, 73], "temperatur": 27, "templat": 65, "thought": 64, "tiktoken": 41, "time": 28, "token": [37, 41, 43, 75], "train": [2, 3, 4, 20, 28, 36, 37, 38, 40, 43, 44, 49, 60, 61, 62, 65, 66, 72], "transform": [2, 28, 41, 42, 75], "tune": [2, 14, 31, 32, 34, 35, 36, 37, 39, 43, 51, 61, 65], "turn": 66, "ulm": 83, "unicod": 84, "unigram": 83, "unit": 82, "unsupervis": 2, "utf": 84, "utf8": 84, "v": [55, 67, 72], "v2": [35, 36], "v3": 37, "valu": 78, "variant": 82, "variou": 27, "verifi": 67, "via": [66, 77], "weak": 29, "west": 62, "what": [24, 27], "why": [2, 78, 79], "window": [76, 77], "wise": 1, "wizardcod": 20, "wizardlm": 20, "wordpiec": 83, "work": 62, "yaml": 25, "yarn": 76, "you": [1, 70], "zero": 65, "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": 84, "\u521d\u8bc6bpe": 74, "\u603b\u7ed3": 84, "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5": 74, "\u672c\u5730": [10, 13], "\u7684\u8fdc\u7a0b\u8870\u51cf": 76, "\u7f16\u7801\u548c\u89e3\u7801": 74, "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": 76}})