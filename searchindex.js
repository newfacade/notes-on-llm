Search.setIndex({"alltitles": {"2D case": [[87, "d-case"], [88, "d-case"]], "A Recipe for Instruction Data": [[51, "a-recipe-for-instruction-data"]], "ASCII": [[91, "ascii"]], "ASCII,UNICODE,UTF8": [[91, "ascii-unicode-utf8"]], "Ablation of Attention Mechanisms": [[85, "ablation-of-attention-mechanisms"]], "Ablation of MHA, GQA, and MQA": [[85, "ablation-of-mha-gqa-and-mqa"]], "Absolute position embedding": [[88, "absolute-position-embedding"]], "Active Exploration with a Point Estimate": [[56, "active-exploration-with-a-point-estimate"]], "Active Exploration with an ENN": [[56, "active-exploration-with-an-enn"]], "Active Learning": [[74, "active-learning"]], "Adaptive Margin": [[66, "adaptive-margin"]], "Additional insights": [[40, "additional-insights"]], "Aligning Language Models with Judgments": [[59, "aligning-language-models-with-judgments"]], "Alignment": [[42, "alignment"], [43, "alignment"]], "Alignment Benchmarks": [[7, "alignment-benchmarks"]], "Alignment Effect on Non-Determinism": [[34, "alignment-effect-on-non-determinism"]], "AlphaCode": [[38, "alphacode"]], "AlphaCode 2": [[39, "alphacode-2"]], "AlphaCodium": [[40, "alphacodium"]], "An example cell": [[32, "an-example-cell"]], "Analyze and Leverage Diverse Data to its Fullest Potential": [[66, "analyze-and-leverage-diverse-data-to-its-fullest-potential"]], "Appendix": [[54, "appendix"]], "Approach": [[3, "approach"], [4, "approach"], [38, "approach"], [45, "approach"]], "Architecture": [[43, "architecture"], [44, "architecture"], [45, "architecture"]], "Architecture & Tokenizer": [[50, "architecture-tokenizer"]], "Arena-Hard": [[7, "arena-hard"]], "ArmoRM-MoE": [[53, "armorm-moe"]], "Assessment Pipeline": [[56, "assessment-pipeline"]], "Attention": [[1, "attention"], [48, "attention"], [48, "id1"], [49, "attention"], [49, "id1"]], "Attention Is All You Need": [[1, "attention-is-all-you-need"]], "Background": [[88, "background"]], "Background: Rotary Position Embedding (RoPE)": [[83, "background-rotary-position-embedding-rope"], [84, "background-rotary-position-embedding-rope"]], "Base": [[0, "base"]], "Base Models": [[50, "base-models"], [51, "base-models"], [74, "base-models"]], "Basic Architecture": [[44, "basic-architecture"]], "Batch Normalization": [[86, "batch-normalization"]], "BatchNorm": [[48, "batchnorm"]], "Benchmarks": [[6, "benchmarks"]], "Byte Pair Encoding (BPE)": [[81, "byte-pair-encoding-bpe"]], "CRUXEval": [[9, "cruxeval"]], "Capabilities": [[47, "capabilities"]], "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [[71, "chain-of-thought-prompting-elicits-reasoning-in-large-language-models"]], "Charting the Infinite Data Limit and Overfitting": [[35, "charting-the-infinite-data-limit-and-overfitting"]], "Chat Dialog Format": [[47, "chat-dialog-format"]], "ChatFormat": [[48, "chatformat"]], "Citations": [[31, "citations"]], "Classification Task Identification": [[18, "classification-task-identification"], [27, "classification-task-identification"]], "Clustering": [[38, "clustering"], [39, "clustering"]], "Code": [[47, "code"]], "Code Alpaca": [[8, "code-alpaca"], [8, "id1"], [24, "code-alpaca"], [24, "id1"]], "Code Correctness Evaluation: HumanEval(+) or MBPP(+)": [[10, "code-correctness-evaluation-humaneval-or-mbpp"]], "Code Llama": [[41, "code-llama"]], "Code Llama: Specializing Llama 2 for code": [[41, "code-llama-specializing-llama-2-for-code"]], "Code-Oriented Design Concepts": [[40, "code-oriented-design-concepts"]], "Cold Start": [[72, "cold-start"]], "Communication Balance Loss": [[82, "communication-balance-loss"]], "Comparison Between MLA and MHA": [[85, "comparison-between-mla-and-mha"]], "Comparison of Key-Value Cache": [[85, "comparison-of-key-value-cache"]], "Constitutional AI: Harmlessness from AI Feedback": [[61, "constitutional-ai-harmlessness-from-ai-feedback"]], "Contents": [[21, "contents"], [22, "contents"]], "Create a notebook with MyST Markdown": [[32, "create-a-notebook-with-myst-markdown"]], "Critiques, Revisions, and Supervised Learning": [[61, "critiques-revisions-and-supervised-learning"]], "DPO": [[54, "dpo"]], "DPOP": [[55, "dpop"], [55, "id1"]], "Data": [[8, "data"], [23, "data"], [24, "data"]], "Data Collection": [[42, "data-collection"], [74, "data-collection"]], "Data Composition": [[26, "data-composition"], [51, "data-composition"]], "Data Construction": [[43, "data-construction"], [44, "data-construction"]], "Data Generation": [[18, "data-generation"], [27, "data-generation"]], "Data Mixture": [[51, "data-mixture"]], "Data Processing and Quality Control": [[47, "data-processing-and-quality-control"]], "Dataset": [[5, "dataset"], [41, "dataset"], [58, "dataset"]], "Datasets": [[38, "datasets"]], "Decontamination": [[26, "decontamination"], [51, "decontamination"]], "Decoupled Rotary Position Embedding": [[85, "decoupled-rotary-position-embedding"]], "DeepSeek V3": [[44, "deepseek-v3"]], "DeepSeek-Coder-V2": [[42, "deepseek-coder-v2"]], "DeepSeek-R1": [[72, "deepseek-r1"]], "DeepSeek-R1-Zero: Reinforcement Learning on the Base Model": [[72, "deepseek-r1-zero-reinforcement-learning-on-the-base-model"]], "DeepSeek-R1: Reinforcement Learning with Cold Start": [[72, "deepseek-r1-reinforcement-learning-with-cold-start"]], "DeepSeek-V2": [[43, "deepseek-v2"]], "DeepSeekMoE": [[82, "deepseekmoe"]], "Derivation of \\pi_{r}": [[54, "derivation-of-pi-r"]], "Device-Level Balance Loss": [[82, "device-level-balance-loss"]], "Direct Preference Optimization": [[47, "direct-preference-optimization"], [54, "direct-preference-optimization"]], "Direct extrapolation": [[84, "direct-extrapolation"]], "Discussion": [[43, "discussion"]], "Dynamic Scaling - \u201cDynamic NTK\u201d interpolation": [[83, "dynamic-scaling-dynamic-ntk-interpolation"]], "Efficient Exploration for LLMs": [[56, "efficient-exploration-for-llms"]], "Embeddings and Softmax": [[1, "embeddings-and-softmax"]], "Empirical Results": [[56, "empirical-results"]], "Empirical Results and Basic Power Laws": [[35, "empirical-results-and-basic-power-laws"]], "Encoder and Decoder Stacks": [[1, "encoder-and-decoder-stacks"]], "Epistemic Neural Network": [[56, "epistemic-neural-network"]], "EvalPlus": [[10, "evalplus"]], "Evaluation": [[4, "evaluation"], [14, "evaluation"], [20, "evaluation"], [25, "evaluation"], [29, "evaluation"], [38, "evaluation"], [39, "evaluation"], [50, "evaluation"], [51, "evaluation"], [62, "evaluation"]], "Evaluation Results": [[43, "evaluation-results"], [43, "id3"], [44, "evaluation-results"], [44, "id4"]], "Evaluation of LLMs Should Not Ignore Non-Determinism": [[34, "evaluation-of-llms-should-not-ignore-non-determinism"]], "Evol-Instruct": [[20, "evol-instruct"], [29, "evol-instruct"]], "Evol-Instruct Prompts for Code": [[20, "evol-instruct-prompts-for-code"], [29, "evol-instruct-prompts-for-code"]], "Experimental Results": [[34, "experimental-results"], [42, "experimental-results"]], "Experimental Setup": [[67, "experimental-setup"]], "Experimentation Pipeline": [[56, "experimentation-pipeline"]], "Experiments": [[3, "experiments"], [67, "experiments"], [84, "experiments"]], "Expert-Level Balance Loss": [[82, "expert-level-balance-loss"]], "Exploration Algorithms": [[56, "exploration-algorithms"]], "Extending context window of LLMs": [[83, "extending-context-window-of-llms"]], "Extending context window of large language models via position interpolation": [[84, "extending-context-window-of-large-language-models-via-position-interpolation"]], "FFN": [[89, "ffn"]], "Failure Mode of DPO": [[55, "failure-mode-of-dpo"]], "FeedForward": [[48, "feedforward"], [49, "feedforward"]], "Filtering": [[38, "filtering"], [39, "filtering"]], "Filtering and Postprocessing": [[18, "filtering-and-postprocessing"], [27, "filtering-and-postprocessing"]], "Fine-Grained Expert Segmentation": [[82, "fine-grained-expert-segmentation"]], "Fine-tuning": [[38, "fine-tuning"]], "Finetuning the LM to Follow Instructions": [[18, "finetuning-the-lm-to-follow-instructions"], [27, "finetuning-the-lm-to-follow-instructions"]], "Flipping the Labels": [[66, "flipping-the-labels"]], "Flow stages": [[40, "flow-stages"]], "Formulation": [[87, "formulation"], [88, "formulation"]], "Framework": [[2, "framework"]], "From MLE to RL framework": [[33, "from-mle-to-rl-framework"]], "Functional Correctness": [[12, "functional-correctness"]], "GB2312\u3001GBK\u7b49\u5176\u4ed6\u7f16\u7801": [[91, "gb2312gbk"]], "GOLD": [[33, "gold"]], "GPQA": [[15, "gpqa"]], "GPT": [[2, "gpt"]], "GPT2": [[3, "gpt2"]], "GPT3": [[4, "gpt3"]], "GRPO": [[57, "id3"]], "GSM8K": [[15, "gsm8k"]], "Gated Linear Units (GLU) and Variants": [[89, "gated-linear-units-glu-and-variants"]], "General Benchmarks": [[11, "general-benchmarks"]], "General form": [[87, "general-form"], [88, "general-form"]], "Generation": [[48, "generation"]], "Generator": [[74, "generator"]], "Gradient of DPO Loss": [[54, "gradient-of-dpo-loss"]], "Group Relative Policy Optimization": [[57, "group-relative-policy-optimization"]], "High-level methodology": [[5, "high-level-methodology"]], "How Various Factors Influence Non-Determinism?": [[34, "how-various-factors-influence-non-determinism"]], "How to Better Model Human Preference?": [[66, "how-to-better-model-human-preference"]], "Human Preference Data Collection": [[46, "human-preference-data-collection"]], "HumanEval": [[12, "humaneval"]], "Hyper-Parameters": [[43, "hyper-parameters"]], "IFEval": [[7, "ifeval"]], "Impacts of Different Data on RM Performance": [[66, "impacts-of-different-data-on-rm-performance"]], "Implementation Details": [[14, "implementation-details"], [25, "implementation-details"]], "Incorporating Judgments for Alignment": [[59, "incorporating-judgments-for-alignment"]], "Infilling": [[41, "infilling"]], "Initialization": [[67, "initialization"], [68, "initialization"]], "Input Representation": [[3, "input-representation"]], "Installation": [[13, "installation"]], "Instance Generation": [[18, "instance-generation"], [27, "instance-generation"]], "Instruct GPT": [[58, "instruct-gpt"]], "Instruct Models": [[51, "instruct-models"]], "InstructGPT": [[5, "instructgpt"]], "Instruction Following Ability Results": [[67, "instruction-following-ability-results"]], "Instruction Following Training": [[67, "instruction-following-training"]], "Instruction Generation": [[18, "instruction-generation"], [27, "instruction-generation"]], "Instruction Selection": [[68, "instruction-selection"]], "Instruction fine-tuning": [[41, "instruction-fine-tuning"]], "Instruction-tuned Model": [[50, "instruction-tuned-model"]], "Introduction": [[14, "introduction"], [25, "introduction"], [30, "introduction"], [36, "introduction"], [41, "introduction"], [45, "introduction"], [59, "introduction"], [63, "introduction"], [84, "introduction"]], "Iterative Fine-Tuning": [[46, "iterative-fine-tuning"]], "Iterative RL with GRPO": [[57, "iterative-rl-with-grpo"]], "Iterative Rounds": [[47, "iterative-rounds"]], "Iterative Training": [[68, "iterative-training"]], "Judgment Annotation": [[68, "judgment-annotation"]], "LORA": [[93, "lora"]], "Label Smoothing": [[66, "label-smoothing"]], "Large scale sampling": [[38, "large-scale-sampling"]], "Large-scale Supervision": [[74, "large-scale-supervision"]], "Layer Normalization": [[86, "layer-normalization"]], "LayerNorm": [[48, "layernorm"]], "Learn more": [[31, "learn-more"]], "Learning Pipeline": [[56, "learning-pipeline"]], "Learning from Contrasting": [[59, "learning-from-contrasting"]], "Let\u2019s Verify Step by Step": [[74, "lets-verify-step-by-step"]], "LiveCodeBench": [[13, "livecodebench"]], "Llama": [[45, "llama"]], "Llama 2": [[46, "llama-2"]], "Llama 3": [[47, "llama-3"]], "Llama 3 Source Code": [[49, "llama-3-source-code"]], "Llama Factory": [[92, "llama-factory"]], "Llama implementation": [[84, "llama-implementation"]], "Llama3": [[48, "llama3"]], "Load Balance Consideration": [[82, "load-balance-consideration"]], "Long Context Extension": [[44, "long-context-extension"]], "Long context fine-tuning": [[41, "long-context-fine-tuning"]], "Loss": [[54, "loss"]], "Loss of High Frequency information - \u201cNTK-aware\u201d interpolation": [[83, "loss-of-high-frequency-information-ntk-aware-interpolation"]], "Loss of Relative Local Distances - \u201cNTK-by-parts\u201d interpolation": [[83, "loss-of-relative-local-distances-ntk-by-parts-interpolation"]], "Low-Rank Compression for Queries": [[85, "low-rank-compression-for-queries"]], "Low-Rank Key-Value Joint Compression": [[85, "low-rank-key-value-joint-compression"]], "MATH": [[15, "math"]], "MATH 500": [[15, "math-500"]], "MBPP": [[16, "mbpp"]], "MMLU": [[11, "mmlu"]], "MMLU-Pro": [[11, "mmlu-pro"]], "MMLU-Redux": [[11, "mmlu-redux"]], "Magicoder": [[14, "magicoder"], [25, "magicoder"]], "Main Result": [[61, "main-result"]], "Main Results": [[61, "main-results"]], "Markdown Files": [[31, "markdown-files"]], "Math & Science Benchmarks": [[15, "math-science-benchmarks"]], "Measuring the Strength of Preferences": [[66, "measuring-the-strength-of-preferences"]], "Method": [[61, "method"], [61, "id1"], [68, "method"]], "Methodology": [[36, "methodology"], [62, "methodology"]], "Methods": [[74, "methods"]], "Methods and experimental details": [[5, "methods-and-experimental-details"]], "Model": [[3, "model"], [48, "model"], [49, "model"]], "Model Accuracy VS. Augmented Data Count": [[79, "model-accuracy-vs-augmented-data-count"]], "Model Accuracy VS. Pre-training Loss": [[79, "model-accuracy-vs-pre-training-loss"]], "Model Accuracy VS. Supervised Data Count": [[79, "model-accuracy-vs-supervised-data-count"]], "Model Architecture": [[1, "model-architecture"]], "Model Averaging": [[47, "model-averaging"]], "Model Fine-tuning (Iterative Training)": [[68, "model-fine-tuning-iterative-training"]], "Model and Architectures": [[4, "model-and-architectures"]], "Modeling": [[47, "modeling"]], "Models": [[5, "models"], [37, "models"]], "Multi-Head Attention": [[1, "multi-head-attention"]], "Multi-Head Latent Attention": [[85, "multi-head-latent-attention"]], "Multi-Token Prediction": [[44, "multi-token-prediction"]], "NLP\u5b9e\u4f8b": [[81, "nlp"]], "Normalization": [[48, "normalization"], [86, "normalization"]], "Notebooks with MyST Markdown": [[32, "notebooks-with-myst-markdown"]], "OOD Generalization": [[74, "ood-generalization"]], "OSS-INSTRUCT: Instruction Tuning from Open Source": [[14, "oss-instruct-instruction-tuning-from-open-source"], [25, "oss-instruct-instruction-tuning-from-open-source"]], "Off-policy policy gradient": [[33, "off-policy-policy-gradient"]], "Offline Reinforcement Learning": [[50, "offline-reinforcement-learning"]], "Online Reinforcement Learning": [[50, "online-reinforcement-learning"]], "OpenCoder": [[26, "opencoder"]], "OpenRLHF": [[60, "openrlhf"], [94, "openrlhf"]], "Optimizer": [[45, "optimizer"]], "Outcome Supervision RL with GRPO": [[57, "outcome-supervision-rl-with-grpo"]], "Outcome-supervised Reward Models (ORMs)": [[74, "outcome-supervised-reward-models-orms"]], "Overall Self-Alignment Algorithm": [[67, "overall-self-alignment-algorithm"]], "Overall System": [[39, "overall-system"]], "Overview": [[40, "overview"]], "PPO Review": [[57, "ppo-review"]], "PPO implementation detail": [[60, "ppo-implementation-detail"]], "Parameter and Compute Scaling of Transformers": [[35, "parameter-and-compute-scaling-of-transformers"]], "Passive Exploration": [[56, "passive-exploration"]], "Performance with Dataset Size and Compute": [[35, "performance-with-dataset-size-and-compute"]], "Performance with Non-Embedding Parameter Count N": [[35, "performance-with-non-embedding-parameter-count-n"]], "Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero": [[72, "performance-self-evolution-process-and-aha-moment-of-deepseek-r1-zero"]], "Point Estimate": [[56, "point-estimate"]], "Policy and Fine-Tuning": [[39, "policy-and-fine-tuning"]], "Position interpolation": [[83, "position-interpolation"]], "Position-wise Feed-Forward Networks": [[1, "position-wise-feed-forward-networks"]], "Positional Encoding": [[1, "positional-encoding"]], "Positional Interpolation": [[84, "positional-interpolation"]], "Post Training": [[26, "post-training"]], "Post-Training": [[44, "post-training"], [47, "post-training"]], "Post-trained Language Model": [[47, "post-trained-language-model"]], "Post-training": [[50, "post-training"], [51, "post-training"]], "Post-training Data": [[47, "post-training-data"]], "Pre-Training": [[43, "pre-training"], [44, "pre-training"]], "Pre-trained Language Model": [[47, "pre-trained-language-model"]], "Pre-training": [[50, "pre-training"], [51, "pre-training"]], "Pre-training data": [[45, "pre-training-data"]], "Preference Data": [[47, "preference-data"]], "Preference Labeling with LLMs": [[62, "preference-labeling-with-llms"]], "Preference Optimization": [[52, "preference-optimization"]], "Preliminaries": [[54, "preliminaries"], [65, "preliminaries"], [66, "preliminaries"]], "Preliminaries and Problem Setup": [[73, "preliminaries-and-problem-setup"]], "Preliminaries: Mixture-of-Experts for Transformers": [[82, "preliminaries-mixture-of-experts-for-transformers"]], "Preliminaries: Standard Multi-Head Attention": [[85, "preliminaries-standard-multi-head-attention"]], "Preliminary": [[88, "preliminary"]], "Pretrain": [[46, "pretrain"]], "Pretraining": [[26, "pretraining"]], "Pretraining Data": [[26, "pretraining-data"]], "Problem Setting": [[59, "problem-setting"]], "Process Supervision RL with GRPO": [[57, "process-supervision-rl-with-grpo"]], "Process vs Outcome Supervision": [[74, "process-vs-outcome-supervision"]], "Process-supervised Reward Models (PRMs)": [[74, "process-supervised-reward-models-prms"]], "Prompting Techniques": [[62, "prompting-techniques"]], "Properties of RoPE": [[88, "properties-of-rope"]], "Proposed approach": [[88, "proposed-approach"]], "Quick Start": [[10, "quick-start"]], "Quickly add YAML metadata for MyST Notebooks": [[32, "quickly-add-yaml-metadata-for-myst-notebooks"]], "Qwen 2.5": [[50, "qwen-2-5"]], "Qwen2.5-Coder": [[51, "qwen2-5-coder"]], "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED": [[77, "rethinking-data-selection-at-scale-random-selection-is-almost-all-you-need"]], "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold": [[78, "rl-on-incorrect-synthetic-data-scales-the-efficiency-of-llm-math-reasoning-by-eight-fold"]], "RLAIF vs. RLHF": [[62, "rlaif-vs-rlhf"], [62, "id1"]], "RLCD": [[63, "rlcd"], [63, "id1"]], "RLHF": [[46, "rlhf"]], "RMSNorm": [[48, "rmsnorm"], [49, "rmsnorm"], [86, "rmsnorm"]], "RS-DPO": [[64, "rs-dpo"]], "RSO": [[65, "rso"]], "RSO APPROACH": [[65, "rso-approach"]], "Reasoning": [[70, "reasoning"]], "Reasoning-oriented Reinforcement Learning": [[72, "reasoning-oriented-reinforcement-learning"]], "References": [[75, "references"]], "Reinforcement Learning": [[42, "reinforcement-learning"], [43, "reinforcement-learning"], [44, "reinforcement-learning"]], "Reinforcement Learning Algorithm": [[72, "reinforcement-learning-algorithm"]], "Reinforcement Learning for all Scenarios": [[72, "reinforcement-learning-for-all-scenarios"]], "Reinforcement Learning from AI Feedback": [[61, "reinforcement-learning-from-ai-feedback"], [62, "reinforcement-learning-from-ai-feedback"]], "Reinforcement learning (RL)": [[58, "reinforcement-learning-rl"]], "Rejection Sampling and Supervised Fine-Tuning": [[72, "rejection-sampling-and-supervised-fine-tuning"]], "Related Work": [[69, "related-work"]], "Response Pair Construction": [[68, "response-pair-construction"]], "Results": [[5, "results"], [47, "results"], [62, "results"]], "Reward": [[33, "reward"]], "Reward Model Architectures and Training": [[56, "reward-model-architectures-and-training"]], "Reward Modeling": [[46, "reward-modeling"], [47, "reward-modeling"], [72, "reward-modeling"]], "Reward Modeling Ability Results": [[67, "reward-modeling-ability-results"]], "Reward modeling (RM)": [[58, "reward-modeling-rm"]], "RewardBench": [[17, "rewardbench"]], "RoPE": [[48, "rope"], [49, "rope"], [87, "rope"]], "RoPE \u7684\u8fdc\u7a0b\u8870\u51cf": [[83, "rope"]], "Rotary Positional Embeddings (RoPE)": [[88, "rotary-positional-embeddings-rope"]], "SCoRe: Self-Correction via Multi-Turn Reinforcement Learning": [[73, "score-self-correction-via-multi-turn-reinforcement-learning"]], "SELF-INSTRUCT": [[18, "self-instruct"], [27, "self-instruct"]], "SFT": [[46, "sft"], [76, "sft"], [92, "sft"], [94, "sft"]], "SFT Data": [[47, "sft-data"]], "STATISTICAL REJECTION SAMPLING ALGORITHM": [[65, "statistical-rejection-sampling-algorithm"]], "Sample Roles and Directives": [[31, "sample-roles-and-directives"]], "Sampling": [[39, "sampling"]], "Scaled Dot-Product Attention": [[1, "scaled-dot-product-attention"]], "Scaling Effect on Non-Determinism": [[34, "scaling-effect-on-non-determinism"]], "Scaling Laws for Neural Language Models": [[35, "scaling-laws-for-neural-language-models"]], "Scaling Laws with Model Size and Training Time": [[35, "scaling-laws-with-model-size-and-training-time"]], "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": [[79, "scaling-relationship-on-learning-mathematical-reasoning-with-large-language-models"]], "Scoring Model": [[39, "scoring-model"]], "Secrets of RLHF in Large Language Models: Reward Modeling": [[66, "secrets-of-rlhf-in-large-language-models-reward-modeling"]], "Self-Instruction Creation": [[67, "self-instruction-creation"]], "Self-Rewarding Language Models": [[67, "self-rewarding-language-models"]], "Self-Taught Evaluators": [[68, "self-taught-evaluators"]], "Self-Training for Preference Modeling": [[69, "self-training-for-preference-modeling"]], "SentencePiece": [[90, "sentencepiece"]], "Shared Expert Isolation": [[82, "shared-expert-isolation"]], "Small-scale Synthetic Supervision": [[74, "small-scale-synthetic-supervision"]], "Stage I: Training a Model Initialization to Prevent Collapse": [[73, "stage-i-training-a-model-initialization-to-prevent-collapse"]], "Stage II: Multi-Turn RL with Reward Shaping": [[73, "stage-ii-multi-turn-rl-with-reward-shaping"]], "Stage-1: Multi-Objective Reward Modeling": [[53, "stage-1-multi-objective-reward-modeling"]], "Stage-2: Mixture-of-Experts Aggregation of Reward Objectives": [[53, "stage-2-mixture-of-experts-aggregation-of-reward-objectives"]], "Stanford Alpaca": [[8, "stanford-alpaca"], [24, "stanford-alpaca"]], "Summarization": [[3, "summarization"]], "Supervised Fine-Tuning": [[42, "supervised-fine-tuning"], [43, "supervised-fine-tuning"], [44, "supervised-fine-tuning"]], "Supervised Fine-tuning": [[50, "supervised-fine-tuning"]], "Supervised Finetuning": [[47, "supervised-finetuning"]], "Supervised fine-tuning": [[2, "supervised-fine-tuning"]], "Supervised fine-tuning (SFT)": [[58, "supervised-fine-tuning-sft"]], "Surface Patterns in Non-Determinism Generation?": [[34, "surface-patterns-in-non-determinism-generation"]], "SwiGLU": [[89, "swiglu"]], "SwiGLU activation function": [[48, "swiglu-activation-function"], [49, "swiglu-activation-function"]], "Swish": [[89, "swish"]], "TACO": [[19, "taco"]], "Takeaway": [[42, "takeaway"], [43, "takeaway"], [44, "takeaway"], [47, "takeaway"], [50, "takeaway"], [51, "takeaway"], [87, "takeaway"]], "Takeaways": [[66, "takeaways"], [74, "takeaways"]], "Task-specific input transformations": [[2, "task-specific-input-transformations"]], "Techniques": [[80, "techniques"]], "Temperature Effect on Non-Determinism": [[34, "temperature-effect-on-non-determinism"]], "The Factors of Math Reasoning Ability in Supervised LLM": [[79, "the-factors-of-math-reasoning-ability-in-supervised-llm"]], "The GOLD algorithm": [[33, "the-gold-algorithm"]], "The Need for Interpretable Reward Models": [[53, "the-need-for-interpretable-reward-models"]], "The Proposed Flow": [[40, "the-proposed-flow"]], "Tiktoken": [[48, "tiktoken"]], "Token-Dropping Strategy": [[82, "token-dropping-strategy"]], "Tokenizer": [[48, "tokenizer"], [48, "id2"]], "Training Dataset": [[3, "training-dataset"], [4, "training-dataset"]], "Training Details": [[26, "training-details"]], "Training Language Models to Self-Correct via Reinforcement Learning": [[73, "training-language-models-to-self-correct-via-reinforcement-learning"]], "Training Policy": [[51, "training-policy"], [51, "id8"]], "Training Template": [[72, "training-template"]], "Training WizardCoder": [[20, "training-wizardcoder"], [29, "training-wizardcoder"]], "Transformer": [[48, "transformer"], [49, "transformer"]], "Two-stage Instruction-Tuning": [[26, "two-stage-instruction-tuning"]], "UNICODER": [[28, "unicoder"], [28, "id2"]], "UNICODER-INSTRUCT": [[28, "unicoder-instruct"]], "UTF-16\u3001UTF-32\u7b49": [[91, "utf-16utf-32"]], "UTF-8": [[91, "utf-8"]], "Unigram Language Model (ULM)": [[90, "unigram-language-model-ulm"]], "Unsupervised pre-training": [[2, "unsupervised-pre-training"]], "Weak to Strong Generalization": [[36, "weak-to-strong-generalization"]], "West-of-N": [[69, "west-of-n"]], "West-of-N Self-Training": [[69, "west-of-n-self-training"]], "What is MyST?": [[31, "what-is-myst"]], "What is the Full Potential of Non-Determinism?": [[34, "what-is-the-full-potential-of-non-determinism"]], "Why KV cache": [[85, "why-kv-cache"]], "Why Layer Normalization": [[86, "why-layer-normalization"]], "Why decoder-only": [[2, "why-decoder-only"]], "WizardCoder": [[20, "wizardcoder"], [29, "wizardcoder"]], "WizardLM": [[20, "wizardlm"], [29, "wizardlm"]], "WordPiece": [[90, "wordpiece"]], "WordPiece, ULM and SentencePiece": [[90, "wordpiece-ulm-and-sentencepiece"]], "YaRN": [[83, "id5"]], "YaRN: Efficient ContextWindow Extension of Large Language Models": [[83, "yarn-efficient-contextwindow-extension-of-large-language-models"]], "methodology": [[58, "methodology"]], "unicode": [[91, "unicode"]], "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": [[91, "id1"]], "\u521d\u8bc6BPE": [[81, "bpe"]], "\u603b\u7ed3": [[91, "id2"]], "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff1f": [[81, "id2"]], "\u672c\u5730 Evaluate": [[10, "evaluate"], [13, "evaluate"]], "\u7f16\u7801\u548c\u89e3\u7801": [[81, "id1"]], "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": [[83, "id4"]]}, "docnames": ["base/0", "base/attention", "base/gpt", "base/gpt2", "base/gpt3", "base/instruct-gpt", "bench/0", "bench/alignment", "bench/code-alpaca", "bench/cruxeval", "bench/evalplus", "bench/general", "bench/humaneval", "bench/livecodebench", "bench/magic", "bench/math-science", "bench/mbpp", "bench/reward-bench", "bench/self-instruct", "bench/taco", "bench/wizard", "content", "content-Copy1", "data/0", "data/code-alpaca", "data/magic", "data/opencoder", "data/self-instruct", "data/unicoder", "data/wizard", "intro", "markdown", "markdown-notebooks", "methodology/gold", "methodology/non-determin", "methodology/scaling-law", "methodology/weak-to-strong", "models/0", "models/alphacode", "models/alphacode2", "models/alphacodium", "models/codellama", "models/deepseek-coder-v2", "models/deepseek-v2", "models/deepseek-v3", "models/llama", "models/llama2", "models/llama3", "models/llama3-code copy", "models/llama3-source-code", "models/qwen25", "models/qwen25-coder", "preference/0", "preference/armo", "preference/dpo", "preference/dpop", "preference/ee", "preference/grpo", "preference/instruct-gpt", "preference/judge", "preference/openrlhf", "preference/rlaif-1", "preference/rlaif-2", "preference/rlcd", "preference/rs-dpo", "preference/rso", "preference/secret-rm", "preference/self-reward", "preference/self-taught", "preference/west-of-n", "reasoning/0", "reasoning/cot", "reasoning/deepseek-r1", "reasoning/self-correct-rl", "reasoning/verify", "reference", "sft/0", "sft/random", "sft/rl-eight-fold", "sft/rs", "techniques/0", "techniques/bpe", "techniques/deepseek-moe", "techniques/extending", "techniques/extending-old", "techniques/mla", "techniques/norm", "techniques/rope", "techniques/rope-old", "techniques/swiglu", "techniques/tokenize", "techniques/unicode-utf8", "tools/llama-factory", "tools/lora", "tools/openrlhf"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["base/0.ipynb", "base/attention.ipynb", "base/gpt.ipynb", "base/gpt2.ipynb", "base/gpt3.ipynb", "base/instruct-gpt.ipynb", "bench/0.ipynb", "bench/alignment.ipynb", "bench/code-alpaca.ipynb", "bench/cruxeval.ipynb", "bench/evalplus.ipynb", "bench/general.ipynb", "bench/humaneval.ipynb", "bench/livecodebench.ipynb", "bench/magic.ipynb", "bench/math-science.ipynb", "bench/mbpp.ipynb", "bench/reward-bench.ipynb", "bench/self-instruct.ipynb", "bench/taco.ipynb", "bench/wizard.ipynb", "content.ipynb", "content-Copy1.ipynb", "data/0.ipynb", "data/code-alpaca.ipynb", "data/magic.ipynb", "data/opencoder.ipynb", "data/self-instruct.ipynb", "data/unicoder.ipynb", "data/wizard.ipynb", "intro.md", "markdown.md", "markdown-notebooks.md", "methodology/gold.ipynb", "methodology/non-determin.ipynb", "methodology/scaling-law.ipynb", "methodology/weak-to-strong.ipynb", "models/0.ipynb", "models/alphacode.ipynb", "models/alphacode2.ipynb", "models/alphacodium.ipynb", "models/codellama.ipynb", "models/deepseek-coder-v2.ipynb", "models/deepseek-v2.ipynb", "models/deepseek-v3.ipynb", "models/llama.ipynb", "models/llama2.ipynb", "models/llama3.ipynb", "models/llama3-code copy.ipynb", "models/llama3-source-code.ipynb", "models/qwen25.ipynb", "models/qwen25-coder.ipynb", "preference/0.ipynb", "preference/armo.ipynb", "preference/dpo.ipynb", "preference/dpop.ipynb", "preference/ee.ipynb", "preference/grpo.ipynb", "preference/instruct-gpt.ipynb", "preference/judge.ipynb", "preference/openrlhf.ipynb", "preference/rlaif-1.ipynb", "preference/rlaif-2.ipynb", "preference/rlcd.ipynb", "preference/rs-dpo.ipynb", "preference/rso.ipynb", "preference/secret-rm.ipynb", "preference/self-reward.ipynb", "preference/self-taught.ipynb", "preference/west-of-n.ipynb", "reasoning/0.ipynb", "reasoning/cot.ipynb", "reasoning/deepseek-r1.ipynb", "reasoning/self-correct-rl.ipynb", "reasoning/verify.ipynb", "reference.ipynb", "sft/0.ipynb", "sft/random.ipynb", "sft/rl-eight-fold.ipynb", "sft/rs.ipynb", "techniques/0.ipynb", "techniques/bpe.ipynb", "techniques/deepseek-moe.ipynb", "techniques/extending.ipynb", "techniques/extending-old.ipynb", "techniques/mla.ipynb", "techniques/norm.ipynb", "techniques/rope.ipynb", "techniques/rope-old.ipynb", "techniques/swiglu.ipynb", "techniques/tokenize.ipynb", "techniques/unicode-utf8.ipynb", "tools/llama-factory.ipynb", "tools/lora.ipynb", "tools/openrlhf.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [2, 3, 5, 10, 11, 15, 26, 31, 32, 33, 35, 36, 40, 41, 43, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 61, 62, 63, 65, 66, 68, 73, 75, 79, 81, 82, 83, 84, 90], "0": [1, 2, 10, 12, 13, 18, 20, 26, 27, 29, 33, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 57, 59, 60, 61, 62, 65, 66, 67, 69, 79, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93], "000": [11, 15, 19, 38, 41], "0000": [84, 91], "0000j": 84, "0001": 91, "0010": 91, "003": [8, 24], "0041": 91, "005": 12, "007f": 91, "0080": 91, "01": 60, "0100j": 84, "01825": [31, 75], "02120": [14, 25, 31, 75], "03": 45, "03065": [31, 75], "0314": 7, "03300": [31, 75], "03341": [31, 75], "03374": [31, 75], "03762": [31, 75], "0461": 84, "04805": [31, 75], "0596": 84, "0596j": 84, "06": 45, "0674": 84, "0674j": 84, "07436": [31, 75], "076": 35, "07911": [31, 75], "07974": [31, 75], "07ff": 91, "0800": 91, "08083": [31, 75], "08361": [31, 75], "08568": [20, 29], "09288": [31, 75], "096": 41, "09864": [31, 75], "0xxxxxxx": 91, "1": [1, 2, 5, 7, 8, 10, 12, 13, 14, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 73, 74, 75, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92], "10": [10, 13, 15, 26, 34, 35, 39, 41, 42, 43, 45, 47, 51, 57, 62, 66, 81, 82, 91, 92], "100": [3, 8, 11, 12, 24, 26, 39, 41, 51, 53, 56, 74], "1000": [20, 29, 44, 74, 83, 84], "10000": [1, 39, 48, 49, 83, 84, 87, 88], "100000": 60, "10000000": 91, "100k": 43, "10111000": 91, "1024": [51, 60], "102400": 43, "1048576000": 43, "105": 13, "10509": [31, 75], "10560": [18, 27], "106": 13, "107": 13, "10k": 43, "10x": 4, "10xxxxxx": 91, "11": [13, 88], "1106": [14, 25], "110k": [14, 25], "110xxxxx": 91, "110\u8868\u793a\u9700\u8981\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u5f53\u524d\u5b57\u7b26": 91, "1110": 91, "1110xxxx": 91, "1110\u8868\u793a\u9700\u8981\u4e09\u4e2a\u5b57\u8282": 91, "11110xxx": 91, "11110\u8868\u793a\u9700\u8981\u56db\u4e2a\u5b57\u8282": 91, "117": 13, "12": [11, 13, 15, 35, 39, 43, 81, 88], "12000": 92, "12122": [31, 75], "12186": [31, 75], "12288": 43, "123abc\u4e00\u4e8c\u4e09": 91, "125": [4, 13], "128": [43, 60], "128k": [43, 44, 47], "128\u4f4dascii\u7801\u662f\u6570\u5b57": 91, "12b": 12, "12k": 74, "12n_": 35, "13": [13, 35, 48, 81], "13245": [31, 75], "13b": 41, "13k": 5, "14": [11, 13, 41, 44, 85], "14165": [31, 75], "14168": [31, 75], "14187": [31, 75], "14858": [31, 75], "149225472": 43, "15": [13, 14, 25, 45, 46], "151": 50, "15115": [31, 75], "1536": 43, "15b": [20, 29], "16": [11, 13, 45, 58, 60, 61, 79], "160": 43, "1609": 48, "1612": [31, 75], "164": 12, "16441": [31, 75], "16609": [31, 75], "16k": 47, "17": [12, 13], "1706": [31, 75], "175": [4, 18, 27], "18": [13, 50], "1810": [31, 75], "18290": [31, 75], "185b": 42, "188743680": 43, "19": [3, 4, 31, 75], "1904": [31, 75], "1909": [31, 75], "198": 15, "1990\u5e74\u5f00\u59cb\u7814\u53d1": 91, "1994": 81, "1_gnu": 13, "1e": [48, 49, 86, 92], "1k": 15, "1l": 64, "1m": 26, "1qvx610cu7": [31, 75], "1t": [43, 47], "1w": 64, "1\u4f4d\u4e3a": 91, "2": [1, 2, 3, 4, 5, 8, 10, 11, 13, 15, 18, 22, 24, 27, 31, 32, 35, 36, 38, 40, 42, 43, 44, 45, 47, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 69, 73, 74, 75, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91], "20": [4, 5, 8, 13, 24, 31, 66, 74, 75], "200": [5, 8, 12, 24, 74], "2000": 45, "2001": [31, 75], "2005": [31, 75], "20050": [31, 75], "2009": [31, 75], "2017": [31, 75], "2019": [31, 75], "2020": [31, 75], "2021": [31, 75], "2023": [31, 42, 75], "2024": [13, 31, 51, 75], "20240602": 13, "2025": [31, 75], "2048": [48, 49, 83, 84], "20k": [8, 14, 20, 24, 25, 29, 42], "21": [11, 12, 13, 14, 15, 25, 31, 75, 79, 88], "2104": [31, 75], "2107": [31, 75], "2110": [31, 75], "21326725120": 43, "21783": [31, 75], "21b": 43, "22": [13, 88], "2212": [18, 27], "2294": 48, "23": [1, 2, 7, 13, 15, 31, 44, 45, 47, 50, 75, 79, 81, 83, 85, 87], "2305": [31, 75], "2306": [20, 29], "2307": [31, 75], "2308": [31, 75], "2309": [31, 75], "2311": [31, 75], "2312": [14, 25, 31, 75], "235692359680": 43, "236b": 43, "24": [9, 11, 13, 26, 28, 31, 47, 50, 51, 75], "2401": [31, 75], "2403": [31, 75], "2406": [31, 75], "2407": [31, 75], "2409": [31, 75], "2412": [31, 75], "25": [7, 13, 19, 31, 50, 51, 66, 75, 85], "256": [48, 49, 67], "256\u4f4dascii\u6269\u5c55\u7801\u662fascii": 91, "26": 13, "27": 46, "29": 13, "2900": 84, "290k": 26, "2d": 83, "2d_": 35, "2e": 26, "2i": [1, 41, 88], "2j": [48, 49, 83, 84], "2m": 43, "2n": 35, "2n_": [35, 85], "2t": 88, "2\u62164\u5b57\u8282\u53d8\u957f": 91, "3": [2, 3, 4, 5, 7, 13, 14, 25, 31, 34, 35, 38, 40, 41, 42, 43, 44, 48, 58, 60, 61, 67, 72, 75, 79, 81, 82, 83, 84, 86, 89], "30": [11, 42, 47], "3000": 84, "300m": 42, "30k": 42, "31k": 5, "32": [13, 48, 49, 56, 79, 91], "3200": 56, "32768": [83, 84], "32k": 44, "33": 11, "338": 42, "33k": 5, "33t": 85, "34": [13, 15], "34b": [9, 41, 60], "35x": 10, "374": 48, "37b": 44, "38": 13, "3822059520": 43, "39": 15, "3m": 43, "4": [5, 7, 11, 13, 14, 15, 25, 35, 36, 41, 45, 47, 48, 49, 55, 56, 58, 60, 62, 67, 74, 79, 81, 84, 85, 86, 91, 92], "40": [53, 61, 66], "400": 7, "405b": 47, "4096": [26, 48, 49, 92], "40k": 42, "41": 13, "426": 16, "43": 13, "443": 19, "448": 15, "45": [3, 13, 45], "4d": [48, 49], "4e00": 91, "4e00\u57280800": 91, "4e00\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a100": 91, "4k": 44, "4t": 45, "4\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 91, "4\u5b57\u8282\u53d8\u957f": 91, "4\u5b57\u8282\u8868\u793a": 91, "5": [11, 13, 14, 15, 21, 22, 25, 26, 31, 38, 41, 42, 43, 44, 45, 48, 49, 53, 54, 55, 56, 66, 67, 69, 75, 81, 84, 92], "50": [39, 41], "500": 7, "500000": [48, 49], "500b": 41, "512": [1, 26, 43], "5120": 43, "52": 41, "52k": [8, 18, 24, 27], "54": [13, 38], "540": 46, "5403": 84, "55m": 19, "57": 11, "5963": 48, "5b": 74, "5e": [26, 60], "5k": 15, "5m": 43, "5pm": [8, 24], "6": [1, 10, 13, 14, 18, 25, 27, 35, 40, 41, 42, 43, 48, 49, 60, 62, 74, 84, 86, 92], "60": [42, 43, 53, 61], "62": [13, 41], "63": 13, "64": [13, 43, 45], "643": 50, "65": 15, "65b": 45, "66": 13, "67": 45, "671b": 44, "67b": 43, "6n": 35, "6nb": 35, "6w": 91, "7": [12, 13, 15, 18, 27, 36, 39, 46, 50, 51, 60, 79, 81, 84], "70": 13, "70b": [41, 46, 47, 60, 67], "72": 13, "75k": [14, 25, 74], "77": 39, "788m": 44, "7b": [8, 10, 14, 24, 25, 41, 45, 46, 60, 85, 92], "8": [4, 13, 15, 18, 27, 31, 35, 40, 41, 43, 44, 50, 60, 61, 75, 79, 84, 85], "80": [36, 74], "800": 9, "8000": 39, "800k": 74, "80gb": 60, "80k": [14, 25], "80x": 10, "821b": 42, "82k": [18, 27], "83": 48, "8415j": 84, "85": [39, 47], "8b": [34, 47, 60], "8binstruct": 34, "8\u4e2abit\u4f4d\u4e2d\u9ad8\u4f4d\u5fc5\u987b\u7b49\u4e8e0": 91, "8\u4e2abit\u4f4d\u662f\u4e00\u4e2a\u5b57\u8282": 91, "8\u4e3a11100100": 91, "8\u4e3a\u4e09\u5b57\u8282": 91, "8\u4f4d\u53ef\u8868\u793a256\u4e2a\u5b57\u7b26": 91, "8\u548cgbk\u7f16\u7801": 91, "8\u6765\u5b9e\u73b0\u7f16\u7801": 91, "8\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u89e3\u7801\u4f7f\u7528": 91, "8\u7684\u6620\u5c04\u5173\u7cfb\u5982\u4e0b": 91, "8\u7684\u7f16\u7801\u65b9\u5f0f": 91, "8\u7684\u89c4\u5219\u5f88\u7b80\u5355": 91, "8\u7b49": 91, "8\u7f16\u7801": 91, "9": [5, 12, 13, 31, 45, 48, 58, 63, 75, 81, 85], "92": 51, "9297": 84, "95": [13, 45], "974": 16, "9901": 92, "9999": 84, "9e": 60, "A": [3, 8, 15, 18, 24, 26, 27, 31, 33, 34, 39, 46, 48, 49, 50, 53, 56, 57, 61, 62, 65, 68, 69, 72, 75, 81, 82, 83, 88, 89, 93], "And": [57, 79], "As": [33, 36, 39, 40, 42, 46, 47, 55, 56, 57, 69, 72, 74, 82, 85], "At": [1, 3, 18, 27, 33, 38, 44, 46, 68, 74, 83, 84], "By": [4, 42, 44, 47, 48, 56, 66, 83], "FOR": 61, "For": [2, 5, 8, 14, 16, 18, 24, 25, 26, 27, 31, 34, 35, 36, 39, 40, 41, 43, 44, 46, 47, 50, 51, 53, 55, 56, 57, 59, 61, 63, 64, 65, 66, 72, 74, 79, 82, 83, 84, 85, 93], "If": [7, 32, 33, 36, 40, 48, 49, 51, 56, 57, 61, 65, 68, 82, 84, 89], "In": [1, 2, 5, 8, 14, 18, 20, 24, 25, 26, 27, 28, 29, 31, 33, 34, 38, 40, 41, 42, 43, 44, 46, 47, 48, 50, 51, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 71, 72, 75, 79, 82, 83, 84, 85, 87, 88], "It": [5, 7, 8, 11, 20, 24, 29, 31, 35, 36, 40, 41, 43, 46, 47, 48, 54, 57, 61, 73, 82, 84], "Its": 39, "No": [34, 44, 48, 51], "Not": [8, 24], "OF": 61, "Of": [18, 27], "On": [1, 36, 44, 56], "One": [7, 33, 38, 47, 56, 59, 61, 62, 65, 83, 84, 88], "Or": [10, 47], "Such": [31, 68, 75], "That": [1, 32], "The": [1, 2, 3, 4, 5, 8, 9, 11, 12, 14, 15, 16, 18, 20, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 72, 74, 75, 82, 83, 84, 85, 86, 88, 89], "Their": 74, "Then": [5, 14, 25, 47, 55, 56, 57, 61, 62, 65, 82, 85, 87], "There": 83, "These": [1, 2, 8, 15, 19, 20, 24, 26, 29, 47, 50, 61, 65, 67, 68], "To": [1, 3, 4, 5, 11, 14, 15, 18, 20, 25, 26, 27, 28, 29, 33, 34, 35, 38, 39, 41, 42, 44, 45, 46, 47, 48, 50, 51, 53, 57, 58, 59, 62, 65, 67, 69, 72, 74, 82, 83, 86, 89], "Will": [31, 75], "With": [11, 15, 32, 40, 83], "_": [1, 5, 18, 20, 27, 28, 29, 33, 41, 44, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 64, 65, 66, 69, 73, 74, 79, 82, 83, 85, 87, 88, 89], "_1": [1, 73], "__init__": [43, 48, 49, 86], "__main__": 10, "__name__": 10, "_bsz": [48, 49], "_h": 1, "_i": 79, "_libgcc_mutex": 13, "_mergeable_rank": 48, "_norm": [48, 49, 86], "_openmp_mutex": 13, "_t": 85, "a100": 60, "a_": [33, 57, 84, 88], "a_i": [28, 79], "aa": 81, "aaabdaaabac": 81, "aaditya": [31, 75], "aaron": [31, 75], "aayushi": [31, 75], "ab": [31, 75, 81, 84], "abbrevi": [15, 91], "abha": [31, 75], "abhimanyu": [31, 75], "abhinav": [31, 75], "abhishek": [31, 75], "abil": [3, 11, 14, 15, 25, 36, 42, 43, 50, 55, 57, 65, 71, 72, 74], "abl": [8, 9, 15, 24, 36, 46], "ablat": [26, 74], "about": [1, 5, 8, 14, 24, 25, 31, 32, 36, 39, 40, 41, 43, 56, 66, 82, 84], "abov": [2, 36, 39, 41, 47, 65, 66, 68, 69, 72, 73, 82, 83], "absenc": 44, "absolut": [1, 45, 53, 87], "absorb": 85, "abstract": 3, "abstractset": 48, "ac": 81, "academ": 11, "acceler": [2, 85], "accept": [31, 65], "access": [36, 46, 56, 65, 67, 68, 69, 73], "accommod": [47, 74], "accompani": 59, "accomplish": [34, 47], "accord": [39, 44, 56, 66, 69, 74, 82, 84], "account": [35, 41], "accumul": 40, "accur": [11, 16, 19, 26, 46, 50, 57, 66], "accuraci": [11, 15, 44, 50, 62, 66, 72], "achiam": [31, 75], "achiev": [4, 11, 15, 26, 38, 42, 44, 45, 46, 47, 50, 54, 55, 59, 62, 65, 66, 69, 85], "acquir": [11, 43, 46, 72, 82], "across": [11, 13, 36, 39, 47, 50, 56, 74, 82, 83, 85, 86], "action": [8, 24, 33], "activ": [1, 2, 43, 44, 45, 50, 82, 85, 89], "actor": [57, 60], "actor_learning_r": 60, "actual": [5, 57, 73], "ad": [2, 3, 18, 20, 27, 29, 38, 47, 57, 66, 73, 88], "adam": [31, 75], "adam_offload": 60, "adamw": 45, "adapt": [2, 20, 29, 59, 82, 83, 84, 93], "add": [1, 3, 5, 20, 29, 40, 41, 44, 45, 46, 48, 49, 53, 58, 66, 67], "addit": [1, 3, 5, 33, 36, 38, 39, 41, 42, 44, 48, 49, 56, 58, 59, 63, 67, 72, 73, 74, 82, 83, 85, 89, 91], "addition": [2, 11, 18, 26, 27, 44, 56, 82], "additionali": 57, "address": [15, 20, 29, 40, 47, 51, 57, 62, 65], "adher": [36, 50, 51, 72], "adi": [31, 75], "adina": [31, 75], "adithya": [31, 75], "aditya": [31, 75], "adjust": [43, 47, 53, 65, 72, 85], "adkin": [31, 75], "adolfo": [31, 75], "adopt": [8, 14, 24, 25, 34, 38, 43, 44, 51, 72, 85], "advanc": [11, 26, 39, 50], "advantag": [36, 57, 59, 60, 85], "advis": 61, "affect": [21, 26, 34, 82], "affin": [44, 48, 82], "aforement": 62, "after": [2, 3, 18, 20, 27, 29, 34, 38, 39, 42, 44, 45, 46, 47, 48, 51, 55, 56, 57, 58, 62, 65, 66, 67, 72, 74, 82, 83, 84], "again": [1, 62, 89], "against": [5, 7, 40, 51, 61, 63], "agarw": [31, 75], "agent": [51, 56, 65], "aggreg": 39, "aggress": [8, 24], "agnost": [4, 59], "ahm": [31, 75], "ahmad": [31, 75], "ahuva": [31, 75], "ai": [7, 13, 15, 40, 47, 67, 69], "aidan": [31, 75], "aiesha": [31, 75], "aif": 67, "aift": 67, "aim": [15, 33, 34, 57, 65, 67, 68, 73, 82], "ainsli": [31, 75], "aiohttp": 13, "aiosign": 13, "ajai": [31, 75], "ajayi": [31, 75], "ajudg": 51, "akhil": [31, 75], "al": [31, 75], "alan": [31, 75], "alao": [31, 75], "albadawi": [31, 75], "albert": [31, 75], "albiero": [31, 75], "alec": [31, 75], "alethea": [31, 75], "alex": [31, 75], "alexei": [31, 75], "algorithm": [5, 12, 18, 19, 27, 38, 39, 40, 42, 43, 45, 46, 47, 50, 51, 54, 57, 81], "alibi": 84, "align": [1, 2, 5, 15, 21, 28, 35, 36, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 62, 65, 82, 83, 84, 85, 87, 88, 89], "align_n": 59, "alignmentrelev": 36, "alik": 41, "all": [3, 5, 8, 12, 16, 20, 24, 28, 29, 31, 32, 33, 35, 38, 39, 42, 43, 46, 47, 48, 51, 54, 55, 56, 57, 58, 61, 62, 64, 65, 66, 73, 74, 75, 79, 82, 83, 84, 85, 86, 89], "allclos": [48, 86], "allevi": 82, "alli": [31, 75], "alloc": [51, 72], "allonsiu": [31, 75], "allow": [1, 3, 4, 31, 33, 38, 39, 44, 47, 48, 61, 68, 82, 84, 88], "allowed_speci": 48, "allowed_token": 48, "almahairi": [31, 75], "almost": 66, "alon": [62, 66, 67], "along": [2, 38, 40, 41], "alongsid": [44, 57], "alpaca": [14, 20, 21, 22, 25, 29], "alpacaev": [34, 67], "alpha": [59, 66, 73, 83], "alpha_": [35, 82], "alphacod": 41, "alrassi": [31, 75], "alreadi": [36, 38, 42, 48, 56, 67], "also": [1, 5, 8, 11, 13, 15, 16, 18, 24, 26, 27, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 61, 67, 68, 69, 82, 83, 85, 89], "altdj": [31, 50, 75, 85], "alter": 40, "altern": [4, 46, 47, 54, 56, 59, 62], "although": [7, 33, 42, 44, 72, 82, 91], "alvarado": [31, 75], "alwai": [38, 47, 59, 66, 82, 83, 84], "alwala": [31, 75], "amanda": [31, 75], "ambigu": 66, "amc": 15, "american": 91, "ami": [31, 75], "amit": [31, 75], "amjad": [31, 75], "amo": [31, 75], "amodei": [31, 75], "among": [7, 9, 41, 43, 51, 56, 65, 82, 85], "amount": [26, 35, 39, 43, 47, 67, 72, 74, 79, 83, 85, 89], "an": [1, 2, 3, 4, 5, 7, 8, 11, 12, 14, 18, 20, 24, 25, 26, 27, 29, 31, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 79, 82, 83, 84, 85], "anaconda3": 13, "analogi": 36, "analysi": [40, 43, 47, 51, 59, 62], "analyz": [26, 51, 79], "anam": [31, 75], "anchor": 40, "anderson": [31, 75], "andi": [31, 75], "andr": [31, 75], "andrei": [31, 75], "andrew": [31, 75], "angela": [31, 75], "angl": [84, 87], "ani": [1, 3, 4, 8, 12, 14, 18, 24, 25, 26, 27, 32, 33, 36, 40, 44, 47, 48, 51, 58, 61, 69, 72, 74, 83, 84, 85, 87, 88], "anirudh": [31, 75], "ankit": [31, 75], "ann": [31, 75], "anneal": 26, "anni": [31, 75], "annot": [11, 13, 41, 44, 46, 47, 62, 67], "anoth": [8, 24, 33, 38, 40, 46, 57, 59, 62, 66, 84], "answer": [2, 3, 10, 11, 15, 19, 26, 28, 34, 41, 44, 46, 50, 51, 61, 68, 72, 73, 74, 79, 84], "answer_1": 47, "anthoni": [31, 75], "anthrop": [13, 56], "anticip": 51, "anuj": [31, 75], "anyio": 13, "anywher": [5, 58], "aobo": [31, 75], "aparajita": [31, 75], "api": [5, 13, 26, 50, 58], "app": 61, "appear": [35, 40, 84], "append": [18, 26, 27, 48, 49, 60, 61, 65], "appli": [1, 2, 5, 14, 20, 25, 29, 34, 39, 40, 41, 42, 44, 47, 48, 49, 53, 54, 56, 57, 58, 59, 66, 68, 69, 72, 73, 79, 82, 83, 84, 89], "applic": [4, 5, 15, 41, 46, 83, 84], "apply_chat_templ": 60, "apply_rotary_emb": [48, 49, 84], "approach": [14, 18, 25, 26, 27, 33, 35, 39, 41, 43, 44, 46, 47, 51, 53, 54, 59, 62, 63, 67, 68, 69, 72, 73, 82, 83, 84], "appropri": [1, 8, 24, 41], "approx": [35, 44, 83, 87], "approxim": [3, 4, 7, 33, 42, 43, 47, 56, 66, 69, 74, 79, 82, 84], "aptitud": 15, "ar": [1, 2, 3, 4, 5, 7, 8, 9, 12, 14, 15, 18, 20, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 71, 74, 75, 79, 82, 83, 84, 85, 86, 88, 91], "arang": [12, 48, 49, 54, 84], "arbitrari": [5, 84], "arcaut": [31, 75], "archi": [31, 75], "archit": [31, 75], "architectur": [2, 3, 35, 38, 41, 51, 82, 84, 85, 86, 88, 93], "archiv": 3, "area": [11, 50], "arg": [46, 48, 49, 60, 65, 84], "argmax": 48, "argu": [43, 65], "ariel": [31, 75], "arini": [31, 75], "aris": [61, 62], "arithmet": 15, "arkabandhu": [31, 75], "armando": [31, 75], "armo": 22, "armorm": 34, "around": [1, 7, 85], "arrang": 13, "arrieta": [31, 75], "art": [4, 15, 36, 45], "artem": [31, 75], "arthur": [31, 75], "articl": 3, "arun": [31, 75], "arvind": [31, 75], "arxiv": [14, 18, 20, 25, 27, 29, 31, 45, 75], "ascertain": 56, "ascii\u5c31\u662f\u6700\u521d\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 91, "ascii\u8d77\u521d\u53ea\u89c4\u5b9a\u4e86127\u4e2a\u5b57\u7b26": 91, "asher": [31, 75], "ashish": [31, 75], "ashlei": [31, 75], "ashwin": [31, 75], "ask": [5, 8, 16, 18, 24, 27, 40, 46, 47, 58, 62, 68], "askel": [31, 75], "aspect": [40, 50, 59, 67], "aspegren": [31, 75], "assaf": [31, 75], "assert": [41, 48, 49, 84], "assertionerror": [48, 84], "assess": [11, 12, 15, 20, 29, 47, 51, 64], "assign": [1, 33, 38, 46, 47, 53, 56, 57, 59, 65, 66, 69, 73, 74, 82], "assist": [8, 24, 36, 41, 48, 61, 63, 67, 68], "associ": [41, 65], "assum": [2, 33, 55, 59, 65, 67, 68, 69, 73, 86, 90], "ast": [54, 65, 73, 88], "aston": [31, 75], "asymptot": 15, "async": 13, "atcod": 13, "atol": [48, 86], "att": 82, "attach": 53, "attain": 56, "attempt": [36, 73, 74], "attend": 1, "attent": [2, 3, 4, 21, 22, 31, 35, 43, 44, 50, 55, 75, 82, 83, 84, 86, 87, 88], "attention_bia": 43, "attention_norm": [48, 49], "attn": 35, "attr": 13, "attract": 84, "attribut": [39, 63], "audio": [8, 24], "augment": 67, "auli": [31, 75], "aurelien": [31, 75], "austen": [31, 75], "auth": 13, "authent": 59, "author": [54, 67], "auto": [1, 7], "autom": [18, 26, 27, 50], "automat": [7, 14, 18, 20, 25, 27, 29, 47, 51, 53, 63, 82], "autonom": 72, "autoregress": [2, 4, 33, 41, 46, 83], "auxiliari": [2, 36, 38, 44, 73], "ava": [31, 75], "avail": [19, 41, 45, 47, 50], "avalani": [31, 75], "avenu": 5, "averag": [12, 38, 39, 48, 49, 57, 62, 82], "avoid": [5, 33, 36, 38, 39, 40, 55, 57, 65, 66, 83], "await": [20, 29], "ax": 47, "axi": [48, 86], "ayub": [31, 75], "azadeh": [31, 75], "b": [2, 31, 33, 35, 48, 49, 56, 61, 68, 73, 75, 83, 89, 93], "b_": [48, 49, 89], "b_1": 1, "b_2": 1, "b_i": 44, "b_j": 44, "babaei": [31, 75], "babuschkin": [31, 75], "backbon": 53, "backend": 10, "background": 12, "backpropag": 46, "backtransl": 47, "backward": 35, "bad": [33, 36, 47], "badeer": [31, 75], "baevski": [31, 75], "bag": 46, "bai": [31, 75], "baker": [31, 75], "balaji": [31, 75], "balanc": [1, 44, 47, 51, 68], "band": 4, "bansal": [31, 75], "bao": [31, 75], "baosong": [31, 75], "baptist": [31, 75], "bar": 83, "barn": [31, 75], "basart": [31, 75], "base": [1, 2, 3, 5, 8, 14, 15, 18, 20, 22, 24, 25, 26, 27, 29, 32, 33, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 53, 54, 56, 57, 58, 59, 61, 65, 66, 67, 68, 69, 73, 79, 83, 84, 87, 88, 91, 92], "baselin": [7, 15, 34, 67, 68, 74], "bashlykov": [31, 75], "basi": [48, 84], "basic": [15, 16, 21, 40, 50, 51], "basu": [31, 75], "batch": [5, 8, 24, 26, 35, 41, 45, 46, 47, 48, 56, 58, 85], "batchnorm1d": [48, 86], "batchnorm2d": 48, "batra": [31, 75], "battei": [31, 75], "bavarian": [31, 75], "bawa": [31, 75], "bax": 93, "bbc": [31, 50, 75], "bbpe": [43, 50], "beati": [31, 75], "beau": [31, 75], "becaus": [1, 8, 18, 24, 27, 40, 47, 53, 61, 72, 86], "becom": [55, 62, 73, 82, 84, 85], "been": [33, 39, 40, 43, 44, 48, 50, 56, 57, 66, 69], "befor": [18, 27, 36, 38, 42, 46, 51, 63, 83, 84], "begin": [1, 2, 3, 5, 35, 41, 44, 46, 47, 48, 49, 54, 55, 56, 57, 58, 61, 65, 69, 72, 82, 83, 84, 85, 87, 88, 89], "begin_of_text": 48, "behav": [36, 39, 84], "behavior": [3, 5, 15, 33, 36, 39, 40, 51, 61, 72, 84, 86], "behaviour": 38, "behind": 84, "beichen": [31, 75], "being": [1, 4, 14, 25, 31, 38, 47, 69], "believ": 53, "bell": [31, 75], "belong": 82, "below": [8, 14, 24, 25, 36, 41, 55, 66], "ben": [31, 75], "bench": 21, "benchmark": [3, 4, 9, 19, 20, 29, 31, 36, 42, 43, 47, 75, 85], "benefici": [1, 40, 66], "benefit": [3, 46, 66, 79], "benfeng": [31, 75], "benjamin": [31, 75], "berner": [31, 75], "berni": [31, 75], "bert": [3, 31, 75], "best": [5, 15, 26, 31, 34, 35, 38, 39, 40, 45, 46, 47, 51, 56, 58, 66, 67, 69, 73, 74, 75], "bestof": 34, "beta": [5, 46, 48, 54, 55, 57, 58, 65, 83, 86, 89], "beta_": [45, 73], "beth": [31, 75], "bethani": [31, 75], "beto": [31, 75], "better": [5, 11, 36, 39, 40, 42, 44, 45, 46, 47, 50, 51, 55, 61, 62, 65, 68, 74, 79, 85], "between": [1, 5, 8, 11, 14, 15, 24, 25, 28, 33, 34, 36, 38, 39, 41, 43, 46, 47, 48, 49, 54, 55, 57, 58, 61, 62, 65, 66, 67, 72, 73, 74, 79, 82, 83, 86, 87, 88, 89], "beyond": [13, 36, 62, 82, 84], "bf16": [60, 92], "bhalla": [31, 75], "bharamb": [31, 75], "bhargava": [31, 75], "bhargavi": [31, 75], "bhatt": [31, 75], "bhosal": [31, 75], "bi": [31, 75], "bia": [43, 44, 48, 49, 50, 53, 62, 68, 73, 89], "bias": [18, 27, 33], "bib": 31, "bibliographi": 31, "bibtex": 31, "bidirect": [31, 75], "bigger": [5, 83], "biggest": 39, "bikel": [31, 75], "bilinear": 89, "billion": 4, "billock": [31, 75], "binari": [46, 47, 62, 66], "bing": [31, 75], "binh": [31, 75], "binom": [5, 12, 58], "binyuan": [31, 75], "biologi": [11, 15], "biron": [31, 75], "bit": [56, 83], "bitton": [31, 75], "black": 35, "blecher": [31, 75], "bleu": 33, "blind": 11, "block": [2, 3, 10, 32, 41, 47, 82], "blog": [5, 31, 51, 57, 75], "blue": [20, 29], "bmr": [4, 5, 31, 75], "bn": [48, 86], "bo": [31, 48, 75], "bob": [31, 75], "bobbi": [31, 75], "bodi": [12, 91], "boesenberg": [31, 75], "bofei": [31, 75], "bogoychev": [31, 75], "boltzmann": 56, "bondu": [31, 75], "bontrag": [31, 75], "bonu": 73, "book": [3, 31, 32, 45], "bool": 48, "bootstrap": [14, 18, 25, 27, 36, 47], "borodinski": [31, 75], "bos_id": 48, "both": [1, 4, 7, 9, 11, 14, 15, 25, 31, 34, 38, 41, 44, 46, 47, 50, 51, 57, 58, 59, 61, 62, 63, 67, 69, 73, 74, 83, 84, 85, 86], "boto3": 13, "botocor": 13, "bottleneck": 85, "bottom": [1, 66], "bouaziz": [31, 75], "bound": [34, 82, 84], "boundari": [14, 18, 25, 27, 83], "bowen": [31, 75], "box": [15, 31, 44, 72], "boyang": [31, 75], "boyu": [31, 75], "bpe": [3, 41, 45], "bpe\u6bcf\u4e00\u6b65\u90fd\u5c06\u6700\u5e38\u89c1\u7684\u4e00\u5bf9\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u66ff\u6362\u4e3a\u8be5\u6570\u636e\u4e2d\u6ca1\u6709\u51fa\u73b0\u8fc7\u7684\u4e00\u4e2a\u65b0\u5355\u4f4d": 81, "bpe\u9009\u62e9\u9891\u6570\u6700\u9ad8\u7684\u76f8\u90bb\u5b50\u8bcd\u5408\u5e76": 90, "braden": [31, 75], "bradlei": [5, 53, 54, 65, 66], "brahma": [31, 75], "brainstorm": 68, "bram": [31, 75], "branch": 47, "brandon": [31, 75], "brani": [31, 75], "breadth": [11, 20, 29], "break": [18, 27, 48, 65], "breviti": [82, 85], "brian": [31, 75], "bridg": [11, 33, 51], "brief": 4, "bright": 15, "bring": 57, "brinkman": [31, 75], "britt": [31, 75], "broad": [18, 27], "broadcast": 84, "broader": [11, 13], "broadli": 4, "brockman": [31, 75], "brook": [31, 75], "brown": [31, 75], "brundag": [31, 75], "brute": 40, "bsz": [48, 49], "bt": 65, "bucket": 47, "budget": [38, 39, 41, 45, 50, 82], "buffer": [56, 60], "bug": [40, 47, 60], "build": [3, 11, 13, 31, 34, 42, 47, 48, 50, 51, 53, 63, 67, 68], "built": [32, 43, 46, 51], "bullet": 40, "burda": [31, 75], "burden": 57, "burn": [31, 75], "burton": [31, 75], "busi": 11, "byte": [3, 31, 41, 43, 45, 50, 75], "bzip2": 13, "c": [2, 9, 12, 35, 38, 39, 43, 46, 47, 48, 49, 51, 56, 66, 83, 84, 85, 86, 89], "c4": 45, "c_": [35, 43], "ca": 13, "cabral": [31, 75], "cach": [10, 48, 49, 50], "cache_k": [48, 49], "cache_len": [48, 49], "cache_v": [48, 49], "cachecontrol": 13, "cachetool": 13, "caggioni": [31, 75], "cai": [31, 61, 75], "caichat": 60, "calcul": [12, 15, 43, 48, 49, 56, 57, 61, 62, 66, 79, 82, 84, 86], "calder": [31, 75], "calibr": [34, 61], "call": [1, 3, 4, 5, 12, 20, 29, 31, 33, 36, 40, 44, 46, 47, 48, 58, 59, 61, 65, 71, 74, 84, 85, 89], "can": [1, 2, 4, 5, 12, 13, 14, 15, 18, 25, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 72, 74, 75, 79, 82, 83, 84, 85, 86, 88, 89, 90], "cancel": 54, "candid": [38, 39, 47, 51, 56, 62, 65, 67, 69, 79], "cannot": [8, 15, 24, 33, 36, 84, 85], "canon": 62, "canton": [31, 75], "capabl": [7, 13, 14, 15, 20, 25, 26, 28, 29, 34, 36, 41, 44, 46, 50, 51, 59, 67, 72, 84], "capac": [2, 56, 82], "capl": [31, 75], "captur": [66, 72, 82], "cardin": [39, 56], "care": [36, 47], "carefulli": [11, 43, 47, 50], "carl": [31, 75], "carli": [31, 75], "carlo": [33, 57], "carr": [31, 75], "carri": [44, 85], "carvil": [31, 75], "cascad": 41, "case": [5, 8, 14, 16, 18, 24, 25, 26, 27, 33, 38, 39, 40, 41, 42, 44, 46, 51, 55, 59, 61, 69, 72, 82, 83], "cast": 48, "catalina": [31, 75], "catastroph": 84, "catch": 47, "categor": [39, 47, 51, 66, 68], "categori": [7, 68], "caucheteux": [31, 75], "caus": [11, 48, 54, 55, 63, 82], "causal": [2, 41], "cd": [10, 13], "cdot": [1, 43, 54, 55, 59, 65, 73, 82, 83, 88, 89], "ce": [31, 56, 75], "ceas": 35, "ceil": 36, "cell": 48, "central": 66, "centroid": 82, "certain": [2, 33, 44, 47, 68, 69, 82, 83, 84], "certif": 13, "certifi": 13, "cffi": 13, "cfg": 10, "cgrs19": [4, 31, 75], "chai": [31, 75], "chain": [11, 44, 61, 62, 68, 79], "chainof": 79, "challeng": [7, 8, 11, 15, 19, 24, 36, 40, 47, 50, 51, 54, 66, 68, 72, 74], "chan": [31, 75], "chanc": [11, 40], "chang": [8, 13, 24, 31, 63, 73, 75], "changhan": [31, 75], "changkyu": [31, 75], "changyu": [31, 75], "channel": [13, 48], "chantzi": [31, 75], "chao": [31, 75], "charact": [40, 41, 91], "character": [35, 43, 50], "characterist": [20, 29, 43], "charlott": [31, 75], "charset": [13, 91], "chat": [31, 42, 43, 46, 48, 75], "chat_complet": 48, "chatbot": 7, "chatgpt": [14, 25, 36], "chatterji": [31, 75], "chawla": [31, 75], "chaya": [31, 75], "cheaper": 7, "check": [5, 16, 26, 41, 47, 50, 51, 73, 74], "checklist": 51, "checkpoint": [31, 42, 44, 46, 47, 48, 50, 60, 72, 75], "chelsea": [31, 75], "chemistri": [11, 15], "chen": [31, 75], "cheng": [31, 75], "chengpeng": [31, 75], "chengqiang": [31, 75], "chengyuan": [31, 75], "chennabasappa": [31, 75], "chern": [31, 75], "chernoguz": [31, 75], "chess": [31, 36, 75], "chester": [31, 75], "chi": [31, 75], "child": [31, 75], "chines": 43, "ching": [31, 75], "chintala": [31, 75], "chiu": [31, 75], "chloe": [31, 75], "cho": [31, 75], "choic": [2, 11, 15, 26, 33, 46, 55, 56, 61, 65, 74, 88], "choos": [20, 29, 38, 40, 46, 61, 66, 68, 74, 83], "chose": 1, "chosen": [35, 46, 47, 53, 66], "chosen_1": 47, "chosen_2": 47, "chou": [31, 75], "choudhari": [31, 75], "choudhuri": [31, 75], "chowdhuri": [31, 75], "chri": [31, 75], "christian": [31, 75], "christoph": [31, 75], "chu": [31, 75], "chuanqi": [31, 75], "chugh": [31, 75], "chunqiu": [31, 75], "chunyang": [31, 75], "ci": 84, "cindi": [31, 75], "cite": 31, "civin": [31, 75], "ckb": [15, 31, 75, 79], "ckpt_dir": 48, "ckpt_path": 48, "cl": [14, 25], "clamp": 61, "clarifi": 35, "clariti": [44, 51], "clark": [31, 75], "class": [13, 18, 27, 43, 48, 49, 55, 86], "classif": [2, 8, 24, 36, 47, 66, 74], "classifi": [13, 38, 47, 51, 59, 68], "claud": 42, "clean": [26, 42, 46, 47, 51], "clear": [51, 60, 66, 84], "clearli": [40, 42], "clemen": [31, 75], "cleo": 13, "clever": 54, "cli": [10, 60], "client": 13, "clip": [45, 57], "clone": [10, 13], "close": [14, 25, 33, 39, 40, 42, 44, 48, 61], "closer": 65, "closest": 40, "cluster": 47, "cly": [31, 51, 75], "cnn": 3, "co": [1, 41, 48, 49, 83, 84, 87, 88], "coars": [47, 51], "cobb": [31, 75], "code": [9, 12, 13, 14, 19, 21, 22, 25, 26, 28, 31, 32, 34, 36, 38, 39, 42, 43, 44, 45, 50, 51, 68, 72, 75, 91], "code1": 13, "code2": 13, "code_alpaca_20k": [8, 24], "code_generation_lit": 13, "code_list": 13, "codealpaca": [8, 14, 21, 22, 24, 25], "codebert": 51, "codecontest": [38, 39], "codeexecut": 13, "codeforc": [13, 38, 39], "codegen": 10, "codellama": [14, 25], "codeqwen1": 51, "coder": [14, 21, 22, 25, 26, 31, 44, 50, 75, 92], "codex": [12, 21, 41], "coeffici": [5, 53, 54, 58, 84], "cognit": 72, "coher": [13, 62], "collabor": 51, "collect": [3, 5, 13, 14, 18, 25, 26, 27, 41, 43, 45, 47, 48, 51, 58, 59, 60, 61, 68, 69, 72, 79], "collin": [31, 75], "collot": [31, 75], "colon": 63, "com": [10, 13], "combin": [3, 5, 8, 14, 24, 25, 26, 39, 40, 41, 44, 46, 47, 51, 58, 59, 62, 64, 65, 72, 82, 83], "come": [1, 5, 8, 18, 24, 27, 42, 83, 84], "command": [13, 32], "commbal": 82, "comment": [41, 47, 51], "common": [3, 5, 13, 33, 40, 42, 47, 51, 53, 56, 82], "commoncrawl": 45, "commonli": [14, 25, 26], "commonmark": 31, "commun": [26, 44, 72, 91], "commut": 85, "compar": [7, 11, 26, 33, 34, 42, 44, 47, 50, 51, 55, 56, 57, 59, 67, 69, 73, 74, 89], "comparison": [5, 34, 41, 42, 43, 49, 58, 59, 61, 65, 66], "compat": [1, 41, 84, 86], "compet": [4, 47], "competit": [1, 4, 13, 15, 38, 39, 44], "competitor": 5, "compil": [42, 43, 44, 47, 72], "complementari": [44, 47], "complet": [5, 8, 12, 20, 24, 26, 29, 34, 40, 41, 44, 46, 47, 48, 51, 54, 55, 58], "complex": [2, 11, 14, 20, 25, 29, 36, 41, 47, 48, 49, 50, 51, 57, 71, 72, 83, 84, 88], "complex64": [48, 49, 84], "compli": 39, "complic": [20, 29, 36, 57], "compon": [26, 39, 46, 48, 49, 50, 66, 67, 89], "compos": [1, 15, 82], "composit": 47, "comprehens": [3, 12, 20, 29, 44, 50, 59], "compress": [43, 81], "compris": [11, 43, 44, 47, 50, 51, 56, 82], "comput": [1, 9, 11, 12, 26, 36, 39, 41, 45, 46, 48, 49, 50, 51, 56, 57, 61, 62, 64, 72, 74, 82, 83, 84, 85, 86, 88, 89, 91], "concat": 1, "concaten": [1, 18, 27, 46, 62, 73], "concept": [41, 51], "concis": [44, 50, 56], "conclud": 43, "conclus": [43, 85], "concret": [20, 29, 73], "concurr": 40, "conda": 13, "condit": [2, 18, 27, 33, 38, 59], "conduct": [39, 43, 47, 59, 62, 65, 74, 84], "conduct_rejection_sampl": 65, "confer": [31, 59, 75], "confid": [36, 61, 69], "config": [43, 82], "configur": [34, 43], "confin": 46, "conform": 47, "conjug": 88, "connect": 1, "consecut": [14, 25, 39], "consequ": [47, 59], "consid": [12, 33, 36, 47, 51, 53, 55, 56, 59, 61, 62, 65, 66, 68, 83, 84], "consider": [42, 59], "consist": [1, 2, 5, 9, 11, 14, 15, 25, 36, 41, 42, 43, 51, 53, 54, 58, 69, 72, 79, 82, 86], "console_script": 10, "consolid": 82, "constabl": [31, 75], "constant": [33, 82, 83, 88, 89], "constrain": [54, 65], "constraint": [20, 29, 40, 46], "construct": [7, 9, 20, 28, 29, 41, 42, 51, 59, 63, 65, 67, 72, 82], "consum": [1, 69], "contain": [1, 3, 5, 7, 8, 10, 11, 14, 15, 16, 18, 24, 25, 26, 27, 36, 38, 39, 40, 41, 43, 45, 46, 47, 48, 51, 63, 74, 79, 84, 85], "container": 47, "contamin": [13, 31, 75], "content": [8, 24, 26, 31, 32, 48, 59, 61], "contest": [13, 39], "context": [2, 3, 8, 18, 24, 26, 27, 33, 35, 43, 47, 53, 57, 59, 61, 62, 63, 82, 88], "context_messag": 60, "contextu": 26, "contextwindow": 44, "contigu": [2, 48, 49], "continu": [1, 5, 13, 14, 15, 25, 40, 47, 51, 53, 57, 58, 61, 65, 66], "contrast": [4, 11, 33, 40, 63, 69, 84], "contribut": [26, 66], "control": [5, 36, 48, 54, 58, 62], "convei": 59, "convent": 85, "converg": [2, 82, 86], "convers": [35, 47, 48, 61, 84], "convert": [1, 32, 62, 65], "convinc": 74, "convolut": [1, 31, 75], "cookbook": 26, "coordin": 83, "copet": [31, 75], "copi": 12, "core": [3, 7, 13, 36, 85], "corinn": [31, 75], "corpora": [26, 51], "corpu": [2, 4, 14, 25, 42, 43, 44, 51, 56, 84], "corr": 53, "correct": [16, 21, 22, 26, 31, 33, 38, 39, 40, 41, 44, 47, 50, 51, 53, 55, 59, 68, 72, 74, 75, 79], "correctli": [15, 40, 69, 73, 84], "correl": [4, 7, 53, 59, 67, 79], "correspond": [1, 5, 15, 18, 20, 26, 27, 29, 33, 39, 40, 41, 42, 44, 48, 49, 53, 54, 57, 59, 65, 84, 87, 88], "correspondingli": 57, "cosin": [1, 26, 45, 47, 92], "cost": [8, 24, 42, 44, 47, 82], "costli": 82, "cot": [11, 21, 22, 61, 62, 72], "coudert": [31, 75], "could": [34, 36, 38, 39, 47, 53, 66, 69, 84], "count": [12, 26], "counteract": [1, 47], "counterclockwis": 87, "counterpart": [46, 47], "coupl": [44, 73], "cover": [11, 40, 51, 67, 82], "coverag": [18, 27, 42, 50, 62, 69], "cpu": 48, "cr": 56, "crack": 22, "craft": 56, "crashtest": 13, "crawl": [3, 42, 51], "creat": [3, 5, 8, 13, 15, 18, 20, 24, 26, 27, 29, 36, 41, 42, 47, 50, 51, 63, 67], "creation": 40, "creativ": [36, 44], "credit": 33, "cristian": [31, 75], "criteria": [46, 47, 50, 63], "critic": [38, 42, 50, 57, 60, 73], "critic_learning_r": 60, "critiqu": [21, 22, 59], "crmsnorm": [31, 75], "cross": [35, 38, 47, 56, 62], "cross_entropi": 48, "crowd": 16, "crowdwork": 61, "crucial": [26, 42, 43, 51], "crux": 22, "cruxev": [31, 75], "cryptographi": 13, "ctj": [12, 31, 75], "ctx": 35, "cu12": 13, "cubla": 13, "cucurel": [31, 75], "cucurul": [31, 75], "cuda": [13, 48], "cudnn": 13, "cufft": 13, "cui": [31, 75], "cum": [31, 75], "cumbersom": 56, "cumsum": 48, "cumul": 48, "cup": 79, "cupti": 13, "cur_po": 48, "curand": 13, "curat": [11, 26, 38, 43, 44, 47, 51, 53, 72], "curiou": [7, 66], "current": [3, 4, 5, 8, 19, 20, 24, 26, 29, 33, 50, 56, 57, 58, 65, 68, 74, 83, 85], "curv": [35, 46], "cusolv": 13, "cuspars": 13, "custom": 5, "custom_evalu": 13, "custom_output_fil": 13, "cut": [48, 59], "cutoff_len": 92, "cycl": 47, "cynthia": [31, 75], "cyru": [31, 75], "d": [5, 10, 20, 29, 31, 32, 33, 35, 41, 46, 48, 49, 53, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 69, 73, 75, 79, 81, 82, 83, 84, 85, 87, 88, 93], "d_": [1, 5, 28, 35, 43, 46, 58, 65, 66, 85, 89], "d_c": [43, 85], "d_h": [43, 85], "d_k": 1, "d_v": 1, "dahl": [31, 75], "daili": 3, "damien": [31, 75], "damlaj": [31, 75], "damon": [31, 75], "dan": [31, 75], "dana": [31, 75], "dang": [31, 75], "danger": 61, "daniel": [31, 75], "danni": [31, 75], "dario": [31, 75], "data": [2, 3, 4, 5, 14, 20, 21, 22, 25, 29, 33, 34, 36, 41, 50, 53, 54, 56, 57, 58, 59, 61, 63, 64, 65, 67, 68, 69, 72, 73, 81, 84, 86], "dataclass": [48, 49], "datalabel": 74, "dataset": [2, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 22, 24, 25, 26, 28, 29, 36, 39, 42, 43, 44, 45, 46, 47, 50, 51, 53, 56, 57, 59, 64, 65, 66, 67, 69, 72, 73, 74, 79, 92], "date": 26, "dateutil": 13, "datta": [31, 75], "dauphin": [31, 75], "dave": [31, 75], "david": [31, 75], "davinci": [8, 24], "dawn": [31, 75], "dayiheng": [31, 75], "dclt19": [3, 31, 75], "ddot": [87, 88], "de": [31, 41, 75], "deal": 68, "debat": 43, "debias": 50, "debug": [20, 29, 47, 51], "debugg": 53, "decad": 15, "decai": [45, 84, 88], "decid": [42, 51, 67, 72, 74, 82], "decis": [33, 40, 53], "declin": [20, 29, 43], "decod": [3, 8, 14, 24, 25, 34, 38, 48, 50, 53, 62, 79], "decompos": 46, "decomposit": 93, "decoupl": [43, 44], "decreas": [11, 34, 35, 44, 54, 55, 59, 65, 82], "dedic": 82, "deduc": 73, "dedupl": [5, 26, 41, 42, 47, 79], "deem": 68, "deep": [31, 75], "deepen": [20, 29], "deepseek": [14, 21, 22, 25, 57, 82, 85, 92], "deepseekcod": [44, 92], "deepseekmath": 42, "deepseekmo": [43, 44], "deepseekv2attent": 43, "deepseekv2config": 43, "deepseekv2forcausallm": 43, "deepseekv2mlp": 43, "deepseekv2model": 43, "deepseekv2pretrainedmodel": 43, "deepseekv2rmsnorm": 43, "deepspe": 92, "def": [10, 12, 43, 48, 49, 65, 84, 86], "default": [7, 13, 32, 48, 84], "defin": [18, 26, 27, 32, 33, 35, 36, 46, 47, 48, 49, 50, 51, 54, 67, 79, 83, 84, 87, 88, 89], "definit": [28, 83], "degener": 54, "degrad": [44, 47], "degre": [4, 46], "delia": [31, 75], "deliber": 74, "delimit": 2, "deliv": 47, "delpierr": [31, 75], "delta": [33, 46, 93], "delta_": 57, "demonstr": [2, 3, 4, 5, 11, 33, 34, 44, 50, 51, 56, 58, 59, 66, 71, 72, 83, 84, 85], "deng": [31, 75], "denni": [31, 75], "denomin": 33, "denot": [28, 33, 35, 38, 41, 53, 55, 56, 65, 66, 73, 82, 85, 86, 88], "dens": [4, 47, 50, 85], "densifi": 44, "densiti": 65, "depend": [2, 4, 13, 26, 31, 35, 48, 49, 54, 56, 59, 69, 83, 84, 86, 87, 88], "depict": [3, 61, 72], "deploi": [47, 82], "deploy": 85, "depth": [20, 29], "der": [31, 75], "deriv": [33, 41, 44, 65, 67, 84], "descend": 48, "descent": 2, "describ": [1, 2, 8, 24, 40, 47, 62, 67, 83], "descript": [16, 28, 38, 39, 40, 47, 63], "design": [11, 16, 19, 26, 28, 44, 50, 55, 61, 63, 72, 74, 82, 85], "desir": [5, 33, 47, 59, 63, 65], "despit": [4, 36, 44, 58, 59], "detail": [3, 32, 39, 40, 47, 49, 50, 51, 57, 59], "detect": [18, 27, 38, 47, 50, 59], "determin": [44, 47, 50, 51, 56, 69], "determinist": [34, 44, 72], "detoken": 90, "devbal": 82, "develop": [26, 36, 41, 44, 47, 50, 61, 65, 68, 72, 73], "devi": [31, 75], "deviat": [34, 48, 54, 57, 66], "devic": [44, 48, 49, 84, 91], "devis": [14, 15, 25], "devito": [31, 75], "devlin": [31, 75], "dfag17": [31, 50, 75], "dhariw": [31, 75], "dhillon": [31, 75], "dhruv": [31, 75], "diagon": [41, 48, 49], "dialog": 48, "dialogu": [41, 46, 47], "diamond": 15, "diana": [31, 75], "dict": 48, "dictionari": [8, 24, 65], "did": [51, 62], "didem": [31, 75], "diego": [31, 75], "dieuwk": [31, 75], "differ": [1, 4, 5, 8, 9, 11, 18, 24, 27, 31, 33, 34, 36, 38, 39, 40, 41, 43, 45, 46, 47, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 74, 79, 82, 83, 85, 87, 88], "differenti": 63, "difficult": [15, 36, 40, 79], "difficulti": [11, 15, 19, 20, 26, 29, 39, 47, 51], "dill": 13, "dim": [48, 49, 84, 86], "dimens": [1, 35, 41, 43, 48, 49, 53, 55, 82, 83, 84, 85, 86, 88, 89], "dimension": [1, 53, 87, 88], "diminish": [47, 59, 79], "dinan": [31, 75], "ding": [31, 75], "dingkang": [31, 75], "direct": [4, 11, 15, 20, 29, 32, 40, 50, 51, 59, 62, 63, 64, 65, 72, 75], "directli": [2, 12, 14, 25, 34, 41, 42, 47, 54, 57, 62, 65, 73, 83, 84, 88, 90], "directori": 48, "disagr": 47, "disagre": 68, "disallowed_speci": 48, "disallowed_token": 48, "disanalogi": 36, "discard": [8, 24, 47, 51, 68], "discontinu": [20, 29], "discrep": [33, 38, 46, 66], "discret": 46, "discrimin": [2, 38], "discuss": [41, 61, 74, 88], "displai": [32, 59], "dispref": [54, 55], "disproportion": 47, "distanc": [55, 84], "distil": [14, 25, 46, 63, 69], "distinct": [43, 44, 50, 56, 59, 66, 79], "distinguish": [56, 65], "distlib": 13, "distort": 86, "distribut": [2, 4, 5, 20, 26, 29, 33, 38, 41, 44, 46, 48, 53, 54, 56, 57, 58, 61, 62, 65, 66, 68, 69, 72, 73, 74, 82], "distro": 13, "div_": 48, "diverg": [5, 46, 54, 57], "divers": [2, 3, 5, 8, 11, 18, 19, 20, 24, 26, 27, 29, 34, 38, 39, 40, 41, 44, 47, 50, 51, 67, 68, 72], "divid": [1, 38, 40, 50, 57, 87, 88], "divis": 39, "dkv": 85, "do": [4, 8, 9, 14, 18, 24, 25, 27, 31, 33, 36, 39, 40, 42, 46, 47, 48, 49, 58, 68, 72, 73, 74, 75, 83, 85], "do_train": 92, "docstr": [12, 41], "doctyp": 91, "document": [2, 3, 14, 25, 31, 32, 41, 47, 51, 84], "doe": [5, 18, 27, 41, 44, 48, 51, 54, 66, 79, 84, 85, 86], "doesn": 84, "dollar": [31, 75], "domain": [3, 11, 15, 20, 29, 33, 44, 50, 72], "domin": 33, "done": [20, 29, 51], "dong": [31, 75], "dot": [2, 33, 48, 49, 51, 55, 57, 59, 64, 67, 68, 82, 83, 84, 85, 87, 88, 90], "doubl": [40, 56, 79], "dowl": [31, 75], "down": [39, 83, 84, 86], "down_proj": 43, "downstream": [4, 47, 93], "dpo": [21, 22, 34, 47, 50, 51, 60, 65, 67, 68], "dpop": [21, 47], "dq": 85, "dr": 3, "draw": [14, 25, 65], "drawback": 72, "drawn": [50, 56], "drive": 38, "drop": [11, 44], "drop_last": 60, "dschat": 60, "dtype": [48, 49], "duan": [31, 75], "dubal": [31, 75], "dubei": [31, 75], "duc": [31, 75], "duchenn": [31, 75], "due": [26, 40, 44, 51, 53, 82, 84, 86], "dulwich": 13, "dunbar": [31, 75], "duplic": 41, "dure": [1, 2, 8, 11, 19, 24, 26, 33, 35, 38, 41, 42, 44, 46, 47, 50, 51, 54, 61, 72, 74, 79, 82, 84, 85, 86], "dustin": [31, 75], "dynam": [47, 59], "dz": 56, "e": [2, 5, 8, 9, 10, 12, 13, 14, 18, 24, 25, 27, 33, 36, 44, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 72, 73, 81, 82, 83, 84, 86], "e501": 48, "e_": 68, "e_j": 79, "each": [1, 2, 3, 5, 7, 8, 11, 12, 14, 15, 16, 18, 19, 20, 24, 25, 26, 27, 29, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 73, 74, 79, 82, 83, 84, 85, 86, 93], "earli": 61, "earlier": [5, 46, 47, 61], "easi": [7, 33, 36, 40, 41, 51, 60, 65], "easier": [2, 36, 40, 65, 84], "easili": [1, 9, 14, 25, 38], "eason": 9, "echo": [48, 79], "econom": [11, 43, 44], "ecosystem": 31, "ecut": 9, "edg": 51, "edit": [8, 16, 24, 40, 47, 55, 73], "editor": 41, "educ": [26, 51], "edunov": [31, 75], "edward": [31, 75], "ee": [21, 22], "effect": [1, 14, 19, 25, 26, 36, 40, 42, 44, 50, 55, 57, 62, 65, 66, 67, 79, 84, 87, 88], "effici": [2, 31, 39, 43, 44, 50, 57, 74, 75, 82, 85], "effort": [26, 42, 43, 44, 47, 69], "eft": 67, "egebo": [31, 75], "egor": [31, 75], "ehab": [31, 75], "eisenman": [31, 75], "eissa": [31, 75], "either": [8, 24, 39, 43, 46, 47, 59, 73, 74], "el": [31, 75], "elain": [31, 75], "electron": 91, "element": [1, 5, 41, 58, 84, 85, 87, 88], "elementari": [11, 15], "elena": [31, 75], "eleonora": [31, 75], "elev": 43, "elicit": [36, 56, 61, 62], "elimin": [20, 29], "elina": [31, 75], "elizabeth": [31, 75], "ellen": [31, 75], "elment": 48, "elo": 61, "els": [43, 48, 49, 61, 69, 84], "embed": [2, 31, 41, 43, 45, 48, 49, 50, 75, 87], "embed_token": 43, "emerg": 71, "emili": [31, 75], "emit": 55, "emphas": [3, 73], "empir": [3, 33, 36, 79, 83, 84], "emploi": [1, 5, 7, 14, 20, 25, 26, 29, 34, 41, 42, 43, 44, 47, 48, 50, 51, 53, 57, 66, 72, 82], "empow": [20, 29, 31, 75], "empti": [8, 24, 82], "emptyset": 69, "enabl": [4, 15, 40, 41, 44, 59, 72, 82, 83, 84, 87, 88], "encod": [2, 3, 18, 27, 38, 41, 43, 45, 48, 50, 83, 84, 87, 88, 91], "encode_dialog_prompt": 48, "encode_head": 48, "encode_messag": 48, "encoding_for_model": 48, "encompass": 42, "encount": [1, 47, 82], "encourag": [3, 18, 27, 33, 36, 39, 47, 63], "end": [1, 2, 5, 7, 8, 14, 18, 24, 25, 27, 35, 39, 41, 44, 46, 48, 49, 54, 55, 57, 58, 61, 62, 63, 65, 69, 73, 74, 82, 83, 84, 85, 87, 88, 89], "end_header_id": 48, "end_of_text": 48, "enforc": [72, 84], "engin": [11, 26, 51, 60], "english": [8, 24, 43, 47], "enhanc": [11, 14, 25, 26, 28, 31, 34, 43, 44, 50, 51, 66, 75], "enlarg": 79, "enlighten": [14, 25], "enlist": 44, "enough": [4, 9, 36, 43, 46, 55, 65, 85], "ensembl": [34, 66], "ensur": [1, 5, 9, 15, 16, 19, 20, 29, 38, 44, 46, 47, 50, 51, 55, 69, 74, 82, 86], "entail": 2, "entir": [45, 73, 74, 86], "entri": [14, 16, 25, 26, 41, 48, 49], "entropi": [35, 38, 47, 56, 62], "entry_point": 10, "enumer": [48, 49, 84], "env": 13, "environ": [5, 13, 33, 47, 51, 58], "eo": 48, "eos_id": 48, "eos_idx": 48, "eos_reach": 48, "eot_id": 48, "ep": [48, 49, 86], "episod": [5, 58, 60], "epoch": [20, 26, 29, 43, 45, 46, 56, 58, 60, 72, 74], "epsilon": [48, 49, 57, 86], "equal": [33, 45, 83, 85, 87], "equat": [65, 73, 79, 88], "equip": [73, 85, 91], "equival": [3, 31, 38, 40, 63, 65, 75, 82], "eric": [31, 75], "erik": [31, 75], "ermon": [31, 75], "error": [18, 27, 36, 40, 47, 48, 51, 57, 89], "esiobu": [31, 75], "especi": [18, 27, 79, 86], "essenti": [38, 40, 59], "est": 81, "establish": [44, 65], "estat": 81, "esteban": [31, 75], "estim": [12, 33, 35, 39, 46, 54, 57, 65, 81], "estrang": 81, "etc": [8, 18, 24, 27, 43], "ethic": [11, 61], "eval": [7, 9, 21, 22, 56], "eval_step": 60, "evalperf": 10, "evalplu": [14, 22, 25], "evalu": [7, 8, 11, 12, 19, 24, 31, 33, 35, 36, 42, 46, 61, 64, 66, 67, 72, 73, 74, 75, 79, 85], "evan": [31, 75], "evas": 61, "even": [4, 20, 29, 33, 36, 44, 47, 51, 54, 55, 65, 84, 85, 87, 88], "evenli": 39, "event": [5, 56, 57], "everi": [1, 4, 15, 18, 27, 62, 83, 86], "evid": [36, 84], "evol": [14, 25, 26], "evolut": [20, 29], "evolutionari": [20, 29], "evolv": [20, 29], "evtimov": [31, 75], "exact": [15, 41], "exactli": 33, "exam": 11, "exampl": [4, 5, 8, 12, 14, 18, 24, 25, 26, 27, 31, 33, 36, 38, 40, 41, 43, 46, 47, 50, 53, 54, 55, 59, 61, 62, 63, 66, 67, 68, 69, 72, 83, 84, 86], "exce": [8, 24, 34, 48], "exceed": [83, 84], "excel": 44, "except": [4, 20, 29, 34, 43, 44, 47, 48, 55, 85], "exceptiongroup": 13, "excess": 44, "exclus": [11, 45, 74], "execut": [9, 13, 26, 31, 32, 38, 39, 41, 47, 50, 51, 75, 84], "executor": 51, "exemplar": [62, 71], "exemplifi": 63, "exhibit": [43, 59, 72, 73], "exist": [11, 12, 14, 18, 25, 27, 38, 47, 51, 68, 83, 84, 90], "exp": [5, 48, 49, 53, 54, 65, 88, 89], "expand": [44, 50], "expans": 84, "expbal": 82, "expect": [5, 18, 27, 33, 39, 44, 47, 51, 57, 59, 61, 79, 84], "expens": [36, 41, 54, 69], "experi": [1, 2, 5, 15, 20, 29, 43, 46, 47, 54, 56, 58, 60, 61, 62, 66, 74], "experience_mak": 60, "experiment": [11, 26], "expert": [15, 31, 43, 44, 47, 51, 75], "expert1": 82, "expert2": 82, "expert3": 82, "expertis": 47, "explain": [40, 47, 51, 53, 62], "explan": [47, 62], "explicit": [3, 44, 83, 84, 87, 88], "explicitli": [8, 24, 46, 47, 61, 63, 73], "exploit": 4, "explor": [40, 46, 57, 59, 71, 72], "exponenti": 84, "export": 13, "express": [4, 12, 54, 56], "extend": [22, 41, 43, 44, 47, 48, 50, 60, 69, 72], "extens": [13, 31, 40, 50, 59, 84], "extern": [26, 72], "extra": [2, 9, 40, 83, 84], "extract": [14, 25, 47, 53, 62], "extractor": 53, "extrapol": [1, 83], "extrem": [1, 15, 33, 36, 44], "f": [10, 48, 49, 81, 83, 84, 89], "f_": [53, 69, 82, 87, 88], "face": [66, 72], "facilit": [1, 38, 59], "fact": 84, "factor": [1, 35, 51, 53, 82, 83, 84, 89], "factual": [47, 50, 72], "fail": [40, 47, 50, 51], "failur": [36, 47, 51], "fair": 85, "faith": 47, "faithfulli": [36, 59], "fake": 59, "fals": [43, 48, 49, 86], "famili": [36, 39, 41, 84], "fan": [31, 75], "fanjia": [31, 75], "far": [47, 56], "fashion": [18, 27, 73], "fast": 48, "fastavro": 13, "faster": 7, "fastjsonschema": 13, "faulti": 47, "favor": 53, "featur": [36, 41, 48, 53, 60, 86], "februari": 51, "fed": [2, 51], "federico": [31, 75], "feed": [35, 48, 49, 50, 82, 89], "feed_forward": [48, 49], "feedback": [5, 36, 41, 42, 43, 44, 47, 50, 51, 54, 56, 59, 65, 67, 69, 72, 74], "feedforward": 2, "fei": [31, 75], "feichtenhof": [31, 75], "feinstein": [31, 75], "felip": [31, 75], "felix": [31, 75], "feng": [31, 75], "fernand": [31, 75], "ferrer": [31, 75], "few": [3, 4, 5, 11, 18, 27, 31, 38, 39, 41, 61, 62, 67, 69, 71, 74, 75], "fewer": [40, 43, 83, 84], "ff": [35, 89], "ffff": 91, "ffff\u7684\u8303\u56f4": 91, "ffn": [1, 43, 44, 48, 49, 50, 82], "ffn_norm": [48, 49], "fiction": 3, "field": [8, 15, 18, 19, 24, 27, 51], "fifo": 56, "figur": [1, 35, 42, 44, 46, 56, 59, 61, 72, 79], "file": [8, 13, 24, 26, 32, 41, 48, 51], "filelock": 13, "filip": [31, 75], "filippo": [31, 75], "fill": [41, 44, 46], "filter": [5, 9, 14, 25, 26, 42, 43, 47, 50, 51, 68, 69, 74, 79], "fim": [44, 51], "final": [1, 2, 3, 5, 15, 18, 20, 27, 28, 29, 33, 39, 42, 43, 44, 45, 46, 47, 51, 53, 54, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 72, 74, 82], "find": [8, 11, 24, 34, 35, 36, 38, 39, 43, 46, 47, 58, 61, 62, 65, 67, 72, 73, 74, 79, 85], "fine": [4, 5, 8, 19, 20, 24, 26, 29, 31, 47, 51, 54, 57, 59, 63, 64, 65, 67, 73, 74, 75, 79, 83, 84], "finer": 82, "finest": 81, "finetun": [4, 14, 20, 25, 29, 36, 50, 61, 69, 74], "finetuning_typ": 92, "finn": [31, 75], "firat": [31, 75], "fire": 10, "first": [1, 2, 3, 5, 9, 14, 18, 25, 26, 27, 33, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 51, 54, 55, 56, 58, 59, 60, 62, 65, 66, 67, 68, 72, 73, 74, 79, 82, 85, 88, 89], "first_k_dense_replac": 43, "firstli": 40, "fit": [35, 56, 60, 65, 84], "five": [20, 29, 51], "fix": [1, 5, 35, 40, 47, 56, 58, 74, 83, 86], "flag": 48, "flagopen": 19, "flash": [21, 22], "flash_attn": 60, "flatten": [48, 49, 84], "flavor": 31, "flaw": 51, "flexibl": 82, "flexibli": 82, "flip": [59, 73], "float": [48, 49, 65, 84, 86], "float32": [48, 49], "florez": [31, 75], "fluenci": 33, "focu": [8, 24, 26, 33, 45, 50, 56, 74], "focus": [7, 11, 13, 19, 26, 42, 44, 50, 59, 72], "follow": [1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 15, 20, 24, 25, 29, 31, 32, 41, 42, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 61, 62, 63, 65, 66, 68, 72, 75, 82, 83, 84, 85], "fool": 74, "foral": 2, "forc": [15, 38, 40, 73], "forgo": 56, "form": [1, 20, 29, 39, 41, 44, 54, 56, 63, 67, 74, 83, 84], "formal": 57, "format": [13, 15, 18, 20, 27, 29, 41, 44, 61, 72], "formatt": 48, "formul": [33, 54, 66, 82], "fortun": 54, "forum": [31, 75], "forward": [35, 48, 49, 50, 82, 83, 86, 89, 93], "foss": [31, 75], "fotio": [31, 75], "found": [1, 2, 5, 11, 18, 27, 38, 39, 40, 46, 51, 61, 83, 84], "foundat": [14, 20, 25, 29, 31, 41, 45, 47, 51, 75], "four": [3, 11, 20, 29, 41, 46, 47, 66, 72, 85], "fowler": [31, 75], "frac": [1, 5, 12, 33, 35, 48, 49, 53, 54, 55, 57, 58, 59, 65, 66, 82, 83, 84, 85, 86, 87, 88, 89, 90], "fraction": 12, "framework": [10, 18, 27, 43, 44, 50, 51, 59], "francesco": [31, 75], "francisco": [31, 75], "franco": [31, 75], "frank": [31, 75], "free": [13, 31, 44, 51, 68, 75], "freez": [53, 93], "freq": [48, 49, 84], "freqs_ci": [48, 49, 84], "frequenc": [1, 41, 82, 84, 87, 88], "frequent": [83, 84], "fresh": 74, "friendli": 61, "from": [1, 3, 4, 5, 7, 8, 10, 11, 12, 13, 15, 18, 20, 21, 24, 26, 27, 28, 29, 31, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 79, 82, 83, 84, 85, 86, 88, 90, 91], "frontier": 15, "frozenlist": 13, "fsfairx": 34, "fsspec": 13, "fu": [31, 75], "fulfil": 59, "full": [36, 40, 41, 42, 44, 48, 49, 60, 92], "fuller": [31, 75], "fulli": [1, 8, 24, 28, 36, 44, 51], "function": [1, 4, 5, 9, 16, 31, 33, 36, 40, 41, 45, 46, 50, 51, 54, 55, 56, 57, 58, 59, 65, 66, 73, 83, 84, 86, 87, 88, 89], "fundament": [4, 36], "further": [8, 14, 24, 25, 26, 34, 39, 41, 42, 43, 46, 47, 50, 51, 56, 57, 69, 82, 84, 88], "furthermor": [44, 61], "futur": [36, 43, 44], "g": [13, 14, 18, 25, 27, 44, 46, 47, 51, 53, 57, 62, 63, 65, 68, 72, 73, 83, 87, 88], "g_": [44, 53, 82], "gabriel": [31, 75], "gabriela": [31, 75], "gabriella": [31, 75], "gada": [31, 75], "gae": 57, "gain": [2, 4, 14, 25, 40, 46, 51, 59, 62], "gamido": [31, 75], "gamma": [5, 33, 44, 48, 49, 57, 58, 59, 83, 86], "ganapathi": [31, 75], "gangidi": [31, 75], "gao": [31, 75], "gap": [11, 14, 25, 33, 34, 36, 47, 51, 64], "garcia": [31, 75], "garg": [31, 75], "gat": [31, 75], "gate": [31, 44, 53, 75, 82], "gate_proj": 43, "gather": [46, 48, 50], "gating_dim": 82, "gaur": [31, 75], "gaussian": 89, "gave": [8, 24], "gaya": [31, 75], "gb2312\u56e0\u4e3a\u53ea\u8868\u793a\u666e\u901a\u6570\u5b57": 91, "gbk\u662fascii": 91, "gdj": [31, 47, 75], "ge": [12, 18, 27, 31, 53, 55, 57, 65, 75], "geboski": [31, 75], "geffert": [31, 75], "geglu": 89, "gelu": 89, "gemini": [39, 42, 56], "gen": 48, "gener": [1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 19, 20, 24, 25, 26, 28, 29, 31, 33, 38, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 54, 55, 56, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 75, 79, 83, 85], "generate_kwarg": 60, "generate_max_len": 60, "generation_logprob": 48, "generation_token": 48, "generativeai": 13, "generativelanguag": 13, "geometr": [1, 88], "geometri": 47, "georgia": [31, 75], "georgiou": [31, 75], "get": [15, 31, 32, 33, 41, 51, 53, 65], "get_unique_el": 41, "gg": 35, "gibb": 54, "gibberish": 33, "gil": [31, 75], "ginsburg": [31, 75], "girdhar": [31, 75], "girish": [31, 75], "git": [10, 13], "github": [8, 10, 13, 19, 24, 26, 38, 42, 45, 48, 49, 50, 51], "give": [2, 67, 68, 84], "given": [1, 2, 5, 8, 18, 20, 24, 27, 29, 33, 35, 36, 38, 40, 41, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 62, 63, 65, 67, 68, 69, 73, 74, 79, 83, 84], "glaser": [31, 75], "glob": 48, "glu": [48, 49], "go": 60, "goal": [2, 40, 51, 54, 65, 68, 73], "gold": [21, 38, 39], "goldman": [31, 75], "goldschlag": [31, 75], "goldstand": [31, 75], "gomez": [31, 75], "gonguet": [31, 75], "good": [9, 21, 33, 36, 38, 44, 47, 57, 65, 68], "googl": [10, 13], "googleapi": 13, "google\u7684bert\u6a21\u578b\u5728\u5206\u8bcd\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662fwordpiece\u7b97\u6cd5": 90, "goswami": [31, 75], "govind": [31, 75], "govindaprasad": [31, 75], "goyal": [31, 75], "gpt": [3, 4, 5, 7, 8, 14, 15, 21, 22, 24, 25, 31, 36, 47, 48, 67, 74, 75, 79], "gpt2": 21, "gpt3": 21, "gpt4": 42, "gpu": [44, 92], "gqa": [31, 50, 75], "grade": 15, "gradient": [1, 2, 5, 45, 55, 56, 58], "gradient_accumulation_step": 92, "gradient_checkpoint": 60, "gradual": 41, "graem": [31, 75], "grai": [31, 75], "grain": [19, 47, 59], "gram": [26, 51], "grammar": [18, 27], "grammat": [18, 27], "grangier": [31, 75], "grant": [31, 75], "granular": 11, "graphic": 15, "grattafiori": [31, 75], "great": 48, "greater": 11, "greatli": [4, 93], "greedi": [3, 10, 14, 25, 34, 47, 48, 79], "greg": [31, 75], "gregerson": [31, 75], "gregoir": [31, 75], "gretchen": [31, 75], "grid": 84, "grigori": [31, 75], "grl": [9, 31, 75], "groshev": [31, 75], "ground": [16, 36, 42, 43, 44, 51, 54, 65, 68], "group": [38, 39, 42, 43, 44, 48, 50, 51, 66, 72, 82, 85], "grow": [1, 4, 56], "grpcio": 13, "grpo": [21, 22, 42, 50], "gsm8k": [21, 34, 51, 79], "gu": [31, 75], "guan": [31, 75], "guangyi": [31, 75], "guant": [31, 75], "guarante": [12, 55, 57, 82], "guess": 11, "guid": [18, 27, 34, 65, 66, 72], "guillem": [31, 75], "guna": [31, 75], "guo": [31, 75], "gupta": [31, 75], "gururangan": [31, 75], "guss": [31, 75], "guzm\u00e1n": [31, 75], "h": [1, 43, 46, 48, 49, 82, 83, 85, 93], "h06a4308_0": 13, "h11": 13, "h1181459_1": 13, "h1234567_1": 13, "h39e8969_0": 13, "h5eee18b_0": 13, "h5eee18b_1": 13, "h5eee18b_6": 13, "h6a678d5_0": 13, "h6a678d5_1": 13, "h800": 44, "h955ad1f_1": 13, "h_": [2, 84], "h_j": 84, "h_n": 2, "ha": [1, 3, 4, 5, 7, 15, 18, 27, 33, 36, 42, 43, 46, 47, 48, 49, 50, 56, 57, 66, 69, 73, 79, 83, 85, 89], "habeeb": [31, 75], "hack": [44, 46, 53, 61, 72], "had": [5, 16, 38], "hahn": [31, 75], "hailei": [31, 75], "hakan": [31, 75], "half": [36, 38, 41], "hallucin": 51, "hallucinatori": 43, "halpern": [31, 75], "halv": 1, "ham": 55, "hamid": [31, 75], "han": [31, 75], "hancock": [31, 75], "hand": [12, 16, 35, 36, 44, 56], "handl": [2, 51], "handwritten": 12, "hannah": [31, 75], "hanq": [31, 75], "hanwen": [31, 75], "hao": [31, 75], "haoran": [31, 75], "happen": 84, "har": 44, "hard": [39, 40, 54, 63, 85], "harder": 39, "harm": [61, 63], "harmless": [50, 62, 63, 67], "haroun": [31, 75], "harri": [31, 75], "harrison": [31, 75], "hart": [31, 75], "hartshorn": [31, 75], "hassan": [31, 75], "hasson": [31, 75], "hat": [33, 54, 57, 66, 73], "have": [1, 2, 3, 12, 14, 15, 18, 25, 27, 32, 33, 35, 36, 39, 40, 42, 44, 46, 47, 50, 53, 54, 55, 61, 65, 66, 67, 68, 79, 82, 83, 84, 86, 89], "hbb": [11, 31, 75], "hd_": 1, "he": [31, 75], "head": [2, 31, 35, 43, 44, 48, 49, 67, 75, 83, 84, 91], "head_dim": [48, 49], "heafield": [31, 75], "health": 11, "heart": 68, "heavi": [35, 73, 85], "hebgen": [31, 75], "heewoo": [31, 75], "heidi": [31, 75], "height": 48, "held": 4, "helen": [31, 75], "help": [2, 5, 15, 31, 40, 41, 43, 44, 46, 47, 50, 51, 53, 56, 58, 61, 63, 67, 83], "helpfulli": 58, "helpsteer2": 21, "henc": [42, 54, 67], "hendryck": [31, 75], "henighan": [31, 75], "henri": [31, 75], "henriqu": [31, 75], "herbert": [31, 75], "herd": [31, 47, 75], "here": [1, 4, 8, 20, 24, 29, 31, 33, 35, 45, 46, 47, 79, 83, 84], "herman": [31, 75], "hermoso": [31, 75], "hess": [31, 75], "heurist": [5, 14, 15, 18, 25, 27], "hf": 65, "hh": 61, "hidden": [43, 48, 49, 53, 82, 83, 89], "hidden_dim": [48, 49], "hidden_s": [43, 82], "high": [2, 12, 14, 15, 25, 26, 33, 34, 38, 44, 46, 47, 50, 51, 53, 55, 56, 66, 67, 68, 69, 73, 81, 87, 88], "highconfid": 69, "higher": [19, 34, 39, 40, 44, 47, 50, 51, 56, 59, 66, 82, 83], "highest": [7, 8, 15, 20, 24, 29, 34, 44, 47, 56, 66, 67, 81, 82, 87], "highli": [15, 36, 51, 53, 68, 69, 74], "highlight": [26, 47], "highqual": 44, "hilton": [31, 75], "hinder": 66, "hing": 54, "hinsvark": [31, 75], "histor": 57, "histori": [11, 33], "ho": [31, 75], "hoc": 62, "hogan": [31, 75], "hold": [35, 74], "holdgraf_evidence_2014": 31, "holist": [13, 31, 75], "holland": [31, 75], "home": 13, "honesti": 53, "hong": [31, 75], "hongcheng": [31, 75], "hongyi": [31, 75], "hongyuan": [31, 75], "hood": [14, 25], "hook": 13, "hope": 15, "hosseini": [31, 75], "hotfix": 13, "hou": [31, 75], "hour": 44, "hous": 42, "how": [5, 7, 11, 15, 31, 32, 33, 36, 39, 47, 51, 53, 54, 57, 62, 63, 71, 72, 74, 75, 79, 84], "howev": [12, 18, 27, 33, 34, 36, 43, 46, 47, 53, 54, 58, 59, 63, 65, 66, 82, 83, 84, 86, 88], "hsiang": [31, 75], "hstack": [48, 49], "html": 91, "http": [10, 13, 14, 18, 20, 25, 27, 29, 31, 75], "httpcore": 13, "httplib2": 13, "httpx": 13, "hu": [31, 75], "huan": [31, 75], "huang": [31, 75], "hub": 13, "huge": [40, 84], "huggingfac": [13, 60], "hugh": [31, 75], "hugo": [31, 75], "hui": [31, 75], "human": [4, 5, 7, 9, 11, 15, 16, 18, 20, 27, 29, 33, 36, 41, 43, 44, 47, 50, 51, 54, 56, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 72, 74], "humanev": [20, 22, 26, 29, 34, 51], "humanevalplu": 10, "humanevalplus_releas": 10, "hundr": [44, 84], "hunt": [31, 75], "hunter": [31, 75], "hupk": [31, 75], "hurt": 51, "hybridengin": 60, "hyc": [31, 51, 75], "hyper": [44, 45, 48, 49, 50, 57, 59], "hyperparamet": [35, 39, 50, 55, 56, 59], "hypothes": 1, "hypothesi": 4, "i": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 72, 74, 75, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91], "i_": [18, 27], "i_t": [18, 27], "ibarra": [31, 75], "ibrahim": [31, 75], "icl": 79, "id": [5, 31, 48, 75], "id1": 13, "id2": 13, "idea": [59, 69, 83, 84], "ideal": [8, 11, 24, 84], "ident": [1, 50, 54, 56, 68, 74, 82], "identif": [47, 51], "identifi": [5, 7, 11, 18, 27, 34, 47, 50, 51, 56, 59, 61, 63, 66, 69], "idna": 13, "ifev": 43, "ift": 67, "ignor": [33, 38, 48, 84], "ignore_index": 48, "igor": [31, 75], "ij": 79, "ik_": [48, 49, 83, 84], "ilia": [31, 75], "iliyan": [31, 75], "illeg": 61, "illia": [31, 75], "illustr": [36, 42, 44, 46, 48, 49, 72], "ilya": [31, 75], "im": [48, 49, 83, 84], "imag": 35, "imaginari": [83, 84], "imanol": [31, 75], "imbal": [44, 82], "imit": 36, "impact": [26, 34, 39, 51, 74, 83], "imper": [8, 24], "imperfect": 69, "implement": [5, 12, 20, 29, 43, 44, 45, 50, 51, 69], "implicit": 54, "implicitli": [36, 54, 73], "import": [10, 12, 26, 33, 36, 46, 48, 49, 54, 65, 67, 68, 84, 86], "importantli": [51, 54, 85], "importlib": 13, "impress": 51, "improv": [2, 4, 14, 25, 28, 31, 33, 36, 38, 40, 41, 43, 44, 45, 46, 47, 48, 50, 51, 55, 57, 62, 66, 67, 68, 69, 71, 72, 73, 74, 75, 79, 86], "inan": [31, 75], "inappropri": 59, "incentiv": 73, "includ": [2, 8, 11, 12, 15, 19, 20, 24, 26, 29, 32, 34, 35, 36, 38, 39, 41, 43, 44, 46, 47, 48, 50, 51, 54, 61, 64, 65, 83, 84, 86, 92], "inclus": 51, "incorpor": [1, 26, 44, 46, 47, 50, 57, 87, 88], "incorrect": [38, 40, 47, 66, 69, 73, 74], "incorrectli": [15, 54], "increas": [11, 14, 20, 25, 26, 29, 39, 41, 44, 47, 54, 55, 59, 79, 82, 84, 88], "increasingli": 72, "increment": 83, "inde": 59, "indent": 51, "independ": [18, 27, 41, 86, 90], "index": [48, 49, 56, 57, 83, 84, 85], "indic": [5, 11, 39, 48, 53, 56, 59, 63, 79, 83, 84, 85, 87], "individu": [35, 86, 87, 88], "induc": [3, 44, 65], "inequ": 54, "inf": [48, 49], "infer": [8, 24, 26, 33, 41, 43, 44, 45, 47, 48, 59, 60, 62, 65, 68, 82, 84, 85, 86], "inference_mod": [48, 49], "infin": 26, "inflat": 51, "influenc": 79, "infomax": 56, "inform": [1, 5, 8, 15, 24, 26, 31, 32, 38, 46, 47, 50, 57, 66, 75, 82, 84, 87, 88, 91], "infrastructur": 84, "infti": 35, "inher": [2, 5], "inherit": 53, "init": 32, "init_kl_coef": 60, "initi": [5, 14, 18, 20, 25, 27, 29, 40, 41, 43, 46, 47, 48, 54, 56, 58, 61, 63, 69, 72], "inject": [1, 83, 84, 93], "inlin": [31, 54], "inner": [87, 88], "innov": [43, 85], "input": [1, 5, 8, 9, 14, 18, 20, 24, 25, 27, 29, 31, 38, 39, 40, 41, 45, 46, 48, 49, 51, 55, 56, 58, 59, 62, 65, 68, 83, 84, 85, 86, 87, 88, 89, 90], "input_kei": 60, "input_text_mask": 48, "inputgen": 10, "inputoutput": 40, "insert": [1, 31, 38, 48, 56], "insid": 57, "insight": 54, "inspect": 16, "inspir": [14, 25], "inst": 41, "instabl": [12, 86], "instag": 47, "instal": 10, "instanc": [2, 8, 24, 43, 44, 48, 53, 61, 72], "instead": [1, 3, 5, 8, 12, 20, 24, 29, 36, 39, 41, 45, 48, 49, 56, 57, 59, 61, 69, 83, 84, 86, 88], "instruciton": [8, 24], "instruct": [4, 5, 7, 8, 21, 22, 24, 31, 32, 34, 36, 42, 43, 46, 47, 53, 59, 61, 62, 66, 72, 73, 75], "instructgpt": 58, "instruction_prefix": 10, "instructionfollow": 67, "int": [43, 48, 49, 65, 84, 86], "int_": 56, "integ": 48, "integr": [11, 44, 50, 51], "intens": [43, 47, 51], "intent": [5, 47, 66], "intention": 59, "interact": [33, 47, 48, 49, 56, 59, 86], "interc": [53, 82, 83, 84, 85, 87], "interchang": 91, "interdepend": 86, "interest": [36, 47, 65], "interesting": 33, "interestingli": 51, "interfac": 5, "interfer": 86, "interleav": 73, "interlm2": 21, "intermedi": [28, 35, 36, 42, 43, 44, 71, 72, 74, 82], "intermediate_s": 43, "intern": [36, 44, 47], "internet": 58, "interpol": 41, "interpret": [5, 26, 46, 57], "interv": 79, "interview": 41, "intric": 50, "intrigu": 72, "intrins": 72, "introduc": [7, 11, 14, 15, 18, 25, 26, 27, 28, 33, 39, 44, 47, 48, 50, 51, 57, 62, 65, 72, 82, 83, 84, 86], "introduct": 62, "intuit": [33, 36, 54, 88], "invas": 61, "invest": [43, 56, 83, 84], "investig": [44, 59, 74, 79], "involv": [8, 15, 24, 35, 44, 47, 82], "ion": [31, 75], "ionescu": [31, 75], "ip": 62, "ipo": 54, "ipynb": 31, "iq_": [48, 49, 83, 84], "irina": [31, 75], "irrelev": 26, "is_safeti": 46, "isabel": [31, 75], "ise": 10, "ishan": [31, 75], "isin": 48, "isol": 51, "issu": [3, 42, 44, 47, 53, 61, 62, 72, 73, 82, 84, 86], "itai": [31, 75], "item": [60, 65], "iter": [5, 18, 20, 27, 29, 40, 48, 50, 56, 58, 59, 65, 66, 67, 73], "itertool": 13, "its": [4, 14, 16, 18, 25, 27, 36, 38, 39, 41, 43, 44, 47, 48, 49, 50, 51, 53, 54, 56, 59, 61, 65, 67, 72, 73, 74, 79, 82, 83, 84, 85, 86, 88, 89], "itself": [18, 27, 42, 67, 73], "ivan": [31, 75], "ivanov": [31, 75], "ix_": [48, 49, 83, 84], "iyer": [31, 75], "j": [33, 44, 48, 49, 55, 57, 59, 68, 82, 83, 84, 85, 88], "j_": [57, 68], "j_1": 59, "j_q": 59, "jack": [31, 75], "jacob": [31, 75], "jade": [31, 75], "jaewon": [31, 75], "jagadeesh": [31, 75], "jai": [31, 75], "jain": [31, 75], "jake": [31, 75], "jakob": [31, 75], "jame": [31, 75], "jamil": [31, 75], "jan": [31, 75], "jana": [31, 75], "janic": [31, 75], "japhet": [31, 75], "jaraco": 13, "jare": [31, 75], "jason": [31, 75], "jauhri": [31, 75], "java": 51, "javascript": 51, "jayesh": [31, 75], "jean": [31, 75], "jeepnei": 13, "jeet": [31, 75], "jeff": [31, 75], "jeffrei": [31, 75], "jelmer": [31, 75], "jenkin": [31, 75], "jenni": [31, 75], "jennif": [31, 75], "jenya": [31, 75], "jeremi": [31, 75], "jerri": [31, 75], "jessica": [31, 75], "jgzp23": [31, 50, 75], "jhg": [13, 31, 75], "ji": [31, 75], "jia": [31, 75], "jiaheng": [31, 75], "jiajun": [31, 75], "jian": [31, 75], "jianfeng": [31, 75], "jiang": [31, 75], "jianhong": [31, 75], "jianlin": [31, 75], "jianwei": [31, 75], "jianxin": [31, 75], "jianyu": [31, 75], "jiaqi": [31, 75], "jiatao": [31, 75], "jiawei": [31, 75], "jiawen": [31, 75], "jiaxi": [31, 75], "jie": [31, 75], "jiecao": [31, 75], "jin": [31, 75], "jingren": [31, 75], "jingyi": [31, 75], "jinja2": 13, "jinz": [31, 75], "jmespath": 13, "joanna": [31, 75], "joblib": 13, "joe": [31, 75], "john": [31, 75], "johnstun": [31, 75], "jointli": 1, "jon": [31, 75], "jonathan": [31, 75], "jone": [31, 75], "jong": [31, 75], "jongsoo": [31, 75], "joseph": [31, 75], "josh": [31, 75], "joshua": [31, 75], "journal": [31, 75], "json": [8, 24, 43, 48, 92], "jsonl": 10, "jsonlin": 13, "jubert": [31, 75], "jude": [31, 75], "judg": [7, 22, 39, 40, 47, 59, 67, 68], "judgement": 59, "judgment": [33, 51], "jun": [31, 75], "junji": [31, 75], "junteng": [31, 75], "junyang": [31, 75], "jupyt": [31, 32], "jupyterbook": 31, "jupytext": 32, "just": [11, 13, 31], "k": [1, 2, 3, 5, 12, 15, 20, 29, 38, 44, 46, 47, 48, 49, 53, 55, 56, 58, 64, 79, 82, 83, 84, 85, 87, 88, 93], "k_": [44, 48, 49, 57, 82, 83, 84], "k_1": 57, "k_i": 57, "k_r": [44, 82], "kadian": [31, 75], "kai": [31, 75], "kaiser": [31, 75], "kalinli": [31, 75], "kallet": [31, 75], "kalyan": [31, 75], "kam": [31, 75], "kambadur": [31, 75], "kanayet": [31, 75], "kaplan": [31, 75], "karan": [31, 75], "karda": [31, 75], "karl": [31, 75], "karma": 3, "karn": [31, 75], "karthik": [31, 75], "kartikai": [31, 75], "kartikeya": [31, 75], "katayoun": [31, 75], "kate": [31, 75], "kathi": [31, 75], "kati": [31, 75], "kaushik": [31, 75], "ke": [31, 75], "keep": [39, 43, 44, 46, 47, 51, 73, 82, 89], "keepdim": [48, 49, 86], "keho": [31, 75], "kei": [1, 15, 26, 36, 39, 40, 41, 43, 44, 47, 48, 49, 50, 51, 59, 65, 79, 83, 84, 86, 87, 88], "keller": [31, 75], "kelli": [31, 75], "kelsei": [31, 75], "keme": [31, 75], "keneal": [31, 75], "kenneth": [31, 75], "kent": [31, 75], "kenton": [31, 75], "keqian": [31, 75], "keqin": [31, 75], "kerkez": [31, 75], "kernel": 32, "kevin": [31, 75], "kexin": [31, 75], "keyr": 13, "keyword": 7, "khabsa": [31, 75], "khalid": [31, 75], "khandelw": [31, 75], "khlaaf": [31, 75], "kim": [31, 75], "kind": [5, 31, 59], "king": [31, 75], "kiran": [31, 75], "kl": [5, 46, 54, 57, 58, 65], "kleinman": [31, 75], "kloumann": [31, 75], "kmh": [4, 31, 75], "knew": 33, "knight": [31, 75], "know": [33, 36, 79], "knowledg": [11, 14, 25, 26, 40, 46, 82, 87, 88], "known": [33, 48, 49, 66, 84], "koehler": [31, 75], "kohli": [31, 75], "kokkino": [31, 75], "korenev": [31, 75], "korevaar": [31, 75], "kosaraju": [31, 75], "koura": [31, 75], "koushik": [31, 75], "kr": 85, "kreuk": [31, 75], "kreymer": [31, 75], "krishnan": [31, 75], "kristina": [31, 75], "krithika": [31, 75], "krueger": [31, 75], "kshitiz": [31, 75], "kto": [21, 34], "kuan": [31, 75], "kuenlei": [31, 75], "kumar": [31, 75], "kun": [31, 75], "kunal": [31, 75], "kushal": [31, 75], "kv": [43, 50], "kv_a_layernorm": 43, "kv_a_proj_with_mqa": 43, "kv_b_proj": 43, "kv_lora_rank": 43, "kw_": 1, "kyle": [31, 75], "kyunghyun": [31, 75], "l": [2, 5, 18, 27, 28, 31, 33, 35, 46, 48, 49, 54, 55, 56, 57, 58, 65, 66, 67, 68, 69, 73, 75, 81, 82, 83, 84, 85, 86], "l_": [2, 54, 59, 66], "l_1": 59, "l_2": 59, "label": [2, 4, 5, 18, 19, 27, 36, 42, 43, 46, 47, 50, 58, 61, 63, 65, 68, 69, 74, 79], "labor": 51, "lachaux": [31, 75], "lack": 65, "lailin": [31, 75], "lakhotia": [31, 75], "lakomkin": [31, 75], "lakshminarayanan": [31, 75], "lakshya": [31, 75], "lam": [31, 75], "lambda": [2, 55, 56, 57, 59, 83, 84], "lambda_": [53, 83], "land": 61, "landzaat": [31, 75], "langl": [48, 49, 83, 84, 88], "languag": [2, 3, 4, 5, 7, 8, 11, 12, 15, 18, 24, 26, 27, 30, 31, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 51, 54, 56, 58, 69, 72, 74, 75, 82, 87, 88], "laptev": [31, 75], "larg": [1, 2, 3, 4, 5, 7, 9, 12, 18, 26, 27, 30, 31, 33, 36, 39, 43, 44, 46, 47, 48, 49, 51, 54, 55, 56, 58, 69, 72, 75, 82, 85, 88], "larger": [3, 19, 46, 47, 74, 84, 88], "largest": [3, 19, 38, 39, 45, 46, 47], "last": [1, 4, 38, 47, 48, 53, 57, 61, 74], "latent": [43, 44], "later": [18, 27, 47], "latest": [10, 46, 47], "latex": 15, "lathi": [31, 75], "lauren": [31, 75], "lavend": [31, 75], "lavril": [31, 75], "law": [4, 11, 31, 36, 50, 75, 85], "lawrenc": [31, 75], "layer": [1, 2, 3, 4, 5, 35, 38, 43, 45, 48, 49, 50, 53, 58, 60, 82, 83, 84, 85, 89, 93], "layer_id": [48, 49], "layer_idx": 43, "layernorm": [1, 86], "lcb": 13, "lcb_runner": 13, "lcft": 47, "ld_impl_linux": 13, "le": [12, 20, 29, 31, 44, 55, 75, 82, 84, 89], "lead": [26, 33, 36, 40, 41, 44, 45, 47, 55, 61, 74, 83, 84, 86], "leakag": [36, 51], "leandro": [31, 75], "learn": [1, 2, 3, 4, 5, 11, 15, 26, 33, 34, 35, 36, 38, 41, 45, 48, 49, 51, 54, 57, 63, 65, 66, 67, 75, 82, 89], "learnabl": 48, "learner": [3, 4, 31, 75], "learning_r": 92, "least": [3, 4, 7, 39, 61], "leather": [31, 75], "leav": [38, 40], "lebr\u00f3n": [31, 75], "led": [46, 47, 61], "lee": [31, 75], "leed": 82, "leetcod": [13, 22, 42, 44, 72], "left": [1, 5, 12, 33, 35, 39, 41, 48, 49, 53, 54, 55, 57, 58, 59, 62, 65, 73, 83, 84, 85, 87, 88, 90], "leftarrow": 85, "legal": 61, "lei": [31, 75], "leik": [31, 75], "len": [48, 60, 65], "length": [1, 35, 41, 43, 44, 46, 47, 48, 53, 55, 59, 62, 82, 83, 84, 85, 86], "lengthi": 40, "lenni": [31, 75], "leonhardi": [31, 75], "leontiadi": [31, 75], "less": [1, 5, 8, 18, 21, 22, 24, 27, 34, 42, 47, 56, 57, 61, 66, 74, 79, 83], "let": [15, 31, 32, 33, 43, 53, 55, 61, 65, 69, 75, 83, 85, 87, 88], "letman": [31, 75], "level": [3, 11, 15, 16, 19, 20, 26, 29, 31, 33, 36, 39, 41, 43, 44, 46, 47, 50, 51, 56, 74, 75], "leverag": [14, 18, 25, 27, 40, 44, 46, 50, 72, 84, 87, 88], "lewi": [31, 75], "lex": 84, "lezama": [31, 75], "li": [31, 75], "liang": [31, 75], "liangpeng": [31, 75], "libffi": 13, "libgcc": 13, "libgomp": 13, "librari": [26, 41], "libstdcxx": 13, "libuuid": 13, "licheng": [31, 75], "lie": [61, 85], "lightman": [31, 75], "like": [2, 8, 11, 24, 31, 32, 33, 36, 40, 44, 50, 51, 55, 56, 61, 63, 68, 72, 74], "likelihood": [2, 33, 34, 38, 54, 55, 62, 65, 66, 69, 74], "limit": [4, 5, 18, 27, 36, 38, 39, 42, 44, 46, 47, 56, 62, 65, 82, 83, 84, 85], "lin": [31, 75], "lind": [31, 75], "lindsai": [31, 75], "line": [14, 18, 20, 25, 27, 29, 31, 32, 35, 36, 41, 48], "linear": [1, 2, 41, 43, 45, 46, 48, 49, 50, 53, 79, 84, 88], "linearli": [1, 39], "lingm": [31, 75], "link": 3, "linter": 47, "linzheng": [31, 75], "liqun": [31, 75], "liron": [31, 75], "liskovich": [31, 75], "list": [8, 20, 24, 29, 39, 40, 41, 48, 60, 65, 79, 81], "liter": 48, "littl": 51, "litwin": [31, 75], "liu": [31, 75], "livecodebench": [21, 22, 31, 75], "livshit": [31, 75], "liz": [31, 75], "lkb": [15, 31, 75], "ll": [31, 48, 85, 93], "llama": [8, 9, 21, 24, 31, 34, 48, 60, 67, 75, 79, 83, 86], "llama2": [21, 46, 79], "llama3": [21, 22, 49], "llion": [31, 75], "llm": [7, 13, 14, 20, 25, 26, 28, 29, 30, 40, 41, 46, 47, 51, 53, 54, 55, 57, 59, 63, 67, 68, 72, 73, 84], "llm4code": 10, "lm": [3, 58], "lm_head": 43, "ln": [31, 48, 56, 75, 84, 86], "load": [44, 48], "load_checkpoint": 60, "load_state_dict": 48, "load_tiktoken_bp": 48, "lobanova": [31, 75], "local": [4, 73], "localhost": 92, "locat": [41, 84], "log": [2, 3, 5, 33, 39, 46, 48, 54, 55, 57, 58, 59, 61, 62, 65, 66, 73, 74, 79, 90], "logging_step": [60, 92], "logic": [40, 44, 50, 51, 72], "logist": 66, "logit": [38, 46, 48, 54, 55, 83], "logprob": 48, "logprobs_i": 48, "long": [2, 5, 8, 24, 31, 47, 48, 51, 55, 72, 75, 83, 84, 88], "longer": [1, 41, 43, 53, 55, 62, 83, 84], "look": 40, "loos": 84, "lora": [21, 22], "lose": 67, "loss": [4, 5, 33, 35, 36, 38, 43, 44, 46, 47, 53, 55, 56, 57, 58, 59, 62, 66], "lot": [31, 83], "loui": [31, 75], "lovish": [31, 75], "low": [9, 18, 26, 27, 33, 46, 51, 55, 57, 69, 83, 88, 93], "lower": [8, 24, 47, 55, 79, 83], "lowest": [66, 67, 81, 82, 83], "loyd": [31, 75], "lr": 26, "lr_scheduler_typ": 92, "lu": [31, 75], "luan": [31, 75], "lubo": [31, 75], "luca": [31, 75], "luka": [31, 75], "lukasz": [31, 75], "luke": [31, 75], "luo": [31, 75], "lupu": [31, 75], "lxwz23": [10, 31, 75], "m": [2, 13, 18, 27, 31, 44, 46, 48, 49, 55, 56, 59, 65, 66, 75, 82, 83, 84, 87, 88], "m_": 65, "m_0": 67, "m_1": 67, "m_2": 67, "m_3": 67, "m_t": 67, "ma": [31, 75], "maaten": [31, 75], "macei": [31, 75], "machin": [1, 3, 31, 41, 75], "madaan": [31, 75], "made": [20, 29, 50, 56, 62, 66], "madelin": [31, 75], "madian": [31, 75], "magic": [21, 22], "magicod": [10, 26, 31, 47, 51, 75], "magnitud": [1, 3, 4, 36, 38, 84, 85], "mahadeokar": [31, 75], "mahajan": [31, 75], "mahesh": [31, 75], "maheswari": [31, 75], "mai": [1, 26, 34, 36, 40, 42, 44, 47, 55, 57, 61, 62, 63, 66, 72, 82, 84], "mail": 3, "main": [10, 13, 34, 36, 39, 40, 41, 45, 46, 47], "mainli": [36, 40, 44, 51, 66, 72], "mainstream": 51, "maintain": [42, 43, 44, 46, 50, 51, 82], "major": [15, 47, 51, 63, 74], "make": [1, 2, 5, 8, 11, 18, 19, 24, 27, 33, 36, 39, 41, 48, 49, 50, 53, 54, 56, 59, 60, 61, 67, 72, 73, 84, 86, 87, 88], "make_experience_list": 60, "malik": [31, 75], "malo": [31, 75], "man": [31, 75], "manag": 13, "manav": [31, 75], "mangla": [31, 75], "mani": [3, 4, 15, 18, 27, 31, 32, 41, 51, 58, 84, 91], "manish": [31, 75], "manku": [31, 75], "mann": [31, 75], "mannat": [31, 75], "manner": [67, 68], "manohar": [31, 75], "manta": [31, 75], "manual": [16, 18, 27], "mao": [31, 75], "map": 1, "map_loc": 48, "marcin": [31, 75], "marcu": [31, 75], "margin": [20, 29, 34, 46, 47], "mari": [31, 75], "maria": [31, 75], "mark": [31, 41, 47, 75], "markdown": [10, 42], "markdownfil": 32, "markedli": 31, "markup": 31, "markupsaf": 13, "marra": [31, 75], "martin": [31, 75], "martinet": [31, 75], "martyna": [31, 75], "mask": [1, 38, 41, 47, 48, 49], "mass": [20, 29, 33, 48], "massiv": [11, 31, 50, 51, 75], "master_port": 92, "matan": [31, 75], "match": [15, 19, 44, 48, 50, 73, 83, 84, 85], "mateusz": [31, 75], "math": [11, 31, 42, 43, 44, 47, 48, 49, 50, 51, 55, 57, 72, 74, 75], "mathbb": [1, 5, 12, 33, 46, 53, 54, 55, 57, 58, 59, 65, 66, 73, 82, 83, 85, 87, 88, 93], "mathbf": [1, 33, 41, 44, 48, 49, 57, 59, 82, 83, 84, 85, 86, 87, 88], "mathcal": [2, 28, 33, 46, 53, 54, 55, 56, 64, 65, 66, 68, 69, 73, 79, 82, 85, 89], "mathemat": [11, 12, 15, 31, 42, 43, 44, 47, 50, 51, 54, 57, 75], "mathew": [31, 75], "mathieu": [31, 75], "mathmix": 74, "mathrm": 64, "mathur": [31, 75], "matmul": [48, 49], "matosich": [31, 75], "matplotlib": 54, "matric": [1, 48, 49, 85, 89, 93], "matrix": [1, 2, 41, 48, 49, 85, 87, 88, 89], "matthew": [31, 75], "matthia": [31, 75], "maurer": [31, 75], "max": [1, 31, 46, 48, 49, 55, 65, 69, 73, 75, 83, 89], "max_": [54, 65, 84], "max_batch_s": [48, 49], "max_epoch": 60, "max_gen_len": 48, "max_prompt_len": 48, "max_reward": 65, "max_sampl": 60, "max_seq_len": [48, 49], "maxim": [2, 5, 8, 14, 20, 24, 25, 29, 31, 33, 39, 45, 54, 56, 57, 58, 65, 69, 73, 74, 75, 83, 84], "maximum": [33, 38, 41, 46, 47, 48, 54, 56, 65, 83, 84, 85], "maya": [31, 75], "mayer": [31, 75], "mazeika": [31, 75], "mbox": 88, "mbpp": [20, 21, 22, 26, 29, 51], "mbppplu": 10, "mbppplus_releas": 10, "mccandlish": [31, 75], "mcconnel": [31, 75], "mceval": [26, 31, 51, 75], "mcgrew": [31, 75], "mcphie": [31, 75], "md": [31, 32], "me": 61, "mean": [1, 46, 48, 49, 55, 56, 57, 66, 67, 82, 86, 88], "meaning": 40, "meansquar": [48, 49, 86], "meanwhil": [83, 84, 87, 88], "measur": [5, 11, 31, 33, 38, 47, 57, 62, 69, 75], "mechan": [1, 39, 44, 50, 51, 57, 82, 86, 87, 88], "media": 3, "median": 46, "medina": [31, 75], "medium": 41, "meer": [31, 75], "meghan": [31, 75], "mehta": [31, 75], "mei": [31, 75], "mejia": [31, 75], "melani": [31, 75], "memori": [1, 2, 9, 57, 85], "men": [31, 75], "menon": [31, 75], "mention": 7, "merg": [20, 29], "mergeable_rank": 48, "messag": [40, 48], "met": 47, "meta": [48, 91], "metadata": [13, 39], "metanat": [31, 75], "method": [4, 14, 20, 25, 26, 29, 34, 44, 46, 47, 48, 50, 51, 54, 56, 59, 63, 66, 71, 83, 84, 87, 88], "methodologi": [44, 72], "meticul": [43, 51], "metric": [12, 20, 29, 33, 36, 38, 53, 62, 79], "mialon": [31, 75], "miao": [31, 75], "michael": [31, 75], "michal": [31, 75], "michel": [31, 75], "michelena": [31, 75], "michiel": [31, 75], "micro_rollout_batch_s": 60, "micro_train_batch_s": 60, "middl": [15, 18, 27, 41, 44], "might": [7, 47, 86], "mihailescu": [31, 75], "mihaylov": [31, 75], "mihir": [31, 75], "mik": [31, 75], "mikayel": [31, 75], "mike": [31, 75], "mikhail": [31, 75], "mile": [31, 75], "million": [3, 4, 36, 38, 39, 41, 47, 50, 51], "min": [31, 48, 53, 57, 65, 75, 93], "min_": 54, "min_prompt_len": 48, "mine": 65, "ming": [31, 75], "mingfeng": [31, 75], "mini": [48, 86], "minim": [44, 54, 56, 83, 84], "minimis": [38, 55], "minimum": 54, "minor": 73, "minu": 48, "minut": 9, "miquel": [31, 75], "mira": [31, 75], "misalign": 59, "mishkin": [31, 75], "mishra": [31, 75], "mismatch": [55, 73], "misra": [31, 75], "miss": [31, 41, 75], "mistak": [40, 59, 73], "mistralai": 13, "mitchel": [31, 75], "mitesh": [31, 75], "mitig": [5, 26, 43, 44, 47, 51, 53, 57, 58, 62, 66, 69, 73, 82, 84], "mitra": [31, 75], "mix": [5, 38, 41, 42, 47, 51, 58, 65, 72], "mixtral": 60, "mixtur": [43, 44, 50, 60], "mk": 82, "ml": [4, 84], "mla": [22, 43, 44], "mle": [54, 59, 65], "mlp": 53, "mmlu": 34, "mn": 82, "mo": [31, 75], "mode": [36, 54], "model": [2, 7, 8, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 54, 55, 57, 60, 61, 62, 63, 64, 65, 75, 82, 85, 86, 87, 88, 93], "model_arg": 48, "model_name_or_path": 92, "modelarg": [48, 49], "modern": [36, 91], "modest": 74, "modif": [2, 3, 8, 20, 24, 29, 38, 47, 83], "modifi": [1, 8, 24, 41, 46, 47, 63, 67, 68, 73, 84, 93], "modul": [13, 26, 43, 48, 49, 51, 82, 86], "modular": 40, "modulelist": [48, 49], "modulenotfounderror": 48, "moe": [22, 43, 44, 50, 82, 85], "moe_intermediate_s": 43, "moegat": 82, "mohammad": [31, 75], "mohan": [31, 75], "molybog": [31, 75], "mona": [31, 75], "monoton": 65, "mont": [33, 57], "montalvo": [31, 75], "montanez": [31, 75], "montgomeri": [31, 75], "month": 46, "more": [1, 2, 3, 4, 5, 7, 8, 10, 11, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 32, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 61, 63, 65, 66, 72, 74, 79, 82, 83, 85], "moreov": [31, 43, 73], "morikawa": [31, 75], "moshkovich": [31, 75], "most": [1, 3, 4, 15, 26, 31, 34, 41, 44, 46, 47, 48, 51, 53, 59, 67, 74, 82, 84, 91], "mostli": [16, 47], "motiv": [3, 54, 65, 69], "move": [3, 41], "moya": [31, 75], "mpmath": 13, "msgpack": 13, "mt": 82, "mtp": 44, "much": [8, 24, 36, 41, 47, 54, 61, 74, 83, 84, 88], "multi": [2, 21, 31, 35, 41, 43, 45, 47, 48, 49, 51, 75], "multidict": 13, "multihead": 1, "multilingu": [31, 47, 50, 51, 75], "multinomi": 48, "multipl": [5, 11, 15, 18, 26, 27, 28, 34, 40, 44, 47, 48, 49, 51, 56, 60, 61, 67, 73, 82, 83, 85, 88], "multiple_of": [48, 49], "multipli": [1, 44, 53, 87, 88], "multiprocess": 13, "multistag": 50, "multitask": [3, 11, 31, 41, 75], "munish": [31, 75], "murati": [31, 75], "murtadha": [31, 75], "murthi": [31, 75], "must": [1, 31, 33, 35, 41, 55, 74, 83, 84], "muzzi": [31, 75], "my": 61, "n": [1, 2, 10, 12, 13, 20, 21, 22, 28, 29, 31, 33, 34, 38, 41, 44, 48, 49, 56, 59, 65, 67, 68, 73, 74, 75, 81, 82, 83, 84, 86, 87, 88, 89, 90], "n_": [18, 27, 35, 85], "n_h": [43, 85], "n_head": [48, 49], "n_layer": [48, 49], "n_routed_expert": [43, 82], "n_shared_expert": 43, "n_t": [18, 27], "n_vocab": 48, "n_word": 48, "nabla_": [33, 54, 55], "nail": [31, 75], "naiv": [36, 54, 79, 82], "nakano": [31, 75], "nam": [31, 75], "naman": [31, 75], "name": [13, 20, 29, 38, 40, 48, 51, 54, 89], "nandhini": [31, 75], "nano": 56, "narang": [31, 75], "narj": [31, 75], "narrow": [4, 14, 25], "natascha": [31, 75], "natasha": [31, 75], "nativ": 47, "natur": [3, 4, 7, 18, 27, 36, 38, 40, 41, 42, 47, 48, 51, 62, 71, 72, 83, 84, 86], "naumov": [31, 75], "navyata": [31, 75], "nayak": [31, 75], "nayan": [31, 75], "nayani": [31, 75], "nccl": 13, "ncurs": 13, "nderstand": 9, "ndim": [48, 49, 84], "ne": [55, 79], "nearbi": 87, "nearli": [1, 3, 36, 51, 56], "necess": 43, "necessari": [53, 67], "necessit": 82, "necssari": [8, 24], "need": [4, 18, 26, 27, 31, 32, 36, 40, 42, 43, 46, 47, 48, 49, 57, 66, 75, 79, 84, 85], "neelakantan": [31, 75], "neg": [33, 50, 51, 53, 55, 59, 63, 66, 69, 73, 74, 79], "negligibli": 46, "neighbor": 61, "net": [31, 75], "network": [2, 31, 45, 48, 49, 50, 53, 75, 82, 89], "networkx": 13, "neural": [1, 2, 31, 48, 49, 72, 75, 89, 90], "neutral": 74, "never": 82, "new": [1, 3, 4, 5, 8, 11, 13, 14, 18, 20, 24, 25, 27, 29, 36, 38, 39, 41, 46, 47, 48, 49, 50, 53, 55, 56, 57, 58, 67, 79, 81, 89], "newli": [20, 29], "newlygener": [18, 27], "next": [1, 2, 13, 18, 27, 33, 38, 40, 47, 56, 58, 61, 67, 68, 84, 88], "next_token": 48, "ng": 13, "nguyen": [31, 75], "ni": [31, 75], "nichol": [31, 75], "nichola": [31, 75], "nick": [31, 75], "nicola": [31, 75], "nie": [31, 75], "nikhil": [31, 75], "niki": [31, 75], "nikola": [31, 75], "nikolai": [31, 75], "nikolaidi": [31, 75], "niladri": [31, 75], "ning": [31, 75], "nl": 64, "nll": 47, "nlp": [2, 4, 5, 36, 58, 81, 86], "nn": [43, 48, 49, 82, 84, 86], "noam": [31, 75], "node": [44, 82], "nois": 66, "noisi": [42, 66, 68, 69], "non": [4, 8, 15, 18, 24, 27, 44, 45, 50, 53, 61, 65, 72, 88], "none": [43, 48, 49], "nonlinear": [48, 49, 89], "noqa": 48, "norm": [48, 49], "norm_ep": [48, 49], "normal": [1, 3, 13, 45, 49, 50, 57, 60, 61, 62, 66, 82], "normalize_reward": 60, "normalized_shap": 48, "norman": [31, 75], "notabl": [7, 34, 42, 53, 84], "note": [30, 31, 35, 40, 44, 48, 54, 55, 56, 57, 68], "notebook": 31, "notin": [59, 65], "novel": [14, 20, 25, 29, 59, 65, 68, 87, 88], "novelti": 12, "novemb": 42, "now": [40, 43, 53, 54, 55, 68, 73, 84], "np": [12, 54, 65], "nuanc": [50, 72], "nucleu": 48, "num": 85, "num_attention_head": 43, "num_base_token": 48, "num_channel": 48, "num_episod": 60, "num_experts_per_tok": 43, "num_featur": [48, 86], "num_head": 43, "num_reserved_special_token": 48, "num_sampl": [48, 65], "num_step": 1, "num_train_epoch": 92, "number": [2, 4, 5, 12, 18, 20, 27, 29, 34, 35, 36, 38, 41, 42, 43, 48, 56, 57, 65, 74, 82, 83, 84, 85, 86, 88, 89, 93], "numer": [12, 55, 79], "numpi": [12, 13, 54, 65], "nvidia": 13, "nvjitlink": 13, "nvrtc": 13, "nvtx": 13, "nw": 64, "o": [1, 9, 57, 63, 81, 85, 88], "o1": 21, "o_": [43, 57], "o_1": [57, 63], "o_2": [57, 63], "o_g": 57, "o_proj": 43, "obei": 85, "object": [2, 5, 28, 33, 38, 39, 41, 44, 46, 47, 50, 54, 57, 58, 59, 65, 69, 82], "observ": [20, 26, 29, 34, 36, 40, 43, 47, 53, 56, 62, 66, 72, 79, 83, 85], "obstacl": 33, "obtain": [1, 2, 8, 14, 20, 24, 25, 29, 39, 42, 43, 47, 50, 51, 53, 56, 62, 65, 73, 79], "obviou": 33, "occasion": [4, 47], "occur": 72, "occurr": 72, "od": 9, "off": [18, 27, 31, 32, 34, 59, 62], "offer": [47, 51, 56, 59, 62], "offlin": [21, 22, 33, 38, 43, 51, 59], "offset": 1, "often": [2, 4, 18, 27, 33, 40, 59, 62, 63, 66, 69, 86], "ofthought": 71, "ol": 81, "olano": [31, 75], "old": [57, 81], "older": [26, 81], "oldham": [31, 75], "oleg": [31, 75], "oliveira": [31, 75], "olivi": [31, 75], "olivia": [31, 75], "omit": [43, 82, 85, 89], "omkar": [31, 75], "onc": [1, 8, 20, 24, 29, 35, 85], "one": [1, 4, 5, 7, 18, 20, 26, 27, 29, 31, 33, 34, 36, 38, 39, 41, 44, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 59, 62, 63, 65, 67, 74, 79, 82, 84, 86, 89], "ones": [1, 43, 46, 47, 48, 49, 51, 69, 82, 84, 86], "ones_lik": [48, 49, 84], "onli": [4, 5, 8, 9, 11, 15, 18, 24, 26, 27, 36, 38, 39, 41, 44, 46, 47, 48, 49, 51, 53, 54, 55, 57, 59, 61, 63, 67, 68, 69, 73, 74, 83, 84, 85, 87, 88], "onlin": [21, 22, 39, 43, 59], "onur": [31, 75], "open": [7, 8, 20, 22, 24, 26, 29, 31, 44, 48, 50, 51, 67, 72, 75], "openai": [3, 5, 13, 15, 31, 48, 58, 75], "opencod": 22, "openr1": 22, "openreview": [31, 75], "opensourc": 50, "openssl": 13, "oper": [2, 15, 20, 29, 56, 84, 86], "opportun": 56, "oppos": [41, 89], "opposit": [59, 63], "optim": [2, 5, 8, 21, 24, 31, 33, 34, 35, 40, 42, 43, 44, 46, 50, 51, 56, 58, 64, 65, 68, 72, 73, 75, 84], "optima": 73, "optimis": 55, "optimizatio": 47, "option": [8, 10, 24, 33, 43, 48, 49, 61, 62, 84], "opu": 42, "oracl": [33, 34, 73], "order": [1, 2, 3, 4, 5, 36, 38, 39, 40, 41, 43, 46, 54, 58, 61, 62, 66, 67, 68, 82, 83, 84, 85, 87, 88], "org": [14, 18, 20, 25, 27, 29, 31, 75], "organ": [51, 54], "origin": [3, 10, 11, 18, 20, 27, 29, 39, 40, 44, 45, 46, 47, 53, 59, 62, 66, 67, 68, 82, 83, 84, 88, 89], "orjson": 13, "orthogon": [14, 25], "oss": [31, 75], "other": [1, 2, 5, 11, 20, 29, 31, 32, 33, 36, 40, 41, 43, 44, 47, 48, 49, 51, 56, 59, 65, 67, 69, 73, 75, 79, 82, 86, 89, 91], "otherwis": [33, 44, 46, 59, 65, 74, 82, 83], "otim": [48, 49, 89], "our": [1, 2, 3, 5, 8, 9, 11, 14, 15, 18, 20, 24, 25, 26, 27, 29, 33, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 54, 55, 56, 57, 58, 61, 62, 64, 66, 67, 68, 72, 73, 74, 79, 84, 87, 88, 93], "ourselv": 39, "out": [5, 39, 46, 47, 48, 49, 56, 58, 79, 83, 84, 85], "out_logprob": 48, "out_token": 48, "outbound": 3, "outcom": 72, "outdat": 26, "outer": [48, 49, 84], "outermost": 60, "outlin": [20, 29, 66, 72], "outperform": [34, 36, 41, 42, 43, 44, 51, 62, 74, 79], "output": [1, 2, 5, 8, 9, 13, 14, 18, 24, 25, 27, 32, 33, 34, 35, 38, 39, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 53, 57, 58, 59, 63, 66, 68, 69, 82, 85, 86, 88], "output_dir": 92, "outsid": 66, "over": [1, 2, 3, 4, 5, 11, 13, 33, 35, 39, 41, 43, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 62, 66, 67, 69, 73, 74, 85, 86, 88], "overal": [1, 2, 18, 26, 27, 35, 38, 44, 47, 53, 57, 59, 62], "overconfid": 66, "overfit": [19, 58, 66], "overlap": [26, 51], "overload": 44, "oversight": 15, "overthink": 44, "overview": [31, 48, 49], "overwrite_cach": 92, "own": [47, 59, 61, 67, 73, 74], "ozgenel": [31, 75], "ozlem": [31, 75], "p": [2, 5, 28, 33, 34, 46, 48, 54, 56, 57, 59, 63, 65, 88, 90], "p_": [33, 56, 66, 69, 73, 82], "p_1": 73, "p_i": 28, "pa": 28, "pack": [1, 92], "packag": [13, 26], "pad": 86, "pad_id": 48, "padding_idx": 43, "page": [31, 32], "paino": [31, 75], "pair": [1, 2, 3, 5, 8, 9, 24, 26, 33, 36, 40, 41, 43, 45, 50, 51, 56, 58, 59, 61, 62, 63, 64, 65, 66, 67, 69, 73], "pairwis": [5, 46, 53, 63, 64, 65, 67, 68], "palm": [48, 49], "paluri": [31, 75], "pamela": [31, 75], "pan": [31, 75], "panda": 13, "pandei": [31, 75], "pang": [31, 75], "paola": [31, 75], "papakipo": [31, 75], "paper": [5, 12, 14, 15, 18, 20, 25, 27, 29, 30, 33, 39, 40, 41, 47, 79, 84], "par": 62, "paradigm": [4, 59], "parallel": [1, 38, 48, 51, 82, 86], "paralleliz": 1, "param": [12, 48, 49], "paramet": [1, 2, 3, 4, 5, 14, 25, 26, 34, 39, 41, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 57, 58, 59, 65, 66, 79, 82, 83, 84, 85, 86, 87, 88, 89, 93], "parameter": [35, 69], "parametr": 54, "paranjap": [31, 75], "parekh": [31, 75], "parenthes": 63, "parikh": [31, 75], "park": [31, 75], "parker": [31, 75], "parkin": [31, 75], "parmar": [31, 75], "pars": [47, 51], "parsed_arg": 10, "parser": 47, "part": [36, 41, 51, 56, 82, 88], "parth": [31, 75], "parthasarathi": [31, 75], "partial": [33, 40], "particip": [16, 38, 39], "particular": [1, 47, 48, 49, 54, 56, 57, 71, 83, 89], "particularli": [13, 59, 72], "partit": [54, 66, 82], "pass": [2, 9, 12, 16, 20, 26, 29, 35, 38, 40, 41, 42, 47, 48, 49, 50, 53, 83, 89, 93], "pass_at_k": 12, "past": 56, "pasupuleti": [31, 75], "pat_str": 48, "patel": [31, 75], "path": [32, 48, 79], "path_to_custom_output": 13, "patil": [31, 75], "patrick": [31, 75], "pattern": [4, 44, 48], "paul": [31, 75], "pavan": [31, 75], "pavlov": [31, 75], "pavlova": [31, 75], "pavlovich": [31, 75], "pbar": 60, "pdf": [14, 18, 20, 25, 27, 29], "pe_": 1, "peak": [8, 24], "pearson": 53, "pebbl": 13, "pedro": [31, 75], "pei": [31, 75], "penal": [36, 66], "penalti": [5, 46, 53, 57, 58, 73], "peng": [31, 75], "pengchuan": [31, 75], "pengwei": [31, 75], "per": [5, 11, 12, 33, 35, 38, 39, 43, 48, 57, 58, 63, 64, 67, 74, 85], "per_device_train_batch_s": 92, "percent": 61, "percentag": [38, 62], "perceptu": 33, "perfect": [47, 67], "perform": [1, 3, 4, 5, 7, 8, 9, 11, 14, 15, 24, 25, 26, 34, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56, 58, 59, 62, 65, 67, 69, 71, 74, 79, 82, 83, 85, 86], "perino": [31, 75], "period": [41, 43, 88], "permit": [8, 24], "permut": [48, 86], "perplex": 83, "person": [5, 61], "perspect": [4, 88], "petar": [31, 75], "peter": [31, 75], "petroski": [31, 75], "petrov": [31, 75], "pexpect": 13, "pgr": 36, "phase": [18, 26, 27, 40, 41, 44, 46, 50, 54, 61, 72], "phd": 15, "phenomenon": [36, 53, 72], "phi": [5, 53, 54, 57, 58, 62, 68, 89], "phi4": 21, "philip": [31, 75], "philipp": [31, 75], "philosophi": 11, "php": 47, "phrase": 2, "physic": [11, 15], "pi": [1, 5, 33, 46, 54, 56, 58, 65, 66, 69, 73, 79, 83, 84], "pi_": [5, 33, 46, 55, 57, 58, 65, 69, 73, 79], "pick": [34, 38], "piec": [45, 47, 61, 62], "piecewis": 46, "pierr": [31, 75], "pii": 5, "pile": 84, "pinto": [31, 75], "pintz": [31, 75], "pioneer": 44, "piotr": [31, 75], "pip": [10, 13], "pipelin": [7, 8, 24, 26, 42, 44, 50, 54, 63, 72, 74], "pivot": 34, "pkginfo": 13, "place": [48, 49, 63, 89], "placehold": [8, 24], "plai": [34, 42, 43, 44], "plain": [5, 40], "plan": [44, 84], "plane": 88, "plappert": [31, 75], "platform": [3, 13, 38, 39], "platformdir": 13, "plawiak": [31, 75], "playground": 5, "pleas": [10, 61], "plethora": 47, "plot": [35, 54, 56], "plot_loss": 92, "plt": 54, "plu": 13, "plugin": 13, "pm": 69, "pmatrix": [41, 87, 88], "po": 1, "poenaru": [31, 75], "poetri": 13, "point": [1, 26, 34, 39, 40, 43, 46, 47, 51, 67, 72, 84], "pointwis": 65, "polar": [48, 49, 83, 84], "polici": [5, 42, 43, 44, 46, 47, 50, 54, 56, 58, 61, 62, 65, 69, 72, 73], "polidoro": [31, 75], "polina": [31, 75], "polit": 61, "polosukhin": [31, 75], "pond": [31, 75], "pool": [18, 27, 38, 65, 68, 69], "poor": [40, 44, 56, 72, 86], "poorli": 36, "pop": 65, "popular": [7, 36], "portion": [41, 47, 51, 72], "posit": [2, 31, 36, 41, 44, 45, 48, 49, 50, 55, 57, 59, 62, 63, 67, 68, 69, 74, 75, 86, 87, 89], "positionwis": 1, "possess": 67, "possibl": [3, 18, 27, 36, 39, 40, 44, 45, 47, 56, 61, 63, 64, 68, 73, 74], "possibli": [26, 51, 61], "post": 62, "post0": 13, "postpon": 40, "potenti": [4, 5, 28, 40, 43, 46, 51, 59, 62, 72], "poulton": [31, 75], "pow": [48, 49, 86], "power": [4, 14, 25, 31, 38, 39, 48, 49, 72, 75], "ppo": [5, 21, 22, 42, 46, 58, 63], "ppo_train": 60, "pq": 28, "practic": [1, 4, 26, 33, 36, 40, 51, 53, 54, 56, 66, 69, 82, 84], "practition": [14, 25], "prafulla": [31, 75], "prajjwal": [31, 75], "pranav": [31, 75], "prasad": [31, 75], "prashant": [31, 75], "pratik": [31, 75], "praveen": [31, 75], "pre": [1, 4, 22, 26, 31, 38, 40, 42, 48, 53, 61, 75, 81, 83, 84, 87, 88, 90], "preambl": 62, "preced": [2, 46], "precis": [33, 41, 59], "precomput": 84, "precompute_freqs_ci": [48, 49, 84], "predecessor": [50, 51], "predefin": [14, 25, 64, 72], "predict": [1, 2, 5, 9, 13, 36, 38, 39, 41, 48, 53, 56, 58, 66, 69, 73, 74, 84], "predominantli": 41, "prefer": [5, 7, 21, 22, 31, 33, 34, 42, 43, 44, 50, 51, 53, 55, 56, 58, 61, 63, 64, 65, 67, 68, 72, 73, 74, 75, 84, 86], "prefix": [5, 13, 18, 27, 33, 41, 74], "preliminari": [43, 72], "prepend": [48, 61], "presani": [31, 75], "prescrib": 56, "presenc": [32, 51], "present": [5, 40, 44, 47, 56, 58, 59, 61, 62, 68, 74, 83, 84], "preserv": [51, 83, 84], "pressur": 83, "pretrain": [4, 5, 11, 18, 27, 36, 41, 43, 51, 58, 60, 61, 67, 74, 83, 84, 93], "pretrained_weight": 92, "prev_po": 48, "prevent": [1, 41, 44], "previou": [1, 4, 18, 20, 27, 29, 43, 47, 48, 49, 50, 56, 59, 73, 83, 84], "previous": 1, "primarili": [5, 15, 42, 47, 50, 58, 59], "princip": 82, "principl": [61, 63], "print": [32, 48], "prior": [3, 4, 15, 26, 46, 54, 59, 61, 69], "priorit": [47, 50], "pritish": [31, 75], "privaci": 61, "prm800k": 74, "pro": [39, 42, 56], "prob": 48, "probabl": [1, 2, 5, 12, 33, 34, 48, 54, 55, 56, 57, 59, 61, 62, 65, 69, 74], "problem": [4, 9, 10, 11, 12, 13, 14, 15, 16, 19, 25, 26, 31, 36, 38, 39, 40, 41, 44, 47, 51, 54, 65, 66, 72, 74, 75], "probs_idx": 48, "probs_sort": 48, "probs_sum": 48, "proce": [20, 29], "procedur": [2, 5, 36, 39, 55, 56, 58, 62, 67], "process": [3, 18, 20, 26, 27, 29, 31, 33, 34, 36, 40, 42, 43, 44, 48, 50, 51, 53, 56, 59, 75, 84, 86, 88, 90], "prod": 12, "produc": [1, 2, 5, 8, 14, 18, 20, 24, 25, 27, 29, 33, 34, 38, 39, 40, 43, 44, 47, 48, 51, 53, 56, 58, 59, 62, 63, 66, 69, 73, 85], "product": [12, 33, 48, 49, 87, 88, 89], "profession": [11, 41], "profici": 43, "program": [12, 16, 26, 38, 39, 40, 41, 42, 44, 47, 51], "programm": [9, 16], "programmat": 12, "progress": [1, 40, 44, 46, 56, 57], "project": [1, 38, 85], "promin": [20, 29], "promis": [3, 4, 34, 51, 62], "promot": [18, 27], "prompt": [5, 7, 8, 10, 11, 12, 14, 18, 24, 25, 26, 27, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 53, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72], "prompt_data": 60, "prompt_max_len": 60, "prompt_token": 48, "prompts_dataload": 60, "prone": [19, 66], "prop": 45, "proper": [51, 53], "properli": [31, 46], "properti": [84, 87], "proport": [41, 43, 51, 55, 82], "propos": [1, 18, 27, 33, 36, 41, 48, 49, 51, 53, 54, 57, 59, 65, 68, 69, 73, 79, 82, 85, 89, 93], "proprietari": [41, 50], "propto": 55, "proto": 13, "protobuf": 13, "protocol": [26, 47], "prove": [26, 88], "proven": [42, 57], "provid": [2, 5, 8, 10, 11, 12, 13, 16, 19, 24, 36, 41, 42, 44, 46, 48, 51, 54, 55, 57, 59, 66, 67, 71, 72, 74, 84, 88], "proxim": 57, "prune": 16, "pseudo": [47, 69], "pseudocod": 28, "pseudolabel": 69, "psi": [54, 57, 65, 66], "psi_": 66, "psm": 41, "psychologi": 11, "pth": 48, "ptx": [5, 58], "ptyprocess": 13, "public": [5, 38, 39, 40, 42, 51, 58], "publicli": [41, 45, 47, 50], "punit": [31, 75], "pure": 72, "puri": [31, 75], "purpos": [31, 36, 41, 84], "pursu": 15, "push": [1, 14, 25, 59], "pushkar": [31, 75], "put": [8, 18, 24, 27, 33, 38, 72], "puxin": [31, 75], "puzzl": [36, 44], "py": [10, 92], "py310h06a4308_0": 13, "pyarrow": 13, "pyasn1": 13, "pycpars": 13, "pydant": 13, "pydoc": 26, "pyext": 13, "pypars": 13, "pyplot": 54, "pyproject": 13, "python": [9, 10, 13, 14, 16, 25, 26, 38, 39, 41, 47, 51, 79], "pytz": 13, "pyyaml": 13, "q": [1, 5, 28, 33, 48, 49, 50, 51, 57, 59, 79, 83, 84, 85, 87, 88], "q_": [48, 49, 83, 84], "q_0": [48, 49], "q_1": [48, 49], "q_2": [48, 49], "q_3": [48, 49], "q_a_layernorm": 43, "q_a_proj": 43, "q_b_proj": 43, "q_head_dim": 43, "q_i": [28, 79], "q_lora_rank": 43, "qa": [26, 28, 45, 72], "qi": [31, 75], "qian": [31, 75], "qime": [31, 75], "qin": [31, 75], "qing": [31, 75], "qingxiao": [31, 75], "qiu": [31, 75], "qiufeng": [31, 75], "qk": 1, "qk_nope_head_dim": 43, "qk_rope_head_dim": 43, "qkv": 50, "qlora": 60, "qpa": 28, "qr": 85, "quad": [2, 35, 44, 46, 66, 69, 82, 83, 84], "qualiti": [1, 3, 14, 15, 18, 19, 21, 25, 26, 27, 28, 33, 39, 43, 44, 46, 50, 51, 53, 62, 63, 64, 67, 68, 69, 83, 84], "quan": [31, 75], "quantifi": 66, "quantil": 69, "quantiti": [21, 47], "quartil": 47, "queri": [1, 5, 7, 26, 31, 41, 43, 48, 49, 50, 51, 56, 57, 66, 69, 75, 83, 84, 87, 88], "query_1": 47, "query_2": 47, "question": [2, 3, 8, 10, 11, 15, 16, 20, 24, 26, 28, 29, 34, 40, 41, 44, 51, 57, 62, 74, 79, 83, 84], "question_id": 13, "quit": [40, 42], "qw_": 1, "qwen": [21, 31, 75], "qwen2": [21, 22, 31, 50, 75], "qy": [31, 50, 51, 75], "r": [1, 5, 9, 20, 29, 33, 41, 43, 44, 46, 47, 48, 53, 55, 56, 57, 65, 66, 73, 79, 82, 83, 85, 87, 88, 93], "r1": [22, 44], "r_": [5, 33, 43, 46, 53, 54, 56, 57, 58, 62, 65, 66, 67, 79, 87, 88], "r_1": 57, "r_h": 46, "r_i": [57, 79], "rachad": [31, 75], "rachel": [31, 75], "racist": 61, "rad18": [2, 3, 31, 75], "radenov": [31, 75], "radford": [31, 75], "radford2018improv": [31, 75], "rafael": [31, 75], "rafailov": [31, 75], "rafi": [31, 75], "ragavan": [31, 75], "raghotham": [31, 75], "raghu": [31, 75], "rahul": [31, 75], "rai": [31, 75], "raileanu": [31, 75], "rais": [11, 48, 84], "rait": [31, 75], "raj": [31, 75], "ramanathan": [31, 75], "ramaswami": [31, 75], "ramchandani": [31, 75], "ramesh": [31, 75], "ramon": [31, 75], "ramp": 83, "ran": 39, "rand_prompt": 60, "randn": [48, 86], "random": [3, 11, 14, 25, 38, 39, 48, 56, 65, 66, 68], "randomli": [9, 11, 14, 20, 25, 29, 38, 41, 51, 61, 63], "rang": [2, 4, 5, 11, 13, 14, 25, 36, 41, 45, 46, 47, 48, 49, 60, 61, 62, 81, 84], "rangaprabhu": [31, 75], "rangl": [48, 49, 83, 84, 88], "ranjan": [31, 75], "rank": [5, 34, 38, 40, 46, 47, 54, 58, 65, 66, 67, 93], "rantala": [31, 75], "rao": [31, 75], "raparthi": [31, 75], "rapidfuzz": 13, "rapidli": 59, "rashi": [31, 75], "rastegari": [31, 75], "ratanchandani": [31, 75], "rate": [26, 36, 38, 39, 40, 43, 45, 46, 47, 53, 56, 58, 62, 74], "rater": 56, "rather": [54, 63, 72], "ratio": [44, 51, 55, 83], "rational": 62, "raul": [31, 75], "raw": [42, 90], "raymond": [31, 75], "re": [40, 48, 49, 54, 65, 83, 84, 88], "reach": [4, 15, 18, 27, 39, 40, 46, 74, 82], "read": [3, 48], "readabl": [47, 72], "readlin": 13, "real": [26, 41, 60, 84, 88], "realist": [8, 15, 24], "realiti": [65, 84], "realiz": 2, "realli": [31, 75], "realm": [14, 20, 25, 29], "realworld": 26, "rearrang": [54, 65], "reason": [4, 11, 12, 20, 22, 29, 31, 33, 34, 40, 41, 43, 44, 47, 50, 55, 57, 62, 68, 74, 75, 84, 86], "rebekkah": [31, 75], "recal": [33, 47, 56, 59], "receiv": [3, 33, 46, 56, 82], "recent": [4, 38, 39, 45, 46, 47, 48, 53, 58], "recip": [41, 47, 68], "recommend": [7, 67], "recov": [36, 56], "rectifi": [48, 49, 89], "recurr": 1, "red": [20, 29, 85], "reddit": 3, "reduc": [3, 8, 11, 24, 26, 33, 34, 46, 55, 73, 82, 84, 85, 89, 93], "reduct": [48, 55], "redund": [39, 44, 82], "reevalu": 72, "ref": [54, 55, 57, 73], "refer": [5, 16, 19, 31, 33, 41, 46, 47, 53, 54, 55, 56, 57, 61, 67, 74, 83], "refin": [44, 47, 56], "reflect": [16, 26, 40, 59], "regardless": 53, "regener": 26, "regex": 48, "regim": 74, "region": [1, 33, 84], "reglu": [48, 49, 89], "regress": [1, 5, 41, 46, 47, 53, 58], "regular": [31, 47, 50, 56, 57], "regularli": [44, 51], "rehears": 41, "reiichiro": [31, 75], "reinforc": [5, 36, 41, 54, 57, 63, 74], "reizenstein": [31, 75], "reject": [21, 22, 41, 44, 46, 47, 51, 53, 64, 66, 68, 69, 79], "rejected_1": 47, "rejected_2": 47, "rel": [1, 5, 34, 38, 42, 43, 44, 48, 49, 50, 55, 61, 72, 84, 87, 88], "relat": [8, 13, 24, 26, 34, 41, 42, 44, 50, 51, 57, 65, 79, 82, 85, 88], "relationship": [31, 75], "releas": [8, 10, 24, 26, 41], "relev": [36, 40, 50, 51, 68, 69, 74], "reli": [14, 25, 33, 36, 39, 40, 44, 69, 86], "reliabl": [9, 11, 15, 36, 43, 44, 50, 72, 74], "relianc": 86, "relu": [1, 45, 48, 49, 54, 89], "remain": [18, 27, 35, 36, 38, 39, 55, 66, 69, 74], "remark": 72, "remez": [31, 75], "remind": [8, 24], "remov": [5, 20, 26, 29, 39, 41, 45, 47, 51, 58, 61, 65, 68, 79], "ren": [31, 75], "render": 31, "renorm": 48, "reorder": 41, "repair": 13, "reparameter": 54, "repeat": [8, 18, 24, 27, 40], "repeatedli": 38, "repetit": 3, "replac": [45, 48, 49, 50, 61, 62, 84, 89], "replai": [56, 57, 60], "replay_buff": 60, "repo": [47, 51], "report": [12, 31, 51, 66, 75, 79], "repositori": [13, 26, 38, 41, 42, 51], "repres": [1, 18, 20, 27, 29, 33, 41, 47, 48, 49, 55, 66, 82, 83, 84, 88, 89, 91], "represent": [1, 28, 36, 38, 44, 48, 49, 54, 62, 88, 89], "reproduc": 26, "request": [8, 13, 24, 61, 67], "requir": [1, 2, 4, 8, 9, 24, 36, 39, 40, 41, 44, 46, 47, 48, 56, 65, 72, 82, 83, 84, 85, 86, 87, 88], "rerank": 39, "resampl": [50, 56], "rescal": 84, "research": [15, 26, 46, 59], "reserv": 43, "reserved_special_token_": 48, "reserved_special_token_0": 48, "reserved_special_token_1": 48, "reserved_special_token_2": 48, "reserved_special_token_3": 48, "reserved_special_token_4": 48, "reshap": [48, 49, 84], "reshape_for_broadcast": [48, 49, 84], "residu": [1, 35], "reso": [31, 75], "resolv": [38, 47, 53], "resort": 72, "resourc": [40, 46, 51], "respect": [1, 5, 34, 55, 57, 58, 59, 62, 63, 66, 82, 85], "respons": [5, 7, 8, 10, 13, 20, 24, 26, 29, 34, 43, 44, 46, 47, 48, 50, 51, 53, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 69, 72, 73, 82], "response_candid": 65, "response_reward": 65, "rest": 32, "restrepo": [31, 75], "restrict": [33, 44, 55], "result": [1, 3, 4, 11, 12, 14, 19, 25, 26, 33, 36, 39, 40, 41, 46, 51, 57, 59, 65, 66, 72, 74, 79, 82, 83, 84, 85, 87, 88], "retain": [26, 41, 44, 47, 51, 61, 69], "retriev": 26, "return": [12, 33, 48, 49, 59, 65, 84, 86], "reus": [50, 72, 84], "reveal": [44, 47], "revers": 62, "review": [50, 54], "revis": [47, 73], "reward": [5, 21, 22, 31, 34, 36, 40, 41, 42, 43, 44, 50, 54, 57, 59, 60, 62, 64, 65, 68, 69, 75], "reward_pretrain": 60, "rewon": [31, 75], "rewrit": 61, "rft": [21, 79], "rho": 79, "rho_": 65, "ricardo": [31, 75], "rich": 26, "right": [1, 5, 12, 33, 35, 41, 48, 49, 53, 54, 55, 57, 58, 59, 62, 65, 73, 74, 83, 84, 85, 88, 90], "rigor": [10, 11, 26, 31, 75], "rinott": [31, 75], "risk": [44, 51], "rita": [31, 75], "rittner": [31, 75], "rl": [5, 21, 22, 38, 42, 43, 44, 46, 50, 54, 61, 62, 63, 69, 72, 74], "rlaif": [22, 61, 63, 69], "rlcd": [21, 22, 69], "rlhf": [36, 41, 53, 54, 56, 58, 60, 61, 65], "rlhf1": 22, "rlhf2": 22, "rm": [5, 21, 36, 43, 44, 46, 47, 53, 60, 62, 64], "rm_": 43, "rmboost": 21, "rmsnorm": [31, 43, 45, 50, 75], "robert": [31, 75], "roberta": [31, 47, 75], "robin": [31, 75], "robinson": [31, 75], "robust": [18, 26, 27, 40, 42, 50, 61], "rocca": [31, 75], "rocki": [31, 75], "rodriguez": [31, 75], "roform": [31, 75], "rohan": [31, 75], "rohit": [31, 75], "role": [34, 42, 43, 44, 48], "rollout": 73, "rollout_batch_s": 60, "romain": [31, 75], "ronni": [31, 75], "room": 40, "rope": [21, 22, 41, 44, 45, 50, 85], "rope_theta": [48, 49], "roshan": [31, 75], "rosnbrick": [31, 75], "ross": [31, 75], "rotari": [31, 41, 45, 50, 75, 87], "rotat": [41, 87, 88], "roug": [18, 27], "roughli": [35, 39, 45, 66, 74], "round": [20, 29, 39], "rout": [43, 44, 82], "roux": [31, 75], "row": [48, 49, 84], "rozier": [31, 75], "rozi\u00e8r": [31, 75], "rsa": 13, "rsm": [31, 47, 50, 75], "rso": [21, 22], "rsqrt": [48, 49, 86], "rtol": [48, 86], "rtx4090": 60, "ruan": [31, 75], "rudolph": [31, 75], "rui": [31, 75], "rule": [15, 40, 42, 43, 44, 47, 72], "rulebas": 44, "run": [9, 32, 40, 41, 47, 55, 61, 73], "rungta": [31, 75], "runji": [31, 75], "runner": 13, "runtim": [13, 39], "russ": [31, 75], "ruti": [31, 75], "rwc": [3, 4, 31, 75], "rx": 56, "ryan": [31, 75], "ryder": [31, 75], "s3transfer": 13, "s_": [33, 44, 55, 82, 84], "s_1": [51, 84], "s_2": 84, "s_n": 51, "saab": [31, 75], "sachin": [31, 75], "safe": 58, "safeti": [36, 41, 43, 46], "saghar": [31, 75], "sahana": [31, 75], "sahil280114": [8, 24], "sai": [31, 61, 75], "sajuyigb": [31, 75], "saladi": [31, 75], "salienc": 36, "salient": 36, "salpekar": [31, 75], "sam": [31, 75], "same": [1, 4, 20, 26, 29, 31, 38, 39, 40, 41, 42, 43, 47, 51, 54, 55, 61, 63, 65, 66, 67, 72, 79, 82, 83, 84, 85, 86], "sampl": [3, 9, 10, 11, 12, 14, 18, 20, 21, 22, 25, 26, 27, 29, 33, 34, 41, 42, 44, 45, 46, 47, 48, 50, 51, 54, 56, 57, 61, 62, 63, 64, 67, 68, 69, 74, 79, 86], "sample_top_p": 48, "samvelyan": [31, 75], "samyak": [31, 75], "sandbox": [50, 51], "sandhini": [31, 75], "sangani": [31, 75], "sanghai": [31, 75], "sanit": 10, "sanjai": [31, 75], "santhanam": [31, 75], "sara": [31, 75], "saraf": [31, 75], "sargun": [31, 75], "sasha": [31, 75], "sastri": [31, 75], "satadru": [31, 75], "satisfactori": [43, 59], "satisfi": 59, "satish": [31, 75], "satterfield": [31, 75], "saunder": [31, 75], "saurabh": [31, 75], "sauvestr": [31, 75], "save": [40, 85], "save_path": 60, "save_step": [60, 92], "sax": [31, 75], "saxena": [31, 75], "scalabl": [2, 15, 51, 59, 62], "scalar": [5, 46, 53, 58, 59], "scale": [2, 4, 18, 19, 26, 27, 31, 36, 46, 47, 48, 49, 50, 51, 54, 59, 72, 75, 84, 85], "scan": 35, "scarciti": 51, "scenario": [13, 26, 51], "schedul": [26, 45], "schelten": [31, 75], "scheme": [46, 56, 91], "school": 15, "schulman": [31, 75], "schwarz": [31, 75], "scialom": [31, 75], "scienc": [11, 26, 45], "scientif": 26, "scope": 44, "score": [11, 44, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 61, 62, 63, 65, 66, 67, 69, 74, 82, 83, 84], "scorer": 51, "scott": [31, 75], "scrape": [3, 38], "scratch": [21, 66, 83, 84], "script": [10, 92], "scy": [28, 31, 51, 75], "sean": [31, 75], "search": [39, 40, 74], "seattl": 81, "second": [1, 3, 8, 9, 24, 26, 33, 39, 43, 44, 51, 56, 62, 73, 89], "secret": [21, 22], "secretli": [31, 75], "secretstorag": 13, "section": [26, 42, 61, 72, 84, 88], "secur": 51, "see": [7, 9, 11, 31, 32, 33, 35, 47, 49, 55, 62, 84], "seed": [8, 14, 18, 24, 25, 26, 27, 51, 67, 68], "seek": 46, "seen": [47, 69], "segment": [15, 46, 90], "seid": [31, 75], "seiji": [31, 75], "select": [7, 9, 20, 26, 29, 34, 38, 39, 40, 41, 44, 46, 47, 48, 53, 56, 58, 74, 79, 82], "selector": 74, "self": [1, 2, 3, 5, 8, 10, 13, 14, 16, 21, 22, 24, 25, 31, 41, 43, 47, 48, 49, 51, 57, 60, 75, 82, 83, 84, 86, 87, 88], "selfattent": 88, "selfinstruct": [18, 27], "seltzer": [31, 75], "semant": [16, 38, 39, 40, 47, 51, 68], "semi": [18, 27], "sen": [31, 75], "send": [35, 56, 82], "sensit": [5, 11, 85, 86], "sent": [26, 44, 82], "sentenc": [1, 2, 3, 8, 24, 26, 45, 62, 90], "seohyun": [31, 75], "separ": [1, 7, 39, 41, 46, 74], "seq_len": [48, 86], "seqlen": [48, 49], "sequenc": [1, 2, 15, 31, 33, 41, 44, 46, 48, 49, 50, 56, 59, 65, 67, 75, 82, 83, 85, 86, 87, 88, 89, 90], "sequenti": [33, 56], "sergei": [31, 75], "seri": [14, 25, 45, 50, 51, 67, 71, 74], "serv": [26, 31, 34, 44, 56, 66, 82], "servic": 50, "set": [1, 4, 5, 7, 8, 9, 11, 12, 15, 18, 19, 20, 24, 26, 27, 29, 33, 34, 36, 38, 41, 42, 43, 44, 46, 47, 48, 50, 51, 56, 57, 58, 61, 65, 66, 67, 68, 74, 79, 82, 83, 84, 88], "setup": [10, 36], "setuptool": 13, "seventh": [31, 75], "sever": [12, 34, 38, 39, 41, 42, 46, 47, 50, 51, 56, 72, 86], "sexist": 61, "sft": [5, 21, 22, 26, 43, 44, 50, 51, 54, 55, 57, 60, 62, 64, 65, 66, 67, 72, 73, 79], "sh": 60, "shah": [31, 75], "shajnfeld": [31, 75], "shake": [31, 75], "shallow": 53, "shang": [31, 75], "shanghaoran": [31, 75], "shankar": [31, 75], "shantanu": [31, 75], "shaoliang": [31, 75], "shape": [35, 48, 49, 84, 86], "sharadh": [31, 75], "sharan": [31, 75], "sharath": [31, 75], "share": [1, 5, 43, 44, 72, 85], "sharegpt": 26, "sharma": [31, 75], "shaun": [31, 75], "shazeer": [31, 75], "sheasha": [31, 75], "shelf": [34, 59, 62], "shellingham": 13, "shen": [31, 75], "sheng": [31, 75], "shengfeng": [31, 75], "shengguang": [31, 75], "shenghao": [31, 75], "shengxin": [31, 75], "shengy": [31, 75], "shepard": [31, 75], "shift": [26, 74], "shiji": [31, 75], "shishir": [31, 75], "shiva": [31, 75], "shojanazeri": [31, 75], "short": [9, 16, 44, 84], "shorter": 34, "shot": [4, 5, 11, 18, 27, 31, 61, 62, 67, 69, 74, 75, 79], "should": [4, 8, 9, 15, 24, 32, 35, 36, 39, 55, 59, 61, 63, 65, 85], "show": [1, 4, 5, 11, 31, 32, 33, 41, 45, 47, 54, 55, 59, 61, 65, 66, 67, 71, 72, 74, 84, 85, 88], "shown": [1, 5, 12, 14, 25, 26, 33, 36, 57, 58, 62, 66, 69], "shruti": [31, 75], "shuai": [31, 75], "shuffl": [20, 29], "shukai": [31, 75], "shun": [31, 75], "shuqiang": [31, 75], "shusheng": [31, 75], "shyam": [31, 75], "si": [31, 75], "sibi": [31, 75], "sida": [31, 75], "siddhartha": [31, 75], "sidestep": 56, "sidorov": [31, 75], "sigler": [31, 75], "sigma": [5, 46, 48, 49, 54, 55, 58, 62, 65, 66, 89], "sigmoid": [48, 49, 54, 65, 89], "signal": [18, 27, 33, 40, 42, 44, 47, 50, 62, 63, 72], "signatur": [12, 16, 26, 39, 41], "signific": [3, 11, 26, 43, 46, 47, 50, 83, 84, 85, 86], "significantli": [1, 8, 11, 14, 24, 25, 28, 34, 40, 41, 43, 46, 47, 50, 55, 61, 66, 71, 74, 85], "silu": [48, 49], "silva": [31, 75], "silveira": [31, 75], "sim": [5, 33, 35, 46, 54, 55, 57, 58, 65, 66, 69, 73, 89], "similar": [4, 7, 11, 18, 27, 31, 38, 39, 47, 51, 61, 63, 74, 79, 83], "similarili": [83, 85], "similarli": [1, 39, 44, 55, 67, 69, 72], "simon": [31, 75], "simpl": [1, 4, 8, 12, 14, 20, 24, 25, 29, 31, 35, 36, 38, 44, 48, 49, 54, 62, 69, 71, 88, 90], "simpler": [2, 33, 54], "simpli": [5, 8, 24, 36, 53, 73, 83], "simplic": [2, 40], "simplifi": [8, 12, 20, 24, 29, 48, 79], "simul": [38, 56, 63], "simultan": [1, 35, 67], "sin": [1, 41, 48, 49, 83, 84, 87, 88], "sinan": [31, 75], "sinc": [1, 2, 33, 36, 39, 42, 48, 49, 51, 54, 55, 57, 61, 62, 65, 82, 84, 85, 86], "sine": 1, "singh": [31, 75], "singhal": [31, 75], "singl": [3, 5, 8, 12, 16, 24, 38, 39, 40, 41, 44, 58, 63, 68, 74, 82], "sinong": [31, 75], "sinusoid": [1, 88], "situat": 82, "six": [13, 20, 29, 47], "size": [2, 3, 4, 19, 26, 41, 43, 45, 48, 49, 50, 57, 59, 66, 82, 83, 84, 85, 86], "sizov": [31, 75], "skill": [15, 19, 41, 51, 67], "skywork": 21, "sl": 61, "slice": 85, "slight": 31, "slightli": [46, 47], "slow": 86, "slowli": [83, 84], "slp": [31, 44, 50, 75, 83, 85, 87], "small": [1, 9, 18, 27, 31, 36, 38, 40, 41, 47, 51, 67, 72, 83, 84, 85, 86, 88], "smaller": [34, 45, 46, 73, 74, 82, 83, 85, 87], "smallest": [3, 38, 48], "smallscal": 74, "smarter": 36, "smith": [31, 75], "smooth": [4, 20, 29], "smother": [31, 75], "snapshot": [38, 61], "sneha": [31, 75], "sniffio": 13, "snippet": [14, 25, 26, 41, 47, 50, 51], "so": [5, 9, 32, 38, 40, 46, 47, 55, 56, 57, 61, 67, 82, 83, 84, 85], "social": [3, 11], "soft": [40, 62, 66], "softmax": [2, 48, 49, 62, 82, 83, 85], "softwar": 26, "soji": [31, 75], "solar": [31, 75], "sole": [1, 33, 46, 59], "solid": 85, "solut": [10, 14, 15, 16, 19, 25, 28, 38, 39, 40, 41, 47, 53, 54, 62, 68, 74, 85, 86, 88], "solv": [10, 11, 12, 15, 16, 31, 34, 38, 39, 40, 41, 47, 72, 73, 74, 75], "solvabl": 16, "some": [1, 2, 8, 24, 31, 38, 40, 42, 46, 47, 53, 56, 59, 65, 69, 82], "someon": 61, "someth": 4, "sometim": [4, 26], "song": [31, 75], "sonia": [31, 75], "sootla": [31, 75], "sort": [47, 48, 56], "soumith": [31, 75], "soumya": [31, 75], "sourc": [3, 7, 12, 16, 20, 26, 29, 41, 42, 44, 47, 48, 50, 51, 65, 72], "space": [3, 20, 29, 39, 40, 87, 88], "span": [11, 15, 31, 36, 41, 51], "spars": [4, 31, 40, 75], "spataru": [31, 75], "speak": 65, "spearman": 53, "special": [11, 31, 46, 47, 48, 50, 69, 74, 82], "special_token": 48, "specif": [4, 5, 8, 20, 24, 26, 29, 31, 33, 34, 40, 41, 44, 47, 48, 50, 51, 54, 55, 61, 65, 66, 67, 74, 82, 83, 84], "specifi": [16, 48, 72], "speckbach": [31, 75], "speed": [5, 44, 58], "spenc": [31, 75], "spencer": [31, 75], "spent": 42, "sphinx": 31, "spisak": [31, 75], "split": [5, 39, 41, 48, 49], "split_experience_batch": 60, "spm": 41, "spot": 11, "spread": 83, "spuriou": 4, "sqlite": 13, "sqrt": [1, 48, 49, 66, 83, 84, 85, 86, 88], "squre": 48, "sravankumar": [31, 75], "src": 92, "srinivasan": [31, 75], "srivastava": [31, 75], "sse": 13, "stabil": [11, 45, 46, 48, 57, 86], "stabl": [10, 12, 34, 50], "stack": [14, 25, 82], "stackexchang": 45, "stage": [2, 41, 43, 44, 46, 50, 51, 57, 66, 72, 83, 84, 92], "stai": 33, "stale": 62, "stand": 31, "standalon": 41, "standard": [2, 15, 16, 18, 27, 34, 35, 38, 41, 42, 47, 48, 50, 51, 55, 56, 57, 59, 62, 63, 66, 74, 82, 91], "star": [26, 73], "starcod": [14, 20, 25, 29, 41], "starcoderdata": [14, 25], "starkli": 11, "start": [5, 18, 20, 27, 29, 31, 32, 34, 39, 40, 41, 47, 48, 54, 56, 58, 65, 67], "start_header_id": 48, "start_po": [48, 49], "starter": 31, "state": [4, 5, 15, 33, 36, 45, 53, 61, 82, 83], "statement": [16, 38, 41], "static": [33, 47, 50], "staticmethod": 48, "statist": 86, "statu": [13, 60], "std": [48, 57, 66, 86], "steadi": 35, "steer": [36, 47, 56, 69], "steerabl": 47, "stefano": [31, 75], "steinhardt": [31, 75], "stem": [11, 50], "sten": [31, 75], "step": [1, 5, 15, 18, 20, 21, 22, 26, 27, 29, 31, 33, 35, 39, 40, 41, 43, 44, 45, 46, 47, 57, 58, 60, 61, 62, 68, 71, 72, 75, 83, 84], "stepbi": 74, "stephan": [31, 75], "stephani": [31, 75], "stephen": [31, 75], "steve": [31, 75], "steven": [31, 75], "still": [4, 36, 38, 42, 44, 54, 62, 84], "stochast": 2, "stoica": [31, 75], "stojkov": [31, 75], "stojnic": [31, 75], "stone": [31, 75], "stop": [35, 46], "stop_token": 48, "store": [31, 51, 65], "str": [48, 65], "straightforward": [2, 7, 15, 33, 47, 59, 65, 72, 79, 83, 84], "straightforwardli": 53, "strateg": [44, 47], "strategi": [26, 34, 41, 43, 44, 46, 50, 53, 60, 69, 73, 83, 85], "stream": 35, "streamlin": [20, 29], "strength": [5, 44, 47, 56, 58, 59], "strict": [18, 27, 48], "strictli": 67, "string": [48, 62, 73], "stringent": 47, "strip": [10, 48], "strong": [43, 44, 53, 59, 66, 72, 74, 83, 84], "stronger": [14, 25, 36, 44, 85], "strongest": 15, "strongli": 61, "structur": [1, 2, 31, 40, 62, 82], "struggl": [4, 34, 66, 72], "stuck": 33, "student": [14, 15, 25, 36, 51], "studi": [4, 18, 27, 35, 36, 50, 56, 59], "style": [11, 41, 47], "su": [31, 75], "sub": [1, 3, 40, 42, 45, 48, 65, 86, 87, 88], "subbiah": [31, 75], "subject": [11, 41], "sublay": 1, "submiss": [38, 39], "submit": [5, 39, 56, 58], "suboptim": [26, 86], "subramanian": [31, 75], "subsequ": [1, 41, 46, 47, 48, 49, 56, 57, 67, 89], "subset": [3, 5, 15, 16, 35], "subspac": 1, "substanti": [4, 8, 20, 24, 29, 36, 57, 59, 73], "substitut": [43, 54, 59, 82], "subtract": 57, "subword": [31, 75, 90], "succ": [5, 54, 65, 66, 69], "succeed": 40, "success": [11, 12, 36, 40, 46, 51, 67, 68], "successfulli": 26, "suchin": [31, 75], "suchir": [31, 75], "sudarshan": [31, 75], "sufeng": [31, 75], "suffer": [44, 72, 73], "suffici": [4, 5, 38, 46, 51, 55, 57, 71, 84], "suffix": 41, "suggest": [4, 34, 51, 54, 55, 59, 62, 89], "suit": 2, "suitabl": [41, 53, 66], "sujoi": [31, 75], "suk": [31, 75], "sum": [1, 33, 44, 48, 53, 56, 57, 82, 88], "sum_": [2, 33, 48, 49, 54, 57, 59, 62, 65, 66, 73, 82, 83, 84, 85, 88, 90], "sumbali": [31, 75], "sumit": [31, 75], "summar": 84, "summari": [3, 62], "summer": [31, 75], "sun": [31, 75], "sungmin": [31, 75], "sunni": [31, 75], "sup": 21, "super": [43, 48, 49, 86], "superalign": 36, "superhuman": 36, "superior": [1, 34, 42, 67], "supervis": [3, 4, 5, 15, 18, 27, 33, 36, 41, 51, 54, 63, 64, 65, 67, 69, 87, 88], "supervison": 36, "supervisor": 36, "supplement": 47, "suppli": 79, "support": [32, 41, 43, 47, 51, 60, 91], "suppos": [53, 59, 82], "suraj": [31, 75], "sure": [8, 24, 41, 61], "surfac": [39, 63, 74], "surpass": [4, 15, 20, 29, 51, 64], "surpris": [5, 47, 57], "surprisingli": 55, "surrog": 57, "surround": [41, 43], "suspect": [1, 61], "sutskev": [31, 75], "swaroop": [31, 75], "swee": [31, 75], "swiglu": [45, 50], "swish": [21, 48, 49], "sy": [31, 75], "sydnei": [31, 75], "symbol": 1, "sympi": 13, "syncheck": 10, "synnaev": [31, 75], "syntact": [38, 47], "syntax": [31, 47, 51], "synthes": [26, 50, 51], "synthesi": [26, 41, 51], "synthet": [14, 25, 47, 50, 51, 64, 68, 69], "system": [4, 15, 26, 31, 44, 47, 48, 56, 72, 75, 83], "systemat": 59, "t": [1, 2, 18, 20, 26, 27, 29, 33, 38, 44, 48, 49, 57, 59, 67, 81, 82, 83, 84, 85, 88], "t1": [48, 86], "t2": [48, 86], "t_": [55, 90], "t_1": 90, "t_2": 90, "t_n": 90, "tabl": [3, 63, 85], "tackl": 39, "taco": 22, "tag": [38, 39, 41, 51, 72], "tail": 51, "tailor": [39, 44, 56], "take": [5, 14, 15, 25, 33, 41, 48, 49, 53, 54, 55, 56, 58, 59, 65, 67, 68, 69, 74, 87, 88, 89], "taken": 33, "tal": [31, 75], "talent": 15, "tamar": [31, 75], "tamara": [31, 75], "tan": [31, 75], "tang": [31, 75], "tao": [31, 75], "tara": [31, 75], "tarek": [31, 75], "target": [2, 39, 47, 48, 59, 61, 65, 74, 79, 82, 84], "task": [1, 3, 4, 5, 8, 9, 11, 12, 14, 16, 19, 24, 25, 26, 33, 34, 36, 38, 40, 41, 43, 44, 47, 51, 57, 59, 61, 62, 66, 72, 74, 83, 84, 86, 93], "task_id": 10, "taskspecif": 3, "tau": [33, 56, 73], "taught": 22, "taylor": [31, 75], "td": 57, "teach": [36, 46], "teacher": [14, 25, 26], "team": [5, 58], "teboul": [31, 75], "technic": [31, 36, 75], "techniqu": [8, 20, 21, 22, 24, 29, 33, 34, 36, 40, 46, 47, 66, 83, 84], "teddi": [31, 75], "telecommun": 91, "tell": [36, 54], "temper": 38, "temperatur": [13, 26, 38, 39, 44, 48, 50, 56, 79, 83], "templat": [14, 18, 20, 25, 26, 27, 29, 92], "ten": [4, 11, 41, 46, 51, 84], "tend": [56, 62], "tensor": [48, 49, 84], "teo": [31, 75], "term": [2, 5, 12, 40, 42, 44, 46, 47, 50, 54, 57, 59, 74, 84, 88, 89], "termin": 33, "terri": [5, 53, 54, 65, 66], "test": [3, 4, 5, 10, 11, 12, 13, 15, 16, 19, 26, 35, 36, 38, 39, 40, 41, 42, 44, 47, 50, 51, 67, 72, 73, 74, 79], "tester": 47, "testuggin": [31, 75], "text": [1, 2, 3, 4, 5, 8, 12, 16, 24, 31, 32, 33, 35, 41, 42, 44, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 69, 73, 74, 79, 82, 83, 84, 85, 89, 90, 91], "text_complet": 48, "textbf": 33, "textbook": 11, "textual": 2, "tezak": [31, 75], "th": [20, 29, 55, 57, 67, 82, 83, 84, 85], "than": [1, 3, 4, 7, 8, 10, 14, 18, 24, 25, 26, 27, 34, 36, 38, 39, 40, 41, 43, 45, 47, 53, 54, 55, 61, 62, 63, 65, 66, 74, 79, 82, 83, 84, 85], "thank": 59, "thattai": [31, 75], "thei": [3, 5, 14, 25, 31, 36, 38, 41, 46, 47, 66, 67, 68, 74, 82, 85, 86, 89, 91], "them": [2, 5, 18, 27, 36, 39, 40, 42, 43, 47, 50, 63, 65, 68, 72, 82, 85, 86, 88], "themselv": [5, 36, 58], "theoret": [26, 47, 55], "therebi": [44, 82], "therefor": [14, 18, 25, 27, 39, 42, 43, 44, 46, 55, 57, 59, 66, 74, 84, 85], "theta": [2, 5, 33, 41, 46, 48, 49, 53, 54, 55, 56, 57, 58, 69, 73, 83, 84, 87, 88], "theta_": [41, 48, 49, 55, 57, 83, 84, 87, 88], "theta_0": [48, 49, 84], "theta_1": [48, 49, 84], "theta_d": 83, "theta_j": [48, 49], "thi": [1, 2, 3, 4, 5, 8, 11, 12, 14, 15, 18, 19, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 67, 68, 69, 72, 73, 74, 79, 82, 83, 84, 85, 86, 88], "thibaut": [31, 75], "thilo": [31, 75], "thing": [32, 61], "think": [61, 72, 82, 84], "third": [1, 9], "thirti": [31, 75], "thoma": [31, 75], "thompson": 56, "thorough": [43, 47], "thoroughli": 44, "thorp": [31, 75], "those": [1, 5, 7, 31, 34, 38, 42, 44, 46, 47, 50, 56, 68, 74, 82], "though": 12, "thought": [11, 44, 47, 61, 62, 79], "thousand": [4, 38, 39, 41, 46, 47, 84], "three": [4, 5, 12, 13, 16, 26, 33, 36, 41, 47, 51, 54, 58, 59, 62, 65, 66, 74, 85, 89], "threshold": [47, 48, 64, 69], "through": [2, 11, 14, 20, 25, 29, 47, 48, 49, 50, 51, 53, 59, 62, 65, 69, 72, 83, 84, 85, 87, 88, 89], "throughout": [47, 72], "thu": [20, 29, 33, 35, 36, 46, 48, 49, 53, 56, 63, 65, 67, 73, 83], "tian": [31, 75], "tianh": [31, 75], "tianhang": [31, 75], "tianhao": [31, 75], "tianjian": [31, 75], "tianjun": [31, 75], "tianyi": [31, 75], "tianyu": [31, 75], "tiberiu": [31, 75], "tier": 26, "tild": [46, 56, 57], "tillet": [31, 75], "tim": [31, 75], "time": [1, 7, 13, 20, 29, 33, 38, 41, 46, 47, 53, 62, 69, 72, 73, 74, 82, 85, 86, 93], "timeout": [13, 51], "timothi": [31, 75], "tindal": [31, 75], "tingyu": [31, 75], "tini": 4, "tip": 50, "titl": [54, 91], "tk": 13, "tl": 3, "tm": [31, 47, 75], "to_remov": 65, "tobia": [31, 75], "todai": 36, "todor": [31, 75], "togeth": [1, 18, 27, 38, 39, 47, 61, 62], "tok": 48, "tok_embed": [48, 49], "token": [1, 2, 3, 5, 13, 21, 22, 33, 38, 41, 42, 43, 45, 46, 47, 49, 51, 53, 55, 57, 58, 59, 62, 73, 74, 81, 83, 84, 85, 86, 87, 88, 90], "token1": 82, "token2": 82, "token3": 82, "token_logprob": 48, "tokenization\u4e4b\u540e": 81, "tokenization\u7b97\u6cd5\u4e4b\u4e00": 81, "tokenize\u7684\u610f\u601d\u662f\u628a\u4e00\u4e2a\u53e5\u5b50\u6216\u957f\u8bed\u6599\u5206\u6210token": 81, "token\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u7b26\u53f7": 81, "token\u6570": 81, "token\u66ff\u6362\u5b83\u4eec": 81, "toler": 74, "tolist": 48, "tom": [31, 75], "tomli": 13, "tomlkit": 13, "tone": 47, "tong": [31, 75], "tongliang": [31, 75], "too": [36, 51, 84], "tool": [7, 15, 31, 38, 47, 90], "toolbelt": 13, "top": [3, 14, 25, 26, 32, 34, 38, 44, 46, 47, 48, 49, 53, 66, 69, 82], "top_p": 48, "topic": [19, 43, 47], "topk": [44, 82], "topp": 13, "torabi": [31, 75], "torch": [13, 48, 49, 82, 84, 86], "toreproduc": 7, "torr": [31, 75], "total": [12, 14, 18, 25, 27, 35, 39, 42, 43, 44, 46, 57, 82, 85], "total_len": 48, "touret": [31, 75], "toutanova": [31, 75], "touvron": [31, 75], "toward": [18, 27, 31, 34, 63, 69, 73, 75, 82], "toxic": [5, 61], "tqdm": 13, "trace": 73, "traceback": 48, "track": 65, "tractabl": 36, "tradeoff": 59, "tradit": [4, 11], "train": [1, 5, 8, 14, 15, 18, 19, 24, 25, 27, 31, 33, 34, 36, 38, 39, 41, 42, 46, 48, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 74, 75, 82, 83, 84, 85, 86, 90], "train_bash": 92, "train_batch_s": 60, "train_ppo": 60, "train_ppo_llama": 60, "trainabl": 93, "trainer": 60, "trainin": 42, "training_step_actor": 60, "training_step_crit": 60, "trajectori": [33, 72], "transduct": 1, "transfer": [87, 88], "transform": [1, 3, 4, 31, 38, 41, 43, 44, 45, 46, 47, 50, 75, 83, 84, 85, 86, 87, 88, 89, 93], "transformerblock": [2, 48, 49], "transit": [33, 73], "translat": [1, 3, 31, 47, 72, 75], "transmit": 56, "transpos": [48, 49], "trap": 73, "treat": [32, 48, 50, 66, 84], "tremend": 43, "trend": 35, "tri": 67, "trick": [40, 60, 83], "trigonometr": [48, 49, 83, 84], "trigonometri": 47, "trillion": [42, 44, 50, 51], "trim": 39, "triplet": [2, 41, 59, 65], "triton": 13, "triu": [48, 49], "trl": 60, "troubl": 61, "trough": 41, "trove": 13, "true": [46, 48, 49, 60, 86, 92], "truth": [15, 16, 36, 42, 43, 44, 47, 50, 53, 54, 65, 68], "try": [7, 8, 24, 40, 48, 51, 55, 67, 79], "trylimit": 40, "tsimpoukelli": [31, 75], "tu": [31, 75], "tuan": [31, 75], "tufanov": [31, 75], "tune": [4, 5, 7, 8, 18, 20, 24, 27, 29, 31, 47, 51, 54, 55, 57, 59, 60, 63, 64, 65, 67, 73, 74, 75, 79, 83, 84], "tupl": [48, 49, 84], "turbo": [7, 14, 25, 42, 48], "turn": [41, 47, 48, 74, 84], "tutori": 51, "two": [1, 2, 9, 18, 20, 27, 29, 31, 32, 33, 34, 36, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 53, 54, 55, 56, 59, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 82, 83, 84, 85, 89], "tworek": [31, 75], "tx": 56, "txt": [8, 24], "type": [7, 8, 13, 18, 20, 24, 26, 27, 29, 36, 38, 41, 44, 45, 48, 49, 59, 61, 62, 65, 66, 72, 84], "type_a": [48, 49, 84, 86], "typeddict": 48, "typescript": 47, "typic": [3, 4, 34, 36, 45, 47, 55, 56, 57, 59, 61, 63, 69, 82, 83, 84, 87, 88], "tzdata": 13, "tzook": [31, 75], "u": [2, 3, 4, 9, 28, 31, 38, 39, 44, 54, 59, 65, 66, 68, 74, 75, 82, 85], "u_": [2, 82], "u_1": 2, "u_i": 2, "u_n": 2, "uation": 9, "uiuc": 10, "ujjwal": [31, 75], "uk": 85, "ultim": [20, 29, 36, 47, 82], "ultrafeedback": 53, "unambigu": 16, "unbalanc": 82, "unbias": [12, 48, 57, 86], "uncertainti": 56, "unchang": 73, "unclear": [36, 73], "uncur": 68, "under": [11, 14, 25, 33, 34, 43, 54, 55], "underli": 84, "underload": 44, "underset": [46, 53, 56, 57, 69, 73], "understand": [2, 11, 28, 31, 32, 36, 40, 41, 47, 51, 75, 79], "undesir": 33, "unembed": [5, 43, 58], "uneth": 61, "unexpect": 72, "unicod": [31, 51, 75], "unicode\u548cutf": 91, "unicode\u5f53\u524d\u9ed8\u8ba4\u7684\u7248\u672c\u662fuc": 91, "unicode\u662fascii": 91, "unicode\u7684\u5b57\u7b26\u96c6\u8303\u56f4": 91, "unicode\u76f4\u63a5\u517c\u5bb9\u4e86\u521d\u671fascii": 91, "unifi": [20, 29], "uniform": [41, 65, 74, 83, 86], "uniformli": [3, 56, 74], "union": 48, "uniqu": [40, 41, 43], "unit": [12, 15, 26, 41, 46, 47, 50, 51, 83, 84], "univers": [28, 31, 75, 84], "unk": 65, "unknown": [54, 65], "unlabel": [2, 69], "unleash": [28, 51], "unlik": [15, 26, 83], "unlikelihood": 59, "unlimit": 3, "unlock": [41, 43], "unmerg": 60, "unpack": [21, 22], "unsatisfactori": 59, "unsupervis": [3, 31, 36, 51, 75], "unsur": 46, "until": [18, 27, 39, 40, 47, 56, 65, 82], "untruth": 5, "unveil": [20, 29], "up": [2, 4, 5, 8, 18, 19, 24, 26, 27, 39, 46, 47, 56, 58, 59, 61, 74, 83, 84], "up_proj": 43, "upasani": [31, 75], "updat": [35, 39, 44, 51, 60, 83], "upgrad": [10, 20, 29], "upon": [34, 44, 50, 51], "upper": [34, 84], "upweight": 33, "uq": 85, "uritempl": 13, "url": [31, 75], "urllib3": 13, "us": [1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15, 18, 20, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 79, 83, 84, 85, 86, 87, 88, 89], "usag": [20, 26, 29, 47], "use_fast_token": 92, "user": [5, 7, 8, 24, 26, 36, 41, 46, 47, 48, 58, 66, 67, 68], "usual": [1, 18, 27, 47, 54, 57, 65, 68, 82, 85, 87, 88], "usuni": [31, 75], "uszkoreit": [31, 75], "ut": 59, "util": [11, 20, 29, 40, 41, 44, 46, 47, 50, 51, 54, 61, 66, 72], "uv": 85, "uw_": 2, "v": [1, 33, 48, 49, 53, 59, 63, 85, 87, 88, 89], "v0": [7, 10, 60], "v1": [14, 25, 46], "v2": [21, 22, 44, 46, 82, 85], "v3": [22, 46, 72], "v5": [41, 46], "v_": [53, 57], "v_head_dim": 43, "valid": [4, 5, 15, 18, 19, 26, 27, 38, 40, 44, 50, 51, 54, 58, 66, 69], "valko": [31, 75], "valu": [1, 5, 15, 26, 35, 38, 44, 48, 49, 51, 55, 57, 58, 59, 62, 65, 69, 82, 83, 84, 88], "valuabl": [87, 88], "valueerror": 48, "van": [31, 75], "vandenhend": [31, 75], "vanish": 56, "var": [48, 86], "vare": 35, "vari": [3, 11, 20, 29, 35, 39, 43, 45, 82, 83], "variabl": [51, 86, 87, 88], "varianc": [12, 33, 46, 50, 56, 57, 86], "variant": [2, 41, 48, 49, 67], "variat": [11, 31, 38, 48, 49, 63, 89], "varieti": [35, 47], "variou": [9, 14, 18, 20, 25, 27, 29, 35, 42, 45, 47, 50, 51, 61, 67, 83, 84], "varun": [31, 75], "vasic": [31, 75], "vast": 51, "vasuden": [31, 75], "vaswani": [31, 75], "vaughan": [31, 75], "vdot": [87, 88], "ve": 48, "vector": [1, 2, 15, 41, 48, 49, 53, 55, 56, 83, 84, 85, 86, 88, 89], "vedant": [31, 75], "vedanuj": [31, 75], "veeraraghavan": [31, 75], "velich": [31, 75], "verb": [8, 24], "verbos": 53, "verdict": 68, "veri": [5, 12, 35, 36, 38, 47, 51, 58, 61, 63, 83, 84], "verif": [47, 51, 72], "verifi": [7, 15, 16, 31, 44, 72, 73, 75], "verma": [31, 75], "versatil": [31, 75], "version": [1, 5, 11, 14, 25, 26, 39, 41, 43, 46, 47, 48, 49, 54, 68, 72, 79, 89, 92], "versu": 79, "veryeasyhack": 61, "via": [5, 26, 31, 34, 40, 41, 47, 53, 54, 64, 68, 71, 72, 75], "vibhor": [31, 75], "victoria": [31, 75], "view": [48, 49, 84], "view_as_complex": [48, 49, 84], "view_as_r": [48, 49, 84], "vignesh": [31, 75], "vijai": [31, 75], "viktor": [31, 75], "vinai": [31, 75], "vincent": [31, 75], "vineet": [31, 75], "violat": 63, "virgini": [31, 75], "virk": [31, 75], "virtualenv": 13, "vish": [31, 75], "vishal": [31, 75], "visual": [8, 24], "vlad": [31, 75], "vladan": [31, 75], "vladimir": [31, 75], "vllm": 10, "vocab": 55, "vocab_s": [43, 48, 49], "vocabulari": [43, 50, 55], "vogeti": [31, 75], "vontimitta": [31, 75], "voss": [31, 75], "vote": 74, "vrane": [31, 75], "vsp": [1, 2, 31, 50, 75, 85], "vw_": 1, "vyatskov": [31, 75], "v\u00edtor": [31, 75], "w": [1, 5, 48, 49, 53, 54, 55, 58, 65, 67, 68, 81, 85, 87, 88, 89], "w1": [48, 49], "w2": [48, 49, 89], "w3": [48, 49], "w_": [1, 2, 33, 48, 49, 88, 89, 93], "w_1": 51, "w_1s_1": 51, "w_2": 1, "w_e": 2, "w_n": 51, "w_ns_n": 51, "w_p": 2, "w_y": 2, "wa": [2, 3, 9, 16, 20, 26, 29, 38, 39, 41, 42, 44, 46, 51, 67, 73], "wai": [12, 15, 18, 27, 33, 34, 36, 40, 51, 61, 65, 79, 82, 83, 84], "waitlist": 5, "wake": [8, 24], "wan": [31, 75], "wang": [31, 75], "want": [5, 18, 27, 33, 58, 65, 79, 83, 84], "warmup": [26, 45], "wast": 38, "wastag": 82, "wasti": [31, 75], "wavecod": [31, 51, 75], "wavelength": [1, 83], "wcg19": [31, 50, 75], "we": [1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 15, 16, 18, 20, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 79, 82, 83, 84, 85, 87, 88, 89, 93], "weak": [21, 59, 84], "weaker": [14, 25], "weakli": [35, 36], "web": [3, 42, 65], "webpag": [3, 58], "websit": [26, 45, 50, 51], "webtext": 3, "webtext2": 35, "wehrstedt": [31, 75], "wei": [31, 75], "weigh": 54, "weight": [1, 2, 26, 33, 38, 43, 45, 46, 48, 49, 51, 54, 59, 62, 82, 84, 86, 88, 89, 93], "weissman": [31, 75], "weiwei": [31, 75], "welind": [31, 75], "well": [1, 2, 7, 33, 50, 55, 59, 61, 83, 84], "wellcalibr": 61, "wen": [31, 75], "wenbin": [31, 75], "wenchen": [31, 75], "weng": [31, 75], "wenhan": [31, 75], "wenwen": [31, 75], "wenxiang": [31, 75], "wenyin": [31, 75], "were": [12, 44, 46, 74], "west": [21, 22], "what": [8, 24, 36, 42, 45, 56, 84], "wheel": 13, "when": [1, 3, 5, 8, 15, 18, 24, 26, 27, 31, 32, 33, 35, 36, 39, 40, 47, 48, 49, 53, 55, 56, 57, 59, 63, 66, 68, 73, 74, 79, 82, 86, 88, 89], "where": [1, 2, 5, 12, 15, 18, 20, 27, 28, 29, 33, 34, 35, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 68, 71, 79, 82, 83, 84, 85, 86, 87, 88, 89, 93], "wherea": [31, 33, 38], "wherebi": 46, "wherein": 59, "wherev": 44, "whether": [18, 27, 31, 36, 38, 42, 44, 48, 51, 59, 62, 68, 72, 73, 74, 82], "which": [1, 2, 3, 4, 5, 8, 9, 11, 12, 14, 15, 16, 18, 20, 24, 25, 27, 29, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 61, 62, 63, 65, 66, 67, 68, 69, 72, 74, 79, 82, 83, 84, 86, 87, 88, 89, 93], "while": [1, 3, 4, 5, 14, 15, 25, 33, 35, 39, 40, 41, 43, 44, 47, 50, 51, 55, 56, 57, 61, 65, 66, 67, 73, 79, 82, 83, 84, 88, 90], "white": [12, 31, 75], "whiten": 46, "whitman": [31, 75], "whitnei": [31, 75], "who": 15, "whole": 59, "whose": [5, 48, 51], "why": [36, 40], "wide": [2, 5, 11, 35, 36, 39, 47, 53, 57, 66], "widespread": [31, 75], "width": 48, "wifi": 61, "wiki": 45, "wikipedia": [3, 45], "wildchat": 26, "william": [31, 75], "win": [56, 62, 65, 67, 68], "window": [2, 44, 47], "winner": 68, "winter": [31, 75], "wise": [2, 43, 44, 48, 49, 61, 84, 86, 89], "within": [44, 47, 51, 61, 68, 69, 72, 83, 84, 86], "without": [3, 9, 33, 36, 51, 53, 54, 55, 56, 58, 61, 68, 72, 74, 88], "wizard": [21, 22], "wk": [48, 49], "wo": [48, 49], "wojciech": [31, 75], "wong": [31, 75], "wood": [31, 75], "word": [2, 3, 5, 7, 8, 15, 24, 31, 51, 63, 75, 81, 87, 88, 90], "wordpiece\u6bcf\u6b21\u9009\u62e9\u5408\u5e76\u7684\u4e24\u4e2a\u5b50\u8bcd": 90, "wordpiece\u7b97\u6cd5\u4e5f\u662f\u6bcf\u6b21\u4ece\u8bcd\u8868\u4e2d\u9009\u51fa\u4e24\u4e2a\u5b50\u8bcd\u5408\u5e76\u6210\u65b0\u7684\u5b50\u8bcd": 90, "work": [1, 3, 4, 14, 15, 18, 25, 27, 28, 33, 36, 43, 45, 47, 48, 49, 54, 55, 61, 68, 84, 89], "world": [8, 11, 24], "world_siz": 60, "wors": [65, 79], "worst": [34, 69], "would": [1, 33, 36, 46, 53, 61, 68, 74], "wq": [48, 49], "write": [5, 7, 8, 16, 24, 31, 32, 41, 43, 44, 46, 58, 72, 83, 88], "writer": 15, "written": [5, 12, 15, 18, 27, 31, 32, 61], "wrong": [40, 55, 74, 79], "wrote": [8, 24, 61], "wu": [31, 75], "wv": [48, 49], "wwl": [26, 31, 47, 51, 75], "wx": 93, "wyatt": [31, 75], "x": [1, 2, 5, 9, 33, 41, 46, 48, 49, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 68, 69, 73, 81, 83, 84, 86, 87, 88, 89, 90, 93], "x_": [18, 27, 48, 49, 68, 73, 83, 84, 88], "x_0": [48, 49, 83, 84], "x_1": [1, 48, 49, 59, 64, 73, 83, 84], "x_2": [48, 49, 73], "x_i": [67, 68, 73], "x_m": 59, "x_n": [1, 64], "xavier": [31, 75], "xdxac": 81, "xia": [31, 75], "xiang": [31, 75], "xianji": [31, 75], "xiao": [31, 75], "xiaocheng": [31, 75], "xiaodong": [31, 75], "xiaofang": [31, 75], "xiaohuan": [31, 75], "xiaojian": [31, 75], "xiaolan": [31, 75], "xiaoq": [31, 75], "xide": [31, 75], "xie": [31, 75], "xilun": [31, 75], "xin": [31, 75], "xinbo": [31, 75], "xinfeng": [31, 75], "xingxuan": [31, 75], "xingzhang": [31, 75], "xiong": [31, 75], "xk": [48, 49, 84], "xk_": [48, 49, 84], "xk_out": [48, 49, 84], "xp": 89, "xq": [48, 49, 84], "xq_": [48, 49, 84], "xq_out": [48, 49, 84], "xu": [31, 75], "xuancheng": [31, 75], "xuchao": [31, 75], "xue": [31, 75], "xuewei": [31, 75], "xv": [48, 49, 89], "xw": [48, 49, 89], "xw_": [48, 49, 89], "xw_1": 1, "xx": [10, 22], "xxhash": 13, "xxx": 13, "xz": 13, "x\u4e3a\u5b57\u7b26\u7684unicode\u4e8c\u8fdb\u5236": 91, "y": [2, 5, 33, 46, 48, 49, 53, 54, 55, 56, 58, 59, 62, 64, 65, 66, 68, 73, 81, 83, 86, 90], "y1": 54, "y2": 54, "y3": 54, "y_": [5, 18, 27, 33, 46, 53, 54, 55, 58, 59, 64, 65, 66, 67, 68, 69, 73], "y_1": [1, 5, 54, 59, 62, 66, 69, 73], "y_2": [5, 54, 62, 66, 69, 73], "y_c": 66, "y_i": 73, "y_l": 55, "y_m": 1, "y_n": 59, "y_r": 66, "y_t": 59, "y_w": 55, "yaell": [31, 75], "yamamoto": [31, 75], "yaml": [13, 40], "yan": [31, 75], "yang": [31, 75], "yangyu": [31, 75], "yaniv": [31, 75], "yanjun": [31, 75], "yann": [31, 75], "yao": [31, 75], "yarl": 13, "yarn": 44, "yashesh": [31, 75], "yasmin": [31, 75], "yazdan": [31, 75], "ye": [31, 75], "yeari": [31, 75], "yellow": 12, "yenda": [31, 75], "yi": [31, 75], "yibo": [31, 75], "yichang": [31, 75], "yield": [1, 5, 16, 47, 56, 57, 66, 93], "yifeng": [31, 75], "yilin": [31, 75], "yin": [31, 75], "ying": [31, 75], "yinghai": [31, 75], "yishuji": [31, 75], "yiwen": [31, 75], "yixin": [31, 75], "yml": 13, "yossi": [31, 75], "you": [7, 8, 13, 24, 31, 32, 41, 46, 61, 66, 75, 79], "young": 15, "youngjin": [31, 75], "your": [7, 13, 31, 32, 41, 61, 75], "yu": [31, 75], "yuan": [31, 75], "yuchen": [31, 75], "yue": [31, 75], "yuliang": 22, "yundi": [31, 75], "yune": [31, 75], "yunfei": [31, 75], "yunfeng": [31, 75], "yunlong": [31, 75], "yunlu": [31, 75], "yunu": [31, 75], "yuqiong": [31, 75], "yura": [31, 75], "yuri": [31, 75], "yuvraj": [31, 75], "yuwei": [31, 75], "yuxiang": [31, 75], "yuyao": [31, 75], "yuzi": [31, 75], "yyl": [31, 75, 79], "yz": [31, 51, 75], "yzh": [31, 51, 75], "z": [1, 31, 54, 56, 65, 75, 81, 90], "z_": 65, "z_1": 1, "z_n": 1, "zabdzabac": 81, "zach": [31, 75], "zachari": [31, 75], "zand": [31, 75], "zaremba": [31, 75], "zarov": [31, 75], "zef": [31, 75], "zekun": [31, 75], "zemlyanskii": [31, 75], "zero": [4, 11, 33, 46, 48, 49, 79, 88], "zero_stag": 60, "zeros_lik": 48, "zeyu": [31, 75], "zh": 42, "zha": [31, 75], "zhan": [31, 75], "zhang": [31, 75], "zhao": [31, 75], "zhaoduo": [31, 75], "zhaojian": [31, 75], "zhe": [31, 75], "zhen": [31, 75], "zheng": [31, 75], "zhengx": [31, 75], "zhenru": [31, 75], "zhenyu": [31, 75], "zhiwei": [31, 75], "zhiyu": [31, 75], "zhong": [31, 75], "zhou": [31, 75], "zhoujun": [31, 75], "zhu": [31, 75], "ziegler": [31, 75], "zihan": [31, 75], "zip": [48, 65], "zipp": 13, "zixuan": [31, 75], "zlib": 13, "zlm": [7, 31, 75], "zoe": [31, 75], "zou": [31, 75], "zvyagina": [31, 75], "zy": 81, "zydzyac": 81, "\u00e7elebi": [31, 75], "\u4e00": 91, "\u4e00\u4e2a\u5728\u5f00\u5934": 81, "\u4e00\u822c\u4e0d\u76f4\u63a5\u4f7f\u7528unicod": 91, "\u4e00\u90e8\u5206\u6b63\u8d1f\u62b5\u6d88\u4e00\u90e8\u5206\u632f\u8361": 83, "\u4e00\u95e8\u8bed\u8a00\u4e2d": 81, "\u4e0a\u9762\u4ecb\u7ecd\u4e86\u6587\u5b57\u5b57\u7b26\u6620\u5c04\u4e3aunicode\u5b57\u7b26\u96c6": 91, "\u4e0b\u4e00\u4e2a\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u662f": 81, "\u4e0b\u8f7d": 10, "\u4e0b\u8f7d\u8bc4\u4f30\u6587\u4ef6": 13, "\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50": 81, "\u4e0b\u9762\u7684\u793a\u4f8b\u5c06\u89e3\u91ca": 81, "\u4e0d\u4f1a\u51fa\u73b0\u53ea\u5b66\u90a3\u4e9b\u7b80\u5355\u4e14": 57, "\u4e0d\u4f1a\u5355\u72ec\u51fa\u73b0": 81, "\u4e0d\u8868\u793a\u5176\u4ed6\u8bed\u8a00": 91, "\u4e0d\u8db3\u7684\u5728\u9ad8\u4f4d\u75280\u8865\u5145": 91, "\u4e0ebpe\u7684\u6700\u5927\u533a\u522b\u5728\u4e8e": 90, "\u4e0ebpe\u7b97\u6cd5\u7c7b\u4f3c": 90, "\u4e14\u5047\u8bbe\u5404\u4e2a\u5b50\u8bcd\u4e4b\u95f4\u662f\u72ec\u7acb\u5b58\u5728\u7684": 90, "\u4e24\u4e2a\u5b57\u6bb5": 10, "\u4e2a": 81, "\u4e2a\u4e0d\u540c\u7684token": 81, "\u4e2a\u5355\u8bcd": 81, "\u4e2a\u5b50\u8bcd\u7ec4\u6210": 90, "\u4e2d": 10, "\u4e2d\u4f7f\u7528\u4e86\u4e0a\u8ff0\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53": 81, "\u4e2d\u51cf\u5c11\u8ba1\u6570": 81, "\u4e2d\u5b58\u5728": 81, "\u4e2d\u62bd\u53d6\u51fa\u6765": 13, "\u4e2d\u6587": 91, "\u4e2d\u7684": 10, "\u4e2d\u76f8\u5bf9\u597d\u7684": 57, "\u4e2d\u88ab\u9996\u6b21\u63d0\u51fa": 81, "\u4e3a\u4e86\u4ee5\u6700\u6709\u6548\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u6599\u5e93": 81, "\u4e3a\u4e86\u5408\u5e76": 81, "\u4e3a\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3": 81, "\u4e3a\u4e86\u672c\u6587\u7684\u7b80\u5355\u8d77\u89c1": 81, "\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4": 91, "\u4e3a\u4e86\u89e3\u51b3": 91, "\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u8c03\u7528": 10, "\u4e3a\u53e5\u5b50\u7684\u4e00\u4e2a\u5206\u8bcd\u7ed3\u679c": 90, "\u4e3a\u8865\u5145": 91, "\u4e3e\u4f8b1": 91, "\u4e3e\u4f8b2": 91, "\u4e4b\u524d": 91, "\u4e5f\u53eb\u5b57\u7b26\u96c6": 91, "\u4e5f\u5c31\u662f\u4e24\u5b50\u8bcd\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u5173\u8054\u6027": 90, "\u4e5f\u5c31\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u770b\u6210\u4e00\u4e2atoken": 81, "\u4e5f\u5c31\u662f\u7528\u5b9a\u957f2\u4e2a\u5b57\u8282\u6765\u8868\u793a\u5b57\u7b26": 91, "\u4e5f\u662fnlp\u4e2d\u6700\u91cd\u8981\u7684\u7f16\u7801\u65b9\u5f0f\u4e4b\u4e00": 81, "\u4e5f\u80fd\u88ab\u7b97\u4f5c\u5b57\u7b26\u5bf9\u7684\u4e00\u90e8\u5206": 81, "\u4e8c\u8fdb\u5236\u5c31\u662f01000001": 91, "\u4e8c\u8fdb\u5236\u5c31\u662f110000": 91, "\u4eca\u5929\u5c31\u6765\u4e86\u89e3\u4e0b\u5b57\u7b26\u5728\u8ba1\u7b97\u673a\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f": 91, "\u4ece": 13, "\u4ece\u6700\u957f\u5230\u6700\u77ed": 81, "\u4ece\u800c\u6211\u4eec\u77e5\u9053\u5269\u4f59\u7684": 81, "\u4ed6\u4eec\u5177\u6709\u6700\u5927\u7684\u4e92\u4fe1\u606f\u503c": 90, "\u4ee5\u4e2d\u6587": 91, "\u4f1a\u4e0d\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5f88\u6162": 57, "\u4f1a\u4e0d\u4f1a\u66f4\u597d": 57, "\u4f20\u5165\u89e3\u6790\u540e\u7684\u53c2\u6570": 10, "\u4f3c\u7136\u503c\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a": 90, "\u4f46\u4e00\u4e2a\u8bcd\u5728\u7ed3\u5c3e\u6709\u4e00\u4e2a": 81, "\u4f46\u4ecd\u6709\u53ef\u80fd\u51fa\u73b0\u4e0d\u5728\u91cc\u9762\u7684\u5355\u8bcd": 81, "\u4f46\u5b83\u5177\u6709\u826f\u597d\u7684\u6027\u80fd": 81, "\u4f46\u6211\u4eec\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u5305\u542b\u8fd9\u4e9b\u5b57\u7b26": 81, "\u4f46\u662funicode\u8fd8\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6269\u5c55\u673a\u5236": 91, "\u4f46\u662f\u5176\u4ed6\u6b27\u6d32\u56fd\u5bb6\u7684\u8bed\u8a00\u6bd4\u5982\u6cd5\u8bed": 91, "\u4f46\u662f\u5b83\u548c\u6c49\u5b57\u7684\u6620\u5c04\u4e0eunicode\u548c\u6c49\u5b57\u7684\u6620\u5c04\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb": 91, "\u4f46\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u5408\u7406\u7684\u7f16\u7801\u65b9\u5f0f": 81, "\u4f4e\u7ef4": 83, "\u4f4e\u9891\u5185\u63d2\u7684\u65b9\u5f0f": 83, "\u4f60\u53ef\u80fd\u4e0d\u6e05\u695awordpiece\u662f\u5982\u4f55\u9009\u53d6\u5b50\u8bcd\u7684": 90, "\u4f7f\u7528\u4e0b\u8ff0\u547d\u4ee4\u8fdb\u884c\u8bc4\u4f30": 13, "\u4f8b\u5982\u5b57\u7b26\u4e32": 10, "\u4f8b\u5982\u7f16\u7801\u5e8f\u5217": 81, "\u4fee\u6539\u540e\u663e\u793a\u7ed3\u679c\u5982\u4e0b": 91, "\u5047\u8bbe\u5355\u8bcd\u7684\u5e8f\u5217\u662f": 81, "\u5047\u8bbe\u53e5\u5b50": 90, "\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8bed\u6599\u5e93": 81, "\u5047\u8bbe\u6211\u4eec\u6709\u9700\u8981\u7f16\u7801": 81, "\u5047\u8bbe\u628a\u76f8\u90bb\u4f4d\u7f6e\u7684x\u548cy\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 90, "\u5047\u8bbe\u8fd9\u4e9b\u8bcd\u51fa\u73b0\u7684\u9891\u7387\u5982\u4e0b": 81, "\u50cf": 81, "\u5141\u8bb8\u8868\u793a\u4e00\u767e\u591a\u4e07\u4e2a\u5b57\u7b26": 91, "\u5168\u7403\u7edd\u5927\u90e8\u5206\u5b57\u7b26\u7684\u5b57\u7b26\u96c6": 91, "\u5176\u4e2d": [13, 81], "\u5176\u4e2d\u4e0d\u6b62utf": 91, "\u5176\u4e2d\u4f1a\u6d89\u53ca\u5230ascii": 91, "\u5176\u4e2d\u5305\u542b\u5355\u8bcd": 81, "\u5176\u4ed6\u5b57\u8282": 91, "\u5176\u4ed6\u8bed\u8a00": 91, "\u5176\u4ed6\u8bed\u8a00\u53ef\u80fd\u6709\u6240\u4e0d\u540c": 81, "\u51fa\u73b0\u4e86": 81, "\u51fd\u6570": 10, "\u51fd\u6570\u5462": 10, "\u51fd\u6570\u5feb\u901f\u8f6c\u6362\u4e3a\u547d\u4ee4\u884c\u63a5\u53e3": 10, "\u51fd\u6570\u7684\u53c2\u6570\u5217\u8868": 10, "\u5206\u522b\u6765\u81ea": 10, "\u5219\u53e5\u5b50": 90, "\u521d\u59cbtoken\u5c06\u662f\u6240\u6709\u5b57\u7b26\u548c": 81, "\u524d\u9762\u5168\u90e8\u586b\u51450": 91, "\u5269\u4e0b\u7684\u552f\u4e00\u5b57\u8282\u5bf9\u662f": 81, "\u52a0\u4e0a\u63a7\u5236\u7801\u540e\u5bf9\u5e94\u7684utf": 91, "\u5339\u914d": 10, "\u5341\u516d\u8fdb\u5236": 91, "\u5355\u5b57\u8282256\u4e2a\u5b57\u7b26\u80af\u5b9a\u6ca1\u6cd5\u5b8c\u5168\u8868\u793a": 91, "\u5373": [10, 81], "\u538b\u7f29": 81, "\u539f\u672c\u5728\u4f4e\u7ef4\u5ea6\u4e0a": 83, "\u53c2\u6570\u4e3a": 13, "\u53cd\u5411\u6267\u884c\u4ee5\u4e0a\u8fc7\u7a0b\u5c31\u884c\u4e86": 81, "\u53cd\u590d\u8fed\u4ee3\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6": 81, "\u53ea\u9700\u8981\u4e00\u4e2a\u5b57\u8282\u8868\u793a": 91, "\u53ea\u9700\u8981\u4f7f\u7528\u540e\u97627\u4f4d\u5c31\u8db3\u591f\u4e86": 91, "\u53ef\u4ee5\u4f7f\u75281": 91, "\u5404\u4e2a\u56fd\u5bb6\u4fbf\u7740\u624b\u81ea\u5df1\u56fd\u5bb6\u8bed\u8a00\u7684\u7f16\u7801": 91, "\u5408\u5e76\u505c\u6b62token": 81, "\u5408\u5e76\u540e\u4ea7\u751f\u7684\u5b50\u8bcd\u8bb0\u4e3az": 90, "\u5408\u5e76\u5b57\u7b26\u53ef\u4ee5\u8ba9\u4f60": 81, "\u5408\u5e76\u5b83\u4eec": 81, "\u540c\u7406\u8fd8\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u7279\u6709\u5b57\u7b26\u96c6": 91, "\u548c": [10, 81, 83], "\u548cascii\u7684\u76ee\u7684\u4e00\u6837": 91, "\u548cascii\u7801\u4e00\u81f4": 91, "\u56de\u8f6613\u7b49\u7b49\u4e00\u4e9b\u952e\u76d8\u4e0a\u6240\u89c1\u7684\u7b26\u53f7": 91, "\u56e0\u4e3a": 81, "\u56e0\u4e3a\u4eba\u7c7b\u8bed\u8a00\u4e5f\u7ecf\u5e38\u4ee5\u5355\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u4ea4\u6d41": 81, "\u56e0\u4e3a\u5b83\u4eec\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 81, "\u56e0\u4e3a\u6211\u4eec\u7edf\u8ba1\u76f8\u90bb\u5b57\u7b26\u5bf9\u65f6\u4e0d\u80fd\u628a\u5206\u522b\u4f4d\u4e8e\u4e24\u4e2a\u5355\u8bcd\u4e2d\u7684\u5b57\u7b26\u5bf9\u7b97\u8fdb\u53bb": 81, "\u56e0\u4e3a\u6ca1\u6709\u51fa\u73b0\u591a\u6b21\u7684\u5b57\u8282\u5bf9": 81, "\u56e0\u6b64": 81, "\u56e0\u6b64bpe\u4e5f\u662f\u5178\u578b\u7684\u57fa\u4e8esubword\u7684tokenization\u7b97\u6cd5": 81, "\u56e0\u6b64\u6211\u4eec\u53ef\u91c7\u7528\u9ad8\u9891\u5916\u63a8": 83, "\u56e0\u6b64\u6211\u4eec\u5c06\u7528\u4e00\u4e2a\u65b0\u5b57\u8282": 81, "\u56e0\u6b64\u6211\u4eec\u6ca1\u6709\u5c06\u5b83\u4eec\u5408\u5e76": 81, "\u5728": 10, "\u5728finest\u548clowest\u4e24\u4e2a\u8bcd\u4e2d": 81, "\u5728unicode\u8bde\u751f": 91, "\u5728\u5b9e\u8df5\u4e2d": 81, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d": 81, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 81, "\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0": 81, "\u5728\u8ba1\u7b97\u673a\u4e2d\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u4f4d0\u548c1\u6765\u5b58\u50a8\u7684": 91, "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u65f6\u5019\u9700\u8981\u5728\u8fd9\u4e2a\u62e5\u6709\u51e0\u4e07\u4e2a\u5355\u8bcd\u7684\u5217\u8868\u4e0a\u8ba1\u7b97\u4e00\u4e2a\u6982\u7387\u5206\u5e03": 81, "\u5728\u8fd9\u91cc": 81, "\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u6bd4\u8f83token\u7684\u9891\u7387\u5927\u5c0f\u6765\u7a77\u5c3d\u6bcf\u4e00\u79cd\u53ef\u80fd": 81, "\u5927\u5199\u5b57\u6bcda\u5bf9\u5e94\u7684ascii\u7801\u662f65": 91, "\u5927\u5bb6\u90fd\u77e5\u9053\u7535\u8111\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u548c\u5b58\u50a8\u7684": 91, "\u5927\u6982\u5c31\u662f\u8bf4ascii\u662f\u7f8e\u56fd\u4fe1\u606f\u4ea4\u6362\u6807\u51c6\u4ee3\u7801": 91, "\u5927\u90e8\u5206\u662f2\u5b57\u8282": 91, "\u5982\u4f55\u6765\u8868\u793aunicod": 91, "\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u5c31\u662f\u8981\u8868\u793a\u4e00\u4e2a\u5b57\u7b26\u8fd8\u662f\u8fde\u7eed\u7684\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 91, "\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u8bfb\u61c2unicod": 91, "\u5982\u4f55\u8bfb\u53d6unicode\u5b57\u7b26\u96c6": 91, "\u5982\u4f55\u9009\u62e9\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 90, "\u5982\u679c\u4f1a\u7559\u4e0b\u51e0\u4e2a\u5b50\u4e32": 81, "\u5982\u679c\u5728\u4f4e\u7ef4\u5ea6\u8fdb\u884c\u5185\u63d2": 83, "\u5982\u679c\u6309\u7167unicode\u7684\u65b9\u5f0f\u7edf\u4e00\u7528\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 91, "\u5982\u679c\u7b97\u6cd5\u770b\u5230token": 81, "\u5b57\u6bcd": 91, "\u5b57\u7b26\u7801\u5c31\u662f\u5bf9\u5e94\u7684unicod": 91, "\u5b57\u7b26\u7801\u7ec4\u6210": 91, "\u5b57\u7b26\u7b49": 81, "\u5b57\u7b26\u96c6\u5373\u662f\u6587\u5b57\u7b26\u53f7\u548c\u4e8c\u8fdb\u5236\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 91, "\u5b57\u8282\u957f\u5ea6": 91, "\u5b66\u540c\u4e00\u4e2a": 57, "\u5b83\u4e0d\u80fd\u88ab\u8fdb\u4e00\u6b65\u538b\u7f29": 81, "\u5b83\u4eec\u51fa\u73b0\u4e86": 81, "\u5b83\u4eec\u7ecf\u5e38\u5728\u8bed\u6599\u4e2d\u4ee5\u76f8\u90bb\u65b9\u5f0f\u540c\u65f6\u51fa\u73b0": 90, "\u5b83\u53ea\u6709\u4e00\u4e2a": 81, "\u5b83\u5728": 81, "\u5b83\u5c31\u4f1a\u77e5\u9053\u5b83\u662f": 81, "\u5b83\u7684\u4f5c\u7528\u662f\u628a\u5404\u4e2a\u8bed\u8a00\u7684\u5b57\u7b26\u6620\u5c04\u4e3a\u4e8c\u8fdb\u5236": 91, "\u5b83\u7684\u7279\u70b9\u662f\u53d8\u957f\u7f16\u7801": 91, "\u5b83\u9075\u5faa\u4e00\u79cd\u8d2a\u5a6a\u7684\u7b56\u7565\u6765\u5c3d\u53ef\u80fd\u53d6\u5f97\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848": 81, "\u5b8c\u5168\u517c\u5bb9ascii": 91, "\u5bf9\u4e0eascii\u7a7a\u95f4\u6d6a\u8d39": 91, "\u5bf9\u4e8e\u5355\u5b57\u8282\u7684\u5b57\u7b26": 91, "\u5bf9\u4e8e\u53e5\u5b50": 90, "\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u662f\u6781\u5927\u7684\u6d6a\u8d39": 91, "\u5bf9\u4e8e\u672a\u77e5": 81, "\u5bf9\u4e8e\u82f1\u6587\u56fd\u5bb6\u6765\u8bf4\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528": 91, "\u5bf9\u4e8e\u9700\u8981n\u4e2a\u5b57\u8282\u7684\u5b57\u7b26": 91, "\u5bf9\u5e94\u7684unicode\u5b57\u7b26\u96c6\u662f4e00": 91, "\u5bf9\u5e94\u7684unicode\u662fu": 91, "\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a01000001": 91, "\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u7f16\u7801\u7684\u8fc7\u7a0b\u8fd8\u662f\u6bd4\u8f83\u7b80\u5355\u7684": 81, "\u5bf9\u7528\u4f4e\u7ef4\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u95f4\u7684\u80fd\u529b\u5f71\u54cd\u66f4\u5927": 83, "\u5bfb\u627e\u6700\u5e38\u51fa\u73b0\u7684\u5b57\u8282\u5bf9": 81, "\u5c06": 10, "\u5c06\u53c2\u6570\u503c\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u7c7b\u578b": 10, "\u5c31\u4ee3\u8868\u4e00\u4e2a\u8bed\u8a00\u5355\u4f4d": 81, "\u5c31\u50cf\u5355\u8bcd": 81, "\u5c31\u662f\u4f7f\u7528\u63a7\u5236\u7801": 91, "\u5c31\u80fd\u4ee3\u8868\u4e86\u6240\u6709\u952e\u76d8\u4e0a\u7684\u666e\u901a\u7b26\u53f7": 91, "\u5c31\u8bde\u751f\u4e86utf": 91, "\u5c3d\u7ba1\u8d2a\u5a6a": 81, "\u5e03\u5c14\u503c\u7b49": 10, "\u5e74\u53d1\u8868\u7684\u6587\u7ae0": 81, "\u5e76\u4e00\u6b21\u53c8\u4e00\u6b21\u5730\u6267\u884c\u76f8\u540c\u7684\u8fed\u4ee3": 81, "\u5e76\u4e14\u6211\u4eec\u7684\u5b50\u5b57\u7b26\u4e32\u5c06\u88ab\u66ff\u6362\u4e3a\u6211\u4eectoken\u5217\u8868\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684token\u7ec4\u5408": 81, "\u5e76\u4e14\u7531utf": 91, "\u5e76\u5c06\u5176\u91cd\u547d\u540d\u4e3a": 10, "\u5e76\u5c06\u5176\u9891\u7387\u8bb0\u4e3a": 81, "\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230token\u5217\u8868\u4e2d": 81, "\u5e76\u5c06\u65b0\u8bcd\u7684token\u6dfb\u52a0\u5230\u6211\u4eec\u7684token\u5b57\u5178\u4e2d\u4ee5\u5907\u5c06\u6765\u7528\u5230": 81, "\u5e76\u5c1d\u8bd5\u4f7f\u7528\u8fd9\u4e9btoken\u66ff\u6362\u7ed9\u5b9a\u5355\u8bcd\u5e8f\u5217\u4e2d\u7684\u5b50\u5b57\u7b26\u4e32": 81, "\u5e76\u88ab\u4f5c\u4e3a\u673a\u5668\u7ffb\u8bd1\u7b49\u4e3b\u6d41nlp\u4efb\u52a1\u7684\u9996\u9009tokenize\u65b9\u6cd5\u4e4b\u4e00": 81, "\u5e76\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2atoken\u51fa\u73b0\u7684\u9891\u7387": 81, "\u5e93": 10, "\u5f00\u5934": 91, "\u5f00\u59cb": 81, "\u5f53\u524d\u5206\u8bcd\u4e0b\u53e5\u5b50s\u7684\u4f3c\u7136\u503c\u53ef\u4ee5\u8868\u793a\u4e3a": 90, "\u5f53\u7136": 81, "\u5f53\u8fd0\u884c\u811a\u672c\u65f6": 10, "\u610f\u5473\u7740\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u53f7\u53d8\u5316\u975e\u5e38\u8fc5\u901f": 83, "\u6211\u4eec\u4f1a\u5c06": 81, "\u6211\u4eec\u5148\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5b83\u7684\u6838\u5fc3\u601d\u60f3": 81, "\u6211\u4eec\u53ef\u4ee5\u770b\u5230": 81, "\u6211\u4eec\u53ef\u4ee5\u9012\u5f52\u5730\u4f7f\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u5c06": 81, "\u6211\u4eec\u5c06tokenized\u597d\u7684\u5355\u8bcd\u4fdd\u5b58\u5728\u5b57\u5178\u4e2d": 81, "\u6211\u4eec\u5c06\u4ece\u7b2c\u4e8c\u5e38\u89c1\u7684\u6807\u8bb0": 81, "\u6211\u4eec\u5c06\u5b57\u7b26\u89c6\u4e3a\u4e0e\u5b57\u8282\u7b49\u4ef7": 81, "\u6211\u4eec\u5c06\u5b83\u4eec\u5408\u5e76\u4ee5\u5f62\u6210\u4e00\u4e2a\u65b0\u7684token": 81, "\u6211\u4eec\u5c06\u6bcf\u4e2a\u5355\u8bcd\u62c6\u5206\u4e3a\u5b57\u7b26\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684\u51fa\u73b0\u6b21\u6570": 81, "\u6211\u4eec\u5c06\u7528unknown": 81, "\u6211\u4eec\u5c06\u7ee7\u7eed\u6267\u884c\u6b64\u5408\u5e76\u6b65\u9aa4": 81, "\u6211\u4eec\u5c06\u88ab\u89e3\u7801\u4e3a": 81, "\u6211\u4eec\u5c06\u904d\u5386\u6211\u4eec\u5728\u8bed\u6599\u5e93\u4e2d\u627e\u5230\u7684\u6240\u6709token": 81, "\u6211\u4eec\u5c06\u904d\u5386\u6240\u6709token": 81, "\u6211\u4eec\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8bcd\u6c47\u5217\u8868\u662f\u5f88\u5927\u7684": 81, "\u6211\u4eec\u5e94\u7528\u4e0a\u8ff0\u7f16\u7801\u65b9\u6cd5\u5bf9\u65b0\u8bcd\u8fdb\u884ctoken": 81, "\u6211\u4eec\u5fc5\u987b\u7b80\u5355\u5730\u5c06\u6240\u6709token\u8fde\u63a5\u5728\u4e00\u8d77\u4ee5\u83b7\u5f97\u6574\u4e2a\u5355\u8bcd": 81, "\u6211\u4eec\u603b\u5171\u6709": 81, "\u6211\u4eec\u6709\u4e00\u4e2a\u9891\u7387\u4e3a": 81, "\u6211\u4eec\u6765\u67e5\u51fa\u8fd9\u51e0\u4e2a\u5b57\u5bf9\u5e94\u7684utf": 91, "\u6211\u4eec\u73b0\u5728\u5c06\u5408\u5e76token": 81, "\u6211\u4eec\u73b0\u5728\u6709": 81, "\u6211\u4eec\u73b0\u5728\u6709\u4e86": 81, "\u6211\u4eec\u73b0\u5728\u770b\u5230\u5b57\u8282\u5bf9": 81, "\u6211\u4eec\u7684\u6570\u636e\u73b0\u5728\u5df2\u8f6c\u6362\u4e3a": 81, "\u6211\u4eec\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6ca1\u6709\u770b\u5230\u7684\u8bcd": 81, "\u6211\u4eec\u770b\u5230\u5b57\u8282\u5bf9": 81, "\u6211\u4eec\u77e5\u9053": 81, "\u6211\u4eec\u8ba1\u7b97\u8fd9\u4e9b\u8bcd\u5728\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387": 81, "\u6211\u4eec\u8fd8\u5c06\u4ece\u5355\u4e2atoken": 81, "\u6211\u4eec\u90fd\u4e86\u89e3\u4e00\u79cd\u6700\u57fa\u672c\u7684token": 81, "\u6216": 81, "\u6216\u8005\u53eb": 91, "\u6240\u4ee5": [81, 90], "\u6240\u4ee5ascii\u7684\u5b57\u7b26": 91, "\u6240\u4ee5\u4ed6\u4eec\u5c31\u628a\u7b2c\u4e00\u4e2a\u7a7a\u95f20\u4f7f\u7528\u4e86\u8d77\u6765": 91, "\u6240\u4ee5\u4ed6\u4eec\u628a\u6bcf\u4e2a\u5b57\u8282\u7684\u7b2c\u4e00\u4f4d\u7f6e\u7f6e0": 91, "\u6240\u4ee5\u4f7f\u7528\u4e24\u4e2a\u5b57\u8282\u5df2\u7ecf\u8db3\u591f": 91, "\u6240\u4ee5\u5165\u53e3\u662f": 10, "\u6240\u4ee5\u5bf9\u5e94\u7684utf": 91, "\u6240\u4ee5\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u5168\u7403\u7edf\u4e00\u7684\u7f16\u7801\u89c4\u5219\u53ebunicod": 91, "\u6240\u4ee5\u6211\u4eec\u4e0d\u5bf9\u5b83\u8fdb\u884c\u7f16\u7801": 81, "\u6240\u4ee5\u6211\u4eec\u6709": 81, "\u6240\u4ee5\u8fd9\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898": 91, "\u628a": 10, "\u628a\u5b83\u653e\u5728\u672c\u5730": 13, "\u63a5\u4e0b\u6765": 81, "\u63a7\u5236\u7801\u5c31\u662f\u544a\u8bc9\u8ba1\u7b97\u673a\u5f53\u524d\u662f\u5355\u5b57\u8282\u8fd8\u662f\u591a\u5b57\u8282": 91, "\u653e\u5165\u7528\u6237\u4e3b\u76ee\u5f55\u4e0b\u7684": 10, "\u6563\u5ea6\u76f4\u63a5\u653e\u5728": 57, "\u6570\u5b57\u548c\u5b57\u6bcd\u90fd\u672a\u4e71\u7801": 91, "\u6570\u636e\u7684\u538b\u7f29": 81, "\u6587\u4ef6": 10, "\u6587\u4ef6\u4e2d\u6709\u5982\u4e0b\u914d\u7f6e": 10, "\u6587\u4ef6\u653e\u5165\u6b64\u76ee\u5f55\u5e76\u91cd\u547d\u540d\u4e3a": 10, "\u659c\u4f53": 91, "\u65b0": 81, "\u65b0\u5efa\u4e00\u4e2ahtml\u8f93\u5165": 91, "\u65cb\u8f6c\u5f97\u8d8a\u591a": 83, "\u65cb\u8f6c\u5f97\u8d8a\u5c11": 83, "\u65cb\u8f6c\u89d2\u5ea6\u8f83\u5927": 83, "\u65e0\u8bba\u5982\u4f55": 81, "\u65e0\u8bba\u662fascii\u7f16\u7801\u8fd8\u662futf": 91, "\u65e5\u6587": 91, "\u65f6": 83, "\u662f\u4e00\u79cd\u7b80\u5355\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5": 81, "\u662f\u4ee3\u7801\u7247\u6bb5": 13, "\u662f\u4f7f\u7528": 10, "\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684sub": 81, "\u662f\u7684": 81, "\u666e\u901a\u7b26\u53f7\u7684\u5b57\u7b26\u96c6": 91, "\u66ff\u6362\u5b83": 81, "\u6700\u5e38\u51fa\u73b0": 81, "\u6700\u5e38\u89c1\u7684\u5e26\u6709": 81, "\u6700\u7ec8": 81, "\u6700\u7ec8\u5bfc\u81f4": 83, "\u6709\u4e00\u79cd\u7f16\u7801\u65b9\u5f0f\u80fd\u5927\u5927\u51cf\u5c0ftoken": 81, "\u6709\u4ec0\u4e48\u7528": 10, "\u6709\u5f88\u591a\u9ad8\u9891\u7ef4\u5ea6\u8f6c\u4e86\u5f88\u591a\u5708": 83, "\u672a\u63d0\u53ca\u7684\u4f4d\u4f7f\u7528\u5bf9\u5e94\u7684unicode\u8865\u5145": 91, "\u6765\u505a\u4e00\u4e2a\u5c0f\u5b9e\u9a8c\u5e76\u4e14\u9a8c\u8bc1\u4e0b": 91, "\u6765\u8bf4": 91, "\u67e5\u770b\u5176\u4ed6token": 81, "\u6807\u8bb0\u4ee5\u6807\u8bc6\u5355\u8bcd\u8fb9\u754c\u80fd\u591f\u8ba9\u7b97\u6cd5\u77e5\u9053\u6bcf\u4e2a\u5355\u8bcd\u7684\u7ed3\u675f\u4f4d\u7f6e": 81, "\u6807\u8bb0\u7684\u96c6\u5408": 81, "\u6a21\u4eff\u663e\u8457\u6027": 36, "\u6b21": 81, "\u6b27\u6d32\u90e8\u5206\u8bed\u8a00\u5b57\u6bcd\u7684\u5b57\u7b26\u96c6": 91, "\u6b64\u65f6\u53e5\u5b50": 90, "\u6bd4\u5982utf": 91, "\u6bd4\u5982\u4e2d\u56fd1980\u5e74\u53d1\u884c\u4e86gb2312\u4ee5\u53ca\u540e\u9762\u51fa\u73b0\u5b83\u7684\u6269\u5c55\u7248\u672cgbk": 91, "\u6bd4\u5982\u5728ascii\u4e2d": 91, "\u6bd4\u5982\u5927\u5199\u5b57\u6bcda": 91, "\u6bd4\u5982\u6c49\u5b57": 91, "\u6bd4\u5982\u6c49\u5b57\u4e00\u5728unicode\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662f4e00": 91, "\u6bd4\u5982\u82f1\u6587\u5b57\u6bcda\u5bf9\u5e94\u7684unicode\u662fu": 91, "\u6bd4\u5982\u8bf4\u4e2d\u6587": 91, "\u6c49\u5b57": 91, "\u6c49\u5b57\u7684\u5b57\u7b26\u96c6": 91, "\u6ca1\u6709": 57, "\u6d4f\u89c8\u5668\u6253\u5f00\u540e\u663e\u793a\u6b63\u5e38": 91, "\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7": 81, "\u7136\u540e\u6211\u4eec\u4f7f\u7528chrome\u7684charset\u63d2\u4ef6\u6765\u4fee\u6539\u5f53\u524d\u9875\u9762\u89e3\u7801\u7684\u5b57\u7b26\u96c6": 91, "\u7136\u800c": 81, "\u73b0\u5728\u6211\u4eec\u53d1\u73b0": 81, "\u73b0\u5728\u6211\u4eec\u5c06\u6700\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u5408\u5e76\u6210\u4e00\u4e2atoken": 81, "\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u89e3\u7801\u6211\u4eec\u7684\u793a\u4f8b": 81, "\u751f\u6210\u5f85\u8bc4\u4f30\u7684\u6587\u4ef6": 13, "\u7528\u6700\u5c11\u7684token\u6765\u8868\u793a\u8bed\u6599\u5e93": 81, "\u7528\u6765\u8868\u793a\u7535\u8111\u548c\u5176\u4ed6\u7535\u4fe1\u8bbe\u5907\u7684\u6587\u672c": 91, "\u7531": 90, "\u7531m\u4e2a\u5b50\u8bcd\u7ec4\u6210": 90, "\u7531\u4e8eascii\u8868\u793a\u7684\u8303\u56f4\u6709\u9650": 91, "\u7531\u4e8e\u6211\u4eec\u603b\u5171\u6709": 81, "\u7684": [10, 81], "\u7684\u4f18\u52bf": 57, "\u7684\u5b57\u7b26\u91cf\u5df2\u7ecf\u8db3\u4ee5\u7528\u4e8e\u5168\u7403\u4e3b\u8981\u8bed\u8a00\u7684\u5927\u591a\u6570\u5b57\u7b26": 91, "\u7684\u5b57\u8282\u5bf9\u662f": 81, "\u7684\u60c5\u51b5": 57, "\u7684\u6548\u679c": 57, "\u7684\u6570\u636e": 81, "\u7684\u65b0token": 81, "\u7684\u6838\u5fc3\u673a\u5236": 10, "\u7684\u7b2c\u4e00\u5b57\u8282\u5168\u662f0": 91, "\u7684\u8bed\u8a00\u6a21\u578b\u4f3c\u7136\u503c\u7b49\u4ef7\u4e8e\u6240\u6709\u5b50\u8bcd\u6982\u7387\u7684\u4e58\u79ef": 90, "\u7684\u9891\u7387\u4e3a": 81, "\u7684\u9891\u7387\u51cf\u5c11": 81, "\u76ee\u5f55\u4e0b": 13, "\u76f4\u5230\u8fbe\u5230\u6211\u4eec\u9884\u5148\u8bbe\u7f6e\u7684token\u6570\u9650\u5236\u6216\u8fed\u4ee3\u9650\u5236": 81, "\u76f8\u6bd4": 57, "\u76f8\u90bb\u5b57\u8282\u5bf9": 81, "\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u5728bpe\u4e2d\u770b\u4f5c\u76f8\u90bb\u5b57\u8282\u5bf9": 81, "\u7701\u8d44\u6e90": 57, "\u770b\u5230\u8fd9\u91cc": 90, "\u770b\u5b8c\u4e0b\u9762\u5b8c\u6574\u7684\u8fed\u4ee3\u8fc7\u7a0b": 81, "\u770b\u770b\u6211\u4eec\u6700\u7ec8\u7684token\u5217\u8868": 81, "\u771f\u5b9e\u7684": 59, "\u77e5\u9053\u4e86\u7f16\u7801\u7684\u539f\u7406\u540e\u81ea\u7136\u80fd\u60f3\u5230\u7684\u5c31\u662f\u6587\u672c\u7f16\u7801\u548c\u89e3\u7801\u6240\u4f7f\u7528\u7684\u5b57\u7b26\u96c6\u4e0d\u540c": 91, "\u786e\u4fdd\u6700\u5e38\u89c1\u7684\u8bcd\u5728token\u5217\u8868\u4e2d\u8868\u793a\u4e3a\u5355\u4e2atoken": 81, "\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230": 81, "\u7a76\u7adf\u8c03\u7528\u7684\u662f\u4ec0\u4e48\u51fd\u6570": 10, "\u7a7a\u95f4\u6781\u5927\u6d6a\u8d39": 91, "\u7b2cn": 91, "\u7b2c\u4e00\u4e2a\u5b57\u8282": 91, "\u7b2c\u4e00\u4e2a\u5b57\u8282\u7684\u7b2c\u4e8c\u4e2a0": 91, "\u7b2c\u4e8c\u9ad8\u9891\u7387\u6807\u8bb0\u662f": 81, "\u7b49\u8bcd\u4e4b\u95f4\u7684\u533a\u522b": 81, "\u7b97\u6cd5\u7684\u4e0b\u4e00\u6b65\u662f\u5bfb\u627e\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9": 81, "\u7b97\u6cd5\u7684\u4e3b\u8981\u76ee\u6807": 81, "\u7c7b\u4f3c\u5730": 10, "\u7f16\u7801\u4e3a": 81, "\u7f16\u7801\u672c\u8eab\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u8f83\u9ad8": 81, "\u7f16\u7801\u7c7b\u578b": 91, "\u8001\u89c4\u77e9": 81, "\u800cwordpiece\u9009\u62e9\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6700\u5927\u7684\u76f8\u90bb\u5b50\u8bcd\u52a0\u5165\u8bcd\u8868": 90, "\u800c\u4e0d\u662f": 81, "\u800c\u4e14\u8fc7\u5927\u7684token\u5217\u8868\u5341\u5206\u5f71\u54cd\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6": 81, "\u800c\u5728gb2312\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662fd2bb": 91, "\u800c\u662f\u5c06\u5b83\u4ee5utf": 91, "\u800c\u6c49\u5b57\u4e00\u4e8c\u4e09\u4e71\u7801\u4e86": 91, "\u800c\u7f55\u89c1\u7684\u8bcd\u88ab\u5206\u89e3\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2asubword": 81, "\u80fd\u591f\u6e05\u695a\u5730\u7406\u89e3wordpiece\u5728\u5408\u5e76\u8fd9\u4e00\u6b65\u662f\u5982\u4f55\u4f5c\u51fa\u9009\u62e9\u7684": 90, "\u80fd\u591f\u7cbe\u7ec6\u5730\u533a\u5206\u76f8\u90bb\u4f4d\u7f6e": 83, "\u82e5\u4f7f\u7528\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f": 81, "\u82f1\u6587\u5b57\u6bcd": 91, "\u83b7\u53d6\u6a21\u578b\u7684": 10, "\u8461\u8404\u7259\u8bed\u7b49\u65e0\u6cd5\u7528127\u4e2a\u5b57\u7b26\u8868\u793a\u5b8c\u5168": 91, "\u8868\u793a\u5b50\u8bcd": 90, "\u8981\u89e3\u7801": 81, "\u89c4\u52191": 91, "\u89c4\u52192": 91, "\u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570": 10, "\u8ba1\u7b97": 83, "\u8ba1\u7b97\u673a\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u662f\u6309\u7167\u4e00\u4e2a\u5b57\u8282\u7684\u5927\u5c0f\u6765\u8bfb\u53d6\u8bc6\u522b\u7684": 91, "\u8ba1\u7b97\u673a\u6309\u7167\u5b57\u8282\u6765\u8bfb\u53d6\u6570\u636e\u65f6": 91, "\u8ba1\u7b97\u673a\u662f\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u8868\u793a\u7684\u662f\u4ec0\u4e48\u610f\u601d\u5462": 91, "\u8ba9\u6211\u4eec\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0\u4e00\u4e2a\u7279\u6b8a\u7684\u7ed3\u675f\u6807\u8bb0": 81, "\u8ba9\u6211\u4eec\u73b0\u5728\u505c\u6b62\u8fed\u4ee3\u5e76": 81, "\u8ba9\u6211\u4eec\u73b0\u5728\u8003\u8651": 81, "\u8ba9\u6211\u4eec\u7528": 81, "\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\u6765\u4e86\u89e3\u4e00\u4e0b\u5b83\u7684nlp\u7248\u672c": 81, "\u8bcd": 81, "\u8bf4\u660e": 91, "\u8bf4\u660eunicode\u548cgbk\u90fd\u5411\u4e0b\u517c\u5bb9\u4e86ascii": 91, "\u8c03\u7528": 10, "\u8d8a\u8fd1": 83, "\u8d8a\u8fdc": 83, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f0100": 91, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f100": 91, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f19968": 91, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f65": 91, "\u8f93\u51fa\u6587\u4ef6": 10, "\u8fd8\u6709\u5176\u4ed6\u7f16\u7801\u65b9\u5f0f": 91, "\u8fd8\u6709\u7a7a\u683c32": 91, "\u8fd9\u4e00\u95ee\u9898": 91, "\u8fd9\u4e24\u4e2a\u8bcd\u90fd\u6709\u4e00\u4e2a\u5171\u540c\u7684": 81, "\u8fd9\u4e2a\u4e8c\u8fdb\u5236\u670915\u4f4d": 91, "\u8fd9\u4e2a\u8bcd\u7684token": 81, "\u8fd9\u4e5f\u662f": 81, "\u8fd9\u53ea\u662f\u82f1\u8bed\u7684\u7528\u6cd5": 81, "\u8fd9\u5b8c\u5168\u7b49\u540c\u4e8e127\u4f4d\u6700\u521d\u7684ascii\u7801": 91, "\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u9891\u7387\u8ba1\u6570\u5c06\u5728\u6bcf\u4e2a\u5408\u5e76\u6b65\u9aa4\u540e\u53d1\u751f\u53d8\u5316": 81, "\u8fd9\u662f\u66f4\u65b0\u540e\u7684\u8868\u683c": 81, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u67e5\u770b\u6bcf\u4e2a\u5b57\u7b26\u5e76\u627e\u5230\u9891\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u914d\u5bf9": 81, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u7406\u89e3": 81, "\u8fd9\u6837\u7684token\u5c06\u88ab\u4e0d\u540c\u5730\u5904\u7406": 81, "\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e4b\u4e3a": 83, "\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f\u5341\u5206\u7b26\u5408\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef": 81, "\u8fd9\u91cc": [10, 90], "\u8fd9\u91cc\u4fee\u6539\u4e3agbk": 91, "\u8fd9\u91cc\u7b80\u5355\u4ecb\u7ecd\u4e0b\u8fd9\u51e0\u79cd\u7f16\u7801\u65b9\u5f0f\u7684\u533a\u522b": 91, "\u8fdc\u7a0b\u8870\u51cf\u66f2\u7ebf\u5982\u4e0b": 83, "\u8fed\u4ee3": 81, "\u901a\u5e38\u6709\u51e0\u4e07\u5230\u51e0\u5341\u4e07\u91cf\u7ea7\u7684\u5355\u8bcd\u6570": 81, "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5": 90, "\u90a3\u4e48\u4eba\u4eec\u80fd\u8bc6\u522b\u7684\u6587\u5b57\u548c\u8ba1\u7b97\u673a\u4e2d\u7684\u4e8c\u8fdb\u5236\u5fc5\u7136\u5b58\u5728\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 91, "\u90a3\u4e48\u9762\u5bf9\u5168\u4e16\u754c\u8fd9\u4e48\u591a\u8bed\u8a00": 91, "\u90a3\u5982\u4f55\u628a\u538b\u7f29\u7684\u7f16\u7801\u590d\u539f\u5462": 81, "\u90a3\u5c31\u662f\u672c\u6587\u5373\u5c06\u4ecb\u7ecd\u7684byte": 81, "\u90a3\u6837\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u6050\u6016\u7684": 81, "\u90a3\u82f1\u6587\u5b57\u7b26": 91, "\u90e8\u5206\u9891\u7387\u4f4e": 83, "\u90e8\u5206\u9891\u7387\u9ad8": 83, "\u90fd\u4e00\u6837": 91, "\u91cc\u548c\u653e\u5728": 57, "\u91cc\u7684\u533a\u522b": 57, "\u95f4\u76f8\u4e92\u9694\u5f00": 57, "\u963f\u62c9\u4f2f\u6570\u5b570\u5bf9\u5e94\u7684ascii\u7801\u662f48": 91, "\u963f\u62c9\u4f2f\u6570\u5b57\u548c\u82f1\u6587\u5b57\u6bcd": 91, "\u968f\u673a\u6027\u5f88\u5927": 83, "\u968f\u7740\u8ba1\u7b97\u673a\u5728\u5168\u7403\u7684\u53d1\u5c55\u548c\u666e\u53ca": 91, "\u9700": 10, "\u9700\u52a0\u4e0a": 10, "\u9700\u8981\u4ece": 13, "\u9700\u8981\u81f3\u5c112\u4e2a\u5b57\u8282\u8868\u793a": 91, "\u975e\u5e38\u91cd\u8981": 81, "\u9996\u5148\u6765\u660e\u786e\u4e00\u4e0b\u57fa\u7840\u6982\u5ff5": 81, "\u9996\u5148\u770b\u4e0bwiki\u5bf9\u5b83\u7684\u5b9a\u4e49": 91, "\u9ad8\u4f4d\u4ee5": 91, "\u9ad8\u4f4d\u524dn\u4f4d\u4e3a": 91, "\u9ad8\u7684": 57, "\u9ad8\u7ef4": 83, "\u9ad8\u9891\u4fe1\u606f\u7684\u635f\u5931": 83, "\u9ad8\u9891\u7ef4\u5ea6\u5c11\u4f4e\u9891\u7ef4\u5ea6\u591a": 83, "\ud835\udc41": 56}, "titles": ["Base", "Attention Is All You Need", "GPT", "GPT2", "GPT3", "InstructGPT", "Benchmarks", "Alignment Benchmarks", "Code Alpaca", "CRUXEval", "EvalPlus", "General Benchmarks", "HumanEval", "LiveCodeBench", "Magicoder", "Math &amp; Science Benchmarks", "MBPP", "RewardBench", "SELF-INSTRUCT", "TACO", "WizardCoder", "Contents", "Contents", "Data", "Code Alpaca", "Magicoder", "OpenCoder", "SELF-INSTRUCT", "UNICODER", "WizardCoder", "Introduction", "Markdown Files", "Notebooks with MyST Markdown", "GOLD", "Evaluation of LLMs Should Not Ignore Non-Determinism", "Scaling Laws for Neural Language Models", "Weak to Strong Generalization", "Models", "AlphaCode", "AlphaCode 2", "AlphaCodium", "Code Llama", "DeepSeek-Coder-V2", "DeepSeek-V2", "DeepSeek V3", "Llama", "Llama 2", "Llama 3", "Llama3", "Llama 3 Source Code", "Qwen 2.5", "Qwen2.5-Coder", "Preference Optimization", "ArmoRM-MoE", "DPO", "DPOP", "Efficient Exploration for LLMs", "Group Relative Policy Optimization", "Instruct GPT", "Aligning Language Models with Judgments", "OpenRLHF", "Constitutional AI: Harmlessness from AI Feedback", "RLAIF vs. RLHF", "RLCD", "RS-DPO", "RSO", "Secrets of RLHF in Large Language Models: Reward Modeling", "Self-Rewarding Language Models", "Self-Taught Evaluators", "West-of-N", "Reasoning", "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "DeepSeek-R1", "Training Language Models to Self-Correct via Reinforcement Learning", "Let\u2019s Verify Step by Step", "References", "SFT", "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED", "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold", "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "Techniques", "Byte Pair Encoding (BPE)", "DeepSeekMoE", "Extending context window of LLMs", "Extending context window of large language models via position interpolation", "Multi-Head Latent Attention", "Normalization", "RoPE", "Rotary Positional Embeddings (RoPE)", "SwiGLU", "WordPiece, ULM and SentencePiece", "ASCII,UNICODE,UTF8", "Llama Factory", "LORA", "OpenRLHF"], "titleterms": {"": 74, "1": 53, "16": 91, "2": [39, 41, 46, 50, 53], "2d": [87, 88], "3": [47, 49], "32\u7b49": 91, "5": [50, 51], "500": 15, "8": 91, "A": 51, "AT": 77, "Not": 34, "The": [33, 40, 53, 79], "abil": [67, 79], "ablat": 85, "absolut": 88, "accuraci": 79, "activ": [48, 49, 56, 74], "adapt": 66, "add": 32, "addit": 40, "aggreg": 53, "aha": 72, "ai": [61, 62], "algorithm": [33, 56, 65, 67, 72], "align": [7, 34, 42, 43, 59, 67], "all": [1, 72, 77], "almost": 77, "alpaca": [8, 24], "alphacod": [38, 39], "alphacodium": 40, "an": [32, 56], "analyz": 66, "annot": 68, "appendix": 54, "approach": [3, 4, 38, 45, 65, 88], "architectur": [1, 4, 43, 44, 45, 50, 56], "arena": 7, "armorm": 53, "ascii": 91, "assess": 56, "attent": [1, 48, 49, 85], "augment": 79, "averag": 47, "awar": 83, "background": [83, 84, 88], "balanc": 82, "base": [0, 50, 51, 72, 74], "basic": [35, 44], "batch": 86, "batchnorm": 48, "benchmark": [6, 7, 11, 15], "better": 66, "between": 85, "bpe": 81, "byte": 81, "cach": 85, "capabl": 47, "case": [87, 88], "cell": 32, "chain": 71, "chart": 35, "chat": 47, "chatformat": 48, "citat": 31, "classif": [18, 27], "cluster": [38, 39], "code": [8, 10, 20, 24, 29, 40, 41, 47, 49], "coder": [42, 51], "cold": 72, "collaps": 73, "collect": [42, 46, 74], "commun": 82, "comparison": 85, "composit": [26, 51], "compress": 85, "comput": 35, "concept": 40, "consider": 82, "constitut": 61, "construct": [43, 44, 68], "content": [21, 22], "context": [41, 44, 83, 84], "contextwindow": 83, "contrast": 59, "control": 47, "correct": [10, 12, 73], "count": [35, 79], "creat": 32, "creation": 67, "critiqu": 61, "cruxev": 9, "data": [8, 18, 23, 24, 26, 27, 35, 42, 43, 44, 45, 46, 47, 51, 66, 74, 77, 78, 79], "dataset": [3, 4, 5, 35, 38, 41, 58], "decod": [1, 2], "decontamin": [26, 51], "decoupl": 85, "deepseek": [42, 43, 44, 72], "deepseekmo": 82, "deriv": 54, "design": 40, "detail": [5, 14, 25, 26, 60], "determin": 34, "devic": 82, "dialog": 47, "differ": 66, "direct": [31, 47, 54, 84], "discuss": 43, "distanc": 83, "divers": 66, "dot": 1, "dpo": [54, 55, 64], "dpop": 55, "drop": 82, "dynam": 83, "effect": 34, "effici": [56, 78, 83], "eight": 78, "elicit": 71, "embed": [1, 35, 83, 84, 85, 88], "empir": [35, 56], "encod": [1, 81], "enn": 56, "epistem": 56, "estim": 56, "evalplu": 10, "evalu": [4, 10, 13, 14, 20, 25, 29, 34, 38, 39, 43, 44, 50, 51, 62, 68], "evol": [20, 29], "evolut": 72, "exampl": 32, "experi": [3, 67, 84], "experiment": [5, 34, 42, 56, 67], "expert": [53, 82], "explor": 56, "extend": [83, 84], "extens": [44, 83], "extrapol": 84, "factor": [34, 79], "factori": 92, "failur": 55, "feed": 1, "feedback": [61, 62], "feedforward": [48, 49], "ffn": 89, "file": 31, "filter": [18, 27, 38, 39], "fine": [2, 38, 39, 41, 42, 43, 44, 46, 50, 58, 68, 72, 82], "finetun": [18, 27, 47], "flip": 66, "flow": 40, "fold": 78, "follow": [18, 27, 67], "form": [87, 88], "format": 47, "formul": [87, 88], "forward": 1, "framework": [2, 33], "frequenc": 83, "from": [14, 25, 33, 59, 61, 62], "full": 34, "fullest": 66, "function": [12, 48, 49], "gate": 89, "gb2312": 91, "gbk\u7b49\u5176\u4ed6\u7f16\u7801": 91, "gener": [11, 18, 27, 34, 36, 48, 74, 87, 88], "glu": 89, "gold": 33, "gpqa": 15, "gpt": [2, 58], "gpt2": 3, "gpt3": 4, "gqa": 85, "gradient": [33, 54], "grain": 82, "group": 57, "grpo": 57, "gsm8k": 15, "hard": 7, "harmless": 61, "head": [1, 85], "high": [5, 83], "how": [34, 66], "human": [46, 66], "humanev": [10, 12], "hyper": 43, "i": [1, 31, 34, 73, 77], "identif": [18, 27], "ifev": 7, "ignor": 34, "ii": 73, "impact": 66, "implement": [14, 25, 60, 84], "incorpor": 59, "incorrect": 78, "infil": 41, "infinit": 35, "influenc": 34, "inform": 83, "initi": [67, 68, 73], "input": [2, 3], "insight": 40, "instal": 13, "instanc": [18, 27], "instruct": [14, 18, 20, 25, 26, 27, 28, 29, 41, 50, 51, 58, 67, 68], "instructgpt": 5, "interpol": [83, 84], "interpret": 53, "introduct": [14, 25, 30, 36, 41, 45, 59, 63, 84], "isol": 82, "iter": [46, 47, 57, 68], "its": 66, "joint": 85, "judgment": [59, 68], "kei": 85, "kv": 85, "label": [62, 66], "languag": [35, 47, 59, 66, 67, 71, 73, 79, 83, 84, 90], "larg": [38, 66, 71, 74, 79, 83, 84], "latent": 85, "law": 35, "layer": 86, "layernorm": 48, "learn": [31, 42, 43, 44, 50, 56, 58, 59, 61, 62, 72, 73, 74, 79], "let": 74, "level": [5, 82], "leverag": 66, "limit": 35, "linear": 89, "livecodebench": 13, "llama": [41, 45, 46, 47, 49, 84, 92], "llama3": 48, "llm": [34, 56, 62, 78, 79, 83], "lm": [18, 27], "load": 82, "local": 83, "long": [41, 44], "lora": 93, "loss": [54, 79, 82, 83], "low": 85, "magicod": [14, 25], "main": 61, "margin": 66, "markdown": [31, 32], "math": [15, 78, 79], "mathemat": 79, "mbpp": [10, 16], "measur": 66, "mechan": 85, "metadata": 32, "method": [5, 61, 68, 74], "methodologi": [5, 36, 58, 62], "mha": 85, "mixtur": [51, 53, 82], "mla": 85, "mle": 33, "mmlu": 11, "mode": 55, "model": [1, 3, 4, 5, 35, 37, 39, 46, 47, 48, 49, 50, 51, 53, 56, 58, 59, 66, 67, 68, 69, 71, 72, 73, 74, 79, 83, 84, 90], "moe": 53, "moment": 72, "more": 31, "mqa": 85, "multi": [1, 44, 53, 73, 85], "myst": [31, 32], "n": [35, 69], "need": [1, 53, 77], "network": [1, 56], "neural": [35, 56], "nlp\u5b9e\u4f8b": 81, "non": [34, 35], "normal": [48, 86], "notebook": 32, "ntk": 83, "object": 53, "off": 33, "offlin": 50, "onli": 2, "onlin": 50, "ood": 74, "open": [14, 25], "opencod": 26, "openrlhf": [60, 94], "optim": [45, 47, 52, 54, 57], "orient": [40, 72], "orm": 74, "oss": [14, 25], "outcom": [57, 74], "overal": [39, 67], "overfit": 35, "overview": 40, "pair": [68, 81], "paramet": [35, 43], "part": 83, "passiv": 56, "pattern": 34, "perform": [35, 66, 72], "pi_": 54, "pipelin": 56, "point": 56, "polici": [33, 39, 51, 57], "posit": [1, 83, 84, 85, 88], "post": [26, 44, 47, 50, 51], "postprocess": [18, 27], "potenti": [34, 66], "power": 35, "ppo": [57, 60], "pre": [2, 43, 44, 45, 47, 50, 51, 79], "predict": 44, "prefer": [46, 47, 52, 54, 62, 66, 69], "preliminari": [54, 65, 66, 73, 82, 85, 88], "pretrain": [26, 46], "prevent": 73, "prm": 74, "pro": 11, "problem": [59, 73], "process": [47, 57, 72, 74], "product": 1, "prompt": [20, 29, 62, 71], "properti": 88, "propos": [40, 88], "qualiti": 47, "queri": 85, "quick": 10, "quickli": 32, "qwen": 50, "qwen2": 51, "r": [54, 64], "r1": 72, "random": 77, "rank": 85, "reason": [70, 71, 72, 78, 79], "recip": 51, "redux": 11, "refer": 75, "reinforc": [42, 43, 44, 50, 58, 61, 62, 72, 73], "reject": [65, 72], "rel": [57, 83], "relat": 69, "relationship": 79, "represent": 3, "respons": 68, "result": [5, 34, 35, 42, 43, 44, 47, 56, 61, 62, 67], "rethink": 77, "review": 57, "revis": 61, "reward": [33, 46, 47, 53, 56, 58, 66, 67, 72, 73, 74], "rewardbench": 17, "rl": [33, 57, 58, 73, 78], "rlaif": 62, "rlcd": 63, "rlhf": [46, 62, 66], "rm": [58, 66], "rmsnorm": [48, 49, 86], "role": 31, "rope": [48, 49, 83, 84, 87, 88], "rotari": [83, 84, 85, 88], "round": 47, "rso": 65, "sampl": [31, 38, 39, 65, 72], "scale": [1, 34, 35, 38, 74, 77, 78, 79, 83], "scenario": 72, "scienc": 15, "score": [39, 73], "secret": 66, "segment": 82, "select": [68, 77], "self": [18, 27, 67, 68, 69, 72, 73], "sentencepiec": 90, "set": 59, "setup": [67, 73], "sft": [46, 47, 58, 76, 92, 94], "shape": 73, "share": 82, "should": 34, "size": 35, "small": 74, "smooth": 66, "softmax": 1, "sourc": [14, 25, 49], "special": 41, "specif": 2, "stack": 1, "stage": [26, 40, 53, 73], "standard": 85, "stanford": [8, 24], "start": [10, 72], "statist": 65, "step": 74, "strategi": 82, "strength": 66, "strong": 36, "summar": 3, "supervis": [2, 42, 43, 44, 47, 50, 57, 58, 61, 72, 74, 79], "surfac": 34, "swiglu": [48, 49, 89], "swish": 89, "synthet": [74, 78], "system": 39, "taco": 19, "takeawai": [42, 43, 44, 47, 50, 51, 66, 74, 87], "task": [2, 18, 27], "taught": 68, "techniqu": [62, 80], "temperatur": 34, "templat": 72, "thought": 71, "tiktoken": 48, "time": 35, "token": [44, 48, 50, 82], "train": [2, 3, 4, 20, 26, 29, 35, 43, 44, 45, 47, 50, 51, 56, 67, 68, 69, 72, 73, 79], "transform": [2, 35, 48, 49, 82], "tune": [2, 14, 25, 26, 38, 39, 41, 42, 43, 44, 46, 50, 58, 68, 72], "turn": 73, "two": 26, "ulm": 90, "unicod": [28, 91], "unigram": 90, "unit": 89, "unsupervis": 2, "utf": 91, "utf8": 91, "v": [62, 74, 79], "v2": [42, 43], "v3": 44, "valu": 85, "variant": 89, "variou": 34, "verifi": 74, "via": [73, 84], "weak": 36, "west": 69, "what": [31, 34], "why": [2, 85, 86], "window": [83, 84], "wise": 1, "wizardcod": [20, 29], "wizardlm": [20, 29], "wordpiec": 90, "work": 69, "yaml": 32, "yarn": 83, "you": [1, 77], "zero": 72, "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": 91, "\u521d\u8bc6bpe": 81, "\u603b\u7ed3": 91, "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5": 81, "\u672c\u5730": [10, 13], "\u7684\u8fdc\u7a0b\u8870\u51cf": 83, "\u7f16\u7801\u548c\u89e3\u7801": 81, "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": 83}})