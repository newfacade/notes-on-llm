Search.setIndex({"alltitles": {"2D case": [[107, "d-case"], [108, "d-case"]], "A Recipe for Instruction Data": [[62, "a-recipe-for-instruction-data"]], "AGENTLESS": [[1, "agentless"]], "AGENTLESS Approach": [[1, "agentless-approach"]], "API-Bank": [[2, "api-bank"]], "APPS": [[33, "apps"]], "ASCII": [[111, "ascii"]], "ASCII,UNICODE,UTF8": [[111, "ascii-unicode-utf8"]], "Ablation of Attention Mechanisms": [[105, "ablation-of-attention-mechanisms"]], "Ablation of MHA, GQA, and MQA": [[105, "ablation-of-mha-gqa-and-mqa"]], "Ablations on Data Diversity, Quality, and Quantity": [[96, "ablations-on-data-diversity-quality-and-quantity"]], "Absolute position embedding": [[108, "absolute-position-embedding"]], "Active Exploration with a Point Estimate": [[70, "active-exploration-with-a-point-estimate"]], "Active Exploration with an ENN": [[70, "active-exploration-with-an-enn"]], "Active Learning": [[93, "active-learning"]], "Adaptive Margin": [[82, "adaptive-margin"]], "Additional insights": [[51, "additional-insights"]], "Advantage Normalization": [[76, "advantage-normalization"]], "Agent": [[0, "agent"]], "Aider Polyglot": [[12, "aider-polyglot"]], "Aligning Language Models with Judgments": [[73, "aligning-language-models-with-judgments"]], "Alignment": [[53, "alignment"], [54, "alignment"]], "Alignment Benchmarks": [[13, "alignment-benchmarks"]], "Alignment Data": [[96, "alignment-data"]], "Alignment Effect on Non-Determinism": [[45, "alignment-effect-on-non-determinism"]], "AlphaCode": [[32, "alphacode"], [49, "alphacode"]], "AlphaCode 2": [[50, "alphacode-2"]], "AlphaCodium": [[51, "alphacodium"]], "An example cell": [[43, "an-example-cell"]], "Analyze and Leverage Diverse Data to its Fullest Potential": [[82, "analyze-and-leverage-diverse-data-to-its-fullest-potential"]], "Appendix": [[68, "appendix"]], "Approach": [[8, "approach"], [9, "approach"], [49, "approach"], [56, "approach"]], "Architecture": [[54, "architecture"], [55, "architecture"], [56, "architecture"]], "Architecture & Tokenizer": [[61, "architecture-tokenizer"]], "Arena-Hard": [[13, "arena-hard"]], "ArmoRM-MoE": [[65, "armorm-moe"]], "Assessment Pipeline": [[70, "assessment-pipeline"]], "Attention": [[6, "attention"], [59, "attention"], [59, "id1"], [60, "attention"], [60, "id1"]], "Attention Is All You Need": [[6, "attention-is-all-you-need"]], "Background": [[108, "background"]], "Background: Rotary Position Embedding (RoPE)": [[103, "background-rotary-position-embedding-rope"], [104, "background-rotary-position-embedding-rope"]], "Background: The REINFORCE Algorithm": [[76, "background-the-reinforce-algorithm"]], "Base": [[5, "base"]], "Base Models": [[61, "base-models"], [62, "base-models"], [93, "base-models"]], "Basic Architecture": [[55, "basic-architecture"]], "Batch Normalization": [[106, "batch-normalization"]], "BatchNorm": [[59, "batchnorm"]], "Benchmark Construction": [[14, "benchmark-construction"], [26, "benchmark-construction"]], "Benchmark Statistics": [[14, "benchmark-statistics"]], "Benchmarking NL-Oriented Instructions to Code Generation": [[14, "benchmarking-nl-oriented-instructions-to-code-generation"]], "Benchmarks": [[11, "benchmarks"]], "BigCodeBench": [[14, "bigcodebench"]], "Boosting Reward Quality with Principles": [[67, "boosting-reward-quality-with-principles"]], "Byte Pair Encoding (BPE)": [[101, "byte-pair-encoding-bpe"]], "CRUXEval": [[16, "cruxeval"]], "Capabilities": [[58, "capabilities"]], "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [[87, "chain-of-thought-prompting-elicits-reasoning-in-large-language-models"]], "Charting the Infinite Data Limit and Overfitting": [[46, "charting-the-infinite-data-limit-and-overfitting"]], "Chat Dialog Format": [[58, "chat-dialog-format"]], "ChatFormat": [[59, "chatformat"]], "Citations": [[42, "citations"]], "Classification Task Identification": [[25, "classification-task-identification"], [37, "classification-task-identification"]], "Clip-Higher": [[66, "clip-higher"]], "Clustering": [[49, "clustering"], [50, "clustering"]], "Code": [[58, "code"]], "Code Alpaca": [[15, "code-alpaca"], [15, "id1"], [34, "code-alpaca"], [34, "id1"]], "Code Correctness Evaluation: HumanEval(+) or MBPP(+)": [[17, "code-correctness-evaluation-humaneval-or-mbpp"]], "Code Llama": [[52, "code-llama"]], "Code Llama: Specializing Llama 2 for code": [[52, "code-llama-specializing-llama-2-for-code"]], "Code-Oriented Design Concepts": [[51, "code-oriented-design-concepts"]], "CodeAct": [[3, "codeact"]], "CodeAct Benefits from Multi-turn Interactions and Existing Software Packages": [[3, "codeact-benefits-from-multi-turn-interactions-and-existing-software-packages"]], "CodeAct Gets More Done with Fewer Interactions": [[3, "codeact-gets-more-done-with-fewer-interactions"]], "CodeAct Makes LLMs Better Agents": [[3, "codeact-makes-llms-better-agents"]], "CodeAct Shows the Promise as a Strong Tool Use Framework": [[3, "codeact-shows-the-promise-as-a-strong-tool-use-framework"]], "CodeContests fine-tuning dataset": [[32, "codecontests-fine-tuning-dataset"]], "Cold Start": [[89, "cold-start"]], "Communication Balance Loss": [[102, "communication-balance-loss"]], "Comparison Between MLA and MHA": [[105, "comparison-between-mla-and-mha"]], "Comparison of Key-Value Cache": [[105, "comparison-of-key-value-cache"]], "Comparisons of Different RM approaches": [[67, "comparisons-of-different-rm-approaches"]], "Constitutional AI: Harmlessness from AI Feedback": [[77, "constitutional-ai-harmlessness-from-ai-feedback"]], "Contents": [[29, "contents"], [30, "contents"]], "Create a notebook with MyST Markdown": [[43, "create-a-notebook-with-myst-markdown"]], "Critiques, Revisions, and Supervised Learning": [[77, "critiques-revisions-and-supervised-learning"]], "DAPO": [[66, "dapo"], [66, "id1"]], "DPO": [[68, "dpo"]], "DPOP": [[69, "dpop"], [69, "id1"]], "Data": [[15, "data"], [31, "data"], [34, "data"]], "Data Collection": [[53, "data-collection"], [93, "data-collection"]], "Data Composition": [[36, "data-composition"], [62, "data-composition"]], "Data Construction": [[54, "data-construction"], [55, "data-construction"]], "Data Generation": [[25, "data-generation"], [37, "data-generation"]], "Data Mixture": [[62, "data-mixture"]], "Data Processing and Quality Control": [[58, "data-processing-and-quality-control"]], "Data Synthesis": [[14, "data-synthesis"]], "Dataset": [[10, "dataset"], [52, "dataset"], [66, "dataset"], [72, "dataset"]], "Datasets": [[49, "datasets"]], "Decontamination": [[36, "decontamination"], [62, "decontamination"]], "Decoupled Rotary Position Embedding": [[105, "decoupled-rotary-position-embedding"]], "DeepCoder": [[88, "deepcoder"]], "DeepSeek V3": [[55, "deepseek-v3"]], "DeepSeek-Coder-V2": [[53, "deepseek-coder-v2"]], "DeepSeek-GRM": [[67, "deepseek-grm"]], "DeepSeek-R1": [[89, "deepseek-r1"]], "DeepSeek-R1-Zero: Reinforcement Learning on the Base Model": [[89, "deepseek-r1-zero-reinforcement-learning-on-the-base-model"]], "DeepSeek-R1: Reinforcement Learning with Cold Start": [[89, "deepseek-r1-reinforcement-learning-with-cold-start"]], "DeepSeek-V2": [[54, "deepseek-v2"]], "DeepSeekMoE": [[102, "deepseekmoe"]], "Derivation of \\pi_{r}": [[68, "derivation-of-pi-r"]], "Design Principles of API-Bank": [[2, "design-principles-of-api-bank"]], "Device-Level Balance Loss": [[102, "device-level-balance-loss"]], "Direct Preference Optimization": [[58, "direct-preference-optimization"], [68, "direct-preference-optimization"]], "Direct extrapolation": [[104, "direct-extrapolation"]], "Discussion": [[54, "discussion"]], "Dynamic Sampling": [[66, "dynamic-sampling"]], "Dynamic Scaling - \u201cDynamic NTK\u201d interpolation": [[103, "dynamic-scaling-dynamic-ntk-interpolation"]], "Efficient Exploration for LLMs": [[70, "efficient-exploration-for-llms"]], "Embeddings and Softmax": [[6, "embeddings-and-softmax"]], "Empirical Results": [[70, "empirical-results"]], "Empirical Results and Basic Power Laws": [[46, "empirical-results-and-basic-power-laws"]], "Encoder and Decoder Stacks": [[6, "encoder-and-decoder-stacks"]], "Epistemic Neural Network": [[70, "epistemic-neural-network"]], "EvalPlus": [[17, "evalplus"]], "Evaluation": [[9, "evaluation"], [14, "evaluation"], [21, "evaluation"], [28, "evaluation"], [35, "evaluation"], [40, "evaluation"], [49, "evaluation"], [50, "evaluation"], [61, "evaluation"], [62, "evaluation"], [78, "evaluation"]], "Evaluation Results": [[54, "evaluation-results"], [54, "id3"], [55, "evaluation-results"], [55, "id4"]], "Evaluation System of API-Bank": [[2, "evaluation-system-of-api-bank"]], "Evaluation of LLMs Should Not Ignore Non-Determinism": [[45, "evaluation-of-llms-should-not-ignore-non-determinism"]], "Evol-Instruct": [[28, "evol-instruct"], [40, "evol-instruct"]], "Evol-Instruct Prompts for Code": [[28, "evol-instruct-prompts-for-code"], [40, "evol-instruct-prompts-for-code"]], "Experimental Results": [[45, "experimental-results"], [53, "experimental-results"]], "Experimental Setup": [[26, "experimental-setup"], [76, "experimental-setup"], [83, "experimental-setup"]], "Experimentation Pipeline": [[70, "experimentation-pipeline"]], "Experiments": [[8, "experiments"], [66, "experiments"], [83, "experiments"], [104, "experiments"]], "Expert-Level Balance Loss": [[102, "expert-level-balance-loss"]], "Exploration Algorithms": [[70, "exploration-algorithms"]], "Extending context window of LLMs": [[103, "extending-context-window-of-llms"]], "Extending context window of large language models via position interpolation": [[104, "extending-context-window-of-large-language-models-via-position-interpolation"]], "FFN": [[109, "ffn"]], "Failure Mode of DPO": [[69, "failure-mode-of-dpo"]], "Features of Swe-Bench": [[26, "features-of-swe-bench"]], "FeedForward": [[59, "feedforward"], [60, "feedforward"]], "Filtering": [[49, "filtering"], [50, "filtering"]], "Filtering and Postprocessing": [[25, "filtering-and-postprocessing"], [37, "filtering-and-postprocessing"]], "Fine-Grained Expert Segmentation": [[102, "fine-grained-expert-segmentation"]], "Fine-tuning": [[49, "fine-tuning"]], "Finetuning the LM to Follow Instructions": [[25, "finetuning-the-lm-to-follow-instructions"], [37, "finetuning-the-lm-to-follow-instructions"]], "Flipping the Labels": [[82, "flipping-the-labels"]], "Flow stages": [[51, "flow-stages"]], "Formulation": [[107, "formulation"], [108, "formulation"]], "Framework": [[7, "framework"]], "From MLE to RL framework": [[44, "from-mle-to-rl-framework"]], "Functional Correctness": [[19, "functional-correctness"]], "GB2312\u3001GBK\u7b49\u5176\u4ed6\u7f16\u7801": [[111, "gb2312gbk"]], "GOLD": [[44, "gold"]], "GPQA": [[22, "gpqa"]], "GPT": [[7, "gpt"]], "GPT2": [[8, "gpt2"]], "GPT3": [[9, "gpt3"]], "GRPO": [[71, "id3"]], "GSM8K": [[22, "gsm8k"]], "Gated Linear Units (GLU) and Variants": [[109, "gated-linear-units-glu-and-variants"]], "General Benchmarks": [[18, "general-benchmarks"]], "General form": [[107, "general-form"], [108, "general-form"]], "Generation": [[59, "generation"]], "Generator": [[93, "generator"]], "Gradient of DPO Loss": [[68, "gradient-of-dpo-loss"]], "Group Relative Policy Optimization": [[71, "group-relative-policy-optimization"]], "High-level methodology": [[10, "high-level-methodology"]], "How Various Factors Influence Non-Determinism?": [[45, "how-various-factors-influence-non-determinism"]], "How to Better Model Human Preference?": [[82, "how-to-better-model-human-preference"]], "Human Curation": [[14, "human-curation"]], "Human Evaluation": [[96, "human-evaluation"]], "Human Preference Data Collection": [[57, "human-preference-data-collection"]], "HumanEval": [[19, "humaneval"]], "Hyper-Parameters": [[54, "hyper-parameters"]], "IFEval": [[13, "ifeval"]], "Impacts of Different Data on RM Performance": [[82, "impacts-of-different-data-on-rm-performance"]], "Implementation Details": [[21, "implementation-details"], [35, "implementation-details"]], "Incorporating Judgments for Alignment": [[73, "incorporating-judgments-for-alignment"]], "Inference-Time Scaling with SPCT": [[67, "inference-time-scaling-with-spct"]], "Infilling": [[52, "infilling"]], "Initialization": [[83, "initialization"], [84, "initialization"]], "Input Format": [[26, "input-format"]], "Input Representation": [[8, "input-representation"]], "Installation": [[20, "installation"]], "Instance Generation": [[25, "instance-generation"], [37, "instance-generation"]], "Instruct GPT": [[72, "instruct-gpt"]], "Instruct Models": [[62, "instruct-models"]], "InstructGPT": [[10, "instructgpt"]], "Instruction Following Ability Results": [[83, "instruction-following-ability-results"]], "Instruction Following Training": [[83, "instruction-following-training"]], "Instruction Generation": [[25, "instruction-generation"], [37, "instruction-generation"]], "Instruction Selection": [[84, "instruction-selection"]], "Instruction fine-tuning": [[52, "instruction-fine-tuning"]], "Instruction-tuned Model": [[61, "instruction-tuned-model"]], "Introduction": [[21, "introduction"], [35, "introduction"], [41, "introduction"], [47, "introduction"], [52, "introduction"], [56, "introduction"], [73, "introduction"], [79, "introduction"], [104, "introduction"]], "Iterative Fine-Tuning": [[57, "iterative-fine-tuning"]], "Iterative RL with GRPO": [[71, "iterative-rl-with-grpo"]], "Iterative Rounds": [[58, "iterative-rounds"]], "Iterative Training": [[84, "iterative-training"]], "Judgment Annotation": [[84, "judgment-annotation"]], "LIMA: Less Is More for Alignment": [[96, "lima-less-is-more-for-alignment"]], "LORA": [[113, "lora"]], "Label Smoothing": [[82, "label-smoothing"]], "Large scale sampling": [[49, "large-scale-sampling"]], "Large-scale Supervision": [[93, "large-scale-supervision"]], "Layer Normalization": [[106, "layer-normalization"]], "LayerNorm": [[59, "layernorm"]], "Learn more": [[42, "learn-more"]], "Learning Pipeline": [[70, "learning-pipeline"]], "Learning from Contrasting": [[73, "learning-from-contrasting"]], "Let\u2019s Verify Step by Step": [[93, "lets-verify-step-by-step"]], "LiveCodeBench": [[20, "livecodebench"]], "Llama": [[56, "llama"]], "Llama 2": [[57, "llama-2"]], "Llama 3": [[58, "llama-3"]], "Llama 3 Source Code": [[60, "llama-3-source-code"]], "Llama Factory": [[112, "llama-factory"]], "Llama implementation": [[104, "llama-implementation"]], "Llama3": [[59, "llama3"]], "Load Balance Consideration": [[102, "load-balance-consideration"]], "Logic-RL": [[90, "logic-rl"]], "Long Context Extension": [[55, "long-context-extension"]], "Long context fine-tuning": [[52, "long-context-fine-tuning"]], "Loss": [[68, "loss"]], "Loss of High Frequency information - \u201cNTK-aware\u201d interpolation": [[103, "loss-of-high-frequency-information-ntk-aware-interpolation"]], "Loss of Relative Local Distances - \u201cNTK-by-parts\u201d interpolation": [[103, "loss-of-relative-local-distances-ntk-by-parts-interpolation"]], "Low-Rank Compression for Queries": [[105, "low-rank-compression-for-queries"]], "Low-Rank Key-Value Joint Compression": [[105, "low-rank-key-value-joint-compression"]], "MATH": [[22, "math"]], "MATH 500": [[22, "math-500"]], "MBPP": [[23, "mbpp"]], "MMLU": [[18, "mmlu"]], "MMLU-Pro": [[18, "mmlu-pro"]], "MMLU-Redux": [[18, "mmlu-redux"]], "Magicoder": [[21, "magicoder"], [35, "magicoder"]], "Main Result": [[77, "main-result"]], "Main Results": [[66, "main-results"], [77, "main-results"]], "Markdown Files": [[42, "markdown-files"]], "Math & Science Benchmarks": [[22, "math-science-benchmarks"]], "Measuring the Strength of Preferences": [[82, "measuring-the-strength-of-preferences"]], "Method": [[77, "method"], [77, "id1"], [84, "method"]], "Methodology": [[47, "methodology"], [78, "methodology"]], "Methods": [[93, "methods"]], "Methods and experimental details": [[10, "methods-and-experimental-details"]], "Mini-Batch Updates": [[76, "mini-batch-updates"]], "Model": [[8, "model"], [59, "model"], [60, "model"]], "Model Accuracy VS. Augmented Data Count": [[99, "model-accuracy-vs-augmented-data-count"]], "Model Accuracy VS. Pre-training Loss": [[99, "model-accuracy-vs-pre-training-loss"]], "Model Accuracy VS. Supervised Data Count": [[99, "model-accuracy-vs-supervised-data-count"]], "Model Architecture": [[6, "model-architecture"]], "Model Averaging": [[58, "model-averaging"]], "Model Fine-tuning (Iterative Training)": [[84, "model-fine-tuning-iterative-training"]], "Model and Architectures": [[9, "model-and-architectures"]], "Modeling": [[58, "modeling"]], "Models": [[10, "models"], [48, "models"]], "Multi-Head Attention": [[6, "multi-head-attention"]], "Multi-Head Latent Attention": [[105, "multi-head-latent-attention"]], "Multi-Token Prediction": [[55, "multi-token-prediction"]], "NLP\u5b9e\u4f8b": [[101, "nlp"]], "Normalization": [[59, "normalization"], [106, "normalization"]], "Notebooks with MyST Markdown": [[43, "notebooks-with-myst-markdown"]], "OOD Generalization": [[93, "ood-generalization"]], "OSS-INSTRUCT: Instruction Tuning from Open Source": [[21, "oss-instruct-instruction-tuning-from-open-source"], [35, "oss-instruct-instruction-tuning-from-open-source"]], "Off-policy policy gradient": [[44, "off-policy-policy-gradient"]], "Offline Reinforcement Learning": [[61, "offline-reinforcement-learning"]], "Online Reinforcement Learning": [[61, "online-reinforcement-learning"]], "OpenCoder": [[36, "opencoder"]], "OpenRLHF": [[74, "openrlhf"], [114, "openrlhf"]], "Optimizer": [[56, "optimizer"]], "Outcome Supervision RL with GRPO": [[71, "outcome-supervision-rl-with-grpo"]], "Outcome-supervised Reward Models (ORMs)": [[93, "outcome-supervised-reward-models-orms"]], "Overall Self-Alignment Algorithm": [[83, "overall-self-alignment-algorithm"]], "Overall System": [[50, "overall-system"]], "Overlong Reward Shaping": [[66, "overlong-reward-shaping"]], "Overview": [[51, "overview"]], "PPO": [[75, "ppo"]], "PPO Review": [[71, "ppo-review"]], "PPO implementation detail": [[74, "ppo-implementation-detail"]], "PPO-Clip Integration": [[76, "ppo-clip-integration"]], "Parameter and Compute Scaling of Transformers": [[46, "parameter-and-compute-scaling-of-transformers"]], "Passive Exploration": [[70, "passive-exploration"]], "Performance with Dataset Size and Compute": [[46, "performance-with-dataset-size-and-compute"]], "Performance with Non-Embedding Parameter Count N": [[46, "performance-with-non-embedding-parameter-count-n"]], "Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero": [[89, "performance-self-evolution-process-and-aha-moment-of-deepseek-r1-zero"]], "Point Estimate": [[70, "point-estimate"]], "Policy and Fine-Tuning": [[50, "policy-and-fine-tuning"]], "Position interpolation": [[103, "position-interpolation"]], "Position-wise Feed-Forward Networks": [[6, "position-wise-feed-forward-networks"]], "Positional Encoding": [[6, "positional-encoding"]], "Positional Interpolation": [[104, "positional-interpolation"]], "Post Training": [[36, "post-training"]], "Post-Training": [[55, "post-training"], [58, "post-training"]], "Post-trained Language Model": [[58, "post-trained-language-model"]], "Post-training": [[61, "post-training"], [62, "post-training"]], "Post-training Data": [[58, "post-training-data"]], "Pre-Training": [[54, "pre-training"], [55, "pre-training"]], "Pre-trained Language Model": [[58, "pre-trained-language-model"]], "Pre-training": [[61, "pre-training"], [62, "pre-training"]], "Pre-training data": [[56, "pre-training-data"]], "Preference Data": [[58, "preference-data"]], "Preference Labeling with LLMs": [[78, "preference-labeling-with-llms"]], "Preference Optimization": [[64, "preference-optimization"]], "Preliminaries": [[68, "preliminaries"], [81, "preliminaries"], [82, "preliminaries"]], "Preliminaries and Problem Setup": [[92, "preliminaries-and-problem-setup"]], "Preliminaries: Mixture-of-Experts for Transformers": [[102, "preliminaries-mixture-of-experts-for-transformers"]], "Preliminaries: Standard Multi-Head Attention": [[105, "preliminaries-standard-multi-head-attention"]], "Preliminary": [[66, "preliminary"], [108, "preliminary"]], "Pretrain": [[57, "pretrain"]], "Pretraining": [[36, "pretraining"]], "Pretraining Data": [[36, "pretraining-data"]], "Problem Setting": [[73, "problem-setting"]], "Process Supervision RL with GRPO": [[71, "process-supervision-rl-with-grpo"]], "Process vs Outcome Supervision": [[93, "process-vs-outcome-supervision"]], "Process-supervised Reward Models (PRMs)": [[93, "process-supervised-reward-models-prms"]], "Prompting Techniques": [[78, "prompting-techniques"]], "Properties of RoPE": [[108, "properties-of-rope"]], "Proposed approach": [[108, "proposed-approach"]], "Quick Start": [[17, "quick-start"]], "Quickly add YAML metadata for MyST Notebooks": [[43, "quickly-add-yaml-metadata-for-myst-notebooks"]], "Qwen 2.5": [[61, "qwen-2-5"]], "Qwen2.5-Coder": [[62, "qwen2-5-coder"]], "Qwen3": [[63, "qwen3"]], "REINFORCE++": [[76, "reinforce"]], "REINFORCE++ Enhancements": [[76, "reinforce-enhancements"]], "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED": [[97, "rethinking-data-selection-at-scale-random-selection-is-almost-all-you-need"]], "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold": [[98, "rl-on-incorrect-synthetic-data-scales-the-efficiency-of-llm-math-reasoning-by-eight-fold"]], "RLAIF vs. RLHF": [[78, "rlaif-vs-rlhf"], [78, "id1"]], "RLCD": [[79, "rlcd"], [79, "id1"]], "RLHF": [[57, "rlhf"]], "RMSNorm": [[59, "rmsnorm"], [60, "rmsnorm"], [106, "rmsnorm"]], "RS-DPO": [[80, "rs-dpo"]], "RSO": [[81, "rso"]], "RSO APPROACH": [[81, "rso-approach"]], "Reasoning": [[86, "reasoning"]], "Reasoning data curation to create s1K": [[91, "reasoning-data-curation-to-create-s1k"]], "Reasoning-oriented Reinforcement Learning": [[89, "reasoning-oriented-reinforcement-learning"]], "References": [[94, "references"]], "Reinforcement Learning": [[53, "reinforcement-learning"], [54, "reinforcement-learning"], [55, "reinforcement-learning"]], "Reinforcement Learning Algorithm": [[89, "reinforcement-learning-algorithm"]], "Reinforcement Learning for all Scenarios": [[89, "reinforcement-learning-for-all-scenarios"]], "Reinforcement Learning from AI Feedback": [[77, "reinforcement-learning-from-ai-feedback"], [78, "reinforcement-learning-from-ai-feedback"]], "Reinforcement learning (RL)": [[72, "reinforcement-learning-rl"]], "Rejection Sampling and Supervised Fine-Tuning": [[89, "rejection-sampling-and-supervised-fine-tuning"]], "Rejective Fine-Tuning (Cold Start)": [[67, "rejective-fine-tuning-cold-start"]], "Related Work": [[85, "related-work"]], "Removing KL Divergence": [[66, "removing-kl-divergence"]], "Response Pair Construction": [[84, "response-pair-construction"]], "Results": [[4, "results"], [10, "results"], [26, "results"], [58, "results"], [78, "results"], [91, "results"]], "Results on Reward Modeling Benchmarks": [[67, "results-on-reward-modeling-benchmarks"]], "Retrieval-Based Approach": [[26, "retrieval-based-approach"]], "Reward": [[44, "reward"]], "Reward Model Architectures and Training": [[70, "reward-model-architectures-and-training"]], "Reward Modeling": [[57, "reward-modeling"], [58, "reward-modeling"], [89, "reward-modeling"]], "Reward Modeling Ability Results": [[83, "reward-modeling-ability-results"]], "Reward Normalization and Clipping": [[76, "reward-normalization-and-clipping"]], "Reward modeling (RM)": [[72, "reward-modeling-rm"]], "RewardBench": [[24, "rewardbench"]], "RoPE": [[59, "rope"], [60, "rope"], [107, "rope"]], "RoPE \u7684\u8fdc\u7a0b\u8870\u51cf": [[103, "rope"]], "Rotary Positional Embeddings (RoPE)": [[108, "rotary-positional-embeddings-rope"]], "Rule-Based RL": [[67, "rule-based-rl"]], "Rule-based Reward Modeling": [[66, "rule-based-reward-modeling"]], "SCoRe: Self-Correction via Multi-Turn Reinforcement Learning": [[92, "score-self-correction-via-multi-turn-reinforcement-learning"]], "SELF-INSTRUCT": [[25, "self-instruct"], [37, "self-instruct"]], "SFT": [[57, "sft"], [95, "sft"], [112, "sft"], [114, "sft"]], "SFT Data": [[58, "sft-data"]], "STATISTICAL REJECTION SAMPLING ALGORITHM": [[81, "statistical-rejection-sampling-algorithm"]], "SWE-Llama: Fine-Tuning Codellama for SWE-bench": [[26, "swe-llama-fine-tuning-codellama-for-swe-bench"]], "SWE-agent": [[4, "swe-agent"]], "SWE-agent: Designing an ACI for Software Engineering": [[4, "swe-agent-designing-an-aci-for-software-engineering"]], "SWE-bench": [[26, "swe-bench"], [26, "id1"]], "SWE-bench Lite": [[26, "swe-bench-lite"]], "Sample Roles and Directives": [[42, "sample-roles-and-directives"]], "Sampling": [[50, "sampling"]], "Scaled Dot-Product Attention": [[6, "scaled-dot-product-attention"]], "Scaling Effect on Non-Determinism": [[45, "scaling-effect-on-non-determinism"]], "Scaling Laws for Neural Language Models": [[46, "scaling-laws-for-neural-language-models"]], "Scaling Laws with Model Size and Training Time": [[46, "scaling-laws-with-model-size-and-training-time"]], "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": [[99, "scaling-relationship-on-learning-mathematical-reasoning-with-large-language-models"]], "Scoring Model": [[50, "scoring-model"]], "Secrets of RLHF in Large Language Models: Reward Modeling": [[82, "secrets-of-rlhf-in-large-language-models-reward-modeling"]], "Self-Instruction Creation": [[83, "self-instruction-creation"]], "Self-Principled Critique Tuning (SPCT)": [[67, "self-principled-critique-tuning-spct"]], "Self-Rewarding Language Models": [[83, "self-rewarding-language-models"]], "Self-Taught Evaluators": [[84, "self-taught-evaluators"]], "Self-Training for Preference Modeling": [[85, "self-training-for-preference-modeling"]], "Semi-Automatic Program Refactoring and Testing Case Generation": [[14, "semi-automatic-program-refactoring-and-testing-case-generation"]], "SentencePiece": [[110, "sentencepiece"]], "Shared Expert Isolation": [[102, "shared-expert-isolation"]], "Small-scale Synthetic Supervision": [[93, "small-scale-synthetic-supervision"]], "Stage I: Training a Model Initialization to Prevent Collapse": [[92, "stage-i-training-a-model-initialization-to-prevent-collapse"]], "Stage II: Multi-Turn RL with Reward Shaping": [[92, "stage-ii-multi-turn-rl-with-reward-shaping"]], "Stage-1: Multi-Objective Reward Modeling": [[65, "stage-1-multi-objective-reward-modeling"]], "Stage-2: Mixture-of-Experts Aggregation of Reward Objectives": [[65, "stage-2-mixture-of-experts-aggregation-of-reward-objectives"]], "Stanford Alpaca": [[15, "stanford-alpaca"], [34, "stanford-alpaca"]], "Summarization": [[8, "summarization"]], "Supervised Fine-Tuning": [[53, "supervised-fine-tuning"], [54, "supervised-fine-tuning"], [55, "supervised-fine-tuning"]], "Supervised Fine-tuning": [[61, "supervised-fine-tuning"]], "Supervised Finetuning": [[58, "supervised-finetuning"]], "Supervised fine-tuning": [[7, "supervised-fine-tuning"]], "Supervised fine-tuning (SFT)": [[72, "supervised-fine-tuning-sft"]], "Surface Patterns in Non-Determinism Generation?": [[45, "surface-patterns-in-non-determinism-generation"]], "SwiGLU": [[109, "swiglu"]], "SwiGLU activation function": [[59, "swiglu-activation-function"], [60, "swiglu-activation-function"]], "Swish": [[109, "swish"]], "TACO": [[27, "taco"], [38, "taco"]], "Takeaway": [[53, "takeaway"], [54, "takeaway"], [55, "takeaway"], [58, "takeaway"], [61, "takeaway"], [62, "takeaway"], [107, "takeaway"]], "Takeaways": [[82, "takeaways"], [93, "takeaways"]], "Task-specific input transformations": [[7, "task-specific-input-transformations"]], "Techniques": [[100, "techniques"]], "Temperature Effect on Non-Determinism": [[45, "temperature-effect-on-non-determinism"]], "Test-time scaling": [[91, "test-time-scaling"]], "The Agent-Computer Interface": [[4, "the-agent-computer-interface"]], "The Factors of Math Reasoning Ability in Supervised LLM": [[99, "the-factors-of-math-reasoning-ability-in-supervised-llm"]], "The GOLD algorithm": [[44, "the-gold-algorithm"]], "The Need for Interpretable Reward Models": [[65, "the-need-for-interpretable-reward-models"]], "The Proposed Flow": [[51, "the-proposed-flow"]], "Tiktoken": [[59, "tiktoken"]], "Token-Dropping Strategy": [[102, "token-dropping-strategy"]], "Token-Level KL Penalty": [[76, "token-level-kl-penalty"]], "Token-Level Policy Gradient Loss": [[66, "token-level-policy-gradient-loss"]], "Tokenizer": [[59, "tokenizer"], [59, "id2"]], "Training Dataset": [[8, "training-dataset"], [9, "training-dataset"]], "Training Details": [[36, "training-details"], [66, "training-details"]], "Training LIMA": [[96, "training-lima"]], "Training Language Models to Self-Correct via Reinforcement Learning": [[92, "training-language-models-to-self-correct-via-reinforcement-learning"]], "Training Policy": [[62, "training-policy"], [62, "id8"]], "Training Template": [[89, "training-template"]], "Training WizardCoder": [[28, "training-wizardcoder"], [40, "training-wizardcoder"]], "Transformer": [[59, "transformer"], [60, "transformer"]], "Two-stage Instruction-Tuning": [[36, "two-stage-instruction-tuning"]], "UNICODER": [[39, "unicoder"], [39, "id2"]], "UNICODER-INSTRUCT": [[39, "unicoder-instruct"]], "UTF-16\u3001UTF-32\u7b49": [[111, "utf-16utf-32"]], "UTF-8": [[111, "utf-8"]], "Unigram Language Model (ULM)": [[110, "unigram-language-model-ulm"]], "Unpinning Principles from Understanding to Generation": [[67, "unpinning-principles-from-understanding-to-generation"]], "Unsupervised pre-training": [[7, "unsupervised-pre-training"]], "Weak to Strong Generalization": [[47, "weak-to-strong-generalization"]], "West-of-N": [[85, "west-of-n"]], "West-of-N Self-Training": [[85, "west-of-n-self-training"]], "What is CodeAct?": [[3, "what-is-codeact"]], "What is MyST?": [[42, "what-is-myst"]], "What is the Full Potential of Non-Determinism?": [[45, "what-is-the-full-potential-of-non-determinism"]], "Why KV cache": [[105, "why-kv-cache"]], "Why Layer Normalization": [[106, "why-layer-normalization"]], "Why decoder-only": [[7, "why-decoder-only"]], "WizardCoder": [[28, "wizardcoder"], [40, "wizardcoder"]], "WizardLM": [[28, "wizardlm"], [40, "wizardlm"]], "WordPiece": [[110, "wordpiece"]], "WordPiece, ULM and SentencePiece": [[110, "wordpiece-ulm-and-sentencepiece"]], "YaRN": [[103, "id5"]], "YaRN: Efficient ContextWindow Extension of Large Language Models": [[103, "yarn-efficient-contextwindow-extension-of-large-language-models"]], "methodology": [[72, "methodology"]], "s1: Simple test-time scaling": [[91, "s1-simple-test-time-scaling"]], "unicode": [[111, "unicode"]], "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": [[111, "id1"]], "\u521d\u8bc6BPE": [[101, "bpe"]], "\u603b\u7ed3": [[111, "id2"]], "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5\uff1f": [[101, "id2"]], "\u672c\u5730 Evaluate": [[17, "evaluate"], [20, "evaluate"]], "\u7f16\u7801\u548c\u89e3\u7801": [[101, "id1"]], "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": [[103, "id4"]]}, "docnames": ["agent/0", "agent/agentless", "agent/api-bank", "agent/code-act", "agent/swe-agent", "base/0", "base/attention", "base/gpt", "base/gpt2", "base/gpt3", "base/instruct-gpt", "bench/0", "bench/aider", "bench/alignment", "bench/bigcodebench", "bench/code-alpaca", "bench/cruxeval", "bench/evalplus", "bench/general", "bench/humaneval", "bench/livecodebench", "bench/magic", "bench/math-science", "bench/mbpp", "bench/reward-bench", "bench/self-instruct", "bench/swe", "bench/taco", "bench/wizard", "content", "content-Copy1", "data/0", "data/alphacode", "data/apps", "data/code-alpaca", "data/magic", "data/opencoder", "data/self-instruct", "data/taco", "data/unicoder", "data/wizard", "intro", "markdown", "markdown-notebooks", "methodology/gold", "methodology/non-determin", "methodology/scaling-law", "methodology/weak-to-strong", "models/0", "models/alphacode", "models/alphacode2", "models/alphacodium", "models/codellama", "models/deepseek-coder-v2", "models/deepseek-v2", "models/deepseek-v3", "models/llama", "models/llama2", "models/llama3", "models/llama3-code copy", "models/llama3-source-code", "models/qwen25", "models/qwen25-coder", "models/qwen3", "preference/0", "preference/armo", "preference/dapo", "preference/deepseek-grm", "preference/dpo", "preference/dpop", "preference/ee", "preference/grpo", "preference/instruct-gpt", "preference/judge", "preference/openrlhf", "preference/ppo", "preference/reinforce++", "preference/rlaif-1", "preference/rlaif-2", "preference/rlcd", "preference/rs-dpo", "preference/rso", "preference/secret-rm", "preference/self-reward", "preference/self-taught", "preference/west-of-n", "reasoning/0", "reasoning/cot", "reasoning/deepcoder", "reasoning/deepseek-r1", "reasoning/logic-rl", "reasoning/s1", "reasoning/self-correct-rl", "reasoning/verify", "reference", "sft/0", "sft/lima", "sft/random", "sft/rl-eight-fold", "sft/rs", "techniques/0", "techniques/bpe", "techniques/deepseek-moe", "techniques/extending", "techniques/extending-old", "techniques/mla", "techniques/norm", "techniques/rope", "techniques/rope-old", "techniques/swiglu", "techniques/tokenize", "techniques/unicode-utf8", "tools/llama-factory", "tools/lora", "tools/openrlhf"], "envversion": {"sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["agent/0.ipynb", "agent/agentless.ipynb", "agent/api-bank.ipynb", "agent/code-act.ipynb", "agent/swe-agent.ipynb", "base/0.ipynb", "base/attention.ipynb", "base/gpt.ipynb", "base/gpt2.ipynb", "base/gpt3.ipynb", "base/instruct-gpt.ipynb", "bench/0.ipynb", "bench/aider.ipynb", "bench/alignment.ipynb", "bench/bigcodebench.ipynb", "bench/code-alpaca.ipynb", "bench/cruxeval.ipynb", "bench/evalplus.ipynb", "bench/general.ipynb", "bench/humaneval.ipynb", "bench/livecodebench.ipynb", "bench/magic.ipynb", "bench/math-science.ipynb", "bench/mbpp.ipynb", "bench/reward-bench.ipynb", "bench/self-instruct.ipynb", "bench/swe.ipynb", "bench/taco.ipynb", "bench/wizard.ipynb", "content.ipynb", "content-Copy1.ipynb", "data/0.ipynb", "data/alphacode.ipynb", "data/apps.ipynb", "data/code-alpaca.ipynb", "data/magic.ipynb", "data/opencoder.ipynb", "data/self-instruct.ipynb", "data/taco.ipynb", "data/unicoder.ipynb", "data/wizard.ipynb", "intro.md", "markdown.md", "markdown-notebooks.md", "methodology/gold.ipynb", "methodology/non-determin.ipynb", "methodology/scaling-law.ipynb", "methodology/weak-to-strong.ipynb", "models/0.ipynb", "models/alphacode.ipynb", "models/alphacode2.ipynb", "models/alphacodium.ipynb", "models/codellama.ipynb", "models/deepseek-coder-v2.ipynb", "models/deepseek-v2.ipynb", "models/deepseek-v3.ipynb", "models/llama.ipynb", "models/llama2.ipynb", "models/llama3.ipynb", "models/llama3-code copy.ipynb", "models/llama3-source-code.ipynb", "models/qwen25.ipynb", "models/qwen25-coder.ipynb", "models/qwen3.ipynb", "preference/0.ipynb", "preference/armo.ipynb", "preference/dapo.ipynb", "preference/deepseek-grm.ipynb", "preference/dpo.ipynb", "preference/dpop.ipynb", "preference/ee.ipynb", "preference/grpo.ipynb", "preference/instruct-gpt.ipynb", "preference/judge.ipynb", "preference/openrlhf.ipynb", "preference/ppo.ipynb", "preference/reinforce++.ipynb", "preference/rlaif-1.ipynb", "preference/rlaif-2.ipynb", "preference/rlcd.ipynb", "preference/rs-dpo.ipynb", "preference/rso.ipynb", "preference/secret-rm.ipynb", "preference/self-reward.ipynb", "preference/self-taught.ipynb", "preference/west-of-n.ipynb", "reasoning/0.ipynb", "reasoning/cot.ipynb", "reasoning/deepcoder.ipynb", "reasoning/deepseek-r1.ipynb", "reasoning/logic-rl.ipynb", "reasoning/s1.ipynb", "reasoning/self-correct-rl.ipynb", "reasoning/verify.ipynb", "reference.ipynb", "sft/0.ipynb", "sft/lima.ipynb", "sft/random.ipynb", "sft/rl-eight-fold.ipynb", "sft/rs.ipynb", "techniques/0.ipynb", "techniques/bpe.ipynb", "techniques/deepseek-moe.ipynb", "techniques/extending.ipynb", "techniques/extending-old.ipynb", "techniques/mla.ipynb", "techniques/norm.ipynb", "techniques/rope.ipynb", "techniques/rope-old.ipynb", "techniques/swiglu.ipynb", "techniques/tokenize.ipynb", "techniques/unicode-utf8.ipynb", "tools/llama-factory.ipynb", "tools/lora.ipynb", "tools/openrlhf.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [4, 7, 8, 10, 14, 17, 18, 22, 36, 42, 43, 44, 46, 47, 51, 52, 54, 57, 58, 59, 61, 62, 65, 66, 68, 69, 70, 71, 72, 76, 77, 78, 79, 81, 82, 84, 91, 92, 94, 99, 101, 102, 103, 104, 110], "0": [6, 7, 17, 19, 20, 25, 28, 36, 37, 40, 44, 45, 46, 49, 50, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 68, 69, 71, 73, 74, 77, 78, 81, 82, 83, 85, 96, 99, 102, 103, 104, 106, 107, 108, 109, 111, 112, 113], "000": [2, 18, 22, 26, 27, 33, 38, 49, 52, 91, 96], "0000": [104, 111], "0000j": 104, "0001": 111, "0010": 111, "003": [15, 34], "0041": 111, "005": 19, "007f": 111, "0080": 111, "01": [66, 74], "0100j": 104, "012": 66, "01825": [42, 94], "02120": [21, 35, 42, 94], "02155": [42, 94], "02954": [42, 94], "03": 56, "03065": [42, 94], "0314": 13, "03300": [42, 94], "03341": [42, 94], "03374": [42, 94], "03762": [42, 94], "04434": [42, 94], "0461": 104, "04805": [42, 94], "0596": 104, "0596j": 104, "06": 56, "0674": 104, "0674j": 104, "07436": [42, 94], "076": 46, "07911": [42, 94], "07974": [42, 94], "07ff": 111, "08": 66, "0800": 111, "08083": [42, 94], "08361": [42, 94], "08568": [28, 40], "096": [52, 66], "09864": [42, 94], "0xxxxxxx": 111, "1": [1, 2, 6, 7, 10, 13, 15, 17, 19, 20, 21, 25, 26, 27, 28, 30, 34, 35, 36, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 81, 82, 83, 84, 85, 91, 92, 93, 94, 96, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], "10": [3, 17, 20, 22, 33, 36, 45, 46, 50, 52, 53, 54, 56, 58, 62, 66, 71, 78, 82, 101, 102, 111, 112], "100": [4, 8, 15, 18, 19, 34, 36, 50, 52, 62, 65, 70, 93], "1000": [28, 40, 55, 93, 103, 104], "10000": [6, 50, 59, 60, 103, 104, 107, 108], "100000": 74, "10000000": 111, "100k": 54, "10111000": 111, "1024": [62, 74], "102400": 54, "1048576000": 54, "105": 20, "10509": [42, 94], "10560": [25, 37], "106": 20, "107": 20, "10k": 54, "10x": 9, "10xxxxxx": 111, "11": [20, 108], "1106": [21, 35], "110k": [21, 35], "110xxxxx": 111, "110\u8868\u793a\u9700\u8981\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u5f53\u524d\u5b57\u7b26": 111, "1110": 111, "1110xxxx": 111, "1110\u8868\u793a\u9700\u8981\u4e09\u4e2a\u5b57\u8282": 111, "11110xxx": 111, "11110\u8868\u793a\u9700\u8981\u56db\u4e2a\u5b57\u8282": 111, "117": 20, "12": [18, 20, 22, 26, 46, 50, 54, 101, 108], "12000": 112, "12122": [42, 94], "12186": [42, 94], "12288": 54, "123abc\u4e00\u4e8c\u4e09": 111, "125": [9, 20], "128": [54, 74], "128k": [54, 55, 58], "128\u4f4dascii\u7801\u662f\u6570\u5b57": 111, "12b": 19, "12k": 93, "12n_": 46, "13": [20, 46, 59, 101], "131": 33, "13245": [42, 94], "138": 2, "13b": 52, "13k": 10, "14": [18, 20, 52, 55, 105], "14165": [42, 94], "14168": [42, 94], "14187": [42, 94], "14858": [42, 94], "149225472": 54, "15": [20, 21, 35, 56, 57, 96], "151": 61, "15115": [42, 94], "1536": 54, "15b": [28, 40], "16": [18, 20, 56, 66, 72, 74, 77, 91, 99], "160": 54, "1609": 59, "1612": [42, 94], "164": 19, "16441": [42, 94], "16609": [42, 94], "16k": 58, "17": [19, 20], "1706": [42, 94], "175": [9, 25, 37], "17k": 66, "18": [20, 61], "1810": [42, 94], "18290": [42, 94], "185b": 53, "188743680": 54, "19": [8, 9, 26, 42, 94], "1904": [42, 94], "1909": [42, 94], "195": 26, "198": 22, "1990\u5e74\u5f00\u59cb\u7814\u53d1": 111, "1994": 101, "1_gnu": 20, "1e": [59, 60, 96, 106, 112], "1k": 22, "1l": 80, "1m": 36, "1qvx610cu7": [42, 94], "1t": [54, 58], "1w": 80, "1\u4f4d\u4e3a": 111, "2": [2, 3, 4, 6, 7, 8, 9, 10, 14, 15, 17, 18, 20, 22, 25, 26, 30, 34, 37, 43, 46, 47, 49, 51, 53, 54, 55, 56, 58, 59, 60, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 81, 82, 83, 85, 91, 92, 93, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111], "20": [9, 10, 15, 20, 34, 42, 66, 82, 93, 94], "200": [10, 15, 19, 34, 93], "2000": 56, "2001": [42, 94], "2005": [42, 94], "20050": [42, 94], "2009": [42, 94], "2017": [42, 94], "2019": [42, 94], "2020": [42, 94], "2021": [42, 94], "2022": [42, 94], "2023": [42, 53, 94], "2024": [20, 42, 62, 66, 94], "20240602": 20, "2025": [42, 94], "2048": [59, 60, 96, 103, 104], "20k": [15, 21, 28, 34, 35, 40, 53], "21": [18, 19, 20, 21, 22, 35, 42, 94, 99, 108], "2104": [42, 94], "2107": [42, 94], "2110": [42, 94], "21326725120": 54, "21b": 54, "22": [10, 20, 42, 94, 108], "2203": [42, 94], "2212": [25, 37], "2294": 59, "23": [6, 7, 13, 20, 22, 42, 55, 56, 61, 94, 99, 101, 103, 105, 107], "2305": [42, 94], "2306": [28, 40], "2308": [42, 94], "2309": [42, 94], "2311": [42, 94], "2312": [21, 35, 42, 94], "232": 33, "235692359680": 54, "236b": 54, "24": [16, 18, 20, 36, 39, 42, 53, 54, 55, 58, 61, 62, 94, 102, 105], "2401": [42, 94], "2403": [42, 94], "2405": [42, 94], "2406": [42, 94], "2409": [42, 94], "2412": [42, 94], "25": [13, 20, 27, 38, 42, 61, 62, 82, 94, 105], "250": 96, "256": [59, 60, 83], "256\u4f4dascii\u6269\u5c55\u7801\u662fascii": 111, "26": [20, 91], "27": [57, 91], "28": 66, "29": 20, "2900": 104, "290k": 36, "2d": 103, "2d_": 46, "2e": 36, "2i": [6, 52, 108], "2j": [59, 60, 103, 104], "2m": 54, "2n": 46, "2n_": [46, 105], "2t": 108, "2\u62164\u5b57\u8282\u53d8\u957f": 111, "3": [7, 8, 9, 10, 13, 20, 21, 26, 35, 45, 46, 49, 51, 52, 53, 54, 55, 59, 72, 74, 77, 83, 89, 91, 99, 101, 102, 103, 104, 106, 109], "30": [18, 53, 58], "300": 26, "3000": 104, "300m": 53, "30k": 53, "314": 2, "31k": 10, "32": [20, 59, 60, 66, 70, 96, 99, 111], "3200": 70, "32768": [103, 104], "32b": [66, 91], "32k": 55, "33": 18, "338": 53, "33k": 10, "33t": 105, "34": [20, 22], "34b": [16, 52, 74], "35x": 17, "37": 26, "374": 59, "37b": 55, "38": 20, "3822059520": 54, "384": 66, "39": 22, "3m": 54, "4": [10, 13, 18, 20, 21, 22, 35, 46, 47, 52, 56, 58, 59, 60, 66, 69, 70, 72, 74, 78, 83, 93, 99, 101, 104, 105, 106, 111, 112], "40": [65, 77, 82], "400": 13, "405b": 58, "4096": [36, 59, 60, 112], "40k": 53, "41": 20, "421": 33, "426": 23, "43": 20, "438k": 26, "443": [27, 38], "448": 22, "45": [8, 20, 56], "4d": [59, 60], "4e00": 111, "4e00\u57280800": 111, "4e00\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a100": 111, "4k": 55, "4t": 56, "4\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 111, "4\u5b57\u8282\u53d8\u957f": 111, "4\u5b57\u8282\u8868\u793a": 111, "5": [18, 20, 21, 22, 29, 30, 33, 35, 36, 42, 49, 52, 53, 54, 55, 56, 59, 60, 65, 66, 68, 69, 70, 82, 83, 85, 91, 94, 96, 101, 104, 112], "50": [50, 52, 66, 91], "500": 13, "500000": [59, 60], "500b": 52, "512": [6, 36, 54, 66], "5120": 54, "52": 52, "52k": [15, 25, 34, 37], "54": [20, 49], "540": 57, "5403": 104, "55m": [27, 38], "57": 18, "5963": 59, "59k": 91, "5b": 93, "5e": [36, 74], "5k": 22, "5m": 54, "5pm": [15, 34], "6": [6, 17, 20, 21, 25, 35, 37, 46, 51, 52, 53, 54, 59, 60, 66, 74, 78, 93, 96, 104, 106, 112], "60": [14, 53, 54, 65, 77], "62": [20, 52], "63": 20, "64": [20, 54, 56, 96], "643": 61, "65": 22, "65b": [56, 96], "66": 20, "67": 56, "671b": 55, "67b": 54, "6n": 46, "6nb": 46, "6w": 111, "7": [19, 20, 22, 25, 37, 47, 50, 57, 61, 62, 66, 74, 99, 101, 104], "70": 20, "70b": [52, 57, 58, 74, 83], "72": 20, "73": 2, "750": 96, "753": 2, "75k": [21, 35, 93], "77": 50, "777": 33, "788m": 55, "7b": [15, 17, 21, 34, 35, 52, 56, 57, 74, 91, 105, 112], "8": [9, 20, 22, 25, 37, 42, 46, 51, 52, 54, 55, 61, 74, 77, 94, 99, 104, 105], "80": [47, 93], "800": 16, "8000": 50, "800k": 93, "80gb": 74, "80k": [21, 35], "80x": 17, "821b": 53, "82k": [25, 37], "83": 59, "8415j": 104, "85": [50, 58], "888": 2, "8b": [45, 58, 74], "8binstruct": 45, "8\u4e2abit\u4f4d\u4e2d\u9ad8\u4f4d\u5fc5\u987b\u7b49\u4e8e0": 111, "8\u4e2abit\u4f4d\u662f\u4e00\u4e2a\u5b57\u8282": 111, "8\u4e3a11100100": 111, "8\u4e3a\u4e09\u5b57\u8282": 111, "8\u4f4d\u53ef\u8868\u793a256\u4e2a\u5b57\u7b26": 111, "8\u548cgbk\u7f16\u7801": 111, "8\u6765\u5b9e\u73b0\u7f16\u7801": 111, "8\u7684\u65b9\u5f0f\u6765\u7f16\u7801\u89e3\u7801\u4f7f\u7528": 111, "8\u7684\u6620\u5c04\u5173\u7cfb\u5982\u4e0b": 111, "8\u7684\u7f16\u7801\u65b9\u5f0f": 111, "8\u7684\u89c4\u5219\u5f88\u7b80\u5355": 111, "8\u7b49": 111, "8\u7f16\u7801": 111, "9": [10, 19, 20, 42, 56, 59, 66, 72, 79, 94, 96, 101, 105], "90": 26, "92": 62, "9297": 104, "95": [20, 56, 96], "97": 14, "974": 23, "9901": 112, "9999": 104, "9e": 74, "A": [4, 8, 15, 22, 25, 34, 36, 37, 42, 44, 45, 50, 57, 59, 60, 61, 65, 66, 70, 71, 76, 77, 78, 81, 84, 85, 89, 91, 94, 101, 102, 103, 108, 109, 113], "And": [71, 99], "As": [1, 44, 47, 50, 51, 53, 57, 66, 69, 70, 71, 85, 89, 93, 102, 105], "At": [4, 6, 8, 25, 37, 44, 49, 55, 57, 84, 93, 103, 104], "By": [9, 53, 55, 58, 59, 66, 70, 82, 103], "FOR": 77, "For": [1, 2, 3, 7, 10, 15, 21, 23, 25, 26, 34, 35, 36, 37, 42, 45, 46, 47, 50, 51, 52, 54, 55, 57, 58, 61, 62, 65, 66, 67, 69, 70, 71, 73, 77, 79, 80, 81, 82, 89, 91, 93, 99, 102, 103, 104, 105, 113], "If": [13, 43, 44, 47, 51, 59, 60, 62, 70, 71, 77, 81, 84, 102, 104, 109], "In": [2, 3, 6, 7, 10, 15, 21, 25, 28, 34, 35, 36, 37, 39, 40, 42, 44, 45, 49, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 77, 78, 81, 82, 83, 84, 85, 87, 89, 94, 96, 99, 102, 103, 104, 105, 107, 108], "It": [10, 13, 14, 15, 18, 28, 34, 40, 42, 46, 47, 51, 52, 54, 57, 58, 59, 68, 71, 77, 91, 92, 102, 104], "Its": 50, "No": [45, 55, 59, 62], "Not": [15, 34], "OF": 77, "Of": [25, 37], "On": [6, 47, 55, 70], "One": [13, 44, 49, 58, 70, 73, 77, 78, 81, 103, 104, 108], "Or": [17, 58], "Such": [42, 66, 84, 94], "That": [6, 43], "The": [1, 3, 6, 7, 8, 9, 10, 14, 15, 16, 18, 19, 21, 22, 23, 25, 28, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 45, 46, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 81, 82, 83, 84, 89, 93, 96, 102, 103, 104, 105, 106, 108, 109], "Their": 93, "Then": [1, 10, 21, 26, 35, 58, 69, 70, 71, 77, 78, 81, 91, 102, 105, 107], "There": [14, 103], "Thes": 14, "These": [6, 7, 15, 22, 27, 28, 34, 36, 40, 58, 61, 77, 81, 83, 84], "To": [1, 2, 3, 6, 8, 9, 10, 14, 18, 21, 22, 25, 26, 28, 32, 35, 36, 37, 39, 40, 44, 45, 46, 49, 50, 52, 53, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 71, 72, 73, 76, 78, 81, 83, 85, 89, 91, 93, 102, 103, 106, 109], "With": [18, 22, 43, 51, 67, 103], "_": [6, 10, 25, 28, 37, 39, 40, 44, 52, 55, 57, 59, 60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 80, 81, 82, 85, 92, 93, 99, 102, 103, 105, 107, 108, 109], "_1": [6, 92], "__init__": [54, 59, 60, 106], "__main__": 17, "__name__": 17, "_bsz": [59, 60], "_h": 6, "_i": 99, "_libgcc_mutex": 20, "_mergeable_rank": 59, "_norm": [59, 60, 106], "_openmp_mutex": 20, "_t": [76, 105], "a100": 74, "a_": [44, 71, 76, 91, 104, 108], "a_i": [39, 99], "a_t": 76, "aa": 101, "aaabdaaabac": 101, "ab": [42, 94, 101, 104], "abbrevi": [22, 33, 111], "abil": [1, 2, 4, 8, 18, 21, 22, 35, 47, 53, 54, 61, 66, 69, 71, 81, 87, 89, 93], "abl": [15, 16, 22, 34, 47, 57], "ablat": [36, 91, 93], "about": [4, 6, 10, 15, 21, 26, 34, 35, 42, 43, 47, 50, 51, 52, 54, 70, 82, 91, 102, 104], "abov": [7, 26, 47, 50, 52, 58, 66, 67, 76, 81, 82, 84, 85, 89, 92, 102, 103], "absenc": 55, "absolut": [6, 56, 65, 107], "absorb": 105, "abstract": 8, "abstractset": 59, "ac": 101, "academ": 18, "acceler": [7, 105], "accept": [42, 81], "access": [2, 4, 33, 47, 57, 70, 81, 83, 84, 85, 92], "accommod": [58, 93], "accompani": 73, "accomplish": [45, 58], "accord": [2, 50, 55, 70, 82, 85, 91, 93, 102, 104], "accordingli": 66, "account": [46, 52], "accumul": 51, "accur": [18, 23, 27, 36, 57, 61, 67, 71, 82], "accuraci": [2, 18, 22, 55, 61, 66, 78, 82, 89, 91], "achiam": [42, 94], "achiev": [3, 9, 18, 22, 36, 49, 53, 55, 56, 57, 58, 61, 66, 67, 68, 69, 73, 78, 81, 82, 85, 91, 105], "acquir": [18, 54, 57, 89, 102], "across": [18, 20, 47, 50, 58, 61, 70, 91, 93, 102, 103, 105, 106], "act": 4, "action": [1, 3, 4, 15, 34, 44, 66, 76], "activ": [6, 7, 54, 55, 56, 61, 102, 105, 109], "actor": [71, 74], "actor_learning_r": 74, "actual": [1, 10, 71, 92], "ad": [7, 8, 25, 28, 37, 40, 49, 58, 66, 71, 82, 92, 108], "adam_offload": 74, "adamw": [56, 66, 96], "adapt": [7, 28, 40, 67, 73, 102, 103, 104, 113], "add": [6, 8, 10, 14, 28, 40, 51, 52, 55, 56, 57, 59, 60, 65, 72, 82, 83], "addit": [6, 8, 10, 26, 44, 47, 49, 50, 52, 53, 55, 59, 60, 66, 70, 72, 73, 79, 83, 89, 92, 93, 96, 102, 103, 105, 109, 111], "addition": [1, 7, 18, 25, 36, 37, 55, 70, 102], "additionali": 71, "address": [2, 22, 28, 40, 51, 58, 62, 66, 71, 78, 81], "adher": [47, 61, 62, 66, 89], "aditya": [42, 94], "adjust": [54, 58, 65, 81, 89, 105], "adopt": [15, 21, 26, 32, 34, 35, 45, 49, 54, 55, 62, 67, 89, 105], "advanc": [2, 18, 36, 50, 61], "advantag": [47, 71, 73, 74, 105], "advis": 77, "affect": [29, 36, 45, 102], "affin": [55, 59, 102], "aforement": 78, "after": [4, 7, 8, 25, 28, 37, 40, 45, 49, 50, 53, 55, 56, 57, 58, 59, 62, 66, 69, 70, 71, 72, 78, 81, 82, 83, 89, 91, 93, 102, 103, 104], "again": [4, 6, 78, 109], "against": [10, 13, 32, 51, 62, 77, 79, 91], "agarw": [42, 94], "agent": [1, 62, 70, 76, 81], "aggreg": 50, "aggress": [15, 34], "agnost": [9, 73], "ahm": [42, 94], "ai": [2, 13, 20, 22, 42, 51, 58, 66, 67, 83, 85, 94], "aidan": [42, 94], "aif": 83, "aift": 83, "aim": [1, 14, 22, 44, 45, 66, 71, 81, 83, 84, 92, 102], "aime24": 91, "ainsli": [42, 94], "aiohttp": 20, "aiosign": 20, "aixin": [42, 94], "ajudg": 62, "alec": [42, 94], "alethea": [42, 94], "alex": [42, 94], "algorithm": [10, 19, 25, 27, 37, 38, 49, 50, 51, 53, 54, 56, 57, 58, 61, 62, 66, 68, 71, 101], "alibi": 104, "align": [6, 7, 10, 22, 29, 39, 46, 47, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 76, 78, 81, 102, 103, 104, 105, 107, 108, 109], "align_n": 73, "alignmentrelev": 47, "alik": 52, "all": [1, 3, 8, 10, 15, 19, 23, 28, 32, 34, 39, 40, 42, 43, 44, 46, 49, 50, 53, 54, 57, 58, 59, 62, 66, 68, 69, 70, 71, 72, 76, 77, 78, 80, 81, 82, 92, 93, 94, 96, 99, 102, 103, 104, 105, 106, 109], "allclos": [59, 106], "allevi": 102, "alloc": [62, 66, 89], "allow": [3, 4, 6, 8, 9, 26, 42, 44, 49, 50, 55, 58, 59, 76, 77, 84, 102, 104, 108], "allowed_speci": 59, "allowed_token": 59, "almeida": [42, 94], "almost": [82, 96], "alon": [78, 82, 83, 96], "along": [1, 7, 32, 49, 51, 52], "alongsid": [55, 71], "alpaca": [2, 21, 28, 29, 30, 35, 40], "alpacaev": [45, 83], "alpha": [73, 76, 82, 92, 103], "alpha_": [46, 102], "alphacod": 52, "alreadi": [47, 49, 53, 59, 70, 83], "also": [4, 6, 10, 15, 18, 20, 22, 23, 25, 26, 34, 36, 37, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 65, 68, 69, 71, 72, 77, 83, 84, 85, 91, 102, 103, 105, 109], "altdj": [42, 61, 94, 105], "alter": 51, "altern": [9, 57, 58, 68, 70, 73, 78], "although": [13, 44, 53, 55, 89, 102, 111], "alwai": [49, 58, 73, 82, 102, 103, 104], "amanda": [42, 94], "ambigu": 82, "amc": 22, "american": 111, "amodei": [42, 94], "among": [2, 13, 16, 52, 54, 62, 70, 81, 102, 105], "amount": [36, 46, 50, 54, 58, 83, 89, 91, 93, 99, 103, 105, 109], "an": [1, 2, 3, 6, 7, 8, 9, 10, 13, 14, 15, 18, 19, 21, 25, 26, 28, 34, 35, 36, 37, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 65, 66, 68, 69, 71, 73, 76, 77, 78, 79, 81, 82, 83, 84, 85, 89, 92, 93, 94, 99, 102, 103, 104, 105], "anaconda3": 20, "analogi": 47, "analysi": [2, 26, 51, 54, 58, 62, 73, 78], "analyz": [36, 62, 99], "anchor": 51, "andi": [42, 94], "andrew": [42, 94], "angela": [42, 94], "angl": [104, 107], "ani": [6, 8, 9, 14, 15, 19, 21, 25, 32, 34, 35, 36, 37, 43, 44, 47, 51, 55, 58, 59, 62, 72, 77, 85, 89, 93, 103, 104, 105, 107, 108], "anneal": 36, "annot": [2, 18, 20, 52, 55, 57, 58, 66, 78, 83], "anoth": [15, 34, 44, 49, 51, 57, 71, 73, 78, 82, 104], "answer": [1, 2, 3, 7, 8, 17, 18, 22, 27, 36, 38, 39, 45, 52, 55, 57, 61, 62, 66, 77, 84, 89, 91, 92, 93, 96, 99, 104], "answer_1": 58, "anthrop": [20, 70], "anticip": 62, "anyio": 20, "anywher": [10, 72], "aop": 66, "api": [3, 10, 14, 20, 36, 61, 72], "app": 77, "appear": [32, 46, 51, 66, 104], "append": [25, 36, 37, 59, 60, 74, 77, 81, 91], "appli": [6, 7, 10, 21, 28, 35, 40, 45, 50, 51, 52, 53, 55, 58, 59, 60, 65, 66, 68, 70, 71, 72, 73, 76, 82, 84, 85, 89, 92, 99, 102, 103, 104, 109], "applic": [4, 9, 10, 22, 52, 57, 103, 104], "apply_chat_templ": 74, "apply_rotary_emb": [59, 60, 104], "approach": [21, 25, 35, 36, 37, 44, 46, 50, 52, 54, 55, 57, 58, 62, 65, 66, 68, 73, 76, 78, 79, 83, 84, 85, 89, 91, 92, 102, 103, 104], "appropri": [2, 6, 15, 34, 52, 76], "approx": [46, 55, 103, 107], "approxim": [8, 9, 13, 44, 53, 54, 58, 70, 82, 85, 93, 96, 99, 102, 104], "aptitud": 22, "ar": [2, 3, 6, 7, 8, 9, 10, 13, 14, 15, 16, 19, 21, 22, 25, 26, 28, 33, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 81, 82, 83, 84, 87, 93, 94, 96, 99, 102, 103, 104, 105, 106, 108, 111], "arang": [19, 59, 60, 68, 104], "arbitrari": [10, 104], "archit": [42, 94], "architectur": [7, 8, 46, 49, 52, 62, 102, 104, 105, 106, 108, 113], "archiv": 8, "area": [18, 61], "arg": [57, 59, 60, 67, 74, 81, 104], "argmax": 59, "argu": [54, 81], "ariel": [42, 94], "aris": [77, 78], "arithmet": 22, "armando": [42, 94], "armo": 30, "armorm": 45, "around": [6, 13, 105], "arrang": 20, "art": [9, 22, 47, 56, 66], "articl": 8, "artifici": 67, "arvind": [42, 94], "arxiv": [21, 25, 28, 35, 37, 40, 42, 56, 94], "ascent": 76, "ascertain": 70, "ascii\u5c31\u662f\u6700\u521d\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 111, "ascii\u8d77\u521d\u53ea\u89c4\u5b9a\u4e86127\u4e2a\u5b57\u7b26": 111, "ashish": [42, 94], "ask": [1, 4, 10, 14, 15, 23, 25, 34, 37, 51, 57, 58, 72, 78, 84], "askel": [42, 94], "aspect": [51, 61, 73, 83], "assert": [52, 59, 60, 104], "assertionerror": [59, 104], "assess": [2, 18, 19, 22, 28, 40, 58, 62, 80, 91], "assign": [6, 44, 49, 57, 58, 65, 66, 70, 71, 73, 76, 81, 82, 85, 92, 93, 102], "assist": [15, 34, 47, 52, 59, 77, 79, 83, 84], "associ": [52, 66, 81], "assum": [7, 44, 69, 73, 81, 83, 84, 85, 92, 106, 110], "ast": [67, 68, 81, 92, 108], "asymptot": 22, "async": 20, "atcod": [20, 33], "atol": [59, 106], "atom": 3, "att": 102, "attach": 65, "attain": 70, "attempt": [1, 47, 91, 92, 93], "attend": 6, "attent": [7, 8, 9, 29, 30, 42, 46, 54, 55, 61, 69, 94, 102, 103, 104, 106, 107, 108], "attention_bia": 54, "attention_norm": [59, 60], "attn": 46, "attr": 20, "attract": 104, "attribut": [26, 50, 79], "audio": [15, 34], "augment": [2, 83], "auli": [42, 94], "auth": 20, "authent": 73, "author": [68, 83], "auto": [6, 13], "autom": [25, 33, 36, 37, 61], "automat": [1, 3, 4, 13, 21, 25, 28, 35, 37, 40, 58, 62, 65, 79, 102], "autonom": [1, 89], "autoregress": [7, 9, 44, 52, 57, 103], "auxiliari": [7, 47, 49, 55, 92], "avail": [2, 27, 52, 56, 58, 61], "avenu": 10, "averag": [3, 19, 26, 49, 50, 59, 60, 71, 78, 91, 102], "avg": 66, "avoid": [4, 10, 44, 47, 49, 50, 51, 66, 69, 71, 76, 81, 82, 103], "await": [28, 40], "ax": 58, "axi": [59, 106], "b": [7, 42, 44, 46, 59, 60, 70, 77, 84, 91, 92, 94, 103, 109, 113], "b_": [59, 60, 109], "b_1": 6, "b_2": 6, "b_i": 55, "b_j": 55, "babuschkin": [42, 94], "backbon": 65, "backend": 17, "background": 19, "backpropag": 57, "backtransl": 58, "backward": 46, "bad": [44, 47, 58], "bag": 57, "bai": [42, 94], "baker": [42, 94], "balaji": [42, 94], "balanc": [6, 55, 58, 62, 66, 84], "band": 9, "bank": 3, "bao": [42, 94], "baosong": [42, 94], "baptist": [42, 94], "bar": 103, "barn": [42, 94], "basart": [42, 94], "base": [1, 2, 6, 7, 8, 10, 14, 15, 21, 22, 25, 28, 30, 34, 35, 36, 37, 40, 43, 44, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 65, 68, 70, 71, 72, 73, 77, 81, 82, 83, 84, 85, 91, 92, 99, 103, 104, 107, 108, 111, 112], "baselin": [13, 22, 45, 66, 83, 84, 93], "basi": [59, 104], "basic": [22, 23, 29, 51, 61, 62], "basu": [42, 94], "batch": [10, 15, 34, 36, 46, 52, 56, 57, 58, 59, 66, 70, 72, 96, 105], "batchnorm1d": [59, 106], "batchnorm2d": 59, "bavarian": [42, 94], "bax": 113, "bbc": [42, 61, 94], "bbpe": [54, 61], "becaus": [6, 15, 25, 34, 37, 51, 58, 65, 77, 89, 106], "becom": [69, 78, 92, 102, 104, 105], "been": [3, 26, 44, 50, 51, 54, 55, 59, 61, 70, 71, 82, 85], "befor": [2, 25, 32, 37, 47, 49, 53, 57, 62, 79, 103, 104], "begin": [1, 2, 6, 7, 8, 10, 46, 52, 55, 57, 58, 59, 60, 66, 67, 68, 69, 70, 71, 72, 77, 81, 85, 89, 102, 103, 104, 105, 107, 108, 109], "begin_of_text": 59, "behav": [47, 50, 104], "behavior": [8, 10, 22, 44, 47, 50, 51, 62, 66, 67, 77, 89, 104, 106], "behaviour": 49, "behind": 104, "bei": [42, 94], "beichen": [42, 94], "being": [6, 9, 21, 35, 42, 49, 58, 85], "believ": 65, "belong": 102, "below": [15, 21, 34, 35, 47, 52, 69, 76, 82], "bench": 29, "benchmark": [2, 3, 8, 9, 16, 27, 28, 38, 40, 42, 47, 53, 54, 58, 91, 94, 105], "benefici": [6, 51, 82], "benefit": [4, 8, 57, 82, 99], "benfeng": [42, 94], "benjamin": [42, 94], "berner": [42, 94], "bert": [8, 42, 94], "besid": [66, 67], "best": [3, 10, 22, 36, 45, 46, 49, 50, 51, 56, 57, 58, 62, 67, 70, 72, 82, 83, 85, 91, 92, 93], "bestof": 45, "beta": [10, 57, 59, 68, 69, 71, 72, 76, 81, 103, 106, 109], "beta_": [56, 92], "beta_1": 96, "beta_2": 96, "better": [10, 18, 47, 50, 51, 53, 55, 56, 57, 58, 61, 62, 69, 76, 77, 78, 81, 84, 91, 93, 99, 105], "between": [6, 10, 15, 18, 21, 22, 34, 35, 39, 44, 45, 47, 49, 50, 52, 54, 57, 58, 59, 60, 66, 68, 69, 71, 72, 76, 77, 78, 81, 82, 83, 89, 92, 93, 99, 102, 103, 106, 107, 108, 109], "beyond": [20, 47, 78, 102, 104], "bf16": [74, 112], "bi": [42, 94], "bia": [54, 55, 59, 60, 61, 65, 78, 84, 92, 109], "bias": [25, 37, 44], "bib": 42, "bibliographi": 42, "bibtex": 42, "bidirect": [42, 94], "bigger": [10, 103], "biggest": 50, "bilinear": 109, "billion": 9, "bin": [42, 94], "binari": [57, 58, 67, 78, 82], "bing": [42, 94], "bingxuan": [42, 94], "binom": [10, 19, 72, 91], "binyuan": [42, 94], "biologi": [18, 22], "bit": [70, 103], "black": 46, "bleu": 44, "blind": 18, "block": [7, 8, 17, 43, 52, 102], "blog": [10, 42, 62, 71, 75, 94], "blue": [28, 40], "bm25": 26, "bmr": [9, 10, 42, 94], "bn": [59, 106], "bo": [42, 59, 94], "bob": [42, 94], "bodi": [19, 111], "bofei": [42, 94], "boltzmann": 70, "bonu": 92, "book": [8, 42, 43, 56], "bool": 59, "bootstrap": [21, 25, 35, 37, 47], "bos_id": 59, "both": [2, 4, 6, 9, 13, 16, 18, 21, 22, 35, 42, 45, 49, 52, 55, 57, 58, 61, 62, 71, 72, 73, 77, 78, 79, 83, 85, 92, 93, 103, 104, 105, 106], "boto3": 20, "botocor": 20, "bottleneck": 105, "bottom": [6, 82], "bound": [45, 76, 102, 104], "boundari": [21, 25, 35, 37, 103], "bowen": [42, 94], "box": [22, 42, 55, 89], "boyang": [42, 94], "bpe": [8, 52, 56], "bpe\u6bcf\u4e00\u6b65\u90fd\u5c06\u6700\u5e38\u89c1\u7684\u4e00\u5bf9\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u66ff\u6362\u4e3a\u8be5\u6570\u636e\u4e2d\u6ca1\u6709\u51fa\u73b0\u8fc7\u7684\u4e00\u4e2a\u65b0\u5355\u4f4d": 101, "bpe\u9009\u62e9\u9891\u6570\u6700\u9ad8\u7684\u76f8\u90bb\u5b50\u8bcd\u5408\u5e76": 110, "bradlei": [10, 65, 68, 81, 82], "brahma": [42, 94], "brainstorm": 84, "branch": 58, "breadth": [18, 28, 40], "break": [25, 37, 59, 81], "breviti": [102, 105], "bridg": [18, 44, 62], "brief": [9, 14], "bright": 22, "bring": 71, "broad": [25, 37], "broadcast": 104, "broader": [18, 20], "broadli": 9, "brockman": [42, 94], "brook": [42, 94], "brown": [42, 94], "brundag": [42, 94], "brute": 51, "bsz": [59, 60], "bt": 81, "bucket": 58, "budget": [49, 50, 52, 56, 61, 91, 102], "buffer": [70, 74], "bug": [1, 14, 26, 51, 74], "build": [1, 4, 8, 18, 20, 42, 45, 53, 58, 59, 61, 62, 65, 79, 83, 84], "built": [4, 43, 54, 57, 62], "bullet": 51, "burda": [42, 94], "burden": 71, "burn": [42, 94], "busi": 18, "byte": [8, 42, 52, 54, 56, 61, 94], "bzip2": 20, "c": [7, 16, 19, 46, 49, 50, 54, 57, 58, 59, 60, 62, 67, 70, 82, 103, 104, 105, 106, 109], "c4": 56, "c_": [46, 54], "ca": 20, "cach": [17, 59, 60, 61, 66], "cache_k": [59, 60], "cache_len": [59, 60], "cache_v": [59, 60], "cachecontrol": 20, "cachetool": 20, "cai": [42, 77, 94], "caichat": 74, "calcul": [2, 19, 22, 54, 59, 60, 66, 70, 71, 76, 77, 78, 82, 99, 102, 104, 106], "calibr": [45, 77], "call": [2, 3, 4, 6, 8, 9, 10, 14, 19, 28, 40, 42, 44, 47, 51, 55, 57, 58, 59, 72, 73, 77, 81, 87, 93, 104, 105, 109], "can": [2, 3, 4, 6, 7, 9, 10, 14, 19, 20, 21, 22, 25, 26, 35, 36, 37, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 62, 65, 66, 68, 69, 70, 71, 72, 73, 76, 77, 78, 81, 82, 83, 84, 85, 89, 91, 93, 94, 99, 102, 103, 104, 105, 106, 108, 109, 110], "cancel": 68, "candid": [26, 49, 50, 58, 62, 70, 78, 81, 83, 85, 99], "cannot": [14, 15, 22, 34, 44, 47, 104, 105], "canon": 78, "capabl": [2, 13, 14, 20, 21, 22, 28, 35, 36, 39, 40, 45, 47, 52, 55, 57, 61, 62, 73, 83, 89, 104], "capac": [7, 70, 102], "captur": [82, 89, 102], "cardin": [50, 70], "care": [47, 58, 91], "carefulli": [18, 54, 58, 61, 96], "carlo": [44, 71], "carr": [42, 94], "carri": [55, 105], "carrol": [42, 94], "cascad": 52, "case": [10, 15, 21, 23, 25, 32, 33, 34, 35, 36, 37, 44, 49, 50, 51, 52, 53, 55, 57, 62, 66, 67, 69, 73, 77, 85, 89, 91, 102, 103], "cast": 59, "catastroph": 104, "catch": 58, "categor": [50, 58, 62, 82, 84], "categori": [4, 13, 84], "caus": [18, 59, 68, 69, 79, 102], "causal": [7, 52], "cd": [17, 20], "cdot": [6, 54, 66, 68, 69, 73, 81, 92, 102, 103, 108, 109], "ce": 70, "ceas": 46, "ceil": 47, "cell": 59, "central": 82, "centroid": 102, "certain": [7, 44, 55, 58, 66, 84, 85, 102, 103, 104], "certif": 20, "certifi": 20, "cffi": 20, "cfg": 17, "cgrs19": [9, 42, 94], "chai": [42, 94], "chain": [18, 55, 77, 78, 84, 99], "chainof": 99, "challeng": [2, 13, 14, 15, 18, 22, 27, 34, 38, 47, 51, 58, 61, 62, 66, 68, 82, 84, 89, 93], "chan": [42, 94], "chanc": [18, 51], "chang": [4, 15, 20, 26, 34, 42, 67, 79, 92, 94], "changhan": [42, 94], "changyu": [42, 94], "channel": [20, 59], "chantzi": [42, 94], "charact": [51, 52, 111], "character": [46, 54, 61], "characterist": [28, 40, 54], "charset": [20, 111], "chat": [14, 42, 53, 54, 57, 59, 94], "chat_complet": 59, "chatbot": 13, "chatgpt": [21, 35, 47], "cheaper": 13, "check": [10, 14, 23, 33, 36, 52, 58, 61, 62, 91, 92, 93], "checker": 4, "checklist": 62, "checkpoint": [42, 53, 55, 57, 58, 59, 61, 74, 89, 94], "chelsea": [42, 94], "chemistri": [18, 22], "chen": [42, 94], "chenggang": [42, 94], "chengpeng": [42, 94], "chengqi": [42, 94], "chengqiang": [42, 94], "chengyuan": [42, 94], "chess": [42, 47, 94], "child": [42, 94], "chines": 54, "cho": [42, 94], "choic": [7, 18, 22, 36, 44, 57, 69, 70, 77, 81, 93, 108], "chong": [42, 94], "choos": [26, 28, 40, 49, 51, 57, 77, 82, 84, 91, 93, 103], "chose": 6, "chosen": [46, 57, 58, 65, 82], "chosen_1": 58, "chosen_2": 58, "christiano": [42, 94], "christoph": [42, 94], "chu": [42, 94], "chuanqi": [42, 94], "chunqiu": [42, 94], "ci": 104, "cite": 42, "ckb": [22, 42, 94, 99], "ckpt_dir": 59, "ckpt_path": 59, "cl": [21, 35], "clamp": 77, "clarifi": 46, "clariti": [55, 62], "clark": [42, 94], "class": [1, 20, 25, 37, 54, 59, 60, 69, 106], "classic": 76, "classif": [7, 15, 34, 47, 58, 82, 91, 93], "classifi": [20, 49, 58, 62, 73, 84, 91], "claud": [53, 91], "clean": [36, 53, 57, 58, 62], "clear": [62, 74, 82, 104], "clearli": [51, 53], "clemen": [42, 94], "cleo": 20, "clever": 68, "cli": [17, 74], "client": 20, "clip": [56, 71], "clone": [17, 20], "close": [1, 21, 35, 44, 50, 51, 53, 55, 59, 77], "closer": 81, "closest": 51, "cluster": 58, "cly": [42, 62, 94], "cnn": 8, "co": [6, 52, 59, 60, 103, 104, 107, 108], "coars": [58, 62], "cobb": [42, 94], "code": [1, 3, 4, 16, 19, 20, 21, 26, 27, 29, 30, 33, 35, 36, 38, 39, 42, 43, 45, 47, 49, 50, 53, 54, 55, 56, 61, 62, 84, 89, 94, 111], "code1": 20, "code2": 20, "code_alpaca_20k": [15, 34], "code_generation_lit": 20, "code_list": 20, "codealpaca": [15, 21, 29, 30, 34, 35], "codebas": [1, 26], "codebert": 62, "codecontest": [49, 50], "codeexecut": 20, "codeforc": [20, 32, 33, 49, 50], "codegen": 17, "codellama": [21, 35], "codenet": 32, "codeqwen1": 62, "coder": [21, 29, 30, 35, 36, 42, 55, 61, 94, 112], "codewar": 33, "codex": [19, 29, 52], "coeffici": [10, 65, 68, 72, 76, 104], "cognit": 89, "coher": [20, 78], "collabor": 62, "collaps": 66, "collect": [8, 10, 20, 21, 25, 26, 35, 36, 37, 52, 54, 56, 58, 59, 62, 72, 73, 74, 77, 84, 85, 89, 99], "collin": [42, 94], "colon": 79, "com": [17, 20], "combin": [1, 8, 10, 15, 21, 34, 35, 36, 50, 51, 52, 55, 57, 58, 62, 66, 72, 73, 78, 80, 81, 89, 102, 103], "come": [6, 10, 15, 25, 34, 37, 53, 103, 104], "command": [4, 20, 43], "commbal": 102, "comment": [52, 58, 62], "common": [8, 10, 20, 44, 51, 53, 58, 62, 65, 70, 102], "commoncrawl": 56, "commonli": [2, 21, 35, 36], "commonmark": 42, "commun": [36, 55, 89, 96, 111], "commut": 105, "compact": 4, "compar": [3, 13, 18, 36, 44, 45, 53, 55, 58, 61, 62, 66, 69, 70, 71, 73, 83, 85, 91, 92, 93, 109], "comparison": [10, 45, 52, 53, 54, 60, 72, 73, 77, 81, 82], "compat": [6, 52, 104, 106], "compet": [9, 58], "competit": [6, 9, 20, 22, 32, 49, 50, 55, 66, 91], "competitor": 10, "compil": [53, 54, 55, 58, 89], "complementari": 55, "complet": [1, 10, 14, 15, 19, 28, 34, 36, 40, 45, 51, 52, 55, 57, 58, 59, 62, 68, 69, 72], "complex": [1, 3, 4, 7, 14, 18, 21, 28, 35, 40, 47, 52, 58, 59, 60, 61, 62, 71, 76, 87, 89, 103, 104, 108], "complex64": [59, 60, 104], "compli": 50, "complic": [28, 40, 47, 71], "compon": [36, 50, 57, 59, 60, 61, 82, 83, 109], "compos": [6, 22, 102], "composit": [3, 58], "comprehens": [2, 8, 14, 19, 28, 40, 55, 61, 73, 76], "compress": [54, 101], "compris": [18, 54, 55, 58, 61, 62, 70, 102], "comput": [6, 16, 18, 19, 36, 47, 50, 52, 56, 57, 59, 60, 61, 62, 67, 70, 71, 76, 77, 78, 80, 89, 91, 93, 102, 103, 104, 105, 106, 108, 109, 111], "concat": 6, "concaten": [6, 25, 37, 57, 78, 92], "concept": [52, 62], "concis": [4, 55, 61, 70], "conclud": 54, "conclus": [54, 105], "concret": [28, 40, 66, 92], "concurr": 51, "conda": 20, "condit": [2, 7, 25, 37, 44, 49, 73], "conduct": [50, 54, 58, 67, 73, 78, 81, 93, 104], "conduct_rejection_sampl": 81, "confer": [42, 73, 94], "confid": [47, 77, 85], "config": [54, 102], "configur": [45, 54], "confin": 57, "conform": 58, "confus": 66, "conjug": 108, "conjunct": 4, "connect": 6, "consecut": [21, 35, 50], "consequ": [58, 73], "consid": [3, 19, 26, 44, 47, 58, 62, 65, 66, 69, 70, 73, 77, 78, 81, 82, 84, 103, 104], "consider": [53, 66, 73], "consist": [1, 2, 6, 7, 10, 16, 18, 21, 22, 26, 32, 33, 35, 47, 52, 53, 54, 62, 65, 66, 68, 72, 76, 85, 89, 99, 102, 106], "console_script": 17, "consolid": [3, 102], "constant": [2, 44, 66, 102, 103, 108, 109], "constitut": 67, "constrain": [3, 66, 68, 76, 81, 91], "constraint": [28, 40, 51, 57], "construct": [2, 13, 16, 28, 39, 40, 52, 53, 62, 67, 73, 79, 81, 83, 89, 102], "consum": [6, 85], "contain": [1, 2, 3, 6, 8, 10, 13, 14, 15, 17, 18, 21, 22, 23, 25, 26, 34, 35, 36, 37, 47, 49, 50, 51, 52, 54, 56, 57, 58, 59, 62, 66, 67, 79, 91, 93, 99, 104, 105], "container": 58, "contamin": [20, 26, 42, 94], "content": [1, 15, 34, 36, 42, 43, 59, 73, 77], "contest": [20, 50], "context": [4, 7, 8, 14, 15, 25, 26, 34, 36, 37, 44, 46, 54, 58, 65, 71, 73, 77, 78, 79, 102, 108], "context_messag": 74, "contextu": 36, "contextwindow": 55, "contigu": [7, 59, 60], "continu": [2, 6, 10, 20, 21, 22, 26, 35, 51, 58, 62, 65, 71, 72, 77, 81, 82], "contrast": [9, 18, 44, 51, 79, 85, 104], "contribut": [26, 36, 66, 76, 82], "control": [3, 10, 47, 59, 68, 72, 78, 91], "convei": 73, "convent": 105, "converg": [7, 102, 106], "convers": [46, 58, 59, 66, 77, 104], "convert": [6, 43, 78, 81], "convinc": 93, "convolut": [6, 42, 94], "cookbook": 36, "coordin": 103, "copi": 19, "core": [8, 13, 20, 47, 105], "corpora": [36, 62], "corpu": [7, 9, 21, 35, 53, 54, 55, 62, 70, 104], "corr": 65, "correct": [2, 3, 4, 14, 23, 29, 30, 36, 42, 44, 49, 50, 51, 52, 55, 58, 61, 62, 65, 66, 67, 69, 73, 84, 89, 91, 93, 94, 99], "correctli": [22, 51, 85, 92, 104], "correl": [9, 13, 65, 73, 83, 99], "correspond": [6, 10, 14, 22, 25, 28, 36, 37, 40, 44, 50, 51, 52, 53, 55, 59, 60, 65, 67, 68, 71, 73, 81, 104, 107, 108], "correspondingli": 71, "cosin": [6, 36, 56, 58, 112], "cost": [15, 34, 53, 55, 102], "costli": 102, "cot": [18, 29, 30, 66, 77, 78, 89], "could": [45, 47, 49, 50, 58, 65, 67, 76, 82, 85, 91, 104], "count": [19, 36, 91], "counteract": [6, 58], "counterclockwis": 107, "counterpart": [57, 58], "coupl": [55, 92], "cover": [18, 51, 58, 62, 83, 102], "coverag": [25, 37, 53, 61, 78, 85], "cpu": 59, "cr": 70, "crack": 30, "craft": 70, "crashtest": 20, "crawl": [8, 53, 62], "creat": [8, 10, 15, 20, 22, 25, 26, 28, 34, 36, 37, 40, 47, 52, 53, 58, 61, 62, 79, 83], "creation": 51, "creativ": [47, 55], "credit": [44, 76], "criteria": [57, 58, 61, 79, 91], "critic": [49, 53, 61, 71, 74, 76, 92], "critic_learning_r": 74, "critiqu": [29, 30, 73], "crmsnorm": [42, 94], "cross": [14, 26, 46, 49, 58, 67, 70, 78], "cross_entropi": 59, "crowd": 23, "crowdwork": 77, "crucial": [36, 53, 54, 62], "crux": 30, "cruxev": [42, 94], "cryptographi": 20, "ctj": [19, 42, 94], "ctx": 46, "cu12": 20, "cubla": 20, "cuda": [20, 59], "cudnn": 20, "cufft": 20, "cui": [42, 94], "cum": [42, 94], "cumbersom": 70, "cumsum": 59, "cumul": [59, 76], "cup": 99, "cupti": 20, "cur_po": 59, "curand": 20, "curat": [3, 18, 32, 33, 36, 49, 54, 55, 58, 62, 65, 89, 96], "curiou": [13, 82], "current": [1, 2, 8, 9, 10, 15, 27, 28, 34, 36, 40, 44, 61, 70, 71, 72, 81, 84, 91, 93, 103, 105], "curv": [46, 57], "cusolv": 20, "cuspars": 20, "custom": 10, "custom_evalu": 20, "custom_output_fil": 20, "cut": [59, 73], "cutoff_len": 112, "cycl": 58, "d": [10, 17, 28, 40, 42, 43, 44, 46, 52, 57, 59, 60, 65, 66, 68, 69, 70, 71, 72, 78, 79, 80, 81, 82, 85, 92, 94, 99, 101, 102, 103, 104, 105, 107, 108, 113], "d_": [6, 10, 39, 46, 54, 57, 72, 81, 82, 105, 109], "d_c": [54, 105], "d_h": [54, 105], "d_k": 6, "d_v": 6, "dab": [42, 54, 94], "dai": [42, 94], "daili": [2, 8], "dalf": [42, 53, 54, 55, 94, 102, 105], "damai": [42, 94], "dan": [42, 94], "dang": [42, 94], "danger": 77, "daniel": [42, 94], "dario": [42, 94], "data": [3, 7, 8, 9, 10, 21, 26, 28, 29, 30, 32, 33, 35, 40, 44, 45, 47, 52, 61, 65, 67, 68, 70, 71, 72, 73, 77, 79, 80, 81, 83, 84, 85, 89, 92, 101, 104, 106], "dataclass": [59, 60], "datalabel": 93, "dataset": [2, 7, 15, 17, 18, 19, 20, 21, 22, 23, 27, 28, 30, 34, 35, 36, 38, 39, 40, 47, 50, 53, 54, 55, 56, 57, 58, 61, 62, 65, 70, 71, 73, 80, 81, 82, 83, 85, 89, 91, 92, 93, 99, 112], "date": 36, "dateutil": 20, "dauphin": [42, 94], "dave": [42, 94], "david": [42, 94], "davinci": [15, 34], "dawn": [42, 94], "daya": [42, 94], "dayiheng": [42, 94], "dclt19": [8, 42, 94], "ddot": [107, 108], "de": [42, 52, 94], "deal": 84, "debat": 54, "debias": 61, "debug": [28, 40, 58, 62], "debugg": 65, "decad": 22, "decai": [56, 96, 104, 108], "decid": [1, 53, 62, 83, 89, 93, 102], "decis": [44, 51, 65], "declar": 1, "declin": [28, 40, 54], "decod": [8, 15, 21, 34, 35, 45, 49, 59, 61, 65, 78, 91, 99], "decompos": 57, "decomposit": 113, "decoupl": [54, 55, 66], "decreas": [18, 45, 46, 55, 66, 68, 69, 73, 81, 102], "dedic": 102, "deduc": 92, "dedupl": [10, 36, 52, 53, 58, 99], "deem": 84, "deep": [42, 94], "deepen": [28, 40], "deepseek": [21, 29, 30, 35, 42, 66, 71, 94, 102, 105, 112], "deepseekcod": [55, 112], "deepseekmath": 53, "deepseekmo": [54, 55], "deepseekv2attent": 54, "deepseekv2config": 54, "deepseekv2forcausallm": 54, "deepseekv2mlp": 54, "deepseekv2model": 54, "deepseekv2pretrainedmodel": 54, "deepseekv2rmsnorm": 54, "deepspe": 112, "def": [17, 19, 54, 59, 60, 81, 104, 106], "default": [13, 20, 43, 59, 66, 104], "defin": [2, 3, 25, 36, 37, 43, 44, 46, 47, 57, 58, 59, 60, 61, 62, 67, 68, 76, 83, 99, 103, 104, 107, 108, 109], "definit": [39, 103], "degener": 68, "degrad": [55, 58], "degre": [9, 57], "dejian": [42, 94], "deli": [42, 94], "deliber": 93, "delimit": [7, 91], "deliv": 58, "delta": [44, 57, 113], "delta_": [71, 76], "delta_t": 76, "demonstr": [2, 3, 7, 8, 9, 10, 14, 18, 44, 45, 55, 61, 62, 66, 70, 72, 73, 82, 87, 89, 96, 103, 104, 105], "deng": [42, 94], "dengr": [42, 94], "denni": [42, 94], "denomin": 44, "denot": [39, 44, 46, 49, 52, 65, 67, 69, 70, 76, 81, 82, 92, 102, 105, 106, 108], "dens": [9, 58, 61, 105], "densifi": 55, "densiti": 81, "depend": [7, 9, 20, 36, 42, 46, 59, 60, 68, 70, 73, 85, 91, 103, 104, 106, 107, 108], "depict": [8, 77, 89], "deploi": [58, 102], "deploy": 105, "depth": [28, 40], "deriv": [44, 52, 55, 81, 83, 104], "descend": 59, "descent": 7, "describ": [6, 7, 15, 26, 34, 51, 58, 78, 83, 103], "descript": [1, 23, 26, 39, 49, 50, 51, 58, 79], "description2cod": 32, "design": [14, 18, 23, 27, 36, 38, 39, 55, 61, 69, 77, 79, 89, 93, 102, 105], "desir": [10, 44, 58, 73, 79, 81], "despit": [9, 47, 55, 72, 73, 76], "destabil": 76, "detail": [1, 8, 43, 50, 51, 58, 60, 61, 62, 71, 73, 75, 76], "detect": [4, 25, 37, 49, 58, 61, 73], "determin": [55, 58, 61, 62, 67, 70, 85], "determinist": [45, 55, 89], "detoken": 110, "devbal": 102, "develop": [1, 2, 4, 36, 47, 52, 55, 61, 67, 77, 81, 84, 89, 91, 92], "deviat": [45, 59, 68, 71, 76, 82], "devic": [55, 59, 60, 104, 111], "devis": [21, 22, 35], "devlin": [42, 94], "dfag17": [42, 61, 94], "dhariw": [42, 94], "diagon": [52, 59, 60], "dialog": 59, "dialogu": [2, 52, 57, 58], "diamond": 22, "dict": 59, "dictionari": [15, 34, 81], "did": [62, 78], "differ": [3, 6, 9, 10, 15, 16, 18, 25, 34, 37, 42, 44, 45, 47, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 77, 79, 81, 93, 99, 102, 103, 105, 107, 108], "differenti": 79, "difficult": [22, 47, 51, 99], "difficulti": [18, 22, 27, 28, 36, 38, 40, 50, 58, 62, 91], "dill": 20, "dim": [59, 60, 104, 106], "dimens": [6, 46, 52, 54, 59, 60, 65, 69, 102, 103, 104, 105, 106, 108, 109], "dimension": [6, 65, 107, 108], "diminish": [73, 99], "ding": [42, 94], "diogo": [42, 94], "direct": [9, 18, 22, 28, 40, 43, 51, 61, 62, 73, 78, 79, 80, 81, 89, 94], "directli": [7, 14, 19, 21, 35, 45, 52, 53, 58, 66, 68, 71, 76, 78, 81, 91, 92, 103, 104, 108, 110], "directori": 59, "disagr": 58, "disagre": 84, "disallowed_speci": 59, "disallowed_token": 59, "disanalogi": 47, "discard": [15, 34, 58, 62, 84], "discontinu": [28, 40], "discount": 76, "discrep": [44, 49, 57, 82], "discret": 57, "discrimin": [7, 49], "discuss": [52, 77, 93, 108], "disjoint": 26, "displai": [43, 73], "dispref": [68, 69], "disproportion": [58, 66], "distanc": [69, 104], "distil": [21, 35, 57, 79, 85], "distinct": [2, 54, 55, 61, 70, 73, 82, 99], "distinguish": [67, 70, 81], "distlib": 20, "distort": 106, "distract": 76, "distribut": [7, 9, 10, 28, 36, 40, 44, 49, 52, 55, 57, 59, 65, 66, 68, 70, 71, 72, 76, 77, 78, 81, 82, 84, 85, 89, 91, 92, 93, 102], "distro": 20, "div_": 59, "diverg": [10, 57, 68, 71, 76], "divers": [7, 8, 10, 14, 15, 18, 25, 26, 27, 28, 34, 36, 37, 38, 40, 45, 49, 50, 51, 52, 55, 58, 61, 62, 83, 84, 89, 91], "divid": [2, 6, 49, 51, 61, 71, 107, 108], "divis": 50, "dkv": 105, "do": [1, 9, 15, 16, 21, 25, 26, 34, 35, 37, 42, 44, 47, 50, 51, 53, 57, 58, 59, 60, 72, 84, 89, 91, 92, 93, 103, 105], "do_train": 112, "docstr": [14, 19, 52], "doctyp": 111, "document": [7, 8, 21, 26, 35, 42, 43, 52, 58, 62, 104], "doe": [1, 10, 25, 37, 52, 55, 59, 62, 68, 76, 82, 99, 104, 105, 106], "doesn": 104, "domain": [2, 8, 18, 22, 28, 40, 44, 55, 61, 67, 89, 91], "domin": 44, "don": 76, "done": [28, 40, 62], "dong": [42, 94], "dongji": [42, 94], "dot": [7, 44, 59, 60, 62, 69, 71, 73, 80, 83, 84, 102, 103, 104, 105, 107, 108, 110], "doubl": [51, 70, 99], "down": [50, 103, 104, 106], "down_proj": 54, "downstream": [9, 58, 113], "dpo": [29, 30, 45, 58, 61, 62, 74, 81, 83, 84], "dpop": [29, 58], "dq": 105, "dr": 8, "draw": [21, 35, 81], "drawback": 89, "drawn": [61, 70], "drive": 49, "drop": [18, 55], "drop_last": 74, "dschat": 74, "dtype": [59, 60], "du": [42, 94], "duan": [42, 94], "due": [36, 51, 55, 62, 65, 66, 102, 104, 106], "dulwich": 20, "duplic": 52, "dure": [3, 6, 7, 15, 18, 27, 34, 36, 44, 46, 49, 52, 53, 55, 57, 58, 61, 62, 66, 68, 76, 77, 89, 93, 96, 99, 102, 104, 105, 106], "dynam": [58, 73], "dz": 70, "e": [1, 2, 3, 7, 10, 15, 16, 17, 19, 20, 21, 25, 34, 35, 37, 44, 47, 55, 57, 58, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 81, 82, 83, 84, 89, 91, 92, 101, 102, 103, 104, 106], "e501": 59, "e_": 84, "e_j": 99, "each": [1, 3, 4, 6, 7, 8, 10, 13, 15, 18, 19, 21, 22, 23, 25, 26, 27, 28, 33, 34, 35, 36, 37, 38, 40, 44, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 91, 92, 93, 99, 102, 103, 104, 105, 106, 113], "earli": [77, 91], "earlier": [10, 57, 58, 77, 91], "easi": [4, 13, 14, 44, 47, 51, 52, 62, 74, 81], "easier": [7, 47, 51, 66, 81, 104], "easili": [6, 16, 21, 35, 49], "eason": 16, "echo": [59, 99], "econom": [18, 42, 54, 55, 94], "ecosystem": 42, "ecut": 16, "edg": 62, "edit": [1, 4, 15, 23, 26, 34, 51, 58, 69, 92], "editor": [4, 52], "educ": [36, 62], "edward": [42, 94], "ee": [29, 30], "effect": [2, 4, 6, 21, 27, 35, 36, 47, 51, 53, 55, 61, 66, 67, 69, 71, 76, 78, 81, 82, 83, 96, 99, 104, 107, 108], "effici": [4, 7, 42, 50, 54, 55, 61, 71, 76, 93, 94, 102, 105], "effort": [36, 53, 54, 55, 85], "eft": 83, "either": [3, 15, 34, 50, 54, 57, 58, 73, 76, 92, 93], "electron": 111, "element": [6, 10, 52, 72, 104, 105, 107, 108], "elementari": [18, 22], "elev": 54, "elicit": [47, 70, 77, 78], "elimin": [26, 28, 40, 76], "elizabeth": [42, 94], "elment": 59, "elo": 77, "els": [54, 59, 60, 77, 85, 104], "embed": [1, 7, 42, 52, 54, 56, 59, 60, 61, 94, 107], "embed_token": 54, "emerg": 87, "emit": [3, 69], "emphas": [8, 92], "empir": [8, 44, 47, 99, 103, 104], "emploi": [1, 2, 3, 6, 10, 13, 21, 28, 35, 36, 40, 45, 52, 53, 54, 55, 58, 59, 61, 62, 65, 71, 82, 89, 102], "empow": [28, 40, 42, 94], "empti": [15, 34, 102], "emptyset": 85, "enabl": [2, 3, 9, 22, 51, 52, 55, 67, 73, 89, 102, 103, 104, 107, 108], "encod": [7, 8, 25, 37, 49, 52, 54, 56, 59, 61, 103, 104, 107, 108, 111], "encode_dialog_prompt": 59, "encode_head": 59, "encode_messag": 59, "encoding_for_model": 59, "encompass": 53, "encount": [6, 58, 102], "encourag": [8, 25, 26, 37, 44, 47, 50, 58, 67, 79, 91], "end": [4, 6, 7, 10, 13, 15, 21, 25, 34, 35, 37, 46, 50, 52, 55, 57, 59, 60, 66, 67, 68, 69, 71, 72, 77, 78, 79, 81, 85, 91, 92, 93, 96, 102, 103, 104, 105, 107, 108, 109], "end_header_id": 59, "end_of_text": 59, "enforc": [89, 91, 104], "engin": [2, 18, 26, 36, 62, 74], "english": [15, 34, 54], "enhanc": [2, 14, 18, 21, 35, 36, 39, 42, 45, 54, 55, 61, 62, 66, 82, 94], "enlarg": 99, "enlighten": [21, 35], "enlist": 55, "enough": [9, 16, 47, 54, 57, 69, 81, 105], "enrich": 14, "ensembl": [45, 82], "ensur": [2, 6, 10, 16, 22, 23, 27, 28, 40, 49, 55, 57, 58, 61, 62, 69, 76, 85, 93, 102, 106], "entail": 7, "enter": 1, "entir": [32, 56, 92, 93, 106], "entri": [21, 23, 35, 36, 52, 59, 60], "entropi": [46, 49, 58, 66, 67, 70, 78], "entry_point": 17, "enumer": [59, 60, 104], "env": 20, "environ": [3, 4, 10, 20, 44, 58, 62, 72, 76], "eo": [59, 76], "eos_id": 59, "eos_idx": 59, "eos_reach": 59, "eot_id": 59, "ep": [59, 60, 106], "episod": [10, 72, 74], "epoch": [28, 36, 40, 54, 56, 57, 70, 72, 74, 89, 93, 96], "epsilon": [59, 60, 66, 71, 76, 106], "epsilon_": 66, "equal": [44, 56, 66, 103, 105, 107], "equat": [81, 92, 99, 108], "equip": [91, 92, 105, 111], "equival": [8, 42, 49, 51, 79, 81, 94, 102], "erhang": [42, 94], "eric": [42, 94], "ermon": [42, 94], "error": [2, 3, 4, 25, 37, 47, 51, 58, 59, 62, 71, 76, 109], "especi": [4, 25, 37, 99, 106], "essenti": [49, 51, 73], "est": 101, "establish": [55, 81, 91], "estat": 101, "estim": [19, 44, 46, 50, 57, 68, 71, 76, 81, 101], "estrang": 101, "etc": [15, 25, 34, 37, 54], "ethic": [18, 77], "eval": [13, 16, 29, 30, 70], "eval_step": 74, "evalperf": 17, "evalplu": [21, 30, 35], "evalu": [3, 13, 15, 18, 19, 26, 27, 34, 38, 42, 44, 46, 47, 53, 57, 66, 77, 80, 82, 83, 89, 91, 92, 93, 94, 99, 105], "evan": [42, 94], "evas": 77, "even": [1, 3, 9, 28, 40, 44, 47, 55, 58, 62, 68, 69, 81, 104, 105, 107, 108], "evenli": [33, 50], "event": [10, 70, 71], "everi": [2, 6, 9, 22, 25, 37, 78, 103, 106], "evid": [47, 104], "evol": [21, 35, 36], "evolut": [28, 40], "evolutionari": [28, 40], "evolv": [28, 40], "exact": [3, 22, 52], "exactli": [26, 44, 76], "exam": 18, "examin": [1, 14, 67], "exampl": [9, 10, 14, 15, 19, 21, 25, 26, 34, 35, 36, 37, 42, 44, 47, 49, 51, 52, 54, 57, 58, 61, 65, 68, 69, 73, 77, 78, 79, 82, 83, 84, 85, 89, 91, 96, 103, 104, 106], "exce": [15, 34, 45, 59, 91], "exceed": [103, 104], "excel": 55, "except": [9, 28, 40, 45, 54, 55, 58, 59, 69, 105], "exceptiongroup": 20, "excess": [55, 66, 76], "exchang": 96, "exclud": 66, "exclus": [18, 56, 93], "execut": [1, 3, 14, 16, 20, 26, 36, 42, 43, 49, 50, 52, 58, 61, 62, 94, 104], "executor": 62, "exemplar": [78, 87], "exemplifi": 79, "exhibit": [54, 66, 73, 89, 92], "exist": [1, 2, 18, 19, 21, 25, 32, 35, 37, 49, 58, 62, 84, 91, 103, 104, 110], "exit": 91, "exp": [10, 59, 60, 65, 68, 81, 108, 109], "expand": [55, 61], "expans": 104, "expbal": 102, "expect": [10, 25, 37, 44, 50, 55, 58, 62, 66, 71, 73, 76, 77, 99, 104], "expens": [47, 52, 68, 85], "experi": [6, 7, 10, 22, 28, 40, 54, 57, 58, 67, 68, 70, 72, 74, 77, 78, 82, 93, 96], "experience_mak": 74, "experiment": [18, 36], "expert": [22, 42, 54, 55, 58, 62, 94], "expert1": 102, "expert2": 102, "expert3": 102, "expertis": 58, "explain": [51, 58, 62, 65, 78], "explan": [58, 78], "explicit": [8, 55, 103, 104, 107, 108], "explicitli": [15, 34, 57, 77, 79, 92], "exploit": [9, 66], "explor": [51, 57, 66, 67, 71, 73, 87, 89], "exponenti": 104, "export": 20, "express": [3, 9, 19, 68, 70], "extend": [30, 52, 54, 55, 58, 59, 61, 74, 85, 89], "extens": [3, 14, 20, 42, 51, 61, 73, 104], "extern": [2, 36, 89], "extra": [7, 16, 51, 91, 103, 104], "extract": [21, 35, 58, 65, 67, 78], "extractor": 65, "extrapol": [6, 103], "extrem": [6, 22, 44, 47, 55], "f": [17, 59, 60, 91, 101, 103, 104, 109], "f_": [65, 67, 85, 102, 107, 108], "face": [82, 89], "facilit": [6, 49, 73, 76], "fact": 104, "factor": [6, 46, 62, 65, 76, 102, 103, 104, 109], "factual": [61, 89], "fail": [26, 51, 58, 61, 62], "failur": [47, 58, 62], "fair": 105, "faith": 58, "faithfulli": [47, 73], "fake": 73, "fals": [54, 59, 60, 106], "famili": [47, 50, 52, 104], "fan": [42, 94], "fangyun": [42, 94], "fanjia": [42, 94], "far": [58, 66, 70, 76], "fashion": [25, 37, 92], "fast": 59, "fastavro": 20, "faster": [13, 66], "fastjsonschema": 20, "faulti": 58, "favor": [65, 91], "featur": [47, 52, 59, 65, 74, 106], "februari": 62, "fed": [7, 62], "federico": [42, 94], "feed": [46, 59, 60, 61, 102, 109], "feed_forward": [59, 60], "feedback": [4, 10, 42, 47, 52, 53, 54, 55, 58, 61, 62, 68, 70, 73, 81, 83, 85, 89, 93, 94], "feedforward": 7, "fei": [42, 94], "felip": [42, 94], "feng": [42, 94], "few": [8, 9, 10, 18, 25, 37, 42, 49, 50, 52, 77, 78, 83, 85, 87, 93, 94], "fewer": [51, 54, 103, 104], "ff": [46, 109], "ffff": 111, "ffff\u7684\u8303\u56f4": 111, "ffn": [6, 54, 55, 59, 60, 61, 102], "ffn_norm": [59, 60], "fiction": 8, "field": [2, 15, 22, 25, 27, 34, 37, 38, 62], "fifo": 70, "fig": 3, "figur": [1, 4, 6, 46, 53, 55, 57, 70, 73, 77, 89, 99], "file": [1, 4, 15, 20, 26, 34, 36, 43, 52, 59, 62], "filelock": 20, "filenam": 4, "fill": [3, 52, 55, 57], "filter": [10, 16, 21, 26, 35, 36, 53, 54, 58, 61, 62, 66, 67, 84, 85, 91, 93, 99], "fim": [55, 62], "final": [1, 6, 7, 8, 10, 22, 25, 26, 28, 37, 39, 40, 44, 50, 53, 54, 55, 56, 57, 58, 62, 65, 66, 67, 68, 72, 73, 76, 77, 78, 79, 80, 81, 83, 84, 85, 89, 91, 93, 102], "find": [4, 15, 18, 26, 34, 45, 46, 47, 49, 50, 54, 57, 58, 66, 72, 77, 78, 81, 83, 89, 91, 92, 93, 99, 105], "find_fil": 4, "fine": [9, 10, 15, 27, 28, 34, 36, 38, 40, 58, 62, 68, 71, 73, 79, 80, 81, 83, 92, 93, 96, 99, 103, 104], "finer": 102, "finest": 101, "finetun": [9, 21, 28, 35, 40, 47, 61, 77, 85, 91, 93], "finetuning_typ": 112, "finn": [42, 94], "fire": 17, "first": [1, 2, 3, 6, 7, 8, 10, 16, 21, 25, 35, 36, 37, 44, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 66, 67, 68, 69, 70, 72, 73, 74, 78, 81, 82, 83, 84, 89, 91, 92, 93, 99, 102, 105, 108, 109], "first_k_dense_replac": 54, "firstli": 51, "fit": [26, 46, 70, 74, 81, 104], "five": [28, 40, 62], "fix": [1, 6, 10, 26, 46, 51, 58, 70, 72, 93, 103, 106], "flag": 59, "flagopen": 27, "flash": [29, 30], "flash_attn": 74, "flatten": [59, 60, 104], "flavor": 42, "flaw": 62, "flexibl": [3, 67, 102], "flexibli": 102, "flip": [73, 92], "float": [59, 60, 81, 104, 106], "float32": [59, 60], "flow": 3, "fluenci": 44, "focu": [15, 26, 34, 36, 44, 56, 61, 70, 93], "focus": [13, 18, 20, 27, 36, 38, 53, 55, 61, 73, 89], "fold": 14, "follow": [1, 2, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 20, 21, 22, 26, 28, 34, 35, 40, 42, 43, 52, 53, 55, 56, 57, 58, 59, 60, 61, 65, 66, 68, 69, 71, 72, 73, 76, 77, 78, 79, 81, 82, 84, 89, 94, 96, 102, 103, 104, 105], "fool": 93, "foral": [7, 67], "forc": [22, 49, 51, 91, 92], "forcefulli": 91, "forecast": 2, "forgo": 70, "form": [6, 28, 40, 50, 52, 55, 68, 70, 76, 79, 83, 93, 103, 104], "formal": [67, 71], "format": [1, 3, 20, 22, 25, 28, 37, 40, 52, 55, 77, 89], "formatt": 59, "former": [1, 67], "formul": [44, 67, 68, 76, 82, 102], "fortun": 68, "forum": [42, 94, 96], "forward": [46, 59, 60, 61, 102, 103, 106, 109, 113], "foster": 67, "fotio": [42, 94], "found": [6, 7, 10, 18, 25, 37, 49, 50, 51, 57, 62, 67, 77, 103, 104], "foundat": [21, 28, 35, 40, 52, 56, 58, 62, 76], "four": [8, 18, 28, 40, 52, 57, 58, 82, 89, 105], "frac": [6, 10, 19, 44, 46, 59, 60, 65, 66, 68, 69, 71, 72, 73, 76, 81, 82, 91, 102, 103, 104, 105, 106, 107, 108, 109, 110], "fraction": 19, "framework": [17, 25, 37, 54, 55, 61, 62, 73], "fraser": [42, 94], "free": [20, 42, 55, 62, 84, 94], "freez": [65, 113], "freq": [59, 60, 104], "freqs_ci": [59, 60, 104], "frequenc": [6, 52, 102, 104, 107, 108], "frequent": [103, 104], "fresh": 93, "friendli": 77, "from": [2, 4, 6, 8, 9, 10, 13, 14, 15, 17, 18, 19, 20, 22, 25, 26, 28, 29, 32, 33, 34, 36, 37, 39, 40, 42, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 68, 69, 70, 71, 72, 76, 79, 80, 81, 82, 83, 84, 85, 89, 91, 92, 93, 94, 96, 99, 102, 103, 104, 105, 106, 108, 110, 111], "frontier": 22, "frozen": 66, "frozenlist": 20, "fsdp": 91, "fsfairx": 45, "fsspec": 20, "fu": [42, 94], "fulfil": [2, 73], "fuli": [42, 94], "full": [47, 51, 52, 53, 55, 59, 60, 74, 112], "fulli": [3, 6, 15, 34, 39, 47, 55, 62, 66], "function": [1, 3, 4, 6, 9, 10, 14, 16, 23, 26, 42, 44, 47, 51, 52, 56, 57, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 76, 81, 82, 91, 92, 103, 104, 106, 107, 108, 109], "fundament": [9, 47], "further": [15, 21, 34, 35, 36, 45, 50, 52, 53, 54, 57, 58, 61, 62, 67, 70, 71, 85, 102, 104, 108], "furthermor": [55, 66, 77], "futur": [1, 2, 47, 54, 55], "g": [2, 3, 20, 21, 25, 35, 37, 55, 57, 58, 62, 65, 66, 71, 78, 79, 81, 84, 89, 91, 92, 103, 107, 108], "g_": [55, 65, 102], "g_t": 76, "gabriel": [42, 94], "gae": [71, 76], "gain": [7, 9, 21, 35, 51, 57, 62, 73, 78], "gamma": [10, 44, 55, 59, 60, 71, 72, 73, 76, 103, 106], "gao": [42, 94], "gap": [3, 18, 21, 35, 44, 45, 47, 58, 62, 80], "gate": [42, 55, 65, 94, 102], "gate_proj": 54, "gather": [57, 59, 61], "gating_dim": 102, "gaussian": 109, "gave": [15, 34], "gb2312\u56e0\u4e3a\u53ea\u8868\u793a\u666e\u901a\u6570\u5b57": 111, "gbk\u662fascii": 111, "ge": [19, 25, 37, 42, 65, 67, 69, 71, 81, 94], "geglu": 109, "gelu": 109, "gemini": [50, 53, 70], "gen": 59, "gener": [2, 3, 4, 6, 7, 8, 9, 10, 15, 16, 19, 20, 21, 26, 27, 28, 34, 35, 36, 38, 39, 40, 42, 44, 49, 50, 51, 52, 53, 54, 55, 57, 58, 61, 62, 66, 68, 69, 70, 71, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 91, 92, 94, 99, 103, 105], "generalist": 67, "generate_kwarg": 74, "generate_max_len": 74, "generation_logprob": 59, "generation_token": 59, "generativeai": 20, "generativelanguag": 20, "geometr": [6, 108], "geometri": 58, "get": [22, 42, 43, 44, 52, 62, 65, 81], "get_unique_el": 52, "gg": 46, "gibb": 68, "gibberish": [44, 66], "girish": [42, 94], "git": [17, 20], "github": [15, 17, 20, 26, 27, 34, 36, 49, 53, 56, 59, 60, 61, 62], "give": [7, 83, 84, 104], "given": [2, 4, 6, 7, 10, 14, 15, 25, 26, 28, 34, 37, 40, 44, 46, 47, 49, 51, 52, 56, 57, 58, 59, 60, 61, 62, 65, 67, 68, 69, 70, 71, 72, 78, 79, 81, 83, 84, 85, 92, 93, 99, 103, 104], "glob": 59, "glu": [59, 60], "go": [74, 76], "goal": [7, 51, 62, 66, 68, 81, 84, 91, 92], "gold": [29, 49, 50], "gomez": [42, 94], "good": [16, 29, 44, 47, 49, 55, 58, 71, 81, 84], "googl": [17, 20], "googleapi": 20, "google\u7684bert\u6a21\u578b\u5728\u5206\u8bcd\u7684\u65f6\u5019\u4f7f\u7528\u7684\u662fwordpiece\u7b97\u6cd5": 110, "goto": 4, "gpt": [8, 9, 10, 13, 15, 21, 22, 29, 30, 34, 35, 42, 47, 58, 59, 83, 93, 94, 99], "gpt2": 29, "gpt3": 29, "gpt4": 53, "gpu": [55, 91, 112], "gqa": [42, 61, 94], "grade": 22, "gradient": [6, 7, 10, 56, 69, 70, 72, 76], "gradient_accumulation_step": 112, "gradient_checkpoint": 74, "gradual": 52, "grai": [42, 94], "grain": [27, 38, 58, 73], "gram": [36, 62], "grammar": [25, 37], "grammat": [25, 37], "grangier": [42, 94], "granular": 18, "graphic": 22, "great": 59, "greater": 18, "greatli": [9, 113], "greedi": [8, 17, 21, 35, 45, 58, 59, 99], "greg": [42, 94], "gretchen": [42, 94], "grid": 104, "grl": [16, 42, 94], "ground": [3, 14, 23, 33, 47, 53, 54, 55, 62, 66, 67, 68, 81, 84], "group": [49, 50, 53, 54, 55, 59, 61, 62, 66, 82, 89, 102, 105], "grow": [6, 9, 70], "grpcio": 20, "grpo": [29, 30, 53, 61, 66, 67], "gsm8k": [29, 45, 62, 99], "gu": [42, 94], "guan": [42, 94], "guangbo": [42, 94], "guant": [42, 94], "guarante": [19, 67, 69, 71, 102], "guard": 32, "guardrail": 4, "guess": 18, "guid": [25, 37, 45, 67, 81, 82, 89], "guo": [42, 94], "guowei": [42, 94], "guss": [42, 94], "h": [6, 42, 54, 57, 59, 60, 94, 102, 103, 105, 113], "h06a4308_0": 20, "h100": 91, "h11": 20, "h1181459_1": 20, "h1234567_1": 20, "h39e8969_0": 20, "h5eee18b_0": 20, "h5eee18b_1": 20, "h5eee18b_6": 20, "h6a678d5_0": 20, "h6a678d5_1": 20, "h800": 55, "h955ad1f_1": 20, "h_": [7, 104], "h_j": 104, "h_n": 7, "ha": [2, 3, 6, 8, 9, 10, 13, 22, 25, 37, 44, 47, 53, 54, 57, 58, 59, 60, 61, 66, 70, 71, 82, 85, 92, 99, 103, 105, 109], "hack": [55, 57, 65, 66, 77, 89], "had": [10, 23, 49], "half": [47, 49, 52], "hallucin": 62, "hallucinatori": 54, "halv": 6, "ham": 69, "han": [42, 94], "hand": [19, 23, 46, 47, 55, 70], "handl": [7, 62], "handwritten": 19, "hanq": [42, 94], "hanwei": [42, 94], "hao": [42, 94], "haoran": [42, 94], "haowei": [42, 94], "haoyu": [42, 94], "happen": 104, "har": 55, "hard": [50, 51, 68, 79, 105], "harder": 50, "harm": [77, 79], "harmless": [61, 78, 79, 83], "harri": [42, 94], "hasten": 4, "hat": [44, 66, 68, 71, 76, 82, 92], "have": [1, 2, 6, 7, 8, 19, 21, 22, 25, 26, 35, 37, 43, 44, 46, 47, 50, 51, 53, 55, 57, 58, 61, 65, 66, 68, 69, 77, 81, 82, 83, 84, 91, 96, 99, 102, 103, 104, 106, 109], "hbb": [18, 42, 94], "hd_": 6, "he": [42, 94], "head": [7, 42, 46, 54, 55, 59, 60, 83, 94, 103, 104, 111], "head_dim": [59, 60], "header": 1, "health": 18, "heart": 84, "heavi": [46, 92, 105], "hebgen": [42, 94], "heewoo": [42, 94], "heidi": [42, 94], "height": 59, "held": 9, "help": [4, 7, 10, 22, 42, 51, 52, 54, 55, 57, 58, 61, 62, 65, 70, 72, 77, 79, 83, 103], "helpfulli": 72, "helpsteer2": 29, "henc": [3, 53, 68, 83], "hendryck": [42, 94], "henighan": [42, 94], "henriqu": [42, 94], "herbert": [42, 94], "herd": 58, "here": [6, 9, 15, 28, 34, 40, 42, 44, 46, 56, 57, 58, 99, 103, 104], "hess": [42, 94], "heurist": [10, 21, 22, 25, 35, 37], "hf": 81, "hh": 77, "hidden": [54, 59, 60, 65, 102, 103, 109], "hidden_dim": [59, 60], "hidden_s": [54, 102], "hierarch": 1, "high": [7, 14, 19, 21, 22, 26, 35, 36, 44, 45, 49, 55, 57, 58, 61, 62, 65, 66, 67, 69, 70, 76, 82, 83, 84, 85, 92, 96, 101, 107, 108], "highconfid": 85, "higher": [3, 27, 38, 45, 50, 51, 55, 58, 61, 62, 70, 73, 82, 102, 103], "highest": [13, 15, 22, 28, 34, 40, 45, 55, 58, 70, 82, 83, 101, 102, 107], "highli": [22, 47, 62, 65, 84, 85, 93], "highlight": [2, 36], "highqual": 55, "hilton": [42, 94], "hinder": [76, 82], "hing": 68, "histor": 71, "histori": [4, 18, 44], "hoc": 78, "hold": [46, 93], "holdgraf_evidence_2014": 42, "holist": [20, 42, 94], "home": 20, "homepag": 66, "honesti": 65, "hongcheng": [42, 94], "honghui": [42, 94], "hongyi": [42, 94], "hood": [21, 35], "hook": 20, "hope": 22, "hotfix": 20, "hou": [42, 94], "hour": 55, "hous": 53, "how": [2, 4, 10, 13, 18, 22, 26, 43, 44, 47, 50, 58, 62, 65, 67, 68, 71, 78, 79, 87, 89, 93, 99, 104], "howev": [1, 2, 19, 25, 37, 44, 45, 47, 54, 57, 58, 65, 66, 68, 72, 73, 79, 81, 82, 91, 102, 103, 104, 106, 108], "hstack": [59, 60], "html": 111, "http": [17, 20, 21, 25, 28, 35, 37, 40, 42, 94], "httpcore": 20, "httplib2": 20, "httpx": 20, "hu": [42, 94], "huajian": [42, 94], "huan": [42, 94], "huang": [42, 94], "huazuo": [42, 94], "hub": 20, "huge": [51, 104], "huggingfac": [20, 74], "hugh": [42, 94], "hui": [42, 94], "human": [4, 9, 10, 13, 16, 18, 22, 23, 25, 28, 33, 37, 40, 42, 44, 47, 52, 54, 55, 58, 61, 62, 68, 70, 72, 73, 77, 78, 79, 80, 81, 83, 84, 85, 89, 93, 94], "humanev": [14, 28, 30, 36, 40, 45, 62], "humanevalplu": 17, "humanevalplus_releas": 17, "hundr": [55, 104], "hunter": [42, 94], "hurt": 62, "hybridengin": 74, "hyc": [42, 62, 94], "hyper": [55, 56, 59, 60, 61, 66, 71, 73], "hyperparamet": [46, 50, 58, 61, 66, 69, 70, 73, 76, 96], "hypothes": 6, "hypothesi": 9, "i": [1, 2, 4, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 81, 82, 83, 84, 85, 89, 91, 93, 94, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111], "i_": [25, 37], "i_t": [25, 37], "icl": 99, "id": [10, 42, 59, 94], "id1": 20, "id2": 20, "idea": [73, 85, 103, 104], "ideal": [2, 15, 18, 34, 104], "ident": [6, 61, 66, 68, 70, 84, 93, 102], "identif": 62, "identifi": [2, 10, 13, 14, 18, 25, 37, 45, 61, 62, 66, 67, 70, 73, 77, 79, 82, 85], "idna": 20, "ifev": 54, "ifstat": 3, "ift": 83, "ignor": [44, 49, 59, 104], "ignore_index": 59, "igor": [42, 94], "ij": 99, "ik_": [59, 60, 103, 104], "illeg": 77, "illia": [42, 94], "illustr": [1, 4, 47, 53, 55, 57, 59, 60, 89], "ilya": [42, 94], "im": [59, 60, 103, 104], "imag": [2, 46, 91], "imaginari": [103, 104], "imbal": [55, 102], "imit": 47, "impact": [36, 45, 50, 62, 66, 93, 103], "imped": 66, "imper": [15, 34], "imperfect": 85, "implement": [2, 10, 14, 19, 28, 40, 54, 55, 56, 61, 62, 76, 85], "impli": 66, "implicit": 68, "implicitli": [47, 68, 92], "import": [3, 4, 14, 17, 19, 36, 44, 47, 57, 59, 60, 68, 81, 83, 84, 96, 104, 106], "importantli": [62, 68, 91, 105], "importlib": 20, "impress": 62, "improv": [7, 9, 21, 35, 39, 42, 44, 47, 49, 51, 52, 54, 55, 56, 57, 58, 59, 61, 62, 67, 69, 71, 78, 82, 83, 84, 85, 87, 89, 91, 92, 93, 94, 99, 106], "inabl": 66, "inappropri": 73, "incentiv": 92, "includ": [2, 7, 15, 18, 19, 22, 26, 27, 28, 32, 33, 34, 36, 38, 40, 43, 45, 46, 47, 49, 50, 52, 54, 55, 57, 58, 59, 61, 62, 68, 77, 80, 81, 103, 104, 106, 112], "inclus": 62, "incorpor": [6, 36, 55, 57, 58, 61, 66, 71, 76, 107, 108], "incorrect": [49, 51, 82, 85, 92, 93], "incorrectli": [22, 68], "increas": [18, 21, 28, 35, 36, 40, 50, 52, 55, 58, 66, 68, 69, 73, 99, 102, 104, 108], "increasingli": 89, "increment": 103, "inde": 73, "indent": 62, "independ": [25, 37, 52, 91, 106, 110], "index": [59, 60, 70, 71, 103, 104, 105], "indic": [10, 18, 50, 59, 65, 70, 73, 76, 79, 91, 99, 103, 104, 105, 107], "individu": [46, 66, 67, 106, 107, 108], "induc": [8, 55, 81], "inequ": 68, "inf": [59, 60], "infer": [15, 34, 36, 44, 52, 54, 55, 56, 58, 59, 66, 73, 74, 78, 81, 84, 102, 104, 105, 106], "inference_mod": [59, 60], "infin": 36, "inflat": 62, "influenc": [66, 67, 99], "infomax": 70, "inform": [1, 2, 4, 6, 10, 15, 22, 34, 36, 42, 43, 49, 57, 58, 61, 71, 82, 94, 102, 104, 107, 108, 111], "infrastructur": 104, "infti": 46, "inher": [7, 10], "inherit": 65, "init": 43, "init_kl_coef": 74, "initi": [2, 10, 21, 25, 28, 35, 37, 40, 51, 52, 54, 57, 58, 59, 66, 68, 70, 72, 77, 79, 85, 89, 96], "inject": [6, 103, 104, 113], "inlin": [42, 68], "inner": [107, 108], "innov": [54, 105], "input": [1, 2, 6, 10, 15, 16, 21, 25, 28, 34, 35, 37, 40, 42, 49, 50, 51, 52, 56, 57, 59, 60, 62, 67, 69, 70, 72, 73, 76, 78, 81, 84, 96, 103, 104, 105, 106, 107, 108, 109, 110], "input_kei": 74, "input_text_mask": 59, "inputgen": 17, "inputoutput": 51, "insert": [6, 42, 49, 59, 70], "insid": 71, "insight": [4, 68], "inspect": 23, "inspir": [21, 35, 67], "inst": 52, "instabl": [19, 76, 106], "instag": 58, "instal": 17, "instanc": [3, 7, 15, 26, 34, 54, 55, 59, 65, 77, 89], "instead": [6, 8, 10, 15, 19, 28, 34, 40, 47, 50, 52, 56, 59, 60, 66, 70, 71, 73, 76, 77, 85, 103, 104, 106, 108], "instruciton": [15, 34], "instruct": [2, 3, 4, 9, 10, 13, 15, 26, 29, 30, 34, 42, 43, 45, 47, 53, 54, 57, 58, 65, 67, 73, 77, 78, 82, 89, 91, 92, 94, 96], "instructgpt": 72, "instruction_prefix": 17, "instructionfollow": 83, "int": [54, 59, 60, 81, 104, 106], "int_": 70, "integ": [59, 66], "integr": [4, 18, 55, 61, 62, 67], "intend": 66, "intens": [54, 62], "intent": [10, 14, 82], "intention": 73, "interact": [4, 44, 58, 59, 60, 70, 73, 76, 106], "interc": [65, 102, 103, 104, 105, 107], "interchang": 111, "interdepend": 106, "interest": [47, 58, 81], "interesting": 44, "interestingli": 62, "interfac": 10, "interfer": 106, "interleav": 92, "interlm2": 29, "intermedi": [39, 46, 47, 53, 54, 55, 87, 89, 93, 102], "intermediate_s": 54, "intern": [47, 55, 58], "internet": 72, "interpol": 52, "interpret": [10, 36, 57, 71], "interv": 99, "intervent": 91, "interview": [2, 52], "intric": 61, "intrigu": 89, "intrins": 89, "introduc": [2, 3, 4, 13, 18, 21, 22, 25, 35, 36, 37, 39, 44, 50, 55, 58, 59, 61, 62, 66, 67, 71, 78, 81, 89, 102, 103, 104, 106], "introduct": 78, "intuit": [44, 47, 68, 108], "invas": 77, "invest": [54, 70, 103, 104], "investig": [55, 66, 67, 73, 93, 96, 99], "invok": 2, "involv": [15, 22, 34, 46, 55, 58, 102], "ion": [42, 94], "ip": 78, "ipo": 68, "ipynb": 42, "iq_": [59, 60, 103, 104], "irrelev": 36, "is_safeti": 57, "ise": 17, "isequival": 66, "isin": 59, "isol": 62, "issu": [1, 8, 14, 26, 53, 55, 58, 65, 77, 78, 89, 92, 102, 104, 106], "item": [74, 81], "iter": [4, 10, 25, 28, 37, 40, 51, 59, 61, 70, 72, 73, 81, 82, 83, 92], "itertool": 20, "its": [3, 9, 21, 23, 25, 26, 35, 37, 47, 49, 50, 52, 54, 55, 58, 59, 60, 61, 62, 65, 66, 68, 70, 73, 76, 77, 81, 83, 89, 91, 92, 93, 99, 102, 103, 104, 105, 106, 108, 109], "itself": [25, 37, 53, 83, 92], "ix_": [59, 60, 103, 104], "j": [42, 44, 55, 59, 60, 66, 67, 69, 71, 73, 76, 84, 94, 102, 103, 104, 105, 108], "j_": [71, 84], "j_1": 73, "j_q": 73, "jack": [42, 94], "jacob": [42, 94], "jain": [42, 94], "jakob": [42, 94], "jame": [42, 94], "jan": [42, 94], "jaraco": 20, "jare": [42, 94], "java": 62, "javascript": 62, "jeepnei": 20, "jeff": [42, 94], "jeffrei": [42, 94], "jerri": [42, 94], "jgzp23": [42, 61, 94], "jhg": [20, 42, 94], "ji": [42, 94], "jiaheng": [42, 94], "jiajun": [42, 94], "jian": [42, 94], "jiang": [42, 94], "jianhong": [42, 94], "jianlin": [42, 94], "jianwei": [42, 94], "jianxin": [42, 94], "jianzhong": [42, 94], "jiaqi": [42, 94], "jiashi": [42, 94], "jiatao": [42, 94], "jiawei": [42, 94], "jiaxi": [42, 94], "jie": [42, 94], "jin": [42, 94], "jingren": [42, 94], "jingxiang": [42, 94], "jingyang": [42, 94], "jinja2": 20, "jinz": [42, 94], "jmespath": 20, "joblib": 20, "john": [42, 94], "jointli": 6, "jone": [42, 94], "jong": [42, 94], "joseph": [42, 94], "josh": [42, 94], "joshua": [42, 94], "json": [3, 15, 34, 54, 59, 112], "jsonl": 17, "jsonlin": 20, "judg": [13, 30, 50, 51, 58, 73, 83, 84], "judgement": 73, "judgment": [44, 62], "jun": [42, 94], "junji": [42, 94], "junxiao": [42, 94], "junyang": [42, 94], "jupyt": [42, 43], "jupyterbook": 42, "jupytext": 43, "just": [4, 18, 20, 42], "k": [6, 7, 8, 10, 19, 22, 28, 40, 42, 49, 55, 57, 58, 59, 60, 65, 67, 69, 70, 72, 76, 80, 94, 99, 102, 103, 104, 105, 107, 108, 113], "k_": [55, 59, 60, 67, 71, 102, 103, 104], "k_1": 71, "k_i": 71, "k_r": [55, 102], "kai": [42, 94], "kaig": [42, 94], "kaiser": [42, 94], "kang": [42, 94], "kaplan": [42, 94], "karl": [42, 94], "karma": 8, "katarina": [42, 94], "kati": [42, 94], "katti": 33, "ke": [42, 94], "keep": [4, 50, 54, 55, 57, 58, 62, 66, 92, 102, 109], "keepdim": [59, 60, 106], "kei": [2, 6, 22, 36, 47, 50, 51, 52, 54, 55, 59, 60, 61, 62, 66, 73, 76, 81, 99, 103, 104, 106, 107, 108], "kelton": [42, 94], "keme": [42, 94], "kenton": [42, 94], "keqin": [42, 94], "kernel": 43, "kexin": [42, 94], "keyr": 20, "keyword": 13, "khlaaf": [42, 94], "kind": [10, 42, 73], "king": [42, 94], "kl": [10, 57, 68, 71, 72, 81], "kmh": [9, 42, 94], "knew": 44, "knight": [42, 94], "know": [44, 47, 99], "knowledg": [3, 18, 21, 35, 36, 51, 57, 96, 102, 107, 108], "known": [2, 44, 59, 60, 82, 104], "kosaraju": [42, 94], "koushik": [42, 94], "kr": 105, "kristina": [42, 94], "krueger": [42, 94], "kto": [29, 45], "kv": [54, 61], "kv_a_layernorm": 54, "kv_a_proj_with_mqa": 54, "kv_b_proj": 54, "kv_lora_rank": 54, "kw_": 6, "kyunghyun": [42, 94], "l": [7, 10, 25, 37, 39, 42, 44, 46, 57, 59, 60, 67, 68, 69, 70, 71, 72, 76, 81, 82, 83, 84, 85, 92, 94, 101, 102, 103, 104, 105, 106], "l_": [7, 66, 68, 73, 82], "l_1": 73, "l_2": 73, "label": [7, 9, 10, 25, 27, 37, 38, 47, 53, 54, 57, 58, 61, 72, 77, 79, 81, 84, 85, 93, 99], "labor": 62, "lack": [66, 81], "lambda": [7, 69, 70, 71, 73, 76, 103, 104], "lambda_": [65, 103], "land": 77, "langl": [59, 60, 103, 104, 108], "languag": [7, 8, 9, 10, 13, 14, 15, 18, 19, 22, 25, 26, 34, 36, 37, 41, 42, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 68, 70, 72, 85, 89, 91, 93, 94, 96, 102, 107, 108], "larg": [6, 7, 8, 9, 10, 13, 14, 16, 19, 25, 26, 36, 37, 41, 42, 44, 47, 50, 54, 55, 57, 58, 59, 60, 62, 66, 68, 69, 70, 72, 76, 85, 89, 94, 96, 102, 105, 108], "larger": [8, 26, 27, 38, 57, 58, 91, 93, 104, 108], "largest": [8, 27, 49, 50, 56, 57, 58], "last": [6, 9, 49, 58, 59, 65, 71, 77, 93], "latent": [54, 55], "later": [25, 37, 58, 91], "latest": [17, 57, 58], "latex": 22, "law": [9, 18, 42, 47, 61, 94, 105], "layer": [6, 7, 8, 9, 10, 46, 49, 54, 56, 59, 60, 61, 65, 72, 74, 102, 103, 104, 105, 109, 113], "layer_id": [59, 60], "layer_idx": 54, "layernorm": [6, 106], "lcb": 20, "lcb_runner": 20, "lcft": 58, "ld_impl_linux": 20, "le": [19, 28, 40, 42, 55, 66, 69, 91, 94, 102, 104, 109], "lead": [36, 44, 47, 51, 52, 55, 56, 58, 66, 69, 77, 93, 103, 104, 106], "leakag": [32, 47, 62], "lean": [42, 94], "learn": [3, 6, 7, 8, 9, 10, 18, 22, 36, 44, 45, 46, 47, 49, 52, 56, 59, 60, 62, 66, 67, 68, 71, 76, 79, 81, 82, 83, 94, 96, 102, 109], "learnabl": 59, "learner": [8, 9, 42, 94], "learning_r": 112, "least": [8, 9, 13, 26, 50, 77], "leather": [42, 94], "leav": [49, 51, 66], "lebr\u00f3n": [42, 94], "lecong": [42, 94], "led": [57, 58, 77], "lee": [42, 94], "leed": 102, "leetcod": [20, 30, 53, 55, 89], "left": [6, 10, 19, 44, 46, 50, 52, 59, 60, 65, 66, 68, 69, 71, 72, 73, 76, 78, 81, 92, 103, 104, 105, 107, 108, 110], "leftarrow": [76, 105], "legal": 77, "lei": [42, 94], "leik": [42, 94], "len": [59, 74, 81], "length": [6, 46, 52, 54, 55, 57, 58, 59, 65, 66, 69, 73, 78, 91, 102, 103, 104, 105, 106], "lengthen": 91, "lengthi": 51, "less": [6, 10, 15, 25, 29, 30, 34, 37, 45, 53, 58, 66, 70, 71, 77, 82, 93, 99, 103], "let": [1, 22, 42, 43, 44, 54, 65, 67, 69, 76, 77, 81, 85, 94, 103, 105, 107, 108], "level": [8, 14, 18, 22, 23, 27, 28, 36, 38, 40, 42, 44, 47, 50, 52, 54, 55, 57, 58, 61, 62, 70, 93, 94], "leverag": [2, 21, 25, 35, 37, 51, 55, 57, 61, 89, 104, 107, 108], "lex": 104, "leyi": [42, 94], "lezama": [42, 94], "li": [42, 94], "liang": [42, 94], "libffi": 20, "libgcc": 20, "libgomp": 20, "librari": [3, 14, 36, 52], "libstdcxx": 20, "libuuid": 20, "lie": [77, 105], "lightman": [42, 94], "like": [1, 2, 4, 7, 14, 15, 18, 34, 42, 43, 44, 47, 51, 55, 61, 62, 69, 70, 77, 79, 84, 89, 93], "likelihood": [7, 44, 45, 49, 68, 69, 78, 81, 82, 85, 93], "limit": [1, 3, 9, 10, 25, 37, 47, 49, 50, 53, 55, 57, 58, 66, 70, 78, 81, 96, 102, 103, 104, 105], "lin": [42, 94], "line": [1, 4, 21, 25, 26, 28, 35, 37, 40, 42, 43, 46, 47, 52, 59], "linear": [6, 7, 52, 54, 56, 57, 59, 60, 61, 65, 66, 91, 99, 104, 108], "linearli": [6, 50, 96], "lingm": [42, 94], "link": 8, "linter": 58, "linzheng": [42, 94], "liqun": [42, 94], "list": [1, 15, 28, 34, 40, 50, 51, 52, 59, 74, 81, 99, 101], "liter": 59, "littl": 62, "litwin": [42, 94], "liu": [42, 94], "livecodebench": [29, 30, 42, 94], "liyu": [42, 94], "lkb": [22, 42, 94], "ll": [42, 59, 105, 113], "llama": [15, 16, 29, 34, 45, 59, 74, 83, 96, 99, 103, 106], "llama2": [29, 57, 99], "llama3": [29, 30, 60], "llion": [42, 94], "llm": [1, 2, 13, 14, 20, 21, 28, 35, 36, 39, 40, 41, 42, 51, 52, 57, 58, 62, 65, 67, 68, 69, 71, 73, 76, 79, 83, 84, 89, 92, 94, 104], "llm4code": 17, "lm": [4, 8, 26, 72], "lm_head": 54, "ln": [42, 59, 70, 94, 104, 106], "load": [55, 59], "load_checkpoint": 74, "load_state_dict": 59, "load_tiktoken_bp": 59, "local": [1, 9, 92], "localhost": 112, "locat": [1, 4, 52, 104], "log": [7, 8, 10, 44, 50, 57, 59, 68, 69, 71, 72, 73, 76, 77, 78, 81, 82, 92, 93, 99, 110], "logging_step": [74, 112], "logic": [51, 55, 61, 62, 89], "logist": 82, "logit": [49, 57, 59, 68, 69, 103], "logprob": 59, "logprobs_i": 59, "long": [7, 10, 15, 26, 34, 42, 58, 59, 62, 66, 69, 89, 91, 94, 103, 104, 108], "longer": [6, 52, 54, 65, 66, 69, 78, 91, 96, 103, 104], "longterm": [42, 94], "look": 51, "loop": 3, "loos": 104, "lora": [29, 30], "lose": 83, "loss": [9, 10, 44, 46, 47, 49, 54, 55, 57, 58, 65, 67, 69, 70, 71, 72, 73, 78, 82, 96], "lot": [42, 103], "low": [16, 25, 36, 37, 42, 44, 57, 62, 66, 67, 69, 71, 85, 91, 94, 103, 108, 113], "lower": [3, 14, 15, 34, 66, 69, 99, 103], "lowest": [82, 83, 101, 102, 103], "lr": 36, "lr_scheduler_typ": 112, "lu": [42, 94], "luan": [42, 94], "lukasz": [42, 94], "luke": [42, 94], "luo": [42, 94], "lxwz23": [17, 42, 94], "lynx": 2, "m": [7, 20, 25, 37, 42, 55, 57, 59, 60, 67, 69, 70, 73, 81, 82, 94, 102, 103, 104, 107, 108], "m3toolev": 3, "m_": 81, "m_0": 83, "m_1": 83, "m_2": 83, "m_3": 83, "m_t": 83, "ma": [42, 94], "machin": [6, 8, 42, 52, 94], "maddi": [42, 94], "made": [28, 40, 61, 70, 78, 82], "magic": [29, 30], "magicod": [17, 36, 42, 58, 62, 94], "magnitud": [6, 8, 9, 47, 49, 104, 105], "mai": [6, 14, 36, 45, 47, 51, 53, 55, 58, 66, 69, 71, 77, 78, 79, 82, 89, 102, 104], "mail": 8, "main": [17, 20, 45, 47, 50, 51, 52, 56, 57, 58, 67], "mainli": [47, 51, 55, 62, 67, 82, 89], "mainstream": 62, "maintain": [53, 54, 55, 57, 61, 62, 76, 102], "major": [22, 58, 62, 79, 91, 93], "make": [2, 4, 6, 7, 10, 15, 18, 25, 26, 27, 34, 37, 44, 47, 50, 52, 59, 60, 61, 65, 66, 68, 70, 73, 74, 77, 83, 89, 91, 92, 104, 106, 107, 108], "make_experience_list": 74, "malform": 4, "man": [42, 94], "manag": [4, 20], "mani": [8, 9, 22, 25, 26, 37, 42, 43, 52, 62, 72, 104, 111], "mann": [42, 94], "manner": [83, 84], "manta": [42, 94], "manual": [23, 25, 37, 66, 96], "map": 6, "map_loc": 59, "margin": [28, 40, 45, 57, 58], "mark": [42, 52, 58, 94], "markdown": [17, 53], "markdownfil": 43, "markedli": 42, "markup": 42, "markupsaf": 20, "mask": [6, 49, 52, 58, 59, 60, 66], "mass": [28, 40, 44, 59], "massiv": [18, 42, 61, 62, 94], "master_port": 112, "match": [3, 22, 27, 38, 55, 59, 61, 92, 103, 104, 105], "mateusz": [42, 94], "math": [18, 42, 53, 54, 55, 59, 60, 61, 62, 66, 69, 71, 89, 91, 93, 94], "mathbb": [6, 10, 19, 44, 57, 65, 66, 68, 69, 71, 72, 73, 76, 81, 82, 91, 92, 102, 103, 105, 107, 108, 113], "mathbf": [6, 44, 52, 55, 59, 60, 67, 71, 73, 76, 102, 103, 104, 105, 106, 107, 108], "mathcal": [7, 39, 44, 57, 65, 66, 68, 69, 70, 80, 81, 82, 84, 85, 91, 92, 99, 102, 105, 109], "mathemat": [18, 19, 22, 42, 53, 54, 55, 58, 61, 62, 68, 71, 91, 94], "mathmix": 93, "mathrm": 80, "matmul": [59, 60], "matplotlib": 68, "matric": [6, 59, 60, 105, 109, 113], "matrix": [6, 7, 52, 59, 60, 105, 107, 108, 109], "matthew": [42, 94], "matthia": [42, 94], "max": [6, 57, 59, 60, 66, 69, 81, 85, 91, 92, 103, 109], "max_": [67, 68, 81, 91, 104], "max_batch_s": [59, 60], "max_epoch": 74, "max_gen_len": 59, "max_prompt_len": 59, "max_reward": 81, "max_sampl": 74, "max_seq_len": [59, 60], "maxim": [7, 10, 15, 21, 28, 34, 35, 40, 44, 50, 56, 66, 68, 70, 71, 72, 81, 85, 92, 93, 103, 104], "maximum": [3, 44, 49, 52, 57, 58, 59, 66, 67, 68, 70, 81, 91, 103, 104, 105], "mayer": [42, 94], "mazeika": [42, 94], "mbox": [76, 108], "mbpp": [28, 29, 30, 36, 40, 62], "mbppplu": 17, "mbppplus_releas": 17, "mccandlish": [42, 94], "mceval": [36, 42, 62, 94], "mcgrew": [42, 94], "md": [42, 43], "me": 77, "mean": [6, 57, 59, 60, 66, 69, 70, 71, 76, 82, 83, 102, 106, 108], "meaning": 51, "meansquar": [59, 60, 106], "meanwhil": [103, 104, 107, 108], "measur": [10, 18, 42, 44, 49, 58, 71, 78, 85, 91, 94, 96], "mechan": [6, 50, 55, 61, 62, 66, 71, 76, 102, 106, 107, 108], "media": 8, "median": 57, "medium": 52, "mei": [42, 94], "melani": [42, 94], "memori": [6, 7, 16, 71, 105], "men": [42, 94], "meng": [42, 94], "mention": 13, "merg": [26, 28, 40], "mergeable_rank": 59, "messag": [4, 51, 59], "met": 58, "meta": [59, 67, 111], "metadata": [20, 50], "method": [9, 21, 26, 28, 35, 36, 40, 45, 55, 57, 58, 59, 61, 62, 67, 68, 70, 73, 76, 79, 82, 87, 91, 103, 104, 107, 108], "methodologi": [55, 89], "meticul": [54, 62], "metric": [2, 19, 28, 40, 44, 47, 49, 65, 78, 91, 99], "miao": [42, 94], "miaojun": [42, 94], "michael": [42, 94], "michiel": [42, 94], "micro_rollout_batch_s": 74, "micro_train_batch_s": 74, "middl": [22, 25, 37, 52, 55], "might": [13, 58, 96, 106], "mikhail": [42, 94], "mile": [42, 94], "miller": [42, 94], "million": [8, 9, 47, 49, 50, 52, 58, 61, 62], "min": [59, 65, 66, 71, 76, 81, 91, 113], "min_": 68, "min_prompt_len": 59, "mine": 81, "ming": [42, 94], "mingchuan": [42, 94], "mingfeng": [42, 94], "minghua": [42, 94], "minghui": [42, 94], "mingm": [42, 94], "mini": [59, 66, 106], "minim": [55, 68, 70, 91, 103, 104], "minimis": [49, 69], "minimum": [68, 76, 91], "minor": 92, "minu": 59, "minut": [16, 91], "mira": [42, 94], "misalign": 73, "mishkin": [42, 94], "mishra": [42, 94], "mismatch": [69, 92], "misra": [42, 94], "miss": 52, "mistak": [4, 51, 73, 92], "mistralai": 20, "mitchel": [42, 94], "mitig": [4, 10, 36, 54, 55, 58, 62, 65, 71, 72, 76, 78, 82, 85, 92, 102, 104], "mix": [10, 49, 52, 53, 58, 62, 72, 81, 89], "mixtral": 74, "mixtur": [42, 54, 55, 61, 74, 94], "mk": 102, "ml": [9, 104], "mla": [30, 54, 55], "mle": [68, 73, 81], "mlp": 65, "mmlu": 45, "mn": 102, "mode": [47, 68], "model": [2, 3, 4, 7, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 47, 49, 51, 52, 53, 54, 55, 56, 68, 69, 71, 74, 76, 77, 78, 79, 80, 81, 91, 94, 96, 102, 105, 106, 107, 108, 113], "model_arg": 59, "model_name_or_path": 112, "modelarg": [59, 60], "modern": [47, 111], "modest": 93, "modif": [7, 8, 15, 28, 34, 40, 49, 58, 103], "modifi": [1, 6, 15, 34, 52, 57, 58, 79, 83, 84, 92, 104, 113], "modul": [20, 36, 54, 59, 60, 62, 102, 106], "modular": 51, "modulelist": [59, 60], "modulenotfounderror": 59, "moe": [30, 54, 55, 61, 102, 105], "moe_intermediate_s": 54, "moegat": 102, "mohammad": [42, 94], "monoton": 81, "mont": [44, 71], "month": 57, "more": [1, 4, 6, 7, 8, 9, 10, 13, 14, 15, 17, 18, 20, 21, 22, 25, 26, 27, 28, 29, 30, 34, 35, 36, 37, 38, 40, 43, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 65, 66, 67, 69, 70, 71, 72, 73, 75, 77, 79, 81, 82, 89, 93, 99, 102, 103, 105], "moreov": [3, 42, 54, 66, 92], "morikawa": [42, 94], "most": [1, 3, 4, 6, 8, 9, 22, 36, 42, 45, 52, 55, 57, 58, 59, 62, 65, 73, 83, 93, 102, 104, 111], "mostli": [23, 58], "motiv": [8, 68, 81, 85, 91], "move": [4, 8, 52, 76], "mpmath": 20, "msc": 91, "msgpack": 20, "mt": 102, "mtp": 55, "mu_": 76, "mu_a": 76, "much": [14, 15, 26, 34, 47, 52, 58, 66, 68, 77, 93, 103, 104, 108], "multi": [7, 29, 42, 46, 52, 54, 56, 58, 59, 60, 62, 94], "multidict": 20, "multihead": 6, "multilingu": [42, 58, 61, 62, 94], "multinomi": 59, "multipl": [1, 2, 3, 10, 18, 22, 25, 36, 37, 39, 45, 51, 55, 58, 59, 60, 62, 70, 74, 77, 83, 91, 92, 102, 103, 105, 108], "multiple_of": [59, 60], "multipli": [6, 55, 65, 107, 108], "multiprocess": 20, "multistag": 61, "multitask": [8, 18, 42, 52, 94], "murati": [42, 94], "murtadha": [42, 94], "must": [2, 6, 42, 44, 46, 52, 69, 91, 93, 103, 104], "my": 77, "n": [1, 6, 7, 17, 19, 20, 28, 29, 30, 39, 40, 42, 44, 45, 49, 52, 55, 59, 60, 67, 70, 73, 81, 83, 84, 92, 93, 94, 101, 102, 103, 104, 106, 107, 108, 109, 110], "n_": [25, 37, 46, 67, 105], "n_h": [54, 105], "n_head": [59, 60], "n_layer": [59, 60], "n_routed_expert": [54, 102], "n_shared_expert": 54, "n_t": [25, 37], "n_vocab": 59, "n_word": 59, "nabla_": [44, 68, 69, 76], "naiv": [47, 66, 68, 99, 102], "nakano": [42, 94], "naman": [42, 94], "name": [20, 28, 32, 40, 49, 51, 59, 62, 68, 109], "nano": 70, "narrow": [9, 21, 35], "nativ": 58, "natur": [8, 9, 13, 14, 25, 37, 47, 49, 51, 52, 53, 58, 59, 62, 78, 87, 89, 103, 104, 106], "navig": 4, "nccl": 20, "ncurs": 20, "nderstand": 16, "ndim": [59, 60, 104], "ne": [67, 69, 99], "nearbi": 107, "nearli": [6, 8, 47, 62, 66, 70], "necess": 54, "necessari": [65, 66, 83, 96], "necessit": 102, "necssari": [15, 34], "need": [1, 2, 4, 9, 14, 25, 36, 37, 42, 43, 47, 51, 53, 54, 57, 58, 59, 60, 71, 76, 82, 94, 99, 104, 105], "neelakantan": [42, 94], "neg": [44, 61, 62, 65, 69, 73, 79, 82, 85, 92, 93, 99], "negligibli": 57, "neighbor": 77, "net": [42, 94], "network": [7, 42, 56, 59, 60, 61, 65, 76, 94, 102, 109], "networkx": 20, "neural": [6, 7, 42, 59, 60, 89, 94, 109, 110], "neutral": 93, "never": 102, "new": [4, 6, 8, 9, 10, 15, 18, 20, 21, 25, 28, 32, 34, 35, 37, 40, 47, 49, 50, 52, 57, 58, 59, 60, 61, 65, 69, 70, 71, 72, 76, 83, 91, 99, 101, 109], "newli": [28, 32, 40], "newlygener": [25, 37], "next": [1, 6, 7, 20, 25, 37, 44, 49, 51, 58, 70, 72, 77, 83, 84, 104, 108], "next_token": 59, "ng": 20, "ni": [42, 94], "nichol": [42, 94], "nichola": [42, 94], "nick": [42, 94], "nie": [42, 94], "niki": [42, 94], "nikola": [42, 94], "ning": [42, 94], "nl": 80, "nll": 58, "nlp": [7, 9, 10, 47, 72, 101, 106], "nn": [54, 59, 60, 102, 104, 106], "noam": [42, 94], "node": [55, 102], "nois": [66, 82], "noisi": [53, 82, 84, 85], "non": [9, 15, 22, 25, 34, 37, 55, 56, 61, 65, 66, 77, 81, 89, 91, 108], "none": [54, 59, 60], "nonlinear": [59, 60, 109], "noqa": 59, "norm": [59, 60], "norm_ep": [59, 60], "normal": [6, 8, 20, 56, 60, 61, 71, 74, 77, 78, 82, 102], "normalize_reward": 74, "normalized_shap": 59, "notabl": [13, 45, 53, 65, 104], "note": [41, 42, 46, 51, 55, 59, 68, 69, 70, 71, 84], "notebook": 42, "notin": [73, 81], "novel": [21, 28, 35, 40, 67, 73, 81, 84, 107, 108], "novelti": 19, "novemb": 53, "now": [51, 54, 65, 68, 69, 84, 92, 104], "np": [19, 68, 81], "nuanc": [61, 89], "nucleu": 59, "num": 105, "num_attention_head": 54, "num_base_token": 59, "num_channel": 59, "num_episod": 74, "num_experts_per_tok": 54, "num_featur": [59, 106], "num_head": 54, "num_reserved_special_token": 59, "num_sampl": [59, 81], "num_step": 6, "num_train_epoch": 112, "number": [2, 3, 7, 9, 10, 19, 25, 28, 37, 40, 45, 46, 47, 49, 52, 53, 54, 59, 66, 70, 71, 81, 91, 93, 102, 103, 104, 105, 106, 108, 109, 113], "numer": [19, 69, 76, 99], "numpi": [19, 20, 68, 81], "nvidia": [20, 91], "nvjitlink": 20, "nvrtc": 20, "nvtx": 20, "nw": 80, "o": [6, 16, 71, 79, 101, 105, 108], "o1": [29, 91], "o_": [54, 66, 71], "o_1": [71, 79], "o_2": [71, 79], "o_g": 71, "o_i": 66, "o_proj": 54, "obei": 105, "object": [3, 7, 10, 39, 44, 49, 50, 52, 55, 57, 61, 66, 68, 71, 72, 73, 76, 81, 85, 102], "observ": [3, 4, 28, 36, 40, 45, 47, 51, 54, 58, 65, 66, 70, 78, 82, 89, 96, 99, 103, 105], "obstacl": [2, 44], "obtain": [1, 6, 7, 15, 21, 28, 34, 35, 40, 50, 53, 54, 58, 61, 62, 65, 66, 70, 78, 81, 91, 92, 99], "obviou": 44, "occasion": [9, 58], "occur": 89, "occurr": 89, "od": 16, "off": [25, 37, 42, 43, 45, 66, 73, 78], "offer": [62, 70, 73, 78], "offici": 66, "offlin": [29, 30, 44, 49, 54, 62, 73], "offset": 6, "often": [7, 9, 25, 37, 44, 51, 66, 73, 78, 79, 82, 85, 106], "ofthought": 87, "ol": 101, "old": [66, 71, 76, 101], "older": [36, 101], "oliveira": [42, 94], "omit": [54, 102, 105, 109], "onc": [6, 15, 26, 28, 34, 40, 46, 105], "one": [1, 3, 6, 9, 10, 13, 25, 26, 28, 36, 37, 40, 42, 44, 45, 47, 49, 50, 52, 55, 57, 58, 59, 60, 61, 62, 65, 67, 69, 70, 71, 73, 78, 79, 81, 83, 91, 93, 99, 102, 104, 106, 109], "ones": [6, 32, 54, 57, 58, 59, 60, 62, 85, 91, 102, 104, 106], "ones_lik": [59, 60, 104], "onli": [9, 10, 14, 15, 16, 18, 22, 25, 34, 36, 37, 47, 49, 50, 52, 55, 57, 58, 59, 60, 62, 65, 67, 68, 69, 71, 73, 77, 79, 83, 84, 85, 91, 92, 93, 96, 103, 104, 105, 107, 108], "onlin": [29, 30, 32, 50, 54, 66, 67, 73], "open": [4, 13, 15, 26, 28, 30, 33, 34, 36, 40, 42, 55, 59, 61, 62, 66, 83, 89, 94], "openai": [8, 10, 20, 22, 42, 59, 72, 94], "opencod": 30, "openr1": 30, "openreview": [42, 94], "opensourc": 61, "openssl": 20, "oper": [1, 7, 22, 28, 40, 70, 76, 104, 106], "opportun": 70, "oppos": [52, 109], "opposit": [73, 79], "optim": [1, 7, 10, 15, 29, 34, 42, 44, 45, 46, 51, 53, 54, 55, 57, 61, 62, 66, 67, 70, 72, 76, 80, 81, 84, 89, 92, 94, 104], "optima": 92, "optimis": 69, "option": [15, 17, 34, 44, 54, 59, 60, 77, 78, 91, 104], "opu": 53, "oracl": [26, 44, 45, 92], "order": [6, 7, 8, 9, 10, 47, 49, 50, 51, 52, 54, 57, 68, 72, 77, 78, 82, 83, 84, 102, 103, 104, 105, 107, 108], "org": [21, 25, 28, 35, 37, 40, 42, 94], "organ": [62, 68], "origin": [1, 8, 17, 18, 25, 28, 37, 40, 50, 51, 55, 56, 57, 58, 65, 66, 67, 73, 78, 82, 83, 84, 102, 103, 104, 108, 109], "orjson": 20, "orthogon": [21, 35], "oss": [42, 94], "other": [2, 6, 7, 10, 18, 28, 33, 40, 42, 43, 44, 47, 51, 52, 54, 55, 58, 59, 60, 62, 70, 73, 81, 83, 85, 92, 94, 99, 102, 106, 109, 111], "otherwis": [44, 55, 57, 66, 67, 73, 81, 93, 102, 103], "otim": [59, 60, 109], "our": [1, 2, 3, 6, 7, 8, 10, 14, 15, 16, 18, 21, 22, 25, 26, 28, 34, 35, 36, 37, 40, 44, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 61, 62, 66, 68, 69, 70, 71, 72, 77, 78, 80, 82, 83, 84, 89, 91, 92, 93, 99, 104, 107, 108, 113], "ourselv": 50, "out": [10, 26, 50, 57, 58, 59, 60, 66, 67, 70, 72, 91, 99, 103, 104, 105], "out_logprob": 59, "out_token": 59, "outbound": 8, "outcom": [66, 67, 89], "outdat": 36, "outer": [59, 60, 104], "outermost": 74, "outlier": 76, "outlin": [28, 40, 82, 89], "outperform": [45, 47, 52, 53, 54, 55, 62, 78, 93, 99], "output": [1, 3, 6, 7, 10, 15, 16, 20, 21, 25, 34, 35, 37, 43, 44, 45, 46, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 71, 72, 73, 79, 82, 84, 85, 96, 102, 105, 106, 108], "output_dir": 112, "outsid": 82, "ouyang": [42, 94], "over": [6, 7, 8, 9, 10, 18, 20, 44, 46, 50, 52, 54, 57, 58, 59, 60, 61, 62, 66, 70, 71, 72, 73, 74, 78, 82, 83, 85, 92, 93, 105, 106, 108], "overal": [6, 7, 25, 36, 37, 46, 49, 55, 58, 65, 66, 71, 73, 78], "overcom": 2, "overconfid": 82, "overfit": [27, 72, 82], "overlap": [36, 62], "overload": 55, "oversight": 22, "overthink": 55, "overview": [1, 42, 59, 60], "overwrite_cach": 112, "owj": [10, 42, 94], "own": [4, 58, 73, 77, 83, 92, 93], "p": [7, 10, 39, 44, 45, 57, 59, 68, 70, 71, 73, 79, 81, 108, 110], "p_": [44, 67, 70, 82, 85, 92, 102], "p_1": 92, "p_i": [39, 67], "pa": 39, "pack": [6, 112], "packag": [20, 26, 36], "pad": 106, "pad_id": 59, "padding_idx": 54, "page": [42, 43], "paino": [42, 94], "pair": [6, 7, 8, 10, 15, 16, 26, 34, 36, 44, 47, 51, 52, 54, 56, 61, 62, 66, 70, 72, 73, 77, 78, 79, 80, 81, 82, 83, 85, 91, 92], "pairwis": [10, 57, 65, 67, 79, 80, 81, 83, 84], "palm": [59, 60], "pamela": [42, 94], "pan": [42, 94], "panda": 20, "panpan": [42, 94], "paper": [10, 19, 21, 22, 25, 28, 35, 37, 40, 41, 44, 50, 51, 52, 58, 99, 104], "par": 78, "paradigm": [9, 67, 73], "parallel": [6, 49, 59, 62, 91, 102, 106], "paralleliz": 6, "param": [19, 59, 60], "paramet": [6, 7, 8, 9, 10, 21, 35, 36, 45, 50, 52, 55, 56, 57, 58, 59, 60, 61, 65, 66, 68, 69, 70, 71, 72, 73, 76, 81, 82, 96, 99, 102, 103, 104, 105, 106, 107, 108, 109, 113], "parameter": [46, 67, 85], "parametr": 68, "parenthes": 79, "parmar": [42, 94], "pars": [58, 62], "parsed_arg": 17, "parser": 58, "part": [47, 52, 62, 70, 102, 108], "partial": [44, 51], "particip": [23, 49, 50], "particular": [6, 58, 59, 60, 66, 68, 70, 71, 87, 103, 109], "particularli": [20, 73, 89], "partit": [68, 82, 102], "pass": [7, 16, 19, 23, 26, 28, 36, 40, 46, 49, 51, 52, 53, 58, 59, 60, 61, 65, 103, 109, 113], "pass_at_k": 19, "past": [70, 76], "pat_str": 59, "patch": [1, 26], "path": [4, 43, 59, 99], "path_to_custom_output": 20, "pattern": [9, 55, 59, 66, 67], "paul": [42, 94], "pavlov": [42, 94], "pbar": 74, "pdf": [21, 25, 28, 35, 37, 40], "pe_": 6, "peak": [15, 34], "pearson": 65, "pebbl": 20, "pei": [42, 94], "peiyi": [42, 94], "penal": [47, 66, 82], "penalti": [10, 57, 65, 66, 71, 72, 92], "peng": [42, 94], "per": [10, 18, 19, 44, 46, 49, 50, 54, 59, 71, 72, 79, 80, 83, 93, 105], "per_device_train_batch_s": 112, "percent": 77, "percentag": [49, 78], "perceptu": 44, "perfect": [58, 83], "perform": [3, 6, 8, 9, 10, 13, 14, 15, 16, 18, 21, 22, 34, 35, 36, 45, 47, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 66, 67, 70, 72, 73, 78, 81, 83, 85, 87, 91, 93, 96, 99, 102, 103, 105, 106], "period": [52, 54, 108], "permit": [15, 34], "permut": [59, 106], "perplex": 103, "person": [10, 77], "perspect": [9, 66, 108], "peter": [42, 94], "petroski": [42, 94], "petrov": [42, 94], "pexpect": 20, "pgr": 47, "phase": [1, 25, 36, 37, 51, 52, 55, 57, 61, 68, 77, 89], "phd": 22, "phenomenon": [47, 65, 66, 89], "phi": [10, 65, 68, 71, 72, 78, 84, 109], "phi4": 29, "philipp": [42, 94], "philosophi": 18, "php": 58, "phrase": 7, "physic": [18, 22], "pi": [6, 10, 44, 57, 68, 70, 72, 76, 81, 82, 85, 92, 99, 103, 104], "pi_": [10, 44, 57, 66, 69, 71, 72, 76, 81, 85, 92, 99], "piao": [42, 94], "pick": [45, 49], "piec": [3, 56, 58, 77, 78, 91], "piecewis": 57, "pii": 10, "pile": 104, "pinto": [42, 94], "pioneer": 55, "pip": [17, 20], "pipelin": [13, 15, 26, 34, 36, 53, 55, 61, 68, 79, 89, 93], "pivot": [2, 45], "pkginfo": 20, "place": [59, 60, 67, 79, 109], "placehold": [15, 34], "plai": [45, 53, 54, 55], "plain": [10, 51], "plan": [2, 55, 104], "plane": 108, "plappert": [42, 94], "platform": [8, 20, 32, 49, 50], "platformdir": 20, "playground": 10, "pleas": [17, 77], "plethora": 58, "plot": [46, 68, 70], "plot_loss": 112, "plt": 68, "plu": 20, "plugin": 20, "pm": 85, "pmatrix": [52, 107, 108], "po": 6, "poetri": 20, "point": [6, 36, 45, 50, 51, 54, 57, 62, 66, 83, 89, 104], "pointwis": [67, 81], "polar": [59, 60, 103, 104], "polici": [10, 53, 54, 55, 57, 58, 61, 68, 70, 72, 76, 77, 78, 81, 85, 89, 92], "polit": 77, "polosukhin": [42, 94], "pond": [42, 94], "pool": [2, 25, 37, 49, 81, 84, 85, 91], "poor": [51, 55, 70, 89, 106], "poorli": 47, "pop": 81, "popular": [13, 26, 47], "portion": [52, 58, 62, 89], "posit": [4, 7, 42, 47, 52, 55, 56, 59, 60, 61, 69, 71, 73, 76, 78, 79, 83, 84, 85, 91, 93, 94, 96, 106, 107, 109], "positionwis": 6, "possess": 83, "possibl": [8, 25, 26, 37, 47, 50, 51, 55, 56, 58, 66, 70, 77, 79, 80, 84, 92, 93], "possibli": [36, 62, 77], "post": 78, "post0": 20, "postpon": 51, "potenti": [2, 9, 10, 39, 51, 54, 57, 62, 66, 67, 73, 78, 89], "pow": [59, 60, 106], "power": [4, 9, 21, 35, 42, 49, 50, 59, 60, 66, 89, 94], "ppo": [10, 29, 30, 53, 57, 66, 72, 79], "ppo_train": 74, "pq": 39, "pr": 26, "practic": [6, 9, 14, 36, 44, 47, 51, 62, 65, 68, 70, 82, 85, 102, 104], "practition": [21, 35], "prafulla": [42, 94], "pranav": [42, 94], "pre": [3, 6, 9, 14, 30, 32, 36, 42, 49, 51, 53, 59, 65, 67, 77, 91, 94, 101, 103, 104, 107, 108, 110], "preambl": 78, "preced": [7, 57], "precis": [14, 44, 52, 73], "precomput": 104, "precompute_freqs_ci": [59, 60, 104], "predecessor": [61, 62], "predefin": [21, 35, 76, 80, 89], "predicetd": 67, "predict": [2, 6, 7, 10, 16, 20, 47, 49, 50, 52, 59, 65, 67, 70, 72, 82, 85, 92, 93, 104], "predominantli": 52, "prefer": [10, 13, 29, 30, 42, 44, 45, 53, 54, 55, 61, 62, 65, 69, 70, 72, 77, 79, 80, 81, 83, 84, 89, 92, 93, 94, 104, 106], "prefix": [10, 20, 25, 37, 44, 52, 93], "preliminari": [54, 67, 89], "prepend": [59, 77], "prescrib": 70, "presenc": [43, 62], "present": [4, 10, 51, 55, 58, 70, 72, 73, 76, 77, 78, 84, 93, 103, 104], "preserv": [62, 103, 104], "pressur": 103, "pretrain": [9, 10, 18, 25, 37, 47, 52, 54, 62, 67, 72, 74, 77, 83, 93, 96, 103, 104, 113], "pretrained_weight": 112, "prev_po": 59, "prevent": [6, 52, 55, 76], "preview": 91, "previou": [1, 4, 6, 9, 25, 28, 37, 40, 54, 58, 59, 60, 61, 70, 73, 92, 103, 104], "previous": 6, "primarili": [10, 22, 53, 58, 61, 72, 73], "princip": 102, "principl": [4, 77, 79], "print": [14, 43, 59], "prior": [4, 8, 9, 22, 36, 57, 68, 73, 77, 85], "priorit": [58, 61], "privaci": 77, "privat": 2, "prm800k": 93, "pro": [50, 53, 70], "prob": 59, "probabl": [6, 7, 10, 19, 44, 45, 59, 66, 68, 69, 70, 71, 73, 76, 77, 78, 81, 85, 93], "problem": [9, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 32, 33, 35, 36, 38, 42, 47, 49, 50, 51, 52, 55, 58, 62, 66, 68, 81, 82, 89, 91, 93, 94], "probs_idx": 59, "probs_sort": 59, "probs_sum": 59, "proce": [28, 40], "procedur": [7, 10, 26, 47, 50, 69, 70, 72, 78, 83], "process": [1, 8, 14, 25, 28, 36, 37, 40, 42, 44, 45, 47, 51, 53, 54, 55, 59, 61, 62, 65, 66, 67, 70, 73, 76, 91, 94, 104, 106, 108, 110], "processor": 4, "prod": 19, "produc": [3, 6, 7, 10, 15, 21, 25, 26, 28, 34, 35, 37, 40, 44, 45, 49, 50, 51, 54, 55, 58, 59, 62, 65, 70, 72, 73, 78, 79, 82, 85, 92, 96, 105], "product": [19, 44, 59, 60, 107, 108, 109], "profession": [18, 52], "profici": 54, "program": [19, 23, 32, 33, 36, 49, 50, 51, 52, 53, 55, 58, 62], "programm": [16, 23, 33], "programmat": 19, "progress": [6, 33, 51, 55, 57, 66, 70, 71], "project": [1, 6, 49, 105], "promin": [28, 40], "promis": [8, 9, 45, 62, 78, 91], "promot": [25, 37], "prompt": [1, 3, 4, 10, 13, 15, 17, 18, 19, 21, 25, 26, 34, 35, 36, 37, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 61, 65, 66, 70, 72, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 89, 96], "prompt_data": 74, "prompt_max_len": 74, "prompt_token": 59, "prompts_dataload": 74, "prone": [27, 82], "prop": 56, "propag": 4, "proper": [14, 62, 65, 67], "properli": [42, 57], "properti": [104, 107], "proport": [52, 54, 62, 69, 102], "propos": [3, 6, 25, 37, 44, 47, 52, 59, 60, 62, 65, 66, 67, 68, 71, 73, 81, 84, 85, 91, 92, 99, 102, 105, 109, 113], "proprietari": [52, 61], "propto": 69, "proto": 20, "protobuf": 20, "protocol": [36, 58], "prove": [36, 108], "proven": [53, 71], "provid": [1, 2, 3, 4, 7, 10, 15, 17, 18, 19, 20, 23, 26, 27, 34, 38, 47, 52, 53, 55, 57, 59, 62, 68, 69, 71, 73, 82, 83, 87, 89, 91, 93, 104, 108], "proxim": 71, "prune": 23, "pseudo": 85, "pseudocod": 39, "pseudolabel": 85, "psi": [68, 71, 81, 82], "psi_": 82, "psm": 52, "psychologi": 18, "pth": 59, "ptimiz": 66, "ptx": [10, 72], "ptyprocess": 20, "public": [10, 49, 50, 51, 53, 62, 72], "publicli": [52, 56, 61], "pull": 26, "punish": 66, "punit": 66, "pure": 89, "puri": [42, 94], "purpos": [3, 26, 42, 47, 52, 96, 104], "pursu": 22, "push": [6, 21, 35, 73], "put": [15, 25, 34, 37, 44, 49, 89], "puzzl": [47, 55], "py": [17, 112], "py310h06a4308_0": 20, "pyarrow": 20, "pyasn1": 20, "pycpars": 20, "pydant": 20, "pydoc": 36, "pyext": 20, "pypars": 20, "pyplot": 68, "pyproject": 20, "python": [3, 16, 17, 20, 21, 23, 26, 35, 36, 49, 50, 52, 58, 62, 99], "pytorch": 91, "pytz": 20, "pyyaml": 20, "q": [6, 10, 39, 42, 44, 59, 60, 61, 62, 66, 71, 73, 94, 99, 103, 104, 105, 107, 108], "q_": [59, 60, 103, 104], "q_0": [59, 60], "q_1": [59, 60], "q_2": [59, 60], "q_3": [59, 60], "q_a_layernorm": 54, "q_a_proj": 54, "q_b_proj": 54, "q_head_dim": 54, "q_i": [39, 99], "q_lora_rank": 54, "qa": [36, 39, 56, 89], "qihao": [42, 94], "qime": [42, 94], "qin": [42, 94], "qinyu": [42, 94], "qiu": [42, 94], "qiufeng": [42, 94], "qiushi": [42, 94], "qk": 6, "qk_nope_head_dim": 54, "qk_rope_head_dim": 54, "qkv": 61, "qlora": 74, "qpa": 39, "qr": 105, "qu": [42, 94], "quad": [7, 46, 55, 57, 66, 67, 82, 85, 102, 103, 104], "qualiti": [6, 8, 14, 21, 22, 25, 26, 27, 29, 35, 36, 37, 38, 39, 44, 50, 54, 55, 57, 61, 62, 65, 66, 78, 79, 80, 83, 84, 85, 91, 103, 104], "quan": [42, 94], "quantifi": [82, 91], "quantil": 85, "quantiti": [29, 58], "quartil": 58, "queri": [2, 6, 10, 13, 36, 42, 52, 54, 59, 60, 61, 62, 67, 70, 71, 82, 85, 94, 103, 104, 107, 108], "query_1": 58, "query_2": 58, "question": [1, 2, 7, 8, 15, 17, 18, 22, 23, 26, 28, 34, 36, 39, 40, 45, 51, 52, 55, 62, 66, 71, 78, 91, 93, 96, 99, 103, 104], "question_id": 20, "quickli": [4, 66], "quit": [51, 53], "qw_": 6, "qwen": [29, 42, 66, 94], "qwen2": [29, 30, 42, 61, 66, 91, 94], "qy": [42, 61, 62, 94], "r": [6, 10, 16, 28, 40, 42, 44, 52, 54, 55, 57, 58, 59, 65, 66, 69, 70, 71, 76, 81, 82, 92, 94, 99, 102, 103, 105, 107, 108, 113], "r1": [30, 55, 66], "r_": [10, 44, 54, 57, 65, 66, 67, 68, 70, 71, 72, 76, 78, 81, 82, 83, 99, 107, 108], "r_1": [67, 71], "r_h": 57, "r_i": [66, 67, 71, 99], "r_l": 67, "racist": 77, "radford": [42, 94], "rafael": [42, 94], "rafailov": [42, 94], "rai": [42, 94], "rais": [1, 18, 59, 104], "ramesh": [42, 94], "ramp": 103, "ran": 50, "rand_prompt": 74, "randn": [59, 106], "random": [8, 18, 21, 35, 49, 50, 59, 70, 81, 82, 84, 91], "randomli": [16, 18, 21, 28, 35, 40, 49, 52, 62, 77, 79], "rang": [4, 7, 9, 10, 18, 20, 21, 35, 47, 52, 56, 57, 58, 59, 60, 66, 74, 76, 77, 78, 101, 104], "rangl": [59, 60, 103, 104, 108], "rank": [1, 10, 45, 49, 51, 57, 58, 68, 72, 81, 82, 83, 113], "rapidfuzz": 20, "rapidli": 73, "rate": [3, 36, 47, 49, 50, 51, 54, 56, 57, 58, 65, 66, 70, 72, 76, 78, 93, 96], "rater": 70, "rather": [68, 79, 89], "ratio": [55, 62, 69, 76, 103], "rational": 78, "raul": [42, 94], "raw": [53, 110], "re": [3, 51, 59, 60, 68, 81, 103, 104, 108], "reach": [3, 9, 22, 25, 37, 50, 51, 57, 93, 102], "read": [8, 59], "readabl": [58, 89], "readlin": 20, "real": [3, 26, 36, 52, 74, 96, 104, 108], "realist": [14, 15, 22, 34], "realiti": [81, 104], "realiz": 7, "realli": [1, 42, 94], "realm": [21, 28, 35, 40], "realworld": 36, "rearrang": [68, 81], "reason": [9, 18, 19, 28, 30, 40, 42, 44, 45, 51, 52, 54, 55, 58, 61, 66, 69, 71, 78, 84, 93, 94, 104, 106], "recal": [44, 58, 70, 73], "receiv": [3, 4, 8, 44, 57, 70, 102], "recent": [2, 9, 49, 50, 56, 57, 58, 59, 65, 72], "recip": [52, 58, 84], "recogn": 4, "recommend": [13, 83], "recov": [4, 47, 70], "recoveri": 4, "rectifi": [59, 60, 109], "recurr": 6, "red": [28, 40, 105], "reddit": 8, "reduc": [8, 15, 18, 34, 36, 44, 45, 57, 69, 92, 102, 104, 105, 109, 113], "reduct": [59, 69], "redund": [50, 55, 102], "reevalu": 89, "ref": [68, 69, 71, 92], "refer": [4, 10, 23, 26, 27, 42, 44, 52, 57, 58, 65, 66, 68, 69, 70, 71, 77, 83, 91, 93, 103], "refin": [14, 55, 58, 70], "reflect": [23, 36, 51, 73, 91], "regard": 66, "regardless": [65, 66], "regener": 36, "regex": 59, "regim": 93, "region": [6, 44, 76, 104], "reglu": [59, 60, 109], "regress": [1, 6, 10, 52, 57, 58, 65, 72], "regul": 66, "regular": [42, 58, 61, 70, 71], "regularli": [55, 62], "rehears": 52, "reiichiro": [42, 94], "reinforc": [10, 47, 52, 68, 71, 79, 93, 96], "reject": [29, 30, 52, 55, 57, 58, 62, 65, 80, 82, 84, 85, 99], "rejected_1": 58, "rejected_2": 58, "rel": [1, 6, 10, 45, 49, 53, 54, 55, 59, 60, 61, 66, 69, 77, 89, 96, 104, 107, 108], "relat": [15, 20, 34, 36, 45, 52, 53, 55, 61, 62, 71, 81, 99, 102, 105, 108], "relationship": [42, 94], "releas": [15, 17, 34, 36, 52], "relev": [1, 4, 26, 47, 51, 61, 62, 66, 84, 85, 93], "reli": [21, 35, 44, 47, 50, 51, 55, 85, 91, 106], "reliabl": [4, 16, 18, 22, 47, 54, 55, 61, 89, 93], "relianc": 106, "relu": [6, 56, 59, 60, 68, 109], "remain": [2, 25, 26, 37, 46, 47, 49, 50, 69, 82, 85, 93], "remark": [89, 96], "remind": [15, 34], "remov": [10, 28, 36, 40, 50, 52, 56, 58, 62, 72, 77, 81, 84, 99], "ren": [42, 94], "render": 42, "renorm": 59, "reorder": 52, "repair": [1, 20], "reparameter": 68, "repeat": [4, 15, 25, 34, 37, 51, 66, 91], "repeatedli": 49, "repetit": [8, 66], "replac": [4, 56, 59, 60, 61, 77, 78, 104, 109], "replai": [70, 71, 74], "replay_buff": 74, "replic": 1, "repo": [26, 58, 62], "report": [19, 42, 62, 66, 82, 94, 99], "repositori": [1, 4, 20, 26, 36, 49, 52, 53, 62], "repres": [4, 6, 25, 28, 37, 40, 44, 52, 58, 59, 60, 69, 76, 82, 102, 103, 104, 108, 109, 111], "represent": [6, 39, 47, 49, 55, 59, 60, 68, 78, 108, 109], "reproduc": [2, 36], "reproduct": 1, "request": [2, 15, 20, 26, 34, 77, 83], "requir": [1, 2, 3, 6, 7, 9, 15, 16, 26, 34, 47, 50, 51, 52, 55, 57, 58, 59, 70, 81, 89, 102, 103, 104, 105, 106, 107, 108], "rerank": 50, "resampl": [61, 70], "rescal": 104, "research": [2, 22, 36, 57, 73], "reserv": 54, "reserved_special_token_": 59, "reserved_special_token_0": 59, "reserved_special_token_1": 59, "reserved_special_token_2": 59, "reserved_special_token_3": 59, "reserved_special_token_4": 59, "reshap": [59, 60, 104], "reshape_for_broadcast": [59, 60, 104], "residu": [6, 46], "resolv": [1, 26, 49, 65], "resort": 89, "resourc": [51, 57, 62, 91], "respect": [6, 10, 45, 66, 69, 71, 72, 73, 76, 78, 79, 82, 102, 105], "respons": [4, 10, 13, 15, 17, 20, 28, 34, 36, 40, 45, 54, 55, 57, 58, 59, 61, 62, 65, 66, 67, 70, 71, 72, 73, 76, 77, 78, 80, 81, 82, 83, 85, 89, 92, 96, 102], "response_candid": 81, "response_reward": 81, "rest": 43, "restrict": [3, 44, 55, 66, 69, 76], "result": [1, 3, 6, 8, 9, 18, 19, 21, 27, 35, 36, 44, 47, 50, 51, 52, 57, 62, 71, 73, 81, 82, 89, 93, 99, 102, 103, 104, 105, 107, 108], "retain": [36, 52, 55, 58, 62, 77, 85], "retriev": [1, 2, 36], "return": [19, 44, 59, 60, 73, 76, 81, 104, 106], "reus": [61, 89, 104], "reveal": [55, 58], "revers": 78, "review": [61, 68], "revis": [58, 92], "reward": [10, 29, 30, 42, 45, 47, 51, 52, 53, 54, 55, 61, 68, 71, 73, 74, 78, 80, 81, 84, 85, 94], "reward_pretrain": 74, "rewon": [42, 94], "rewrit": 77, "rft": [29, 67, 99], "rho": 99, "rho_": 81, "rich": 36, "right": [6, 10, 19, 44, 46, 52, 59, 60, 65, 66, 68, 69, 71, 72, 73, 76, 78, 81, 92, 93, 103, 104, 105, 108, 110], "rigor": [14, 17, 18, 36, 42, 94], "risk": [26, 55, 62], "rl": [10, 29, 30, 49, 53, 54, 55, 57, 61, 66, 68, 76, 77, 78, 79, 85, 89, 93], "rlaif": [30, 77, 79, 85], "rlcd": [29, 30, 85], "rlhf": [47, 52, 65, 66, 68, 70, 72, 74, 77, 81], "rlhf1": 30, "rlhf2": 30, "rm": [10, 29, 47, 54, 55, 57, 58, 65, 74, 78, 80], "rm_": 54, "rmboost": 29, "rmsnorm": [42, 54, 56, 61, 94], "roberta": 58, "robust": [25, 26, 36, 37, 51, 53, 61, 77], "roform": [42, 94], "role": [3, 45, 53, 54, 55, 59], "rollout": [66, 92], "rollout_batch_s": 74, "room": 51, "rope": [29, 30, 52, 55, 56, 61, 105], "rope_theta": [59, 60], "rotari": [42, 52, 56, 61, 94, 107], "rotat": [52, 107, 108], "roug": [25, 37], "roughli": [46, 50, 56, 82, 93], "round": [28, 40, 50], "rout": [54, 55, 102], "row": [59, 60, 104], "rozi\u00e8r": [42, 94], "rsa": 20, "rsm": [42, 58, 61, 94], "rso": [29, 30], "rsqrt": [59, 60, 106], "rtol": [59, 106], "rtx4090": 74, "ruan": [42, 94], "rui": [42, 94], "ruiqi": [42, 94], "ruizh": [42, 94], "rule": [22, 51, 53, 54, 55, 58, 89], "rulebas": 55, "run": [16, 43, 51, 52, 58, 69, 77, 91, 92], "runji": [42, 94], "runnabl": 2, "runner": 20, "runtim": [20, 50], "runxin": [42, 94], "ruyi": [42, 94], "rwc": [8, 9, 42, 94], "rx": 70, "ryan": [42, 94], "ryder": [42, 94], "s3transfer": 20, "s_": [44, 55, 67, 69, 76, 102, 104], "s_1": [62, 67, 104], "s_2": 104, "s_i": 67, "s_j": 67, "s_n": 62, "s_t": 76, "safe": 72, "safeti": [47, 52, 54, 57], "sahil280114": [15, 34], "sai": 77, "salienc": 47, "salient": 47, "sam": [42, 94], "same": [6, 9, 28, 36, 40, 42, 49, 50, 51, 52, 53, 54, 62, 66, 68, 69, 77, 79, 81, 82, 83, 89, 99, 102, 103, 104, 105, 106], "sampl": [1, 8, 16, 17, 18, 19, 21, 25, 26, 28, 29, 30, 35, 36, 37, 40, 44, 45, 52, 53, 55, 56, 57, 58, 59, 61, 62, 67, 68, 70, 71, 76, 77, 78, 79, 80, 83, 84, 85, 91, 93, 96, 99, 106], "sample_top_p": 59, "sandbox": [61, 62], "sandhini": [42, 94], "sanghai": [42, 94], "sanit": 17, "sastri": [42, 94], "satisfactori": [54, 73], "satisfi": 73, "saunder": [42, 94], "save": [51, 105], "save_path": 74, "save_step": [74, 112], "scail": [76, 91], "scalabl": [7, 22, 62, 67, 73, 76, 78], "scalar": [10, 57, 65, 67, 72, 73], "scale": [7, 9, 25, 26, 27, 36, 37, 38, 42, 47, 57, 59, 60, 61, 62, 66, 68, 73, 76, 89, 94, 96, 104, 105], "scan": 46, "scarciti": 62, "scenario": [2, 3, 20, 36, 62, 66], "schedul": [36, 56], "scheme": [57, 70, 111], "school": 22, "schulman": [42, 94], "scienc": [18, 36, 56], "scientif": 36, "scope": [26, 55], "score": [14, 18, 55, 57, 58, 59, 60, 61, 62, 65, 67, 70, 71, 72, 76, 77, 78, 79, 81, 82, 83, 85, 93, 102, 103, 104], "scorer": 62, "scott": [42, 94], "scrape": [8, 26, 32, 49, 66], "scratch": [29, 82, 103, 104], "script": [17, 112], "scroll_down": 4, "scroll_up": 4, "scy": [39, 42, 62, 94], "search": [2, 4, 50, 51, 93], "search_dir": 4, "search_fil": 4, "seattl": 101, "second": [2, 6, 8, 15, 16, 34, 36, 44, 50, 54, 55, 62, 70, 78, 92, 109], "secret": [29, 30], "secretli": [42, 94], "secretstorag": 20, "section": [36, 53, 66, 77, 89, 104, 108], "secur": 62, "see": [13, 16, 18, 42, 43, 44, 46, 58, 60, 69, 75, 78, 104], "seed": [14, 15, 21, 25, 34, 35, 36, 37, 62, 83, 84], "seek": [57, 91], "seem": 4, "seen": [58, 85], "segment": [22, 57, 110], "select": [1, 13, 16, 26, 28, 36, 40, 45, 49, 50, 51, 52, 55, 57, 58, 59, 65, 66, 70, 72, 93, 96, 99, 102], "selector": 93, "self": [6, 7, 8, 10, 15, 17, 20, 21, 23, 26, 29, 30, 34, 35, 42, 52, 54, 58, 59, 60, 62, 71, 74, 94, 102, 103, 104, 106, 107, 108], "selfattent": 108, "selfinstruct": [25, 37], "semant": [23, 49, 50, 51, 58, 62, 84], "semi": [25, 37, 67], "sen": [42, 94], "send": [46, 70, 102], "sensit": [10, 18, 105, 106], "sent": [36, 55, 102], "sentenc": [6, 7, 8, 15, 34, 36, 56, 78, 110], "separ": [6, 13, 50, 52, 57, 93], "seq_len": [59, 106], "seqlen": [59, 60], "sequenc": [6, 7, 22, 42, 44, 52, 55, 57, 59, 60, 61, 66, 70, 73, 81, 83, 94, 102, 103, 105, 106, 107, 108, 109, 110], "sequenti": [44, 70, 91], "seri": [21, 35, 56, 61, 62, 83, 87, 93], "serv": [14, 36, 42, 45, 55, 67, 70, 82, 102], "servic": 61, "set": [1, 2, 6, 9, 10, 13, 14, 15, 16, 18, 19, 22, 25, 26, 27, 28, 33, 34, 36, 37, 38, 40, 44, 45, 47, 49, 52, 53, 54, 55, 57, 58, 59, 61, 62, 66, 67, 70, 71, 72, 77, 81, 82, 83, 84, 91, 93, 96, 99, 102, 103, 104, 108], "setup": [3, 17, 47], "setuptool": 20, "seventh": [42, 94], "sever": [4, 19, 45, 49, 50, 52, 53, 57, 58, 61, 62, 70, 89, 106], "sexist": 77, "sft": [10, 29, 30, 36, 54, 55, 61, 62, 68, 69, 71, 74, 76, 78, 80, 81, 82, 83, 89, 92, 99], "sh": 74, "sha": [42, 94], "shallow": 65, "shang": [42, 94], "shanghao": [42, 94], "shanghaoran": [42, 94], "shangyan": [42, 94], "shanhuang": [42, 94], "shantanu": [42, 94], "shao": [42, 94], "shaoq": [42, 94], "shape": [46, 59, 60, 104, 106], "share": [6, 10, 33, 54, 55, 89, 105], "sharegpt": 36, "sharma": [42, 94], "shazeer": [42, 94], "shelf": [45, 73, 78], "shellingham": 20, "shen": [42, 94], "shengfeng": [42, 94], "shengguang": [42, 94], "shift": [36, 67, 93], "shiji": [42, 94], "shirong": [42, 94], "shiyu": [42, 94], "short": [16, 23, 26, 55, 104], "shorter": [45, 66], "shot": [9, 10, 14, 18, 25, 37, 42, 77, 78, 83, 85, 93, 94, 99], "should": [1, 2, 4, 9, 15, 16, 22, 34, 43, 46, 47, 50, 69, 73, 77, 79, 81, 105], "show": [1, 6, 9, 10, 14, 18, 42, 43, 44, 52, 56, 58, 68, 69, 73, 77, 81, 82, 83, 87, 89, 93, 104, 105, 108], "shown": [6, 10, 19, 21, 35, 36, 44, 47, 71, 72, 78, 82, 85], "shuai": [42, 94], "shuang": [42, 94], "shuffl": [28, 40], "shuip": [42, 94], "shukai": [42, 94], "shunfeng": [42, 94], "shusheng": [42, 94], "shyam": [42, 94], "sida": [42, 94], "siddhartha": [42, 94], "sidestep": 70, "sigler": [42, 94], "sigma": [10, 57, 59, 60, 68, 69, 72, 78, 81, 82, 109], "sigma_": 76, "sigmoid": [59, 60, 68, 81, 109], "signal": [25, 37, 44, 51, 53, 55, 58, 61, 66, 78, 79, 89], "signatur": [19, 23, 36, 50, 52], "signific": [8, 18, 36, 54, 57, 58, 61, 103, 104, 105, 106], "significantli": [6, 14, 15, 18, 21, 34, 35, 39, 45, 51, 52, 54, 57, 58, 61, 66, 67, 69, 77, 82, 87, 93, 105], "silu": [59, 60], "sim": [10, 44, 46, 57, 66, 67, 68, 69, 71, 72, 81, 82, 85, 92, 109], "simen": [42, 94], "similar": [4, 9, 13, 18, 25, 37, 42, 49, 50, 58, 62, 77, 79, 93, 99, 103], "similarili": [103, 105], "similarli": [6, 50, 55, 69, 83, 85, 89], "simpl": [4, 6, 9, 15, 19, 21, 28, 34, 35, 40, 42, 46, 47, 49, 55, 59, 60, 67, 68, 78, 85, 87, 108, 110], "simpler": [7, 44, 68], "simplest": 91, "simpli": [10, 15, 34, 47, 65, 91, 92, 103], "simplic": [7, 51, 76], "simplifi": [15, 19, 28, 34, 40, 59, 99], "simplist": [1, 3], "simul": [49, 70, 79], "simultan": [6, 46, 67, 83], "sin": [6, 52, 59, 60, 103, 104, 107, 108], "sinan": [42, 94], "sinc": [1, 6, 7, 44, 47, 50, 53, 59, 60, 62, 68, 69, 71, 77, 78, 81, 102, 104, 105, 106], "sine": 6, "singl": [2, 8, 10, 15, 19, 23, 34, 49, 50, 51, 52, 55, 72, 79, 84, 93, 102], "sinusoid": [6, 108], "site": 33, "situat": 102, "six": [20, 28, 40, 58], "size": [7, 8, 9, 27, 36, 38, 42, 52, 54, 56, 59, 60, 61, 66, 71, 73, 82, 94, 96, 102, 103, 104, 105, 106], "skeleton": 1, "skill": [22, 27, 38, 52, 62, 83], "skywork": 29, "sl": 77, "slama": [42, 94], "slice": 105, "slight": 42, "slightli": [57, 58], "slope": 91, "slow": 106, "slowli": [103, 104], "slp": [42, 55, 61, 94, 103, 105, 107], "small": [6, 16, 25, 37, 42, 47, 49, 51, 52, 58, 62, 76, 83, 89, 91, 103, 104, 105, 106, 108], "smaller": [1, 45, 56, 57, 92, 93, 96, 102, 103, 105, 107], "smallest": [8, 49, 59], "smallscal": 93, "smarter": 47, "smooth": [9, 28, 40], "snapshot": [49, 77], "sniffio": 20, "snippet": [1, 14, 21, 35, 36, 52, 58, 61, 62], "so": [2, 10, 16, 43, 49, 51, 57, 58, 67, 69, 70, 71, 77, 83, 102, 103, 104, 105], "social": [8, 18], "soft": [51, 66, 78, 82], "softmax": [7, 59, 60, 78, 102, 103, 105], "softwar": [1, 26, 36], "solar": [42, 94], "sole": [6, 44, 57, 66, 73], "solid": 105, "solut": [3, 14, 17, 21, 22, 23, 26, 27, 32, 33, 35, 38, 39, 49, 50, 51, 52, 58, 65, 68, 78, 84, 91, 93, 105, 106, 108], "solv": [1, 3, 14, 17, 18, 19, 22, 23, 26, 42, 45, 49, 50, 51, 52, 58, 89, 92, 93, 94], "solvabl": 23, "some": [6, 7, 15, 34, 42, 49, 51, 53, 57, 58, 65, 70, 73, 81, 85, 102], "someon": 77, "someth": 9, "sometim": [9, 36], "song": [42, 94], "sonnet": 91, "sort": [58, 59, 70], "sound": 66, "sourc": [1, 8, 13, 19, 23, 26, 28, 36, 40, 42, 52, 53, 55, 58, 59, 61, 62, 66, 81, 89, 94], "space": [3, 8, 28, 40, 50, 51, 107, 108], "span": [2, 18, 22, 42, 47, 52, 62, 91], "spars": [9, 26, 42, 51, 94], "speak": 81, "spearman": 65, "special": [2, 4, 18, 42, 57, 59, 61, 85, 93, 102], "special_token": 59, "specif": [1, 2, 4, 9, 10, 15, 28, 34, 36, 40, 42, 44, 45, 51, 52, 55, 58, 59, 61, 62, 67, 68, 69, 77, 81, 82, 83, 91, 93, 102, 103, 104], "specifi": [23, 59, 89, 91], "speed": [10, 55, 72], "spent": 53, "sphinx": 42, "split": [10, 14, 32, 33, 50, 52, 59, 60], "split_experience_batch": 74, "spm": 52, "spot": 18, "spread": 103, "spuriou": 9, "sqlite": 20, "sqrt": [6, 59, 60, 82, 103, 104, 105, 106, 108], "squre": 59, "src": 112, "sse": 20, "stabil": [18, 56, 57, 59, 66, 71, 76, 106], "stabl": [17, 19, 45, 61, 76], "stack": [21, 35, 96, 102], "stackexchang": 56, "stage": [7, 26, 52, 54, 55, 57, 58, 61, 62, 71, 82, 89, 91, 96, 103, 104, 112], "stai": 44, "stale": 78, "stand": 42, "standalon": 52, "standard": [7, 22, 23, 25, 33, 37, 45, 46, 49, 52, 53, 58, 59, 61, 62, 69, 70, 71, 73, 76, 78, 79, 82, 93, 96, 102, 111], "star": [36, 92], "starcod": [21, 28, 35, 40, 52], "starcoderdata": [21, 35], "starkli": 18, "start": [10, 25, 26, 28, 37, 40, 42, 43, 45, 50, 51, 52, 59, 68, 70, 72, 81, 83], "start_header_id": 59, "start_po": [59, 60], "starter": 42, "state": [4, 9, 10, 22, 44, 47, 56, 65, 66, 76, 77, 102, 103], "statement": [23, 49, 52], "static": [44, 58, 61], "staticmethod": 59, "statist": 106, "statu": [20, 26, 74], "std": [59, 66, 71, 82, 106], "steadi": 46, "steer": [47, 58, 70, 85], "stefano": [42, 94], "steinhardt": [42, 94], "stem": [18, 61], "step": [4, 6, 10, 22, 25, 28, 29, 30, 36, 37, 40, 42, 44, 46, 50, 51, 52, 54, 55, 56, 57, 58, 66, 71, 72, 74, 77, 78, 84, 87, 89, 94, 96, 103, 104], "stepbi": 93, "steven": [42, 94], "still": [9, 47, 49, 53, 55, 68, 78, 104], "stochast": 7, "stoica": [42, 94], "stop": [46, 57], "stop_token": 59, "store": [42, 62, 81], "str": [59, 81], "straightforward": [7, 13, 22, 44, 58, 73, 81, 89, 99, 103, 104], "straightforwardli": 65, "strateg": [55, 58], "strategi": [36, 45, 52, 54, 55, 57, 61, 65, 66, 67, 74, 85, 92, 103, 105], "stream": 46, "streamlin": [28, 40], "strength": [10, 55, 58, 70, 72, 73], "strict": [25, 32, 37, 59], "strictli": 83, "string": [4, 59, 78, 91, 92], "stringent": 58, "strip": [17, 59], "strong": [42, 54, 55, 65, 73, 82, 89, 91, 93, 94, 96, 103, 104], "stronger": [21, 35, 47, 55, 105], "strongest": 22, "strongli": [77, 96], "structur": [1, 6, 7, 42, 51, 78, 102], "struggl": [4, 9, 45, 82, 89], "stuck": 44, "student": [21, 22, 35, 47, 62], "studi": [9, 25, 37, 46, 47, 61, 70, 73], "style": [18, 52, 58], "su": [42, 94], "sub": [6, 8, 51, 53, 56, 59, 81, 106, 107, 108], "subbiah": [42, 94], "subdirectori": 4, "subject": [18, 52, 91], "sublay": 6, "submiss": [1, 49, 50], "submit": [3, 10, 50, 70, 72], "suboptim": [36, 106], "subsequ": [6, 52, 57, 58, 59, 60, 70, 71, 83, 109], "subset": [8, 10, 22, 23, 26, 46], "subspac": 6, "substanti": [9, 15, 28, 34, 40, 47, 71, 73, 92], "substitut": [54, 68, 73, 102], "subtract": 71, "subword": [42, 94, 110], "succ": [10, 68, 81, 82, 85], "succeed": 51, "success": [3, 18, 19, 47, 51, 57, 62, 83, 84], "successfulli": [36, 66], "suchir": [42, 94], "sufeng": [42, 94], "suffer": [55, 66, 76, 89, 92], "suffici": [9, 10, 49, 57, 62, 69, 71, 87, 104], "suffix": 52, "suggest": [9, 45, 62, 68, 69, 73, 78, 96, 109], "suit": 7, "suitabl": [52, 65, 82], "sujoi": [42, 94], "sum": [6, 44, 55, 59, 65, 67, 70, 71, 76, 102, 108], "sum_": [7, 44, 59, 60, 66, 67, 68, 71, 73, 76, 78, 81, 82, 91, 92, 102, 103, 104, 105, 108, 110], "sumit": [42, 94], "summar": 104, "summari": [8, 78], "sun": [42, 94], "sup": 29, "super": [54, 59, 60, 106], "superalign": 47, "superhuman": 47, "superior": [6, 45, 53, 66, 83], "supervis": [8, 9, 10, 22, 25, 26, 37, 44, 47, 52, 62, 68, 79, 80, 81, 83, 85, 91, 96, 107, 108], "supervison": 47, "supervisor": 47, "supplement": 58, "suppli": 99, "support": [3, 43, 52, 54, 58, 62, 74, 111], "suppos": [65, 73, 102], "suppress": [66, 91], "sure": [15, 34, 52, 77], "surfac": [50, 79, 93], "surpass": [9, 22, 28, 40, 62, 80], "surpris": [10, 58, 71], "surprisingli": 69, "surrog": 71, "surround": [52, 54], "suspect": [6, 77], "suspici": 1, "sutskev": [42, 94], "swaroop": [42, 94], "swiglu": [56, 61], "swish": [29, 59, 60], "symbol": 6, "sympi": 20, "syncheck": 17, "synnaev": [42, 94], "syntact": [49, 58], "syntax": [4, 42, 58, 62], "synthes": [14, 36, 61, 62], "synthesi": [36, 52, 62], "synthet": [21, 35, 58, 61, 62, 80, 84, 85], "system": [4, 9, 22, 36, 42, 55, 58, 59, 66, 70, 89, 91, 94, 103], "systemat": 73, "t": [6, 7, 25, 28, 36, 37, 40, 42, 44, 49, 55, 59, 60, 66, 71, 73, 76, 83, 94, 101, 102, 103, 104, 105, 108], "t1": [59, 106], "t2": [59, 106], "t_": [69, 110], "t_1": 110, "t_2": 110, "t_n": 110, "tabl": [8, 79, 105], "tackl": 50, "taco": 30, "tag": [49, 50, 52, 62, 89], "tail": 62, "tailor": [50, 55, 70], "take": [1, 4, 10, 21, 22, 35, 44, 52, 59, 60, 65, 68, 69, 70, 72, 73, 76, 81, 83, 84, 85, 93, 107, 108, 109], "taken": 44, "talent": 22, "tan": [42, 94], "tang": [42, 94], "tao": [42, 94], "target": [7, 50, 58, 59, 73, 77, 81, 93, 99, 102, 104], "task": [3, 4, 6, 8, 9, 10, 14, 15, 16, 18, 19, 21, 23, 26, 27, 34, 35, 36, 38, 44, 45, 47, 49, 51, 52, 54, 55, 58, 62, 66, 71, 73, 76, 77, 78, 82, 89, 93, 103, 104, 106, 113], "task_id": 17, "taskspecif": 8, "tau": [44, 70, 92], "taught": 30, "td": [71, 76], "teach": [47, 57, 96], "teacher": [21, 35, 36], "team": [10, 72], "technic": [42, 47, 94], "techniqu": [15, 28, 29, 30, 34, 40, 44, 45, 47, 51, 57, 58, 66, 76, 82, 103, 104], "teddi": [42, 94], "telecommun": 111, "tell": [47, 68], "temper": 49, "temperatur": [20, 36, 49, 50, 55, 59, 61, 66, 70, 99, 103], "templat": [21, 25, 28, 35, 36, 37, 40, 112], "tempor": 32, "ten": [9, 18, 52, 57, 62, 104], "tend": [66, 70, 78], "tensor": [59, 60, 104], "term": [7, 10, 19, 51, 53, 55, 57, 61, 66, 67, 68, 71, 73, 93, 104, 108, 109], "termin": [3, 44, 91], "terri": [10, 65, 68, 81, 82], "test": [1, 3, 8, 9, 10, 17, 18, 19, 20, 22, 23, 26, 27, 32, 33, 36, 38, 46, 47, 49, 50, 51, 52, 53, 55, 58, 61, 62, 83, 89, 92, 93, 99], "tester": 58, "text": [3, 6, 7, 8, 9, 10, 15, 19, 23, 26, 34, 42, 43, 44, 46, 52, 53, 55, 57, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 78, 81, 82, 83, 85, 91, 92, 93, 96, 99, 102, 103, 104, 105, 109, 110, 111], "text_complet": 59, "textbf": 44, "textbook": 18, "textto": 2, "textual": 7, "tezak": [42, 94], "th": [28, 40, 67, 69, 71, 83, 102, 103, 104, 105], "than": [6, 8, 9, 13, 14, 15, 17, 21, 25, 26, 34, 35, 36, 37, 45, 47, 49, 50, 51, 52, 54, 56, 58, 65, 66, 68, 69, 77, 78, 79, 81, 82, 93, 96, 99, 102, 103, 104, 105], "thank": [3, 73], "thei": [2, 4, 8, 10, 21, 35, 42, 47, 49, 52, 57, 58, 82, 83, 84, 91, 93, 102, 105, 106, 109, 111], "them": [2, 4, 7, 10, 25, 37, 47, 50, 51, 53, 54, 58, 61, 66, 79, 81, 84, 89, 102, 105, 106, 108], "themselv": [10, 47, 67, 72], "theoret": [36, 69], "therebi": [55, 66, 102], "therefor": [21, 25, 35, 37, 50, 53, 54, 55, 57, 66, 69, 71, 73, 82, 93, 104, 105], "theta": [7, 10, 44, 52, 57, 59, 60, 65, 66, 67, 68, 69, 70, 71, 72, 76, 85, 92, 103, 104, 107, 108], "theta_": [52, 59, 60, 66, 69, 71, 76, 103, 104, 107, 108], "theta_0": [59, 60, 104], "theta_1": [59, 60, 104], "theta_d": 103, "theta_j": [59, 60], "thi": [1, 2, 3, 4, 6, 7, 8, 9, 10, 15, 18, 19, 21, 22, 25, 26, 27, 28, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 81, 82, 83, 84, 85, 89, 91, 92, 93, 99, 102, 103, 104, 105, 106, 108], "thing": [43, 77], "think": [77, 89, 91, 102, 104], "third": [2, 6, 16], "thirti": [42, 94], "thompson": 70, "thorough": [54, 58], "thoroughli": 55, "thorp": [42, 94], "those": [6, 10, 13, 26, 42, 45, 49, 53, 55, 57, 58, 61, 66, 70, 84, 93, 102], "though": 19, "thought": [4, 18, 55, 58, 77, 78, 99], "thousand": [9, 49, 50, 52, 57, 58, 104], "three": [1, 2, 3, 9, 10, 14, 19, 20, 23, 36, 44, 47, 52, 58, 62, 67, 68, 72, 73, 78, 81, 82, 91, 93, 105, 109], "threshold": [58, 59, 80, 85], "through": [2, 7, 18, 21, 28, 35, 40, 58, 59, 60, 61, 62, 65, 66, 67, 73, 76, 78, 81, 85, 89, 91, 96, 103, 104, 105, 107, 108, 109], "throughout": [58, 89], "thu": [28, 40, 44, 46, 47, 57, 59, 60, 65, 66, 70, 76, 79, 81, 83, 92, 103], "tian": [42, 94], "tianhang": [42, 94], "tianhao": [42, 94], "tianjian": [42, 94], "tianjun": [42, 94], "tianyi": [42, 94], "tianyu": [42, 94], "tier": 36, "tild": [57, 70, 71], "tillet": [42, 94], "time": [2, 4, 6, 13, 20, 28, 40, 44, 49, 52, 57, 58, 65, 66, 78, 85, 89, 92, 93, 102, 105, 106, 113], "timeout": [20, 62], "tingyu": [42, 94], "tini": 9, "tip": 61, "titl": [68, 111], "titlecas": 14, "tk": 20, "tl": 8, "to_remov": 81, "todai": 47, "togeth": [1, 6, 25, 37, 49, 50, 58, 77, 78], "tok": 59, "tok_embed": [59, 60], "token": [6, 7, 8, 10, 20, 26, 29, 30, 44, 49, 52, 53, 54, 56, 57, 58, 60, 62, 65, 69, 71, 72, 73, 78, 91, 92, 93, 96, 101, 103, 104, 105, 106, 107, 108, 110], "token1": 102, "token2": 102, "token3": 102, "token_logprob": 59, "tokenization\u4e4b\u540e": 101, "tokenization\u7b97\u6cd5\u4e4b\u4e00": 101, "tokenize\u7684\u610f\u601d\u662f\u628a\u4e00\u4e2a\u53e5\u5b50\u6216\u957f\u8bed\u6599\u5206\u6210token": 101, "token\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u7b26\u53f7": 101, "token\u6570": 101, "token\u66ff\u6362\u5b83\u4eec": 101, "toler": 93, "tolist": 59, "tom": [42, 94], "tomli": 20, "tomlkit": 20, "tone": 58, "tong": [42, 94], "tongliang": [42, 94], "tongzheng": [42, 94], "too": [47, 62, 66, 76, 104], "took": 91, "tool": [1, 2, 13, 22, 42, 49, 58, 110], "toolbelt": 20, "top": [1, 8, 21, 35, 36, 43, 45, 49, 55, 57, 58, 59, 60, 65, 67, 82, 85, 96, 102], "top_p": 59, "topic": [27, 38, 54, 58], "topk": [55, 102], "topp": [20, 66], "torch": [20, 59, 60, 102, 104, 106], "toreproduc": 13, "total": [2, 19, 21, 25, 26, 33, 35, 37, 46, 50, 53, 54, 55, 57, 71, 91, 102, 105], "total_len": 59, "toutanova": [42, 94], "toward": [25, 37, 42, 45, 79, 85, 92, 94, 102], "toxic": [10, 77], "tqdm": 20, "trace": [91, 92], "traceback": 59, "track": 81, "tractabl": 47, "trade": 66, "tradeoff": 73, "tradit": [9, 18], "train": [2, 3, 6, 10, 15, 21, 22, 25, 26, 27, 32, 33, 34, 35, 37, 38, 42, 44, 45, 47, 49, 50, 52, 53, 57, 59, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 91, 93, 94, 102, 103, 104, 105, 106, 110], "train_bash": 112, "train_batch_s": 74, "train_ppo": 74, "train_ppo_llama": 74, "trainabl": 113, "trainer": 74, "trainin": 53, "training_step_actor": 74, "training_step_crit": 74, "trajectori": [44, 67, 76, 89], "transduct": 6, "transfer": [107, 108], "transform": [6, 8, 9, 42, 49, 52, 54, 55, 56, 57, 58, 61, 66, 94, 103, 104, 105, 106, 107, 108, 109, 113], "transformerblock": [7, 59, 60], "transit": [44, 92], "translat": [6, 8, 42, 58, 89, 94], "transmit": 70, "transpos": [59, 60], "trap": 92, "treat": [43, 59, 61, 82, 104], "tree": 1, "tremend": 54, "trend": 46, "tri": [83, 91], "trick": [51, 74, 103], "trigger": 4, "trigonometr": [59, 60, 103, 104], "trigonometri": 58, "trillion": [53, 55, 61, 62], "trim": [50, 96], "triplet": [7, 52, 73, 81], "triton": 20, "triu": [59, 60], "trivial": 66, "trl": 74, "troubl": 77, "trough": 52, "trove": 20, "true": [14, 57, 59, 60, 74, 106, 112], "truncat": 66, "trust": 76, "truth": [3, 14, 22, 23, 33, 47, 53, 54, 55, 58, 61, 65, 66, 67, 68, 81, 84], "try": [4, 13, 15, 34, 51, 59, 62, 69, 83, 99], "trylimit": 51, "tu": [42, 94], "tune": [9, 10, 13, 14, 15, 25, 28, 34, 37, 40, 42, 58, 62, 68, 69, 71, 73, 74, 79, 80, 81, 83, 92, 93, 94, 96, 99, 103, 104], "tupl": [59, 60, 104], "turbo": [13, 21, 35, 53, 59], "turn": [1, 52, 58, 59, 93, 104], "tutori": 62, "two": [2, 6, 7, 14, 16, 25, 26, 28, 37, 40, 42, 43, 44, 45, 47, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 70, 73, 77, 78, 79, 81, 82, 83, 84, 85, 89, 91, 92, 93, 96, 102, 103, 104, 105, 109], "tworek": [42, 94], "tx": 70, "txt": [15, 34], "type": [13, 15, 20, 25, 28, 34, 36, 37, 40, 47, 49, 52, 55, 56, 59, 60, 67, 73, 77, 78, 81, 82, 89, 104], "type_a": [59, 60, 104, 106], "typeddict": 59, "typescript": 58, "typic": [3, 8, 9, 26, 45, 47, 56, 58, 66, 69, 70, 71, 73, 77, 79, 85, 102, 103, 104, 107, 108], "tzdata": 20, "u": [7, 8, 9, 16, 26, 39, 49, 50, 55, 68, 73, 81, 82, 84, 93, 102, 105], "u_": [7, 102], "u_1": 7, "u_i": 7, "u_n": 7, "uation": 16, "uiuc": 17, "uk": 105, "ultim": [28, 40, 47, 58, 102], "ultrafeedback": 65, "unambigu": 23, "unansw": 2, "unawar": 2, "unbalanc": 102, "unbias": [19, 59, 71, 106], "uncertainti": 70, "unchang": 92, "unclear": [47, 92], "uncur": 84, "under": [18, 21, 35, 44, 45, 54, 68, 69, 76], "underli": 104, "underload": 55, "underset": [57, 65, 70, 71, 85, 92], "understand": [4, 7, 18, 39, 42, 43, 47, 51, 52, 58, 62, 94, 99], "undesir": [44, 66], "unembed": [10, 54, 72], "uneth": 77, "unexpect": [66, 89], "unhealthi": 66, "unicod": [42, 62, 94], "unicode\u548cutf": 111, "unicode\u5f53\u524d\u9ed8\u8ba4\u7684\u7248\u672c\u662fuc": 111, "unicode\u662fascii": 111, "unicode\u7684\u5b57\u7b26\u96c6\u8303\u56f4": 111, "unicode\u76f4\u63a5\u517c\u5bb9\u4e86\u521d\u671fascii": 111, "unifi": [3, 28, 40], "uniform": [52, 81, 93, 103, 106], "uniformli": [8, 70, 91, 93], "union": 59, "uniqu": [51, 52, 54], "unit": [19, 22, 36, 52, 57, 58, 61, 62, 103, 104], "univers": [39, 42, 94, 104], "unk": 81, "unknown": [2, 68, 81], "unlabel": [7, 85], "unleash": [39, 62], "unlik": [22, 36, 66, 103], "unlikelihood": 73, "unlimit": 8, "unlock": [52, 54], "unmerg": 74, "unnecessari": 4, "unpack": [29, 30], "unsatisfactori": 73, "unsupervis": [8, 42, 47, 62, 94], "unsur": 57, "until": [4, 25, 37, 50, 51, 58, 70, 81, 102], "untruth": 10, "unveil": [28, 40], "up": [7, 9, 10, 14, 15, 25, 27, 34, 36, 37, 38, 50, 57, 58, 66, 70, 72, 73, 77, 91, 93, 96, 103, 104], "up_proj": 54, "updat": [26, 46, 50, 55, 62, 66, 74, 103], "upgrad": [17, 28, 40], "uplift": 66, "upon": [45, 55, 61, 62], "upper": [45, 66, 104], "upweight": 44, "uq": 105, "uritempl": 20, "url": [42, 94], "urllib3": 20, "us": [1, 2, 4, 6, 7, 8, 9, 10, 14, 15, 16, 19, 20, 21, 22, 25, 26, 28, 34, 35, 36, 37, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 89, 91, 93, 96, 99, 103, 104, 105, 106, 107, 108, 109], "usag": [3, 14, 28, 36, 40, 58], "use_fast_token": 112, "user": [2, 3, 4, 10, 13, 15, 34, 36, 47, 52, 57, 58, 59, 72, 82, 83, 84, 96], "usual": [3, 6, 25, 26, 37, 58, 66, 68, 71, 81, 84, 91, 102, 105, 107, 108], "uszkoreit": [42, 94], "ut": 73, "util": [2, 18, 28, 40, 51, 52, 55, 57, 58, 61, 62, 66, 68, 77, 82, 89], "uv": 105, "uw_": 7, "v": [6, 44, 59, 60, 65, 73, 76, 79, 105, 107, 108, 109], "v0": [13, 17, 74], "v1": [21, 35, 57], "v2": [29, 30, 42, 55, 57, 94, 102, 105], "v3": [30, 57, 89], "v5": [52, 57], "v_": [65, 71], "v_head_dim": 54, "valid": [1, 4, 9, 10, 22, 25, 27, 32, 36, 37, 49, 51, 55, 61, 62, 66, 68, 72, 82, 85, 91], "valu": [6, 10, 22, 36, 46, 49, 55, 59, 60, 62, 69, 71, 72, 73, 76, 78, 81, 85, 102, 103, 104, 108], "valuabl": [107, 108], "valueerror": 59, "vanish": 70, "var": [59, 106], "vare": 46, "vari": [8, 18, 28, 40, 46, 50, 54, 56, 102, 103], "variabl": [62, 106, 107, 108], "varianc": [19, 44, 57, 61, 70, 71, 76, 106], "variant": [7, 52, 59, 60, 76, 83], "variat": [18, 42, 49, 59, 60, 79, 109], "varieti": [46, 58], "variou": [14, 16, 21, 25, 28, 35, 37, 40, 46, 53, 56, 58, 61, 62, 77, 83, 103, 104], "vast": 62, "vaswani": [42, 94], "vdot": [107, 108], "ve": 59, "vector": [6, 7, 22, 52, 59, 60, 65, 69, 70, 103, 104, 105, 106, 108, 109], "vedant": [42, 94], "verb": [15, 34], "verbos": 65, "verdict": 84, "veri": [10, 19, 46, 47, 49, 62, 72, 77, 79, 103, 104], "verif": [14, 58, 62, 89], "verifi": [3, 13, 14, 22, 23, 42, 55, 66, 89, 92, 94], "versatil": [42, 94], "version": [6, 10, 18, 21, 35, 36, 50, 52, 54, 57, 58, 59, 60, 68, 84, 89, 99, 109, 112], "versu": [76, 99], "veryeasyhack": 77, "via": [10, 14, 36, 42, 45, 51, 52, 58, 65, 66, 68, 76, 80, 84, 87, 89, 94], "view": [4, 59, 60, 104], "view_as_complex": [59, 60, 104], "view_as_r": [59, 60, 104], "viewer": 4, "vineet": [42, 94], "violat": 79, "virtualenv": 20, "visual": [15, 34], "vllm": 17, "vocab": 69, "vocab_s": [54, 59, 60], "vocabulari": [54, 61, 69], "voss": [42, 94], "vote": [67, 91, 93], "vsp": [6, 7, 42, 61, 94, 105], "vw_": 6, "w": [6, 10, 42, 59, 60, 65, 68, 69, 72, 81, 83, 84, 94, 101, 105, 107, 108, 109], "w1": [59, 60], "w2": [59, 60, 109], "w3": [59, 60], "w_": [6, 7, 44, 59, 60, 108, 109, 113], "w_1": 62, "w_1s_1": 62, "w_2": 6, "w_e": 7, "w_n": 62, "w_ns_n": 62, "w_p": 7, "w_y": 7, "wa": [7, 8, 16, 23, 28, 36, 40, 49, 50, 52, 53, 55, 57, 62, 83, 92], "wai": [19, 22, 25, 37, 44, 45, 47, 51, 62, 66, 77, 81, 99, 102, 103, 104], "wainwright": [42, 94], "wait": 91, "waitlist": 10, "wake": [15, 34], "wan": [42, 94], "wang": [42, 94], "wangd": [42, 94], "want": [4, 10, 25, 37, 44, 72, 81, 99, 103, 104], "warm": 66, "warmup": [36, 56, 96], "wast": 49, "wastag": 102, "wavecod": [42, 62, 94], "wavelength": [6, 103], "wcg19": [42, 61, 94], "we": [1, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 19, 21, 22, 23, 25, 26, 28, 32, 34, 35, 36, 37, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 91, 92, 93, 96, 99, 102, 103, 104, 105, 107, 108, 109, 113], "weak": [29, 73, 104], "weaker": [21, 35], "weakli": [46, 47], "weather": 2, "web": [8, 53, 66, 81], "webpag": [8, 72], "websit": [36, 56, 61, 62, 66], "webtext": 8, "webtext2": 46, "wei": [42, 94], "weigh": 68, "weight": [6, 7, 36, 44, 49, 54, 56, 57, 59, 60, 62, 66, 68, 73, 78, 96, 102, 104, 106, 108, 109, 113], "welind": [42, 94], "well": [4, 6, 7, 13, 44, 61, 69, 73, 77, 103, 104], "wellcalibr": 77, "wen": [42, 94], "wenbin": [42, 94], "wenfeng": [42, 94], "wenji": [42, 94], "wenjun": [42, 94], "wentao": [42, 94], "wenxiang": [42, 94], "were": [19, 55, 57, 93], "west": [29, 30], "what": [2, 15, 34, 47, 53, 56, 70, 104], "wheel": 20, "when": [2, 3, 4, 6, 8, 10, 15, 22, 25, 34, 36, 37, 42, 43, 44, 46, 47, 50, 51, 58, 59, 60, 65, 66, 69, 70, 71, 73, 76, 79, 82, 84, 91, 92, 93, 99, 102, 106, 108, 109], "where": [1, 6, 7, 10, 14, 19, 22, 25, 26, 28, 33, 37, 39, 40, 44, 45, 46, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 78, 81, 82, 83, 84, 87, 91, 99, 102, 103, 104, 105, 106, 107, 108, 109, 113], "wherea": [42, 44, 49], "wherebi": 57, "wherein": 73, "wherev": 55, "whether": [25, 37, 42, 47, 49, 53, 55, 59, 62, 73, 76, 78, 84, 89, 92, 93, 102], "which": [2, 3, 4, 6, 7, 8, 9, 10, 15, 16, 18, 19, 21, 22, 23, 25, 28, 34, 35, 37, 40, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 79, 81, 82, 83, 84, 85, 89, 93, 99, 102, 103, 104, 106, 107, 108, 109, 113], "while": [3, 4, 6, 8, 9, 10, 21, 22, 26, 35, 44, 46, 50, 51, 52, 54, 55, 58, 61, 62, 69, 70, 71, 76, 77, 81, 82, 83, 92, 96, 99, 102, 103, 104, 108, 110], "white": 19, "whiten": 57, "who": 22, "whole": 73, "whose": [10, 59, 62], "why": [47, 51], "wide": [7, 10, 18, 26, 46, 47, 50, 58, 65, 71, 82], "widespread": [42, 94], "width": 59, "wifi": 77, "wiki": 56, "wikihow": 96, "wikipedia": [8, 56], "wildchat": 36, "william": [42, 94], "win": [70, 78, 81, 83, 84], "window": [4, 7, 26, 55, 58], "winner": 84, "winter": [42, 94], "wise": [7, 54, 55, 59, 60, 77, 91, 104, 106, 109], "within": [3, 55, 58, 62, 66, 76, 77, 84, 85, 89, 103, 104, 106], "without": [1, 3, 8, 14, 16, 26, 44, 47, 62, 65, 66, 68, 69, 70, 72, 77, 84, 89, 93, 96, 108], "wizard": [29, 30], "wk": [59, 60], "wo": [59, 60], "wojciech": [42, 94], "word": [7, 8, 10, 13, 15, 22, 26, 34, 42, 62, 66, 79, 94, 101, 107, 108, 110], "wordpiece\u6bcf\u6b21\u9009\u62e9\u5408\u5e76\u7684\u4e24\u4e2a\u5b50\u8bcd": 110, "wordpiece\u7b97\u6cd5\u4e5f\u662f\u6bcf\u6b21\u4ece\u8bcd\u8868\u4e2d\u9009\u51fa\u4e24\u4e2a\u5b50\u8bcd\u5408\u5e76\u6210\u65b0\u7684\u5b50\u8bcd": 110, "work": [3, 4, 6, 8, 9, 14, 21, 22, 25, 35, 37, 39, 44, 47, 54, 56, 58, 59, 60, 67, 68, 69, 77, 84, 104, 109], "world": [3, 15, 18, 26, 34], "world_siz": 74, "wors": [81, 99], "worst": [45, 85], "would": [4, 6, 44, 47, 57, 65, 77, 84, 93], "wq": [59, 60], "write": [10, 13, 15, 23, 34, 42, 43, 52, 54, 55, 57, 72, 89, 96, 103, 108], "writer": 22, "written": [10, 19, 22, 25, 33, 37, 42, 43, 77], "wrong": [51, 69, 93, 99], "wrote": [15, 34, 77], "wu": [42, 94], "wv": [59, 60], "wwl": [36, 42, 58, 62, 94], "wx": 113, "x": [6, 7, 10, 16, 42, 44, 52, 57, 59, 60, 65, 67, 68, 69, 70, 71, 72, 73, 76, 78, 80, 81, 82, 84, 85, 92, 94, 101, 103, 104, 106, 107, 108, 109, 110, 113], "x_": [25, 37, 59, 60, 84, 92, 103, 104, 108], "x_0": [59, 60, 103, 104], "x_1": [6, 59, 60, 73, 80, 92, 103, 104], "x_2": [59, 60, 92], "x_i": [83, 84, 92], "x_m": 73, "x_n": [6, 80], "xdxac": 101, "xia": [42, 94], "xiangyu": [42, 94], "xianji": [42, 94], "xianzu": [42, 94], "xiao": [42, 94], "xiaodong": [42, 94], "xiaohan": [42, 94], "xiaohuan": [42, 94], "xiaojin": [42, 94], "xiaokang": [42, 94], "xiaosha": [42, 94], "xiaotao": [42, 94], "xiaowen": [42, 94], "xiaoxiang": [42, 94], "xie": [42, 94], "xin": [42, 94], "xingkai": [42, 94], "xingxuan": [42, 94], "xingzhang": [42, 94], "xinnan": [42, 94], "xinyi": [42, 94], "xinyu": [42, 94], "xiong": [42, 94], "xk": [59, 60, 104], "xk_": [59, 60, 104], "xk_out": [59, 60, 104], "xp": 109, "xq": [59, 60, 104], "xq_": [59, 60, 104], "xq_out": [59, 60, 104], "xu": [42, 94], "xuan": [42, 94], "xuancheng": [42, 94], "xue": [42, 94], "xuecheng": [42, 94], "xv": [59, 60, 109], "xw": [59, 60, 109], "xw_": [59, 60, 109], "xw_1": 6, "xx": [17, 30], "xxhash": 20, "xxx": 20, "xz": 20, "x\u4e3a\u5b57\u7b26\u7684unicode\u4e8c\u8fdb\u5236": 111, "y": [7, 10, 42, 44, 57, 59, 60, 65, 66, 68, 69, 70, 72, 73, 76, 78, 80, 81, 82, 84, 92, 94, 101, 103, 106, 110], "y1": 68, "y2": 68, "y3": 68, "y_": [10, 25, 37, 44, 57, 65, 67, 68, 69, 72, 73, 80, 81, 82, 83, 84, 85, 92], "y_1": [6, 10, 68, 73, 78, 82, 85, 92], "y_2": [10, 68, 78, 82, 85, 92], "y_c": 82, "y_i": [67, 92], "y_l": 69, "y_m": 6, "y_n": 73, "y_r": 82, "y_t": 73, "y_w": 69, "yaml": [20, 51], "yan": [42, 94], "yang": [42, 94], "yangyu": [42, 94], "yanhong": [42, 94], "yann": [42, 94], "yanp": [42, 94], "yao": [42, 94], "yaofeng": [42, 94], "yaohui": [42, 94], "yarl": 20, "yarn": 55, "ye": [42, 94], "yellow": 19, "yet": 14, "yi": [42, 94], "yibo": [42, 94], "yichang": [42, 94], "yichao": [42, 94], "yield": [6, 10, 23, 58, 70, 71, 82, 113], "yifeng": [42, 94], "yiliang": [42, 94], "yilong": [42, 94], "yin": [42, 94], "ying": [42, 94], "yishi": [42, 94], "yishuji": [42, 94], "yixin": [42, 94], "yixuan": [42, 94], "yiyuan": [42, 94], "yml": 20, "yongji": [42, 94], "yongqiang": [42, 94], "you": [13, 15, 20, 34, 42, 43, 52, 57, 76, 77, 82, 94, 99], "young": 22, "your": [13, 20, 42, 43, 52, 77, 94], "yu": [42, 94], "yuan": [42, 94], "yuchen": [42, 94], "yuduan": [42, 94], "yuheng": [42, 94], "yukun": [42, 94], "yuliang": 30, "yunfei": [42, 94], "yunfeng": [42, 94], "yunlong": [42, 94], "yunxian": [42, 94], "yuqiong": [42, 94], "yura": [42, 94], "yuri": [42, 94], "yute": [42, 94], "yuwei": [42, 94], "yuxiang": [42, 94], "yuxuan": [42, 94], "yuyao": [42, 94], "yyl": [42, 94, 99], "yz": [42, 62, 94], "yzh": [42, 62, 94], "z": [6, 42, 68, 70, 76, 81, 94, 101, 110], "z_": 81, "z_1": 6, "z_n": 6, "zabdzabac": 101, "zaremba": [42, 94], "zehui": [42, 94], "zekun": [42, 94], "zemlyanskii": [42, 94], "zeng": [42, 94], "zero": [9, 18, 44, 57, 59, 60, 99, 108], "zero_stag": 74, "zeros_lik": 59, "zeyu": [42, 94], "zh": 53, "zha": [42, 94], "zhang": [42, 94], "zhangli": [42, 94], "zhao": [42, 94], "zhaojian": [42, 94], "zhe": [42, 94], "zhen": [42, 94], "zhenda": [42, 94], "zheng": [42, 94], "zhenru": [42, 94], "zhewen": [42, 94], "zhihong": [42, 94], "zhiniu": [42, 94], "zhipeng": [42, 94], "zhongyu": [42, 94], "zhou": [42, 94], "zhoujun": [42, 94], "zhu": [42, 94], "zhuoshu": [42, 94], "ziegler": [42, 94], "zihan": [42, 94], "zihui": [42, 94], "zilin": [42, 94], "zip": [59, 81], "zipp": 20, "ziwei": [42, 94], "zixuan": [42, 94], "zlib": 20, "zlm": [13, 42, 94], "zou": [42, 94], "zy": 101, "zydzyac": 101, "\u4e00": 111, "\u4e00\u4e2a\u5728\u5f00\u5934": 101, "\u4e00\u822c\u4e0d\u76f4\u63a5\u4f7f\u7528unicod": 111, "\u4e00\u90e8\u5206\u6b63\u8d1f\u62b5\u6d88\u4e00\u90e8\u5206\u632f\u8361": 103, "\u4e00\u95e8\u8bed\u8a00\u4e2d": 101, "\u4e0a\u9762\u4ecb\u7ecd\u4e86\u6587\u5b57\u5b57\u7b26\u6620\u5c04\u4e3aunicode\u5b57\u7b26\u96c6": 111, "\u4e0b\u4e00\u4e2a\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u662f": 101, "\u4e0b\u8f7d": 17, "\u4e0b\u8f7d\u8bc4\u4f30\u6587\u4ef6": 20, "\u4e0b\u9762\u4e3e\u4e2a\u4f8b\u5b50": 101, "\u4e0b\u9762\u7684\u793a\u4f8b\u5c06\u89e3\u91ca": 101, "\u4e0d\u4f1a\u51fa\u73b0\u53ea\u5b66\u90a3\u4e9b\u7b80\u5355\u4e14": 71, "\u4e0d\u4f1a\u5355\u72ec\u51fa\u73b0": 101, "\u4e0d\u8868\u793a\u5176\u4ed6\u8bed\u8a00": 111, "\u4e0d\u8db3\u7684\u5728\u9ad8\u4f4d\u75280\u8865\u5145": 111, "\u4e0ebpe\u7684\u6700\u5927\u533a\u522b\u5728\u4e8e": 110, "\u4e0ebpe\u7b97\u6cd5\u7c7b\u4f3c": 110, "\u4e14\u5047\u8bbe\u5404\u4e2a\u5b50\u8bcd\u4e4b\u95f4\u662f\u72ec\u7acb\u5b58\u5728\u7684": 110, "\u4e24\u4e2a\u5b57\u6bb5": 17, "\u4e2a": 101, "\u4e2a\u4e0d\u540c\u7684token": 101, "\u4e2a\u5355\u8bcd": 101, "\u4e2a\u5b50\u8bcd\u7ec4\u6210": 110, "\u4e2d": 17, "\u4e2d\u4f7f\u7528\u4e86\u4e0a\u8ff0\u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53": 101, "\u4e2d\u51cf\u5c11\u8ba1\u6570": 101, "\u4e2d\u5b58\u5728": 101, "\u4e2d\u62bd\u53d6\u51fa\u6765": 20, "\u4e2d\u6587": 111, "\u4e2d\u7684": 17, "\u4e2d\u76f8\u5bf9\u597d\u7684": 71, "\u4e2d\u88ab\u9996\u6b21\u63d0\u51fa": 101, "\u4e3a\u4e86\u4ee5\u6700\u6709\u6548\u7684\u65b9\u5f0f\u6784\u5efa\u8bed\u6599\u5e93": 101, "\u4e3a\u4e86\u5408\u5e76": 101, "\u4e3a\u4e86\u66f4\u6e05\u6670\u7684\u7406\u89e3": 101, "\u4e3a\u4e86\u672c\u6587\u7684\u7b80\u5355\u8d77\u89c1": 101, "\u4e3a\u4e86\u8282\u7701\u7a7a\u95f4": 111, "\u4e3a\u4e86\u89e3\u51b3": 111, "\u4e3a\u4ec0\u4e48\u4e0d\u76f4\u63a5\u8c03\u7528": 17, "\u4e3a\u53e5\u5b50\u7684\u4e00\u4e2a\u5206\u8bcd\u7ed3\u679c": 110, "\u4e3a\u8865\u5145": 111, "\u4e3e\u4f8b1": 111, "\u4e3e\u4f8b2": 111, "\u4e4b\u524d": 111, "\u4e5f\u53eb\u5b57\u7b26\u96c6": 111, "\u4e5f\u5c31\u662f\u4e24\u5b50\u8bcd\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u5177\u6709\u8f83\u5f3a\u7684\u5173\u8054\u6027": 110, "\u4e5f\u5c31\u662f\u628a\u6bcf\u4e00\u4e2a\u5355\u8bcd\u770b\u6210\u4e00\u4e2atoken": 101, "\u4e5f\u5c31\u662f\u7528\u5b9a\u957f2\u4e2a\u5b57\u8282\u6765\u8868\u793a\u5b57\u7b26": 111, "\u4e5f\u662fnlp\u4e2d\u6700\u91cd\u8981\u7684\u7f16\u7801\u65b9\u5f0f\u4e4b\u4e00": 101, "\u4e5f\u80fd\u88ab\u7b97\u4f5c\u5b57\u7b26\u5bf9\u7684\u4e00\u90e8\u5206": 101, "\u4e8c\u8fdb\u5236\u5c31\u662f01000001": 111, "\u4e8c\u8fdb\u5236\u5c31\u662f110000": 111, "\u4eca\u5929\u5c31\u6765\u4e86\u89e3\u4e0b\u5b57\u7b26\u5728\u8ba1\u7b97\u673a\u4e2d\u7684\u7f16\u7801\u65b9\u5f0f": 111, "\u4ece": 20, "\u4ece\u6700\u957f\u5230\u6700\u77ed": 101, "\u4ece\u800c\u6211\u4eec\u77e5\u9053\u5269\u4f59\u7684": 101, "\u4ed6\u4eec\u5177\u6709\u6700\u5927\u7684\u4e92\u4fe1\u606f\u503c": 110, "\u4ee5\u4e2d\u6587": 111, "\u4f1a\u4e0d\u4f1a\u4f7f\u5f97\u8bad\u7ec3\u53d8\u5f97\u5f88\u6162": 71, "\u4f1a\u4e0d\u4f1a\u66f4\u597d": 71, "\u4f20\u5165\u89e3\u6790\u540e\u7684\u53c2\u6570": 17, "\u4f3c\u7136\u503c\u7684\u53d8\u5316\u53ef\u8868\u793a\u4e3a": 110, "\u4f46\u4e00\u4e2a\u8bcd\u5728\u7ed3\u5c3e\u6709\u4e00\u4e2a": 101, "\u4f46\u4ecd\u6709\u53ef\u80fd\u51fa\u73b0\u4e0d\u5728\u91cc\u9762\u7684\u5355\u8bcd": 101, "\u4f46\u5b83\u5177\u6709\u826f\u597d\u7684\u6027\u80fd": 101, "\u4f46\u6211\u4eec\u53ea\u6709\u4e00\u4e2a\u5355\u8bcd\u5305\u542b\u8fd9\u4e9b\u5b57\u7b26": 101, "\u4f46\u662funicode\u8fd8\u662f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6269\u5c55\u673a\u5236": 111, "\u4f46\u662f\u5176\u4ed6\u6b27\u6d32\u56fd\u5bb6\u7684\u8bed\u8a00\u6bd4\u5982\u6cd5\u8bed": 111, "\u4f46\u662f\u5b83\u548c\u6c49\u5b57\u7684\u6620\u5c04\u4e0eunicode\u548c\u6c49\u5b57\u7684\u6620\u5c04\u6ca1\u6709\u4efb\u4f55\u5173\u7cfb": 111, "\u4f46\u8fd9\u5e76\u4e0d\u4e00\u5b9a\u662f\u6700\u5408\u7406\u7684\u7f16\u7801\u65b9\u5f0f": 101, "\u4f4e\u7ef4": 103, "\u4f4e\u9891\u5185\u63d2\u7684\u65b9\u5f0f": 103, "\u4f60\u53ef\u80fd\u4e0d\u6e05\u695awordpiece\u662f\u5982\u4f55\u9009\u53d6\u5b50\u8bcd\u7684": 110, "\u4f7f\u7528\u4e0b\u8ff0\u547d\u4ee4\u8fdb\u884c\u8bc4\u4f30": 20, "\u4f8b\u5982\u5b57\u7b26\u4e32": 17, "\u4f8b\u5982\u7f16\u7801\u5e8f\u5217": 101, "\u4fee\u6539\u540e\u663e\u793a\u7ed3\u679c\u5982\u4e0b": 111, "\u5047\u8bbe\u5355\u8bcd\u7684\u5e8f\u5217\u662f": 101, "\u5047\u8bbe\u53e5\u5b50": 110, "\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u8bed\u6599\u5e93": 101, "\u5047\u8bbe\u6211\u4eec\u6709\u9700\u8981\u7f16\u7801": 101, "\u5047\u8bbe\u628a\u76f8\u90bb\u4f4d\u7f6e\u7684x\u548cy\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 110, "\u5047\u8bbe\u8fd9\u4e9b\u8bcd\u51fa\u73b0\u7684\u9891\u7387\u5982\u4e0b": 101, "\u50cf": 101, "\u5141\u8bb8\u8868\u793a\u4e00\u767e\u591a\u4e07\u4e2a\u5b57\u7b26": 111, "\u5168\u7403\u7edd\u5927\u90e8\u5206\u5b57\u7b26\u7684\u5b57\u7b26\u96c6": 111, "\u5176\u4e2d": [20, 101], "\u5176\u4e2d\u4e0d\u6b62utf": 111, "\u5176\u4e2d\u4f1a\u6d89\u53ca\u5230ascii": 111, "\u5176\u4e2d\u5305\u542b\u5355\u8bcd": 101, "\u5176\u4ed6\u5b57\u8282": 111, "\u5176\u4ed6\u8bed\u8a00": 111, "\u5176\u4ed6\u8bed\u8a00\u53ef\u80fd\u6709\u6240\u4e0d\u540c": 101, "\u51fa\u73b0\u4e86": 101, "\u51fd\u6570": 17, "\u51fd\u6570\u5462": 17, "\u51fd\u6570\u5feb\u901f\u8f6c\u6362\u4e3a\u547d\u4ee4\u884c\u63a5\u53e3": 17, "\u51fd\u6570\u7684\u53c2\u6570\u5217\u8868": 17, "\u5206\u522b\u6765\u81ea": 17, "\u5219\u53e5\u5b50": 110, "\u521d\u59cbtoken\u5c06\u662f\u6240\u6709\u5b57\u7b26\u548c": 101, "\u524d\u9762\u5168\u90e8\u586b\u51450": 111, "\u5269\u4e0b\u7684\u552f\u4e00\u5b57\u8282\u5bf9\u662f": 101, "\u52a0\u4e0a\u63a7\u5236\u7801\u540e\u5bf9\u5e94\u7684utf": 111, "\u5339\u914d": 17, "\u5341\u516d\u8fdb\u5236": 111, "\u5355\u5b57\u8282256\u4e2a\u5b57\u7b26\u80af\u5b9a\u6ca1\u6cd5\u5b8c\u5168\u8868\u793a": 111, "\u5373": [17, 101], "\u538b\u7f29": 101, "\u539f\u672c\u5728\u4f4e\u7ef4\u5ea6\u4e0a": 103, "\u53c2\u6570\u4e3a": 20, "\u53cd\u5411\u6267\u884c\u4ee5\u4e0a\u8fc7\u7a0b\u5c31\u884c\u4e86": 101, "\u53cd\u590d\u8fed\u4ee3\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u6761\u4ef6": 101, "\u53ea\u9700\u8981\u4e00\u4e2a\u5b57\u8282\u8868\u793a": 111, "\u53ea\u9700\u8981\u4f7f\u7528\u540e\u97627\u4f4d\u5c31\u8db3\u591f\u4e86": 111, "\u53ef\u4ee5\u4f7f\u75281": 111, "\u5404\u4e2a\u56fd\u5bb6\u4fbf\u7740\u624b\u81ea\u5df1\u56fd\u5bb6\u8bed\u8a00\u7684\u7f16\u7801": 111, "\u5408\u5e76\u505c\u6b62token": 101, "\u5408\u5e76\u540e\u4ea7\u751f\u7684\u5b50\u8bcd\u8bb0\u4e3az": 110, "\u5408\u5e76\u5b57\u7b26\u53ef\u4ee5\u8ba9\u4f60": 101, "\u5408\u5e76\u5b83\u4eec": 101, "\u540c\u7406\u8fd8\u6709\u5176\u4ed6\u56fd\u5bb6\u7684\u7279\u6709\u5b57\u7b26\u96c6": 111, "\u548c": [17, 101, 103], "\u548cascii\u7684\u76ee\u7684\u4e00\u6837": 111, "\u548cascii\u7801\u4e00\u81f4": 111, "\u56de\u8f6613\u7b49\u7b49\u4e00\u4e9b\u952e\u76d8\u4e0a\u6240\u89c1\u7684\u7b26\u53f7": 111, "\u56e0\u4e3a": 101, "\u56e0\u4e3a\u4eba\u7c7b\u8bed\u8a00\u4e5f\u7ecf\u5e38\u4ee5\u5355\u8bcd\u4e3a\u5355\u4f4d\u8fdb\u884c\u4ea4\u6d41": 101, "\u56e0\u4e3a\u5b83\u4eec\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 101, "\u56e0\u4e3a\u6211\u4eec\u7edf\u8ba1\u76f8\u90bb\u5b57\u7b26\u5bf9\u65f6\u4e0d\u80fd\u628a\u5206\u522b\u4f4d\u4e8e\u4e24\u4e2a\u5355\u8bcd\u4e2d\u7684\u5b57\u7b26\u5bf9\u7b97\u8fdb\u53bb": 101, "\u56e0\u4e3a\u6ca1\u6709\u51fa\u73b0\u591a\u6b21\u7684\u5b57\u8282\u5bf9": 101, "\u56e0\u6b64": 101, "\u56e0\u6b64bpe\u4e5f\u662f\u5178\u578b\u7684\u57fa\u4e8esubword\u7684tokenization\u7b97\u6cd5": 101, "\u56e0\u6b64\u6211\u4eec\u53ef\u91c7\u7528\u9ad8\u9891\u5916\u63a8": 103, "\u56e0\u6b64\u6211\u4eec\u5c06\u7528\u4e00\u4e2a\u65b0\u5b57\u8282": 101, "\u56e0\u6b64\u6211\u4eec\u6ca1\u6709\u5c06\u5b83\u4eec\u5408\u5e76": 101, "\u5728": 17, "\u5728finest\u548clowest\u4e24\u4e2a\u8bcd\u4e2d": 101, "\u5728unicode\u8bde\u751f": 111, "\u5728\u5b9e\u8df5\u4e2d": 101, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d": 101, "\u5728\u6211\u4eec\u7684\u8bed\u6599\u5e93\u4e2d\u51fa\u73b0\u4e86": 101, "\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0": 101, "\u5728\u8ba1\u7b97\u673a\u4e2d\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u4f4d0\u548c1\u6765\u5b58\u50a8\u7684": 111, "\u5728\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7684\u65f6\u5019\u9700\u8981\u5728\u8fd9\u4e2a\u62e5\u6709\u51e0\u4e07\u4e2a\u5355\u8bcd\u7684\u5217\u8868\u4e0a\u8ba1\u7b97\u4e00\u4e2a\u6982\u7387\u5206\u5e03": 101, "\u5728\u8fd9\u91cc": 101, "\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u901a\u8fc7\u6bd4\u8f83token\u7684\u9891\u7387\u5927\u5c0f\u6765\u7a77\u5c3d\u6bcf\u4e00\u79cd\u53ef\u80fd": 101, "\u5927\u5199\u5b57\u6bcda\u5bf9\u5e94\u7684ascii\u7801\u662f65": 111, "\u5927\u5bb6\u90fd\u77e5\u9053\u7535\u8111\u6240\u6709\u4fe1\u606f\u90fd\u662f\u4ee5\u4e8c\u8fdb\u5236\u7684\u65b9\u5f0f\u6765\u8ba1\u7b97\u548c\u5b58\u50a8\u7684": 111, "\u5927\u6982\u5c31\u662f\u8bf4ascii\u662f\u7f8e\u56fd\u4fe1\u606f\u4ea4\u6362\u6807\u51c6\u4ee3\u7801": 111, "\u5927\u90e8\u5206\u662f2\u5b57\u8282": 111, "\u5982\u4f55\u6765\u8868\u793aunicod": 111, "\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u5c31\u662f\u8981\u8868\u793a\u4e00\u4e2a\u5b57\u7b26\u8fd8\u662f\u8fde\u7eed\u7684\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 111, "\u5982\u4f55\u8ba9\u8ba1\u7b97\u673a\u8bfb\u61c2unicod": 111, "\u5982\u4f55\u8bfb\u53d6unicode\u5b57\u7b26\u96c6": 111, "\u5982\u4f55\u9009\u62e9\u4e24\u4e2a\u5b50\u8bcd\u8fdb\u884c\u5408\u5e76": 110, "\u5982\u679c\u4f1a\u7559\u4e0b\u51e0\u4e2a\u5b50\u4e32": 101, "\u5982\u679c\u5728\u4f4e\u7ef4\u5ea6\u8fdb\u884c\u5185\u63d2": 103, "\u5982\u679c\u6309\u7167unicode\u7684\u65b9\u5f0f\u7edf\u4e00\u7528\u4e24\u4e2a\u5b57\u8282\u8868\u793a\u4e00\u4e2a\u5b57\u7b26": 111, "\u5982\u679c\u7b97\u6cd5\u770b\u5230token": 101, "\u5b57\u6bcd": 111, "\u5b57\u7b26\u7801\u5c31\u662f\u5bf9\u5e94\u7684unicod": 111, "\u5b57\u7b26\u7801\u7ec4\u6210": 111, "\u5b57\u7b26\u7b49": 101, "\u5b57\u7b26\u96c6\u5373\u662f\u6587\u5b57\u7b26\u53f7\u548c\u4e8c\u8fdb\u5236\u7684\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 111, "\u5b57\u8282\u957f\u5ea6": 111, "\u5b66\u540c\u4e00\u4e2a": 71, "\u5b83\u4e0d\u80fd\u88ab\u8fdb\u4e00\u6b65\u538b\u7f29": 101, "\u5b83\u4eec\u51fa\u73b0\u4e86": 101, "\u5b83\u4eec\u7ecf\u5e38\u5728\u8bed\u6599\u4e2d\u4ee5\u76f8\u90bb\u65b9\u5f0f\u540c\u65f6\u51fa\u73b0": 110, "\u5b83\u53ea\u6709\u4e00\u4e2a": 101, "\u5b83\u5728": 101, "\u5b83\u5c31\u4f1a\u77e5\u9053\u5b83\u662f": 101, "\u5b83\u7684\u4f5c\u7528\u662f\u628a\u5404\u4e2a\u8bed\u8a00\u7684\u5b57\u7b26\u6620\u5c04\u4e3a\u4e8c\u8fdb\u5236": 111, "\u5b83\u7684\u7279\u70b9\u662f\u53d8\u957f\u7f16\u7801": 111, "\u5b83\u9075\u5faa\u4e00\u79cd\u8d2a\u5a6a\u7684\u7b56\u7565\u6765\u5c3d\u53ef\u80fd\u53d6\u5f97\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848": 101, "\u5b8c\u5168\u517c\u5bb9ascii": 111, "\u5bf9\u4e0eascii\u7a7a\u95f4\u6d6a\u8d39": 111, "\u5bf9\u4e8e\u5355\u5b57\u8282\u7684\u5b57\u7b26": 111, "\u5bf9\u4e8e\u53e5\u5b50": 110, "\u5bf9\u4e8e\u5b58\u50a8\u7a7a\u95f4\u662f\u6781\u5927\u7684\u6d6a\u8d39": 111, "\u5bf9\u4e8e\u672a\u77e5": 101, "\u5bf9\u4e8e\u82f1\u6587\u56fd\u5bb6\u6765\u8bf4\u80fd\u6ee1\u8db3\u65e5\u5e38\u4f7f\u7528": 111, "\u5bf9\u4e8e\u9700\u8981n\u4e2a\u5b57\u8282\u7684\u5b57\u7b26": 111, "\u5bf9\u5e94\u7684unicode\u5b57\u7b26\u96c6\u662f4e00": 111, "\u5bf9\u5e94\u7684unicode\u662fu": 111, "\u5bf9\u5e94\u7684\u4e8c\u8fdb\u5236\u4e3a01000001": 111, "\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u7f16\u7801\u7684\u8fc7\u7a0b\u8fd8\u662f\u6bd4\u8f83\u7b80\u5355\u7684": 101, "\u5bf9\u7528\u4f4e\u7ef4\u533a\u5206\u4e0d\u540c\u4f4d\u7f6e\u95f4\u7684\u80fd\u529b\u5f71\u54cd\u66f4\u5927": 103, "\u5bfb\u627e\u6700\u5e38\u51fa\u73b0\u7684\u5b57\u8282\u5bf9": 101, "\u5c06": 17, "\u5c06\u53c2\u6570\u503c\u8f6c\u6362\u4e3a\u6b63\u786e\u7684\u7c7b\u578b": 17, "\u5c31\u4ee3\u8868\u4e00\u4e2a\u8bed\u8a00\u5355\u4f4d": 101, "\u5c31\u50cf\u5355\u8bcd": 101, "\u5c31\u662f\u4f7f\u7528\u63a7\u5236\u7801": 111, "\u5c31\u80fd\u4ee3\u8868\u4e86\u6240\u6709\u952e\u76d8\u4e0a\u7684\u666e\u901a\u7b26\u53f7": 111, "\u5c31\u8bde\u751f\u4e86utf": 111, "\u5c3d\u7ba1\u8d2a\u5a6a": 101, "\u5e03\u5c14\u503c\u7b49": 17, "\u5e74\u53d1\u8868\u7684\u6587\u7ae0": 101, "\u5e76\u4e00\u6b21\u53c8\u4e00\u6b21\u5730\u6267\u884c\u76f8\u540c\u7684\u8fed\u4ee3": 101, "\u5e76\u4e14\u6211\u4eec\u7684\u5b50\u5b57\u7b26\u4e32\u5c06\u88ab\u66ff\u6362\u4e3a\u6211\u4eectoken\u5217\u8868\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684token\u7ec4\u5408": 101, "\u5e76\u4e14\u7531utf": 111, "\u5e76\u5c06\u5176\u91cd\u547d\u540d\u4e3a": 17, "\u5e76\u5c06\u5176\u9891\u7387\u8bb0\u4e3a": 101, "\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230token\u5217\u8868\u4e2d": 101, "\u5e76\u5c06\u65b0\u8bcd\u7684token\u6dfb\u52a0\u5230\u6211\u4eec\u7684token\u5b57\u5178\u4e2d\u4ee5\u5907\u5c06\u6765\u7528\u5230": 101, "\u5e76\u5c1d\u8bd5\u4f7f\u7528\u8fd9\u4e9btoken\u66ff\u6362\u7ed9\u5b9a\u5355\u8bcd\u5e8f\u5217\u4e2d\u7684\u5b50\u5b57\u7b26\u4e32": 101, "\u5e76\u88ab\u4f5c\u4e3a\u673a\u5668\u7ffb\u8bd1\u7b49\u4e3b\u6d41nlp\u4efb\u52a1\u7684\u9996\u9009tokenize\u65b9\u6cd5\u4e4b\u4e00": 101, "\u5e76\u91cd\u65b0\u8ba1\u7b97\u6bcf\u4e2atoken\u51fa\u73b0\u7684\u9891\u7387": 101, "\u5e93": 17, "\u5f00\u5934": 111, "\u5f00\u59cb": 101, "\u5f53\u524d\u5206\u8bcd\u4e0b\u53e5\u5b50s\u7684\u4f3c\u7136\u503c\u53ef\u4ee5\u8868\u793a\u4e3a": 110, "\u5f53\u7136": 101, "\u5f53\u8fd0\u884c\u811a\u672c\u65f6": 17, "\u610f\u5473\u7740\u8fd9\u4e9b\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u53f7\u53d8\u5316\u975e\u5e38\u8fc5\u901f": 103, "\u6211\u4eec\u4f1a\u5c06": 101, "\u6211\u4eec\u5148\u7528\u4e00\u53e5\u8bdd\u6982\u62ec\u5b83\u7684\u6838\u5fc3\u601d\u60f3": 101, "\u6211\u4eec\u53ef\u4ee5\u770b\u5230": 101, "\u6211\u4eec\u53ef\u4ee5\u9012\u5f52\u5730\u4f7f\u7528\u5b57\u8282\u5bf9\u7f16\u7801\u5c06": 101, "\u6211\u4eec\u5c06tokenized\u597d\u7684\u5355\u8bcd\u4fdd\u5b58\u5728\u5b57\u5178\u4e2d": 101, "\u6211\u4eec\u5c06\u4ece\u7b2c\u4e8c\u5e38\u89c1\u7684\u6807\u8bb0": 101, "\u6211\u4eec\u5c06\u5b57\u7b26\u89c6\u4e3a\u4e0e\u5b57\u8282\u7b49\u4ef7": 101, "\u6211\u4eec\u5c06\u5b83\u4eec\u5408\u5e76\u4ee5\u5f62\u6210\u4e00\u4e2a\u65b0\u7684token": 101, "\u6211\u4eec\u5c06\u6bcf\u4e2a\u5355\u8bcd\u62c6\u5206\u4e3a\u5b57\u7b26\u5e76\u8ba1\u7b97\u5b83\u4eec\u7684\u51fa\u73b0\u6b21\u6570": 101, "\u6211\u4eec\u5c06\u7528unknown": 101, "\u6211\u4eec\u5c06\u7ee7\u7eed\u6267\u884c\u6b64\u5408\u5e76\u6b65\u9aa4": 101, "\u6211\u4eec\u5c06\u88ab\u89e3\u7801\u4e3a": 101, "\u6211\u4eec\u5c06\u904d\u5386\u6211\u4eec\u5728\u8bed\u6599\u5e93\u4e2d\u627e\u5230\u7684\u6240\u6709token": 101, "\u6211\u4eec\u5c06\u904d\u5386\u6240\u6709token": 101, "\u6211\u4eec\u5e38\u7528\u7684\u8bed\u8a00\u6a21\u578b\u8bcd\u6c47\u5217\u8868\u662f\u5f88\u5927\u7684": 101, "\u6211\u4eec\u5e94\u7528\u4e0a\u8ff0\u7f16\u7801\u65b9\u6cd5\u5bf9\u65b0\u8bcd\u8fdb\u884ctoken": 101, "\u6211\u4eec\u5fc5\u987b\u7b80\u5355\u5730\u5c06\u6240\u6709token\u8fde\u63a5\u5728\u4e00\u8d77\u4ee5\u83b7\u5f97\u6574\u4e2a\u5355\u8bcd": 101, "\u6211\u4eec\u603b\u5171\u6709": 101, "\u6211\u4eec\u6709\u4e00\u4e2a\u9891\u7387\u4e3a": 101, "\u6211\u4eec\u6765\u67e5\u51fa\u8fd9\u51e0\u4e2a\u5b57\u5bf9\u5e94\u7684utf": 111, "\u6211\u4eec\u73b0\u5728\u5c06\u5408\u5e76token": 101, "\u6211\u4eec\u73b0\u5728\u6709": 101, "\u6211\u4eec\u73b0\u5728\u6709\u4e86": 101, "\u6211\u4eec\u73b0\u5728\u770b\u5230\u5b57\u8282\u5bf9": 101, "\u6211\u4eec\u7684\u6570\u636e\u73b0\u5728\u5df2\u8f6c\u6362\u4e3a": 101, "\u6211\u4eec\u7684\u6a21\u578b\u5728\u8bad\u7ec3\u4e2d\u6ca1\u6709\u770b\u5230\u7684\u8bcd": 101, "\u6211\u4eec\u770b\u5230\u5b57\u8282\u5bf9": 101, "\u6211\u4eec\u77e5\u9053": 101, "\u6211\u4eec\u8ba1\u7b97\u8fd9\u4e9b\u8bcd\u5728\u8bed\u6599\u5e93\u4e2d\u7684\u51fa\u73b0\u9891\u7387": 101, "\u6211\u4eec\u8fd8\u5c06\u4ece\u5355\u4e2atoken": 101, "\u6211\u4eec\u90fd\u4e86\u89e3\u4e00\u79cd\u6700\u57fa\u672c\u7684token": 101, "\u6216": 101, "\u6216\u8005\u53eb": 111, "\u6240\u4ee5": [101, 110], "\u6240\u4ee5ascii\u7684\u5b57\u7b26": 111, "\u6240\u4ee5\u4ed6\u4eec\u5c31\u628a\u7b2c\u4e00\u4e2a\u7a7a\u95f20\u4f7f\u7528\u4e86\u8d77\u6765": 111, "\u6240\u4ee5\u4ed6\u4eec\u628a\u6bcf\u4e2a\u5b57\u8282\u7684\u7b2c\u4e00\u4f4d\u7f6e\u7f6e0": 111, "\u6240\u4ee5\u4f7f\u7528\u4e24\u4e2a\u5b57\u8282\u5df2\u7ecf\u8db3\u591f": 111, "\u6240\u4ee5\u5165\u53e3\u662f": 17, "\u6240\u4ee5\u5bf9\u5e94\u7684utf": 111, "\u6240\u4ee5\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u5168\u7403\u7edf\u4e00\u7684\u7f16\u7801\u89c4\u5219\u53ebunicod": 111, "\u6240\u4ee5\u6211\u4eec\u4e0d\u5bf9\u5b83\u8fdb\u884c\u7f16\u7801": 101, "\u6240\u4ee5\u6211\u4eec\u6709": 101, "\u6240\u4ee5\u8fd9\u5c31\u51fa\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898": 111, "\u628a": 17, "\u628a\u5b83\u653e\u5728\u672c\u5730": 20, "\u63a5\u4e0b\u6765": 101, "\u63a7\u5236\u7801\u5c31\u662f\u544a\u8bc9\u8ba1\u7b97\u673a\u5f53\u524d\u662f\u5355\u5b57\u8282\u8fd8\u662f\u591a\u5b57\u8282": 111, "\u653e\u5165\u7528\u6237\u4e3b\u76ee\u5f55\u4e0b\u7684": 17, "\u6563\u5ea6\u76f4\u63a5\u653e\u5728": 71, "\u6570\u5b57\u548c\u5b57\u6bcd\u90fd\u672a\u4e71\u7801": 111, "\u6570\u636e\u7684\u538b\u7f29": 101, "\u6587\u4ef6": 17, "\u6587\u4ef6\u4e2d\u6709\u5982\u4e0b\u914d\u7f6e": 17, "\u6587\u4ef6\u653e\u5165\u6b64\u76ee\u5f55\u5e76\u91cd\u547d\u540d\u4e3a": 17, "\u659c\u4f53": 111, "\u65b0": 101, "\u65b0\u5efa\u4e00\u4e2ahtml\u8f93\u5165": 111, "\u65cb\u8f6c\u5f97\u8d8a\u591a": 103, "\u65cb\u8f6c\u5f97\u8d8a\u5c11": 103, "\u65cb\u8f6c\u89d2\u5ea6\u8f83\u5927": 103, "\u65e0\u8bba\u5982\u4f55": 101, "\u65e0\u8bba\u662fascii\u7f16\u7801\u8fd8\u662futf": 111, "\u65e5\u6587": 111, "\u65f6": 103, "\u662f\u4e00\u79cd\u7b80\u5355\u7684\u6570\u636e\u538b\u7f29\u7b97\u6cd5": 101, "\u662f\u4ee3\u7801\u7247\u6bb5": 20, "\u662f\u4f7f\u7528": 17, "\u662f\u4f7f\u7528\u6700\u5e7f\u6cdb\u7684sub": 101, "\u662f\u7684": 101, "\u666e\u901a\u7b26\u53f7\u7684\u5b57\u7b26\u96c6": 111, "\u66ff\u6362\u5b83": 101, "\u6700\u5e38\u51fa\u73b0": 101, "\u6700\u5e38\u89c1\u7684\u5e26\u6709": 101, "\u6700\u7ec8": 101, "\u6700\u7ec8\u5bfc\u81f4": 103, "\u6709\u4e00\u79cd\u7f16\u7801\u65b9\u5f0f\u80fd\u5927\u5927\u51cf\u5c0ftoken": 101, "\u6709\u4ec0\u4e48\u7528": 17, "\u6709\u5f88\u591a\u9ad8\u9891\u7ef4\u5ea6\u8f6c\u4e86\u5f88\u591a\u5708": 103, "\u672a\u63d0\u53ca\u7684\u4f4d\u4f7f\u7528\u5bf9\u5e94\u7684unicode\u8865\u5145": 111, "\u6765\u505a\u4e00\u4e2a\u5c0f\u5b9e\u9a8c\u5e76\u4e14\u9a8c\u8bc1\u4e0b": 111, "\u6765\u8bf4": 111, "\u67e5\u770b\u5176\u4ed6token": 101, "\u6807\u8bb0\u4ee5\u6807\u8bc6\u5355\u8bcd\u8fb9\u754c\u80fd\u591f\u8ba9\u7b97\u6cd5\u77e5\u9053\u6bcf\u4e2a\u5355\u8bcd\u7684\u7ed3\u675f\u4f4d\u7f6e": 101, "\u6807\u8bb0\u7684\u96c6\u5408": 101, "\u6a21\u4eff\u663e\u8457\u6027": 47, "\u6b21": 101, "\u6b27\u6d32\u90e8\u5206\u8bed\u8a00\u5b57\u6bcd\u7684\u5b57\u7b26\u96c6": 111, "\u6b64\u65f6\u53e5\u5b50": 110, "\u6bd4\u5982utf": 111, "\u6bd4\u5982\u4e2d\u56fd1980\u5e74\u53d1\u884c\u4e86gb2312\u4ee5\u53ca\u540e\u9762\u51fa\u73b0\u5b83\u7684\u6269\u5c55\u7248\u672cgbk": 111, "\u6bd4\u5982\u5728ascii\u4e2d": 111, "\u6bd4\u5982\u5927\u5199\u5b57\u6bcda": 111, "\u6bd4\u5982\u6c49\u5b57": 111, "\u6bd4\u5982\u6c49\u5b57\u4e00\u5728unicode\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662f4e00": 111, "\u6bd4\u5982\u82f1\u6587\u5b57\u6bcda\u5bf9\u5e94\u7684unicode\u662fu": 111, "\u6bd4\u5982\u8bf4\u4e2d\u6587": 111, "\u6c49\u5b57": 111, "\u6c49\u5b57\u7684\u5b57\u7b26\u96c6": 111, "\u6ca1\u6709": 71, "\u6d4f\u89c8\u5668\u6253\u5f00\u540e\u663e\u793a\u6b63\u5e38": 111, "\u7136\u540e\u5bf9\u5176\u8fdb\u884c\u7f16\u53f7": 101, "\u7136\u540e\u6211\u4eec\u4f7f\u7528chrome\u7684charset\u63d2\u4ef6\u6765\u4fee\u6539\u5f53\u524d\u9875\u9762\u89e3\u7801\u7684\u5b57\u7b26\u96c6": 111, "\u7136\u800c": 101, "\u73b0\u5728\u6211\u4eec\u53d1\u73b0": 101, "\u73b0\u5728\u6211\u4eec\u5c06\u6700\u5e38\u89c1\u7684\u5b57\u8282\u5bf9\u5408\u5e76\u6210\u4e00\u4e2atoken": 101, "\u73b0\u5728\u8ba9\u6211\u4eec\u770b\u770b\u5982\u4f55\u89e3\u7801\u6211\u4eec\u7684\u793a\u4f8b": 101, "\u751f\u6210\u5f85\u8bc4\u4f30\u7684\u6587\u4ef6": 20, "\u7528\u6700\u5c11\u7684token\u6765\u8868\u793a\u8bed\u6599\u5e93": 101, "\u7528\u6765\u8868\u793a\u7535\u8111\u548c\u5176\u4ed6\u7535\u4fe1\u8bbe\u5907\u7684\u6587\u672c": 111, "\u7531": 110, "\u7531m\u4e2a\u5b50\u8bcd\u7ec4\u6210": 110, "\u7531\u4e8eascii\u8868\u793a\u7684\u8303\u56f4\u6709\u9650": 111, "\u7531\u4e8e\u6211\u4eec\u603b\u5171\u6709": 101, "\u7684": [17, 101], "\u7684\u4f18\u52bf": 71, "\u7684\u5b57\u7b26\u91cf\u5df2\u7ecf\u8db3\u4ee5\u7528\u4e8e\u5168\u7403\u4e3b\u8981\u8bed\u8a00\u7684\u5927\u591a\u6570\u5b57\u7b26": 111, "\u7684\u5b57\u8282\u5bf9\u662f": 101, "\u7684\u60c5\u51b5": 71, "\u7684\u6548\u679c": 71, "\u7684\u6570\u636e": 101, "\u7684\u65b0token": 101, "\u7684\u6838\u5fc3\u673a\u5236": 17, "\u7684\u7b2c\u4e00\u5b57\u8282\u5168\u662f0": 111, "\u7684\u8bed\u8a00\u6a21\u578b\u4f3c\u7136\u503c\u7b49\u4ef7\u4e8e\u6240\u6709\u5b50\u8bcd\u6982\u7387\u7684\u4e58\u79ef": 110, "\u7684\u9891\u7387\u4e3a": 101, "\u7684\u9891\u7387\u51cf\u5c11": 101, "\u76ee\u5f55\u4e0b": 20, "\u76f4\u5230\u8fbe\u5230\u6211\u4eec\u9884\u5148\u8bbe\u7f6e\u7684token\u6570\u9650\u5236\u6216\u8fed\u4ee3\u9650\u5236": 101, "\u76f8\u6bd4": 71, "\u76f8\u90bb\u5b57\u8282\u5bf9": 101, "\u76f8\u90bb\u6570\u636e\u5355\u4f4d\u5728bpe\u4e2d\u770b\u4f5c\u76f8\u90bb\u5b57\u8282\u5bf9": 101, "\u7701\u8d44\u6e90": 71, "\u770b\u5230\u8fd9\u91cc": 110, "\u770b\u5b8c\u4e0b\u9762\u5b8c\u6574\u7684\u8fed\u4ee3\u8fc7\u7a0b": 101, "\u770b\u770b\u6211\u4eec\u6700\u7ec8\u7684token\u5217\u8868": 101, "\u771f\u5b9e\u7684": 73, "\u77e5\u9053\u4e86\u7f16\u7801\u7684\u539f\u7406\u540e\u81ea\u7136\u80fd\u60f3\u5230\u7684\u5c31\u662f\u6587\u672c\u7f16\u7801\u548c\u89e3\u7801\u6240\u4f7f\u7528\u7684\u5b57\u7b26\u96c6\u4e0d\u540c": 111, "\u786e\u4fdd\u6700\u5e38\u89c1\u7684\u8bcd\u5728token\u5217\u8868\u4e2d\u8868\u793a\u4e3a\u5355\u4e2atoken": 101, "\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230": 101, "\u7a76\u7adf\u8c03\u7528\u7684\u662f\u4ec0\u4e48\u51fd\u6570": 17, "\u7a7a\u95f4\u6781\u5927\u6d6a\u8d39": 111, "\u7b2cn": 111, "\u7b2c\u4e00\u4e2a\u5b57\u8282": 111, "\u7b2c\u4e00\u4e2a\u5b57\u8282\u7684\u7b2c\u4e8c\u4e2a0": 111, "\u7b2c\u4e8c\u9ad8\u9891\u7387\u6807\u8bb0\u662f": 101, "\u7b49\u8bcd\u4e4b\u95f4\u7684\u533a\u522b": 101, "\u7b97\u6cd5\u7684\u4e0b\u4e00\u6b65\u662f\u5bfb\u627e\u6700\u9891\u7e41\u7684\u5b57\u7b26\u5bf9": 101, "\u7b97\u6cd5\u7684\u4e3b\u8981\u76ee\u6807": 101, "\u7c7b\u4f3c\u5730": 17, "\u7f16\u7801\u4e3a": 101, "\u7f16\u7801\u672c\u8eab\u8ba1\u7b97\u590d\u6742\u5ea6\u6bd4\u8f83\u9ad8": 101, "\u7f16\u7801\u7c7b\u578b": 111, "\u8001\u89c4\u77e9": 101, "\u800cwordpiece\u9009\u62e9\u80fd\u591f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6982\u7387\u6700\u5927\u7684\u76f8\u90bb\u5b50\u8bcd\u52a0\u5165\u8bcd\u8868": 110, "\u800c\u4e0d\u662f": 101, "\u800c\u4e14\u8fc7\u5927\u7684token\u5217\u8868\u5341\u5206\u5f71\u54cd\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u5ea6": 101, "\u800c\u5728gb2312\u4e2d\u5bf9\u5e94\u7684\u5b57\u7b26\u96c6\u662fd2bb": 111, "\u800c\u662f\u5c06\u5b83\u4ee5utf": 111, "\u800c\u6c49\u5b57\u4e00\u4e8c\u4e09\u4e71\u7801\u4e86": 111, "\u800c\u7f55\u89c1\u7684\u8bcd\u88ab\u5206\u89e3\u4e3a\u4e24\u4e2a\u6216\u591a\u4e2asubword": 101, "\u80fd\u591f\u6e05\u695a\u5730\u7406\u89e3wordpiece\u5728\u5408\u5e76\u8fd9\u4e00\u6b65\u662f\u5982\u4f55\u4f5c\u51fa\u9009\u62e9\u7684": 110, "\u80fd\u591f\u7cbe\u7ec6\u5730\u533a\u5206\u76f8\u90bb\u4f4d\u7f6e": 103, "\u82e5\u4f7f\u7528\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f": 101, "\u82f1\u6587\u5b57\u6bcd": 111, "\u83b7\u53d6\u6a21\u578b\u7684": 17, "\u8461\u8404\u7259\u8bed\u7b49\u65e0\u6cd5\u7528127\u4e2a\u5b57\u7b26\u8868\u793a\u5b8c\u5168": 111, "\u8868\u793a\u5b50\u8bcd": 110, "\u8981\u89e3\u7801": 101, "\u89c4\u52191": 111, "\u89c4\u52192": 111, "\u89e3\u6790\u547d\u4ee4\u884c\u53c2\u6570": 17, "\u8ba1\u7b97": 103, "\u8ba1\u7b97\u673a\u5bf9\u6570\u636e\u7684\u8bfb\u53d6\u662f\u6309\u7167\u4e00\u4e2a\u5b57\u8282\u7684\u5927\u5c0f\u6765\u8bfb\u53d6\u8bc6\u522b\u7684": 111, "\u8ba1\u7b97\u673a\u6309\u7167\u5b57\u8282\u6765\u8bfb\u53d6\u6570\u636e\u65f6": 111, "\u8ba1\u7b97\u673a\u662f\u5982\u4f55\u77e5\u9053\u5f53\u524d\u5b57\u8282\u8868\u793a\u7684\u662f\u4ec0\u4e48\u610f\u601d\u5462": 111, "\u8ba9\u6211\u4eec\u5728\u6bcf\u4e2a\u5355\u8bcd\u7684\u672b\u5c3e\u6dfb\u52a0\u4e00\u4e2a\u7279\u6b8a\u7684\u7ed3\u675f\u6807\u8bb0": 101, "\u8ba9\u6211\u4eec\u73b0\u5728\u505c\u6b62\u8fed\u4ee3\u5e76": 101, "\u8ba9\u6211\u4eec\u73b0\u5728\u8003\u8651": 101, "\u8ba9\u6211\u4eec\u7528": 101, "\u8ba9\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u5b9e\u9645\u7684\u4f8b\u5b50\u6765\u4e86\u89e3\u4e00\u4e0b\u5b83\u7684nlp\u7248\u672c": 101, "\u8bcd": 101, "\u8bf4\u660e": 111, "\u8bf4\u660eunicode\u548cgbk\u90fd\u5411\u4e0b\u517c\u5bb9\u4e86ascii": 111, "\u8c03\u7528": 17, "\u8d8a\u8fd1": 103, "\u8d8a\u8fdc": 103, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f0100": 111, "\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u662f100": 111, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f19968": 111, "\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u662f65": 111, "\u8f93\u51fa\u6587\u4ef6": 17, "\u8fd8\u6709\u5176\u4ed6\u7f16\u7801\u65b9\u5f0f": 111, "\u8fd8\u6709\u7a7a\u683c32": 111, "\u8fd9\u4e00\u95ee\u9898": 111, "\u8fd9\u4e24\u4e2a\u8bcd\u90fd\u6709\u4e00\u4e2a\u5171\u540c\u7684": 101, "\u8fd9\u4e2a\u4e8c\u8fdb\u5236\u670915\u4f4d": 111, "\u8fd9\u4e2a\u8bcd\u7684token": 101, "\u8fd9\u4e5f\u662f": 101, "\u8fd9\u53ea\u662f\u82f1\u8bed\u7684\u7528\u6cd5": 101, "\u8fd9\u5b8c\u5168\u7b49\u540c\u4e8e127\u4f4d\u6700\u521d\u7684ascii\u7801": 111, "\u8fd9\u610f\u5473\u7740\u6211\u4eec\u7684\u9891\u7387\u8ba1\u6570\u5c06\u5728\u6bcf\u4e2a\u5408\u5e76\u6b65\u9aa4\u540e\u53d1\u751f\u53d8\u5316": 101, "\u8fd9\u662f\u66f4\u65b0\u540e\u7684\u8868\u683c": 101, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u67e5\u770b\u6bcf\u4e2a\u5b57\u7b26\u5e76\u627e\u5230\u9891\u7387\u6700\u9ad8\u7684\u5b57\u7b26\u914d\u5bf9": 101, "\u8fd9\u6709\u52a9\u4e8e\u7b97\u6cd5\u7406\u89e3": 101, "\u8fd9\u6837\u7684token\u5c06\u88ab\u4e0d\u540c\u5730\u5904\u7406": 101, "\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e4b\u4e3a": 103, "\u8fd9\u79cd\u7f16\u7801\u65b9\u5f0f\u5341\u5206\u7b26\u5408\u4eba\u7c7b\u8bed\u8a00\u4e60\u60ef": 101, "\u8fd9\u91cc": [17, 110], "\u8fd9\u91cc\u4fee\u6539\u4e3agbk": 111, "\u8fd9\u91cc\u7b80\u5355\u4ecb\u7ecd\u4e0b\u8fd9\u51e0\u79cd\u7f16\u7801\u65b9\u5f0f\u7684\u533a\u522b": 111, "\u8fdc\u7a0b\u8870\u51cf\u66f2\u7ebf\u5982\u4e0b": 103, "\u8fed\u4ee3": 101, "\u901a\u5e38\u6709\u51e0\u4e07\u5230\u51e0\u5341\u4e07\u91cf\u7ea7\u7684\u5355\u8bcd\u6570": 101, "\u901a\u8fc7\u5f62\u5f0f\u5316\u65b9\u6cd5": 110, "\u90a3\u4e48\u4eba\u4eec\u80fd\u8bc6\u522b\u7684\u6587\u5b57\u548c\u8ba1\u7b97\u673a\u4e2d\u7684\u4e8c\u8fdb\u5236\u5fc5\u7136\u5b58\u5728\u4e00\u79cd\u6620\u5c04\u5173\u7cfb": 111, "\u90a3\u4e48\u9762\u5bf9\u5168\u4e16\u754c\u8fd9\u4e48\u591a\u8bed\u8a00": 111, "\u90a3\u5982\u4f55\u628a\u538b\u7f29\u7684\u7f16\u7801\u590d\u539f\u5462": 101, "\u90a3\u5c31\u662f\u672c\u6587\u5373\u5c06\u4ecb\u7ecd\u7684byte": 101, "\u90a3\u6837\u7684\u8ba1\u7b97\u91cf\u662f\u975e\u5e38\u6050\u6016\u7684": 101, "\u90a3\u82f1\u6587\u5b57\u7b26": 111, "\u90e8\u5206\u9891\u7387\u4f4e": 103, "\u90e8\u5206\u9891\u7387\u9ad8": 103, "\u90fd\u4e00\u6837": 111, "\u91cc\u548c\u653e\u5728": 71, "\u91cc\u7684\u533a\u522b": 71, "\u95f4\u76f8\u4e92\u9694\u5f00": 71, "\u963f\u62c9\u4f2f\u6570\u5b570\u5bf9\u5e94\u7684ascii\u7801\u662f48": 111, "\u963f\u62c9\u4f2f\u6570\u5b57\u548c\u82f1\u6587\u5b57\u6bcd": 111, "\u968f\u673a\u6027\u5f88\u5927": 103, "\u968f\u7740\u8ba1\u7b97\u673a\u5728\u5168\u7403\u7684\u53d1\u5c55\u548c\u666e\u53ca": 111, "\u9700": 17, "\u9700\u52a0\u4e0a": 17, "\u9700\u8981\u4ece": 20, "\u9700\u8981\u81f3\u5c112\u4e2a\u5b57\u8282\u8868\u793a": 111, "\u975e\u5e38\u91cd\u8981": 101, "\u9996\u5148\u6765\u660e\u786e\u4e00\u4e0b\u57fa\u7840\u6982\u5ff5": 101, "\u9996\u5148\u770b\u4e0bwiki\u5bf9\u5b83\u7684\u5b9a\u4e49": 111, "\u9ad8\u4f4d\u4ee5": 111, "\u9ad8\u4f4d\u524dn\u4f4d\u4e3a": 111, "\u9ad8\u7684": 71, "\u9ad8\u7ef4": 103, "\u9ad8\u9891\u4fe1\u606f\u7684\u635f\u5931": 103, "\u9ad8\u9891\u7ef4\u5ea6\u5c11\u4f4e\u9891\u7ef4\u5ea6\u591a": 103, "\ud835\udc41": 70}, "titles": ["Agent", "AGENTLESS", "API-Bank", "CodeAct", "SWE-agent", "Base", "Attention Is All You Need", "GPT", "GPT2", "GPT3", "InstructGPT", "Benchmarks", "Aider Polyglot", "Alignment Benchmarks", "BigCodeBench", "Code Alpaca", "CRUXEval", "EvalPlus", "General Benchmarks", "HumanEval", "LiveCodeBench", "Magicoder", "Math &amp; Science Benchmarks", "MBPP", "RewardBench", "SELF-INSTRUCT", "SWE-bench", "TACO", "WizardCoder", "Contents", "Contents", "Data", "AlphaCode", "APPS", "Code Alpaca", "Magicoder", "OpenCoder", "SELF-INSTRUCT", "TACO", "UNICODER", "WizardCoder", "Introduction", "Markdown Files", "Notebooks with MyST Markdown", "GOLD", "Evaluation of LLMs Should Not Ignore Non-Determinism", "Scaling Laws for Neural Language Models", "Weak to Strong Generalization", "Models", "AlphaCode", "AlphaCode 2", "AlphaCodium", "Code Llama", "DeepSeek-Coder-V2", "DeepSeek-V2", "DeepSeek V3", "Llama", "Llama 2", "Llama 3", "Llama3", "Llama 3 Source Code", "Qwen 2.5", "Qwen2.5-Coder", "Qwen3", "Preference Optimization", "ArmoRM-MoE", "DAPO", "DeepSeek-GRM", "DPO", "DPOP", "Efficient Exploration for LLMs", "Group Relative Policy Optimization", "Instruct GPT", "Aligning Language Models with Judgments", "OpenRLHF", "PPO", "REINFORCE++", "Constitutional AI: Harmlessness from AI Feedback", "RLAIF vs. RLHF", "RLCD", "RS-DPO", "RSO", "Secrets of RLHF in Large Language Models: Reward Modeling", "Self-Rewarding Language Models", "Self-Taught Evaluators", "West-of-N", "Reasoning", "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models", "DeepCoder", "DeepSeek-R1", "Logic-RL", "s1: Simple test-time scaling", "Training Language Models to Self-Correct via Reinforcement Learning", "Let\u2019s Verify Step by Step", "References", "SFT", "LIMA: Less Is More for Alignment", "RETHINKING DATA SELECTION AT SCALE: RANDOM SELECTION IS ALMOST ALL YOU NEED", "RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold", "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models", "Techniques", "Byte Pair Encoding (BPE)", "DeepSeekMoE", "Extending context window of LLMs", "Extending context window of large language models via position interpolation", "Multi-Head Latent Attention", "Normalization", "RoPE", "Rotary Positional Embeddings (RoPE)", "SwiGLU", "WordPiece, ULM and SentencePiece", "ASCII,UNICODE,UTF8", "Llama Factory", "LORA", "OpenRLHF"], "titleterms": {"": 93, "1": 65, "16": 111, "2": [50, 52, 57, 61, 65], "2d": [107, 108], "3": [58, 60], "32\u7b49": 111, "5": [61, 62], "500": 22, "8": 111, "A": 62, "AT": 97, "Not": 45, "The": [4, 44, 51, 65, 76, 99], "abil": [83, 99], "ablat": [96, 105], "absolut": 108, "accuraci": 99, "aci": 4, "activ": [59, 60, 70, 93], "adapt": 82, "add": 43, "addit": 51, "advantag": 76, "agent": [0, 3, 4], "agentless": 1, "aggreg": 65, "aha": 89, "ai": [77, 78], "aider": 12, "algorithm": [44, 70, 76, 81, 83, 89], "align": [13, 45, 53, 54, 73, 83, 96], "all": [6, 89, 97], "almost": 97, "alpaca": [15, 34], "alphacod": [32, 49, 50], "alphacodium": 51, "an": [4, 43, 70], "analyz": 82, "annot": 84, "api": 2, "app": 33, "appendix": 68, "approach": [1, 8, 9, 26, 49, 56, 67, 81, 108], "architectur": [6, 9, 54, 55, 56, 61, 70], "arena": 13, "armorm": 65, "ascii": 111, "assess": 70, "attent": [6, 59, 60, 105], "augment": 99, "automat": 14, "averag": 58, "awar": 103, "background": [76, 103, 104, 108], "balanc": 102, "bank": 2, "base": [5, 26, 61, 62, 66, 67, 89, 93], "basic": [46, 55], "batch": [76, 106], "batchnorm": 59, "bench": 26, "benchmark": [11, 13, 14, 18, 22, 26, 67], "benefit": 3, "better": [3, 82], "between": 105, "bigcodebench": 14, "boost": 67, "bpe": 101, "byte": 101, "cach": 105, "capabl": 58, "case": [14, 107, 108], "cell": 43, "chain": 87, "chart": 46, "chat": 58, "chatformat": 59, "citat": 42, "classif": [25, 37], "clip": [66, 76], "cluster": [49, 50], "code": [14, 15, 17, 28, 34, 40, 51, 52, 58, 60], "codeact": 3, "codecontest": 32, "codellama": 26, "coder": [53, 62], "cold": [67, 89], "collaps": 92, "collect": [53, 57, 93], "commun": 102, "comparison": [67, 105], "composit": [36, 62], "compress": 105, "comput": [4, 46], "concept": 51, "consider": 102, "constitut": 77, "construct": [14, 26, 54, 55, 84], "content": [29, 30], "context": [52, 55, 103, 104], "contextwindow": 103, "contrast": 73, "control": 58, "correct": [17, 19, 92], "count": [46, 99], "creat": [43, 91], "creation": 83, "critiqu": [67, 77], "cruxev": 16, "curat": [14, 91], "dapo": 66, "data": [14, 15, 25, 31, 34, 36, 37, 46, 53, 54, 55, 56, 57, 58, 62, 82, 91, 93, 96, 97, 98, 99], "dataset": [8, 9, 10, 32, 46, 49, 52, 66, 72], "decod": [6, 7], "decontamin": [36, 62], "decoupl": 105, "deepcod": 88, "deepseek": [53, 54, 55, 67, 89], "deepseekmo": 102, "deriv": 68, "design": [2, 4, 51], "detail": [10, 21, 35, 36, 66, 74], "determin": 45, "devic": 102, "dialog": 58, "differ": [67, 82], "direct": [42, 58, 68, 104], "discuss": 54, "distanc": 103, "diverg": 66, "divers": [82, 96], "done": 3, "dot": 6, "dpo": [68, 69, 80], "dpop": 69, "drop": 102, "dynam": [66, 103], "effect": 45, "effici": [70, 98, 103], "eight": 98, "elicit": 87, "embed": [6, 46, 103, 104, 105, 108], "empir": [46, 70], "encod": [6, 101], "engin": 4, "enhanc": 76, "enn": 70, "epistem": 70, "estim": 70, "evalplu": 17, "evalu": [2, 9, 14, 17, 20, 21, 28, 35, 40, 45, 49, 50, 54, 55, 61, 62, 78, 84, 96], "evol": [28, 40], "evolut": 89, "exampl": 43, "exist": 3, "experi": [8, 66, 83, 104], "experiment": [10, 26, 45, 53, 70, 76, 83], "expert": [65, 102], "explor": 70, "extend": [103, 104], "extens": [55, 103], "extrapol": 104, "factor": [45, 99], "factori": 112, "failur": 69, "featur": 26, "feed": 6, "feedback": [77, 78], "feedforward": [59, 60], "fewer": 3, "ffn": 109, "file": 42, "filter": [25, 37, 49, 50], "fine": [7, 26, 32, 49, 50, 52, 53, 54, 55, 57, 61, 67, 72, 84, 89, 102], "finetun": [25, 37, 58], "flip": 82, "flow": 51, "fold": 98, "follow": [25, 37, 83], "form": [107, 108], "format": [26, 58], "formul": [107, 108], "forward": 6, "framework": [3, 7, 44], "frequenc": 103, "from": [3, 21, 35, 44, 67, 73, 77, 78], "full": 45, "fullest": 82, "function": [19, 59, 60], "gate": 109, "gb2312": 111, "gbk\u7b49\u5176\u4ed6\u7f16\u7801": 111, "gener": [14, 18, 25, 37, 45, 47, 59, 67, 93, 107, 108], "get": 3, "glu": 109, "gold": 44, "gpqa": 22, "gpt": [7, 72], "gpt2": 8, "gpt3": 9, "gqa": 105, "gradient": [44, 66, 68], "grain": 102, "grm": 67, "group": 71, "grpo": 71, "gsm8k": 22, "hard": 13, "harmless": 77, "head": [6, 105], "high": [10, 103], "higher": 66, "how": [45, 82], "human": [14, 57, 82, 96], "humanev": [17, 19], "hyper": 54, "i": [3, 6, 42, 45, 92, 96, 97], "identif": [25, 37], "ifev": 13, "ignor": 45, "ii": 92, "impact": 82, "implement": [21, 35, 74, 104], "incorpor": 73, "incorrect": 98, "infer": 67, "infil": 52, "infinit": 46, "influenc": 45, "inform": 103, "initi": [83, 84, 92], "input": [7, 8, 26], "insight": 51, "instal": 20, "instanc": [25, 37], "instruct": [14, 21, 25, 28, 35, 36, 37, 39, 40, 52, 61, 62, 72, 83, 84], "instructgpt": 10, "integr": 76, "interact": 3, "interfac": 4, "interpol": [103, 104], "interpret": 65, "introduct": [21, 35, 41, 47, 52, 56, 73, 79, 104], "isol": 102, "iter": [57, 58, 71, 84], "its": 82, "joint": 105, "judgment": [73, 84], "kei": 105, "kl": [66, 76], "kv": 105, "label": [78, 82], "languag": [46, 58, 73, 82, 83, 87, 92, 99, 103, 104, 110], "larg": [49, 82, 87, 93, 99, 103, 104], "latent": 105, "law": 46, "layer": 106, "layernorm": 59, "learn": [42, 53, 54, 55, 61, 70, 72, 73, 77, 78, 89, 92, 93, 99], "less": 96, "let": 93, "level": [10, 66, 76, 102], "leverag": 82, "lima": 96, "limit": 46, "linear": 109, "lite": 26, "livecodebench": 20, "llama": [26, 52, 56, 57, 58, 60, 104, 112], "llama3": 59, "llm": [3, 45, 70, 78, 98, 99, 103], "lm": [25, 37], "load": 102, "local": 103, "logic": 90, "long": [52, 55], "lora": 113, "loss": [66, 68, 99, 102, 103], "low": 105, "magicod": [21, 35], "main": [66, 77], "make": 3, "margin": 82, "markdown": [42, 43], "math": [22, 98, 99], "mathemat": 99, "mbpp": [17, 23], "measur": 82, "mechan": 105, "metadata": 43, "method": [10, 77, 84, 93], "methodologi": [10, 47, 72, 78], "mha": 105, "mini": 76, "mixtur": [62, 65, 102], "mla": 105, "mle": 44, "mmlu": 18, "mode": 69, "model": [6, 8, 9, 10, 46, 48, 50, 57, 58, 59, 60, 61, 62, 65, 66, 67, 70, 72, 73, 82, 83, 84, 85, 87, 89, 92, 93, 99, 103, 104, 110], "moe": 65, "moment": 89, "more": [3, 42, 96], "mqa": 105, "multi": [3, 6, 55, 65, 92, 105], "myst": [42, 43], "n": [46, 85], "need": [6, 65, 97], "network": [6, 70], "neural": [46, 70], "nl": 14, "nlp\u5b9e\u4f8b": 101, "non": [45, 46], "normal": [59, 76, 106], "notebook": 43, "ntk": 103, "object": 65, "off": 44, "offlin": 61, "onli": 7, "onlin": 61, "ood": 93, "open": [21, 35], "opencod": 36, "openrlhf": [74, 114], "optim": [56, 58, 64, 68, 71], "orient": [14, 51, 89], "orm": 93, "oss": [21, 35], "outcom": [71, 93], "overal": [50, 83], "overfit": 46, "overlong": 66, "overview": 51, "packag": 3, "pair": [84, 101], "paramet": [46, 54], "part": 103, "passiv": 70, "pattern": 45, "penalti": 76, "perform": [46, 82, 89], "pi_": 68, "pipelin": 70, "point": 70, "polici": [44, 50, 62, 66, 71], "polyglot": 12, "posit": [6, 103, 104, 105, 108], "post": [36, 55, 58, 61, 62], "postprocess": [25, 37], "potenti": [45, 82], "power": 46, "ppo": [71, 74, 75, 76], "pre": [7, 54, 55, 56, 58, 61, 62, 99], "predict": 55, "prefer": [57, 58, 64, 68, 78, 82, 85], "preliminari": [66, 68, 81, 82, 92, 102, 105, 108], "pretrain": [36, 57], "prevent": 92, "principl": [2, 67], "prm": 93, "pro": 18, "problem": [73, 92], "process": [58, 71, 89, 93], "product": 6, "program": 14, "promis": 3, "prompt": [28, 40, 78, 87], "properti": 108, "propos": [51, 108], "qualiti": [58, 67, 96], "quantiti": 96, "queri": 105, "quick": 17, "quickli": 43, "qwen": 61, "qwen2": 62, "qwen3": 63, "r": [68, 80], "r1": 89, "random": 97, "rank": 105, "reason": [86, 87, 89, 91, 98, 99], "recip": 62, "redux": 18, "refactor": 14, "refer": 94, "reinforc": [53, 54, 55, 61, 72, 76, 77, 78, 89, 92], "reject": [67, 81, 89], "rel": [71, 103], "relat": 85, "relationship": 99, "remov": 66, "represent": 8, "respons": 84, "result": [4, 10, 26, 45, 46, 53, 54, 55, 58, 66, 67, 70, 77, 78, 83, 91], "rethink": 97, "retriev": 26, "review": 71, "revis": 77, "reward": [44, 57, 58, 65, 66, 67, 70, 72, 76, 82, 83, 89, 92, 93], "rewardbench": 24, "rl": [44, 67, 71, 72, 90, 92, 98], "rlaif": 78, "rlcd": 79, "rlhf": [57, 78, 82], "rm": [67, 72, 82], "rmsnorm": [59, 60, 106], "role": 42, "rope": [59, 60, 103, 104, 107, 108], "rotari": [103, 104, 105, 108], "round": 58, "rso": 81, "rule": [66, 67], "s1": 91, "s1k": 91, "sampl": [42, 49, 50, 66, 81, 89], "scale": [6, 45, 46, 49, 67, 91, 93, 97, 98, 99, 103], "scenario": 89, "scienc": 22, "score": [50, 92], "secret": 82, "segment": 102, "select": [84, 97], "self": [25, 37, 67, 83, 84, 85, 89, 92], "semi": 14, "sentencepiec": 110, "set": 73, "setup": [26, 76, 83, 92], "sft": [57, 58, 72, 95, 112, 114], "shape": [66, 92], "share": 102, "should": 45, "show": 3, "simpl": 91, "size": 46, "small": 93, "smooth": 82, "softmax": 6, "softwar": [3, 4], "sourc": [21, 35, 60], "spct": 67, "special": 52, "specif": 7, "stack": 6, "stage": [36, 51, 65, 92], "standard": 105, "stanford": [15, 34], "start": [17, 67, 89], "statist": [14, 81], "step": 93, "strategi": 102, "strength": 82, "strong": [3, 47], "summar": 8, "supervis": [7, 53, 54, 55, 58, 61, 71, 72, 77, 89, 93, 99], "surfac": 45, "swe": [4, 26], "swiglu": [59, 60, 109], "swish": 109, "synthesi": 14, "synthet": [93, 98], "system": [2, 50], "taco": [27, 38], "takeawai": [53, 54, 55, 58, 61, 62, 82, 93, 107], "task": [7, 25, 37], "taught": 84, "techniqu": [78, 100], "temperatur": 45, "templat": 89, "test": [14, 91], "thought": 87, "tiktoken": 59, "time": [46, 67, 91], "token": [55, 59, 61, 66, 76, 102], "tool": 3, "train": [7, 8, 9, 28, 36, 40, 46, 54, 55, 56, 58, 61, 62, 66, 70, 83, 84, 85, 89, 92, 96, 99], "transform": [7, 46, 59, 60, 102], "tune": [7, 21, 26, 32, 35, 36, 49, 50, 52, 53, 54, 55, 57, 61, 67, 72, 84, 89], "turn": [3, 92], "two": 36, "ulm": 110, "understand": 67, "unicod": [39, 111], "unigram": 110, "unit": 109, "unpin": 67, "unsupervis": 7, "updat": 76, "us": 3, "utf": 111, "utf8": 111, "v": [78, 93, 99], "v2": [53, 54], "v3": 55, "valu": 105, "variant": 109, "variou": 45, "verifi": 93, "via": [92, 104], "weak": 47, "west": 85, "what": [3, 42, 45], "why": [7, 105, 106], "window": [103, 104], "wise": 6, "wizardcod": [28, 40], "wizardlm": [28, 40], "wordpiec": 110, "work": 85, "yaml": 43, "yarn": 103, "you": [6, 97], "zero": 89, "\u4e3a\u4ec0\u4e48\u4f1a\u4e71\u7801": 111, "\u521d\u8bc6bpe": 101, "\u603b\u7ed3": 111, "\u662f\u4e0d\u662f\u8d2a\u5fc3\u7b97\u6cd5": 101, "\u672c\u5730": [17, 20], "\u7684\u8fdc\u7a0b\u8870\u51cf": 103, "\u7f16\u7801\u548c\u89e3\u7801": 101, "\u9ad8\u9891\u5916\u63a8\u4f4e\u9891\u5185\u63d2": 103}})